import torch
import numpy as np
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
import time
import pandas as pd


def create_list_embeddings(model, dataloader, device, distributed=False):

    # Empty lists.
    embeddings = []
    labels = []

    # Disable gradients for faster calculations.
    # Put the model in evaluation mode.
    model.eval()
    with torch.no_grad():
        # for i, (x, y, fnames) in enumerate(dataloader_val):
        # Now taking only the first transformed batch.
        # for i, ((x, _), y, fnames) in enumerate(dataloader['val']):
        for x, y in dataloader['val']:

            # Move the images to the GPU.
            x = x.to(device)
            y = y.to(device)

            # Embed the images with the pre-trained backbone.
            if distributed:
                emb = model.module.backbone(x).flatten(start_dim=1)
            else:
                emb = model.backbone(x).flatten(start_dim=1)

            # Store the embeddings and filenames in lists.
            embeddings.append(emb)
            labels.append(y)

    # Concatenate the embeddings and convert to numpy.
    embeddings = torch.cat(embeddings, dim=0).to('cpu').numpy()
    labels = torch.cat(labels, dim=0).to('cpu').numpy()

    # Show shapes.
    print(np.shape(embeddings))
    print(np.shape(labels))

    return embeddings, labels


def pca_computation(embeddings, labels, seed):
    """
    Takes the "embeddings" and "labels" and
    computes and plots the PCA method.

    Args:
        embeddings: generated by the model.
        labels: labels of the samples.
        seed: seed for reproducibility.

    Returns:
        df: dataframe with the results.
    """

    # PCA computation.
    time_start = time.time()
    pca = PCA(n_components=3,
              random_state=seed)
    pca_results = pca.fit_transform(embeddings)
    print(f'\nPCA completed! Time elapsed (s): {time.time()-time_start}')
    print(f'Explained variation per principal component: '
          f'{pca.explained_variance_ratio_}\n')

    # Create dataframe with the resulting data.
    df = pd.DataFrame()
    df['pca_x'] = pca_results[:, 0]
    df['pca_y'] = pca_results[:, 1]
    df['pca_z'] = pca_results[:, 2]
    df['labels'] = labels

    return df


def tsne_computation(embeddings, labels, seed, n_components):
    """
    Takes the "embeddings" and "labels" and
    computes and plots the t-SNE method.

    Args:
        embeddings: generated by the model.
        labels: labels of the samples.
        seed: seed for reproducibility.
        n_components: number of components to compute.

    Returns:
        df: dataframe with the results.
    """

    # t-SNE computation.
    time_start = time.time()
    tsne = TSNE(
        n_components=n_components,
        perplexity=30,
        learning_rate='auto',
        n_iter=1000,
        init='random',  # PCA can be used here.
        verbose=1,
        random_state=seed
    )
    tsne_results = tsne.fit_transform(embeddings)
    print(f'\nt-SNE completed! Time elapsed (s): {time.time()-time_start}')

    # Create dataframe with the resulting data.
    df = pd.DataFrame()
    df['tsne_x'] = tsne_results[:, 0]
    df['tsne_y'] = tsne_results[:, 1]
    if n_components == 3:
        df['tsne_z'] = tsne_results[:, 2]
    df['labels'] = labels

    return df
