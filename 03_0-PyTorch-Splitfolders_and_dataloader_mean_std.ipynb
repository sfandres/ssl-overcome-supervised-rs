{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdfe9a2-c9bd-4888-8328-957001cd2d3d",
   "metadata": {},
   "source": [
    "**DATASET HANDLING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190f7cd-02a9-4b8e-8b35-f27fffee6fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a0ac0-39cf-4d54-8a6e-93215e337037",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4fb5df-2719-4007-b5fa-1ce43a06d73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility.\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980098f6-8d45-4873-bd68-fc9c1dee3ed3",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca21427c-8634-4b89-ac05-b0f02d0476c1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c39d1a-c859-45ec-bb95-d1aaaf526436",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Split the dataset folder"
   ]
  },
  {
   "cell_type": "raw",
   "id": "becd2556-9aa8-463c-a46f-d3f19f3737e2",
   "metadata": {},
   "source": [
    "import splitfolders\n",
    "\n",
    "data_dir_initial = 'datasets/Sentinel2GlobalLULC_full_raw/Sentinel2LULC_JPEG/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebbf3a5-2956-4b33-9c19-aebcd44d59bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ratio (imbalanced)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "93eb1116-4258-4a9d-89ff-a0d65a2ff82f",
   "metadata": {},
   "source": [
    "# Split with a ratio.\n",
    "# To only split into training and validation set,\n",
    "# set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "splitfolders.ratio(data_dir_initial,\n",
    "                   output=\"datasets/Sentinel2GlobalLULC_full_ratio_seed=\"\n",
    "                   + str(SEED),\n",
    "                   seed=SEED,\n",
    "                   ratio=(.7, .1, .2),\n",
    "                   group_prefix=None,\n",
    "                   move=False)  # Default values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af15d6e2-2ff8-4fd2-8c84-3d78150200fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Ratio to create reduced sample"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7e7bb76-f6d6-4d33-a552-21b60d03bc75",
   "metadata": {},
   "source": [
    "# Split with a ratio.\n",
    "# To only split into training and validation set,\n",
    "# set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "splitfolders.ratio(data_dir_initial,\n",
    "                   output=\"datasets/Sentinel2GlobalLULC_reduced_ratio_seed=\"\n",
    "                   + str(SEED),\n",
    "                   seed=SEED,\n",
    "                   ratio=(.01, .01, .98),\n",
    "                   group_prefix=None,\n",
    "                   move=False)  # Default values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b141bd-c8f8-4939-a7c4-08638a19a307",
   "metadata": {},
   "source": [
    "## Fixed (balanced)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e803ee7a-14e8-40e3-8a13-f2b2192361bc",
   "metadata": {},
   "source": [
    "# Split val/test with a fixed number of items, e.g. `(100, 100)`, for each set.\n",
    "# To only split into train-val set, use a single number to `fixed`, i.e., `10`.\n",
    "# Set 3 values, e.g. `(300, 100, 100)`, to limit the number of training values.\n",
    "splitfolders.fixed(data_dir_initial,\n",
    "                   output=\"datasets/Sentinel2GlobalLULC_full_balanced_seed=\"\n",
    "                   + str(SEED),\n",
    "                   seed=SEED,\n",
    "                   fixed=(250, 100),\n",
    "                   oversample=True,\n",
    "                   group_prefix=None,\n",
    "                   move=False)  # Default values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a70fbbf-0ee4-4db3-87e8-d99c4419809f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09562a1-4066-42e1-a525-90b2ecbf3c91",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596485c2-1e41-4924-aeae-2fdab33abd12",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compute the mean and std of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6442ba-d2a0-466a-b1c8-ae2d2648a92e",
   "metadata": {},
   "source": [
    "## Libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8098771-cad2-4577-9b54-3ed8458ba6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eff356-1df3-4c32-9b2a-ad2ddf6e76dc",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d08b78-c3ed-4699-b32c-01b58178fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed torch and numpy.\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Enable CUDNN deterministic mode.\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Issues a warning if it is not met.\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f7e416-c3ba-400b-9668-3954b74ebd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dataloaders.\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1220dd-fc67-4524-819f-5c1adbc66672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable deterministic behavior using external GPU.\n",
    "# %env CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
    "# %env CUBLAS_WORKSPACE_CONFIG=:16:8\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':16:8'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b5e75-6a50-483a-a4a7-4b285a13d274",
   "metadata": {},
   "source": [
    "## Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43716c06-f933-4cdc-99f4-15d9c793481a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import listdir_fullpath\n",
    "from utils import get_mean_std_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d1a3a0-6b70-4b81-9af3-cf6746b534b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(listdir_fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8cd902-27f0-4646-b463-35e6a0664f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of trained models.\n",
    "datasets_dir = 'datasets/'\n",
    "\n",
    "# Get the subsets with full path.\n",
    "data_dirs = listdir_fullpath(datasets_dir)\n",
    "print(data_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72026024-e0bf-4cb6-8c60-27e9b2a0ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(get_mean_std_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c55be-f02e-46d1-859c-b2379febfa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization.\n",
    "splits = ['train', 'val', 'test']\n",
    "\n",
    "# Loop over the datasets (except raw and clothing).\n",
    "for data_dir in data_dirs[2:]:\n",
    "\n",
    "    # Loading the datasets into a dic.\n",
    "    datasets = {x: torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x),\n",
    "        transform=torchvision.transforms.ToTensor()\n",
    "    ) for x in splits}\n",
    "\n",
    "    # Creating the dataloaders into a dic.\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(\n",
    "        datasets[x],\n",
    "        batch_size=128,\n",
    "        worker_init_fn=seed_worker,\n",
    "        generator=g\n",
    "    ) for x in splits}\n",
    "\n",
    "    # Loop over the train, val, and test datasets.\n",
    "    for x in splits:\n",
    "        print(f'{data_dir}/{x}/')\n",
    "        mean, std = get_mean_std_dataloader(dataloaders[x])\n",
    "        print(mean)\n",
    "        print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd708eb5-e349-4baa-895d-f1b542510f56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lulc-venv",
   "language": "python",
   "name": "lulc-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
