{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdfe9a2-c9bd-4888-8328-957001cd2d3d",
   "metadata": {},
   "source": [
    "**DATASET HANDLING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190f7cd-02a9-4b8e-8b35-f27fffee6fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a0ac0-39cf-4d54-8a6e-93215e337037",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff0cfd2-d886-4359-bc50-79d5e25297d1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de6edb0-d5dc-4168-a31a-bdb56be4ab5e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25072781-af02-4f95-b232-2f83ae72b0a5",
   "metadata": {},
   "source": [
    "# Dataset stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb9dbab-94e5-4549-87ab-6725a3b8d1fe",
   "metadata": {},
   "source": [
    "I use this code to check the resulting number of samples per class after splitting the target dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d08339-c54e-4622-8920-635314295344",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4379417e-0911-4747-b3e9-6bb897531bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d88e1-ae09-499d-a20b-1724268cc26b",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de7c911-200d-4f8c-b62f-65255f04c53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target dataset.\n",
    "initial_dir_dataset = ('datasets/0_Raw/'\n",
    "                       'Sentinel2GlobalLULC_full_raw/'\n",
    "                       'Sentinel2LULC_JPEG/')\n",
    "\n",
    "# Loading the three datasets.\n",
    "data = torchvision.datasets.ImageFolder(initial_dir_dataset)\n",
    "\n",
    "# Get classes and number of samples per class.\n",
    "class_names = data.classes\n",
    "samples_per_class = np.unique(data.targets, return_counts=True)[1]\n",
    "\n",
    "# Building the dataframe.\n",
    "df = pd.DataFrame(class_names, columns=['Class'])\n",
    "df.set_index('Class', drop=True, inplace=True)\n",
    "df['100%_samples'] = samples_per_class\n",
    "df['E1-T-95%'] = (df['100%_samples']*0.95).astype(int)\n",
    "df['E1-V-1.75%'] = (df['100%_samples']*0.175).astype(int)\n",
    "df['E1-T-3.25%'] = (df['100%_samples']*0.325).astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980098f6-8d45-4873-bd68-fc9c1dee3ed3",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca21427c-8634-4b89-ac05-b0f02d0476c1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596485c2-1e41-4924-aeae-2fdab33abd12",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compute the mean and std of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6442ba-d2a0-466a-b1c8-ae2d2648a92e",
   "metadata": {},
   "source": [
    "## Libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8098771-cad2-4577-9b54-3ed8458ba6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d1a3a0-6b70-4b81-9af3-cf6746b534b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(listdir_fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72026024-e0bf-4cb6-8c60-27e9b2a0ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(get_mean_std_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eff356-1df3-4c32-9b2a-ad2ddf6e76dc",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2306440a-afe8-43ee-8e65-a9aeab418b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = utils.Experiment()\n",
    "exp.reproducibility()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b5e75-6a50-483a-a4a7-4b285a13d274",
   "metadata": {},
   "source": [
    "## Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8cd902-27f0-4646-b463-35e6a0664f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of trained models.\n",
    "datasets_dir = 'datasets/'\n",
    "\n",
    "# Get the subsets with full path.\n",
    "data_dirs = utils.listdir_fullpath(datasets_dir)\n",
    "\n",
    "# Leave out unwanted subsets.\n",
    "data_dirs = data_dirs[2:]\n",
    "for dirs in data_dirs:\n",
    "    print(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c55be-f02e-46d1-859c-b2379febfa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization.\n",
    "splits = ['train', 'val', 'test']\n",
    "filename = 'dataset_mean_std.txt'\n",
    "\n",
    "# Loop over the datasets (except raw and clothing).\n",
    "for data_dir in data_dirs:\n",
    "\n",
    "    # Create path to the txt file.\n",
    "    filepath = os.path.join(data_dir, filename)\n",
    "\n",
    "    # Removing the old txt file if exists.\n",
    "    if os.path.exists(filepath):\n",
    "        os.remove(filepath)\n",
    "        print('Old txt file removed and new one created.')\n",
    "    else:\n",
    "        print('New txt file created.')\n",
    "\n",
    "    # Creating/opening the file.\n",
    "    f = open(filepath, 'w')\n",
    "\n",
    "    # Loading the datasets into a dic.\n",
    "    datasets = {x: torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x),\n",
    "        transform=torchvision.transforms.ToTensor()\n",
    "    ) for x in splits}\n",
    "\n",
    "    # Creating the dataloaders into a dic.\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(\n",
    "        datasets[x],\n",
    "        batch_size=128,\n",
    "        worker_init_fn=exp.seed_worker,\n",
    "        generator=exp.g\n",
    "    ) for x in splits}\n",
    "\n",
    "    # Loop over the train, val, and test datasets.\n",
    "    for x in splits:\n",
    "\n",
    "        # Computation.\n",
    "        print(f'{data_dir}/{x}/')\n",
    "        print(f'Samples to be processed: '\n",
    "              f'{len(dataloaders[x].dataset)}')\n",
    "        mean, std = utils.get_mean_std_dataloader(dataloaders[x])\n",
    "        print(mean)\n",
    "        print(std)\n",
    "\n",
    "        # Write to file.\n",
    "        f.write(f'{x}\\n')\n",
    "        f.write(f'{mean}\\n')\n",
    "        f.write(f'{std}\\n')\n",
    "\n",
    "    # Close file and print a space.\n",
    "    f.close()\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfcdc82-813f-49ba-a51d-fe045710e03c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1687776-490d-4d67-a323-a63276e70739",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lulc-venv",
   "language": "python",
   "name": "lulc-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
