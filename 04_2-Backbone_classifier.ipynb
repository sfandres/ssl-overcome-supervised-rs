{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "293858ae-5611-498e-afd6-acddd993850f",
   "metadata": {},
   "source": [
    "**LOADING THE PRETRAINED SSL MODEL AND TRAINING A CLASSIFIER ON TOP OF IT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d101e8-426c-408d-a5fc-345d08a4434d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6141892-5b73-4968-98e2-61837b6a244f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b574714-7ea8-4883-961b-1d3ce2357de3",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a1262a1-84e2-4377-944b-46eb82304281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfandres/Documents/Git/lulc/lulc-venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchinfo import summary\n",
    "\n",
    "import lightly\n",
    "from lightly.models.modules.heads import SimSiamPredictionHead,SimSiamProjectionHead\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aec6f345-15d8-4fd2-8f11-a3149e9d7ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamenters.\n",
    "input_size = 224  # input_size = 256\n",
    "batch_size = 32   # batch_size = 128\n",
    "num_workers = 8\n",
    "epochs = 5\n",
    "\n",
    "# Seed torch and numpy.\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26be3b23-92b4-44b8-b22c-50d1174ec17e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d7d453-00f5-4527-9ae2-15a40a90611a",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c9124d-5700-4c98-9043-a334f2021684",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb521dda-f0fe-4df0-8ba8-51d7956e5c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'datasets/Sentinel2GlobalLULC_ratio'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bad482-37e6-476e-aa61-df9d4b9a1b3c",
   "metadata": {},
   "source": [
    "## Custom tranforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8f76676-60af-41f1-b7a2-98f2a172ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the augmentations for self-supervised learning.\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((input_size, input_size)),\n",
    "    torchvision.transforms.RandomResizedCrop(size=input_size, scale=(0.2, 1.0)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "    torchvision.transforms.GaussianBlur(21),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((input_size, input_size)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf02f61-451a-4423-b6d9-12b95d431f8a",
   "metadata": {},
   "source": [
    "## ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c81591-9d0e-44ec-b34d-f037711f9c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading both datasets.\n",
    "train_data = torchvision.datasets.ImageFolder(data_dir + '/train/')\n",
    "\n",
    "val_data = torchvision.datasets.ImageFolder(data_dir + '/val/')\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(data_dir + '/test/')\n",
    "\n",
    "train_data_lightly = lightly.data.LightlyDataset.from_torch_dataset(train_data)\n",
    "test_data_lightly = lightly.data.LightlyDataset.from_torch_dataset(test_data,\n",
    "                                                                   transform=test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45964e25-9395-4672-9974-97c70c5b1737",
   "metadata": {},
   "source": [
    "## Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf23f035-f351-4a26-b4ff-bef4972709c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the augmentations for self-supervised learning.\n",
    "collate_fn_train = lightly.data.collate.BaseCollateFunction(train_transform)\n",
    "\n",
    "# Create a dataloader for training and embedding.\n",
    "dataloader_train_simsiam = torch.utils.data.DataLoader(\n",
    "    train_data_lightly,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn_train,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    test_data_lightly,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e47e699-b80c-4b9c-bbdc-73dcbab10030",
   "metadata": {},
   "source": [
    "## Check balance and size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39b914ac-a148-4c0d-979e-a6ec9f834140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]), array([9800, 3259, 6208, 9800, 8355, 3105,  943, 9800, 7306, 4466, 2015,\n",
      "        396,  880, 9800, 2739, 2710, 9793,  291,  340, 2943, 9800, 9800,\n",
      "       9800, 1402,  589,  714,  247,  289, 8813]))\n"
     ]
    }
   ],
   "source": [
    "# Check samples per class in train dataset.\n",
    "print(np.unique(train_data.targets, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec4bb2c4-7a4a-4e89-8d86-20c31fb688b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]), array([1400,  465,  886, 1400, 1193,  443,  134, 1400, 1043,  638,  288,\n",
      "         56,  125, 1400,  391,  387, 1399,   41,   48,  420, 1400, 1400,\n",
      "       1400,  200,   84,  102,   35,   41, 1259]))\n"
     ]
    }
   ],
   "source": [
    "# Check samples per class in val dataset.\n",
    "print(np.unique(val_data.targets, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27bd4dc5-c061-4645-be13-cae153fa5bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136403\n",
      "19478\n",
      "38996\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data.targets))\n",
    "print(len(val_data.targets))\n",
    "print(len(test_data.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f9060d-ee60-48e7-9bac-cdf725edcdfb",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47381c60-3bd2-41a9-bf2b-9b55f12c7e51",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fe40ed-ca86-4418-8cec-1500c0ae480e",
   "metadata": {},
   "source": [
    "# Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7760fc7-5b30-4490-8ac5-70ab237d6dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = torchvision.models.resnet18(weights=None)\n",
    "model = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
    "model.load_state_dict(torch.load('pytorch_models/simsiam_backbone_resnet18'))\n",
    "# model.eval() or model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7660c35-8460-4f3f-ae95-dd8d80b8ad1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(np.unique(train_data.targets, return_counts=False))\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bacdbbc8-21a1-45b1-8f4b-1d9c0d6c19e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               [32, 512, 1, 1]           --\n",
       "├─Conv2d: 1-1                            [32, 64, 112, 112]        9,408\n",
       "├─BatchNorm2d: 1-2                       [32, 64, 112, 112]        128\n",
       "├─ReLU: 1-3                              [32, 64, 112, 112]        --\n",
       "├─MaxPool2d: 1-4                         [32, 64, 56, 56]          --\n",
       "├─Sequential: 1-5                        [32, 64, 56, 56]          --\n",
       "│    └─BasicBlock: 2-1                   [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-1                  [32, 64, 56, 56]          36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [32, 64, 56, 56]          128\n",
       "│    │    └─ReLU: 3-3                    [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-4                  [32, 64, 56, 56]          36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [32, 64, 56, 56]          128\n",
       "│    │    └─ReLU: 3-6                    [32, 64, 56, 56]          --\n",
       "│    └─BasicBlock: 2-2                   [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-7                  [32, 64, 56, 56]          36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [32, 64, 56, 56]          128\n",
       "│    │    └─ReLU: 3-9                    [32, 64, 56, 56]          --\n",
       "│    │    └─Conv2d: 3-10                 [32, 64, 56, 56]          36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [32, 64, 56, 56]          128\n",
       "│    │    └─ReLU: 3-12                   [32, 64, 56, 56]          --\n",
       "├─Sequential: 1-6                        [32, 128, 28, 28]         --\n",
       "│    └─BasicBlock: 2-3                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-13                 [32, 128, 28, 28]         73,728\n",
       "│    │    └─BatchNorm2d: 3-14            [32, 128, 28, 28]         256\n",
       "│    │    └─ReLU: 3-15                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-16                 [32, 128, 28, 28]         147,456\n",
       "│    │    └─BatchNorm2d: 3-17            [32, 128, 28, 28]         256\n",
       "│    │    └─Sequential: 3-18             [32, 128, 28, 28]         8,448\n",
       "│    │    └─ReLU: 3-19                   [32, 128, 28, 28]         --\n",
       "│    └─BasicBlock: 2-4                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-20                 [32, 128, 28, 28]         147,456\n",
       "│    │    └─BatchNorm2d: 3-21            [32, 128, 28, 28]         256\n",
       "│    │    └─ReLU: 3-22                   [32, 128, 28, 28]         --\n",
       "│    │    └─Conv2d: 3-23                 [32, 128, 28, 28]         147,456\n",
       "│    │    └─BatchNorm2d: 3-24            [32, 128, 28, 28]         256\n",
       "│    │    └─ReLU: 3-25                   [32, 128, 28, 28]         --\n",
       "├─Sequential: 1-7                        [32, 256, 14, 14]         --\n",
       "│    └─BasicBlock: 2-5                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-26                 [32, 256, 14, 14]         294,912\n",
       "│    │    └─BatchNorm2d: 3-27            [32, 256, 14, 14]         512\n",
       "│    │    └─ReLU: 3-28                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-29                 [32, 256, 14, 14]         589,824\n",
       "│    │    └─BatchNorm2d: 3-30            [32, 256, 14, 14]         512\n",
       "│    │    └─Sequential: 3-31             [32, 256, 14, 14]         33,280\n",
       "│    │    └─ReLU: 3-32                   [32, 256, 14, 14]         --\n",
       "│    └─BasicBlock: 2-6                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-33                 [32, 256, 14, 14]         589,824\n",
       "│    │    └─BatchNorm2d: 3-34            [32, 256, 14, 14]         512\n",
       "│    │    └─ReLU: 3-35                   [32, 256, 14, 14]         --\n",
       "│    │    └─Conv2d: 3-36                 [32, 256, 14, 14]         589,824\n",
       "│    │    └─BatchNorm2d: 3-37            [32, 256, 14, 14]         512\n",
       "│    │    └─ReLU: 3-38                   [32, 256, 14, 14]         --\n",
       "├─Sequential: 1-8                        [32, 512, 7, 7]           --\n",
       "│    └─BasicBlock: 2-7                   [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-39                 [32, 512, 7, 7]           1,179,648\n",
       "│    │    └─BatchNorm2d: 3-40            [32, 512, 7, 7]           1,024\n",
       "│    │    └─ReLU: 3-41                   [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-42                 [32, 512, 7, 7]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43            [32, 512, 7, 7]           1,024\n",
       "│    │    └─Sequential: 3-44             [32, 512, 7, 7]           132,096\n",
       "│    │    └─ReLU: 3-45                   [32, 512, 7, 7]           --\n",
       "│    └─BasicBlock: 2-8                   [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-46                 [32, 512, 7, 7]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-47            [32, 512, 7, 7]           1,024\n",
       "│    │    └─ReLU: 3-48                   [32, 512, 7, 7]           --\n",
       "│    │    └─Conv2d: 3-49                 [32, 512, 7, 7]           2,359,296\n",
       "│    │    └─BatchNorm2d: 3-50            [32, 512, 7, 7]           1,024\n",
       "│    │    └─ReLU: 3-51                   [32, 512, 7, 7]           --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [32, 512, 1, 1]           --\n",
       "==========================================================================================\n",
       "Total params: 11,176,512\n",
       "Trainable params: 11,176,512\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 58.03\n",
       "==========================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 1271.66\n",
       "Params size (MB): 44.71\n",
       "Estimated Total Size (MB): 1335.63\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(batch_size, 3, input_size, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "17f27b2f-fe4c-4309-8fa4-991b2e03aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    model,\n",
    "    torch.nn.Linear(in_features=32*512, out_features=num_classes),\n",
    "    torch.nn.Softmax(dim=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93a3d5c8-c1de-480b-876e-fe1fdf9f69e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Sequential: 1, Conv2d: 2, BatchNorm2d: 2, ReLU: 2, MaxPool2d: 2, Sequential: 2, BasicBlock: 3, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, BasicBlock: 3, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Sequential: 2, BasicBlock: 3, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Conv2d: 4, BatchNorm2d: 4, Sequential: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 4, BasicBlock: 3, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Sequential: 2, BasicBlock: 3, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Conv2d: 4, BatchNorm2d: 4, Sequential: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 4, BasicBlock: 3, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Sequential: 2, BasicBlock: 3, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Conv2d: 4, BatchNorm2d: 4, Sequential: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 4, BasicBlock: 3, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, AdaptiveAvgPool2d: 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/Git/lulc/lulc-venv/lib/python3.8/site-packages/torchinfo/torchinfo.py:287\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[0;32m--> 287\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/Documents/Git/lulc/lulc-venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1148\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1148\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m~/Documents/Git/lulc/lulc-venv/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Git/lulc/lulc-venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1148\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m-> 1148\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n",
      "File \u001b[0;32m~/Documents/Git/lulc/lulc-venv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (16384x1 and 32x29)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msummary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Git/lulc/lulc-venv/lib/python3.8/site-packages/torchinfo/torchinfo.py:217\u001b[0m, in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, mode, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m validate_user_params(\n\u001b[1;32m    211\u001b[0m     input_data, input_size, columns, col_width, device, dtypes, verbose\n\u001b[1;32m    212\u001b[0m )\n\u001b[1;32m    214\u001b[0m x, correct_input_size \u001b[38;5;241m=\u001b[39m process_input(\n\u001b[1;32m    215\u001b[0m     input_data, input_size, batch_dim, device, dtypes\n\u001b[1;32m    216\u001b[0m )\n\u001b[0;32m--> 217\u001b[0m summary_list \u001b[38;5;241m=\u001b[39m \u001b[43mforward_pass\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_forward_pass\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m formatting \u001b[38;5;241m=\u001b[39m FormattingOptions(depth, verbose, columns, col_width, rows)\n\u001b[1;32m    221\u001b[0m results \u001b[38;5;241m=\u001b[39m ModelStatistics(\n\u001b[1;32m    222\u001b[0m     summary_list, correct_input_size, get_total_memory_used(x), formatting\n\u001b[1;32m    223\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Git/lulc/lulc-venv/lib/python3.8/site-packages/torchinfo/torchinfo.py:296\u001b[0m, in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, mode, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    295\u001b[0m     executed_layers \u001b[38;5;241m=\u001b[39m [layer \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m summary_list \u001b[38;5;28;01mif\u001b[39;00m layer\u001b[38;5;241m.\u001b[39mexecuted]\n\u001b[0;32m--> 296\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to run torchinfo. See above stack traces for more details. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecuted layers up to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecuted_layers\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hooks:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: [Sequential: 1, Conv2d: 2, BatchNorm2d: 2, ReLU: 2, MaxPool2d: 2, Sequential: 2, BasicBlock: 3, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, BasicBlock: 3, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Sequential: 2, BasicBlock: 3, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Conv2d: 4, BatchNorm2d: 4, Sequential: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 4, BasicBlock: 3, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Sequential: 2, BasicBlock: 3, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Conv2d: 4, BatchNorm2d: 4, Sequential: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 4, BasicBlock: 3, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Sequential: 2, BasicBlock: 3, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Conv2d: 4, BatchNorm2d: 4, Sequential: 4, Conv2d: 5, BatchNorm2d: 5, ReLU: 4, BasicBlock: 3, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, Conv2d: 4, BatchNorm2d: 4, ReLU: 4, AdaptiveAvgPool2d: 2]"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(batch_size, 3, input_size, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eafe15c-247d-4bd4-804d-47f34880d071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860b3244-9d30-41ce-ae4d-5e75cfbebd97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lulc-venv",
   "language": "python",
   "name": "lulc-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
