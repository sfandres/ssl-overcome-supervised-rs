{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "293858ae-5611-498e-afd6-acddd993850f",
   "metadata": {},
   "source": [
    "**USING RESNET18 WITH AND WITHOUT PRETRAINED WEIGHTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90375b5c-0b66-445d-9260-f68b8bf991df",
   "metadata": {},
   "source": [
    "**LOADING THE SSL MODEL AND TRAINING A CLASSIFIER ON TOP OF IT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e9469c-2666-4529-9eaf-1a1925b6eef0",
   "metadata": {},
   "source": [
    "Reference 1: https://pytorch.org/tutorials/beginner/introyt/trainingyt.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26195bb6-2965-4abd-b858-161c062294b6",
   "metadata": {},
   "source": [
    "Reference 2: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7dd78-3b06-441e-9cb8-4ca54a7b955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d06a82-af2e-4dc0-a873-1a2a225e284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24803b53-5c6f-4603-9e46-74b468dc6a4b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3123cba7-2168-4887-bf98-a65fa199db70",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d3b8f7-6c4c-47ec-a517-76e02872c1a6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c4791a-9d48-4508-8338-79dabc7c1754",
   "metadata": {},
   "source": [
    "## Libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c251f-635b-4c62-a485-7a7783aed523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import lightly\n",
    "from lightly.models.modules.heads import SimSiamPredictionHead\n",
    "from lightly.models.modules.heads import SimSiamProjectionHead\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "# Training checks.\n",
    "import time\n",
    "\n",
    "# Showing images in the notebook.\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80aa854-ce45-46ef-806a-18a1fac093f7",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bf93d6-efdf-429b-8521-41c0a35f4838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training on GPU.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Hyperparamenters.\n",
    "expt = utils.Experiment(epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977f3f16-a19f-48f2-beab-cb5c97159106",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d55f4a9-b9a2-40da-a96e-cf95c22eea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed torch and numpy.\n",
    "os.environ['PYTHONHASHSEED'] = str(expt.seed)\n",
    "torch.manual_seed(expt.seed)\n",
    "np.random.seed(expt.seed)\n",
    "random.seed(expt.seed)\n",
    "\n",
    "# Enable CUDNN deterministic mode.\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Issues a warning if it is not met.\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440ad27-f875-4730-8c3a-c583a34a817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dataloaders.\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(expt.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1964f0c0-fdc2-42cb-879e-8fb4c1053e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable deterministic behavior using external GPU.\n",
    "# %env CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
    "# %env CUBLAS_WORKSPACE_CONFIG=:16:8\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':16:8'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d940bd-cf06-40e7-aedd-65ff1f9980d7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bcd19d-b8ff-423a-a2de-5ed81895d678",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce58376-03c3-4e2d-be6d-8e5d50072143",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fd08be-7b93-4d21-b694-002e95ef567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = (.01, .01, .98)\n",
    "# ratio = (.7, .1, .2)\n",
    "\n",
    "data_dir_target = f'datasets/Sentinel2GlobalLULC_full' \\\n",
    "                  f'-ratio={ratio}' \\\n",
    "                  f'-seed={expt.seed}'\n",
    "\n",
    "print(data_dir_target)\n",
    "\n",
    "if ratio == (.01, .01, .98):\n",
    "\n",
    "    mean_train = [0.3341, 0.3395, 0.3636]\n",
    "    std_train = [0.2904, 0.2328, 0.2091]\n",
    "\n",
    "    mean_val = [0.3357, 0.3382, 0.3616]\n",
    "    std_val = [0.2942, 0.2330, 0.2069]\n",
    "\n",
    "    mean_test = [0.3327, 0.3372, 0.3603]\n",
    "    std_test = [0.2976, 0.2376, 0.2115]\n",
    "\n",
    "elif ratio == (.7, .1, .2):\n",
    "\n",
    "    mean_train = [0.3329, 0.3373, 0.3603]\n",
    "    std_train = [0.2978, 0.2377, 0.2115]\n",
    "\n",
    "    mean_val = [0.3318, 0.3363, 0.3597]\n",
    "    std_val = [0.2962, 0.2364, 0.2104]\n",
    "\n",
    "    mean_test = [0.3328, 0.3375, 0.3605]\n",
    "    std_test = [0.2974, 0.2378, 0.2118]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4022454b-8858-4b93-98b7-742b14ffbe51",
   "metadata": {},
   "source": [
    "## Custom tranforms (w/o normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9816d93-e2ce-4842-8707-aa3956045aa0",
   "metadata": {},
   "source": [
    "Define the augmentations for self-supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0cc09-236f-4120-ad7b-e90136363863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentations for the train dataset.\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((expt.input_size, expt.input_size)),\n",
    "    torchvision.transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n",
    "    torchvision.transforms.RandomApply([\n",
    "            torchvision.transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)\n",
    "        ], p=0.8),  # not strengthened\n",
    "    torchvision.transforms.RandomGrayscale(p=0.2),\n",
    "    # torchvision.transforms.RandomApply([\n",
    "    #     simsiam.loader.GaussianBlur([.1, 2.])\n",
    "    # ], p=0.5),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean_train, std_train)\n",
    "])\n",
    "\n",
    "# Data augmentations for the val and test datasets.\n",
    "val_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((expt.input_size, expt.input_size)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean_val, std_val)\n",
    "])\n",
    "\n",
    "# Data augmentations for the val and test datasets.\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((expt.input_size, expt.input_size)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean_test, std_test)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac31fc9-ef1b-49ff-bce1-6b913422346d",
   "metadata": {},
   "source": [
    "## ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b48ae6-b974-41a3-99b0-4fccdd6a62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the three datasets.\n",
    "train_data = torchvision.datasets.ImageFolder(data_dir_target + '/train/',\n",
    "                                              transform=train_transform)\n",
    "\n",
    "val_data = torchvision.datasets.ImageFolder(data_dir_target + '/val/',\n",
    "                                            transform=val_transform)\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(data_dir_target + '/test/',\n",
    "                                             transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3518a1-2aeb-4e8d-bfde-7c30f4df195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classes and number.\n",
    "class_names = train_data.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660ba5f0-e15f-47c3-b614-bf44c75c67e3",
   "metadata": {},
   "source": [
    "## PyTorch dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a77009-440f-45af-8bd1-feaa61adef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader for training.\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=expt.batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=expt.num_workers,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")\n",
    "\n",
    "# Dataloader for validating.\n",
    "dataloader_val = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size=expt.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=expt.num_workers,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")\n",
    "\n",
    "# Dataloader for embedding.\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=expt.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=expt.num_workers,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeaaff0-6d50-4888-85cd-63de0902668d",
   "metadata": {},
   "source": [
    "## Check the balance and size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa664a-1c20-4aef-876a-327fdaee8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check samples per class in train dataset.\n",
    "print(np.unique(train_data.targets, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c5f14-2cc4-4867-9bcf-a053e94d082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check samples per class in test dataset.\n",
    "print(np.unique(test_data.targets, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1562cd9-5ba7-4e07-aa5b-143c703a644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some stats from the train dataset.\n",
    "print(len(train_data.targets))\n",
    "\n",
    "# Print some stats from the train dataloader.\n",
    "print('N samples in train dataset: ' + str(len(dataloader_train.sampler)))\n",
    "print('N samples in train dataset: ' + str(len(dataloader_train.dataset)))\n",
    "print('N batches in train dataset: ' + str(len(dataloader_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e5780-0557-4a29-834b-41f00cf56ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some stats from the val dataset.\n",
    "print(len(val_data.targets))\n",
    "\n",
    "# Print some stats from the val dataloader.\n",
    "print('N samples in val dataset: ' + str(len(dataloader_val.dataset)))\n",
    "print('N batches in val dataset: ' + str(len(dataloader_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ca802-c715-45e4-93cc-62eaaab062b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some stats from the test dataset.\n",
    "print(len(test_data.targets))\n",
    "\n",
    "# Print some stats from the test dataloader.\n",
    "print('N samples in test dataset: ' + str(len(dataloader_test.dataset)))\n",
    "print('N batches in test dataset: ' + str(len(dataloader_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc00d03-ff40-4c82-8982-27aff5d9927f",
   "metadata": {},
   "source": [
    "## See some samples (pytorch dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e34469-dddd-42fa-ba43-6f5da105f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(dataloader_train))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(torch.permute(img, (1, 2, 0)), cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {class_names[label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06196e35-2417-40f2-9bad-f197103911de",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb2512f-dd8c-4bcf-b5b6-fbb648845fd5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c8e405-4183-4e6b-97f6-34edd7fbf17b",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437632b1-b33e-46a7-9c0c-5c0046318faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function.\n",
    "def train_model(model, criterion, optimizer, device,\n",
    "                epochs=10, save_best_model=False):\n",
    "    \"\"\"\n",
    "    Main training function.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Using {device} device\")\n",
    "\n",
    "    # Avoiding \"CUDA out of memory\" in PyTorch.\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Loss history.\n",
    "    loss_values = {}\n",
    "    loss_values['train'] = []\n",
    "    loss_values['val'] = []\n",
    "    total_time = 0\n",
    "\n",
    "    # Saving best model's weights.\n",
    "    best_model_val_wts = copy.deepcopy(model.state_dict())\n",
    "    lowest_val_loss = 10000\n",
    "\n",
    "    # Model to GPU if available.\n",
    "    model.to(device)\n",
    "\n",
    "    # Iterating over the epochs.\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Initialize training loss.\n",
    "        running_train_loss = 0.0\n",
    "\n",
    "        # Start timer.\n",
    "        since = time.time()\n",
    "\n",
    "        for i, data in enumerate(dataloader_train):\n",
    "\n",
    "            # Get the inputs; data is a list of [inputs, labels].\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Enable training.\n",
    "            model.train()\n",
    "\n",
    "            # Zero the parameter gradients.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward: make predictions.\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute the loss and its gradients.\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Averaged loss across all training examples * batch_size.\n",
    "            running_train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            if i % 200 == 199:\n",
    "                print(f'T[{epoch + 1}, {i + 1:5d}] | '\n",
    "                      f'Running loss: '\n",
    "                      f'{running_train_loss/(i*inputs.size(0)):.4f}')\n",
    "\n",
    "            # Adjust learning weights.\n",
    "            optimizer.step()\n",
    "\n",
    "        # Loss averaged across all training examples for the current epoch.\n",
    "        epoch_train_loss = running_train_loss / len(dataloader_train.sampler)\n",
    "\n",
    "        # Change model to evaluation mode.\n",
    "        model.eval()\n",
    "\n",
    "        # Initialize validating loss.\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for j, vdata in enumerate(dataloader_val):\n",
    "\n",
    "                # Get the inputs; data is a list of [inputs, labels].\n",
    "                vinputs, vlabels = vdata[0].to(device), vdata[1].to(device)\n",
    "\n",
    "                # Forward: make predictions.\n",
    "                voutputs = model(vinputs)\n",
    "\n",
    "                # Compute the loss (w/o gradients).\n",
    "                vloss = criterion(voutputs, vlabels)\n",
    "\n",
    "                # Averaged loss across all validating examples * batch_size.\n",
    "                running_val_loss += vloss.item() * vinputs.size(0)\n",
    "\n",
    "                if j % 50 == 49:\n",
    "                    print(f'V[{epoch + 1}, {j + 1:5d}] | '\n",
    "                          f'Running loss: '\n",
    "                          f'{running_val_loss/(j*inputs.size(0)):.4f}')\n",
    "\n",
    "        # Loss averaged across all validating examples for the current epoch.\n",
    "        epoch_val_loss = running_val_loss / len(dataloader_val.sampler)\n",
    "\n",
    "        # Append loss values.\n",
    "        loss_values['train'].append(epoch_train_loss)\n",
    "        loss_values['val'].append(epoch_val_loss)\n",
    "\n",
    "        # Deep copy the weights of the model.\n",
    "        save_weights = epoch_val_loss < lowest_val_loss\n",
    "        if save_weights:\n",
    "            lowest_val_loss = epoch_val_loss\n",
    "            best_model_train_loss = epoch_train_loss\n",
    "            best_model_val_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        # End timer.\n",
    "        time_elapsed = time.time() - since\n",
    "        total_time += time_elapsed\n",
    "\n",
    "        # Show stats.\n",
    "        print(f'Epoch: {epoch} | '\n",
    "              f'Train loss: {epoch_train_loss:.4f} | '\n",
    "              f'Val loss: {epoch_val_loss:.4f} | '\n",
    "              f'Elapsed: {time_elapsed // 60:.0f}m '\n",
    "              f'{time_elapsed % 60:.0f}s | '\n",
    "              f'Save weights: {save_weights}')\n",
    "\n",
    "    print(f'\\nTraining completed in {total_time // 60:.0f}m '\n",
    "          f'{total_time % 60:.0f}s')\n",
    "\n",
    "    # Load best model weights.\n",
    "    model.load_state_dict(best_model_val_wts)\n",
    "\n",
    "    if save_best_model:\n",
    "\n",
    "        # Move to CPU before saving it.\n",
    "        model.to('cpu')\n",
    "\n",
    "        # Filename with stats.\n",
    "        save_path = f'pytorch_models/resnet18' \\\n",
    "                    f'-losses={best_model_train_loss:.2f}' \\\n",
    "                    f'_{lowest_val_loss:.2f}' \\\n",
    "                    f'-time={datetime.now():%Y_%m_%d-%H_%M_%S}'\n",
    "\n",
    "        # Save this pretrained model (recommended approach).\n",
    "        torch.save(model.state_dict(), save_path)\n",
    "\n",
    "        print('Model successfuly saved')\n",
    "\n",
    "        # Move back to the GPU.\n",
    "        model.to(device)\n",
    "\n",
    "    return model, loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3a7f82-4423-4d81-85a8-0ecbaba41c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(loss_history, title='', save_fig=False):\n",
    "    \"\"\"\n",
    "    Function for plotting the training and validation losses\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    plt.plot(loss_history['train'], label='Train')\n",
    "    plt.plot(loss_history['val'], label='Validation')\n",
    "    plt.xlabel('Epoch', labelpad=15)\n",
    "    plt.ylabel('Loss', labelpad=15)\n",
    "    plt.title(title)\n",
    "    plt.gcf().subplots_adjust(bottom=0.15)\n",
    "    plt.gcf().subplots_adjust(left=0.15)\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if save_fig:\n",
    "        fig.savefig('plt_loss_values.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ff272e-4786-4a49-b7fc-73ce774a88af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_on_test(model, device):\n",
    "    \"\"\"\n",
    "    Function to evaluate the performance\n",
    "    of the model on the test dataset.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Avoiding \"CUDA out of memory\" in PyTorch.\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Since we're not training, we don't need to calculate\n",
    "    # the gradients for our outputs with torch.no_grad():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader_test):\n",
    "\n",
    "            # Dataset.\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Calculate outputs by running images through the network.\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # The class with the highest energy is what we\n",
    "            # choose as prediction.\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Progress bar.\n",
    "            if i % 50 == 49:\n",
    "                print(f'Progress: {100 * i // len(dataloader_test)}%',\n",
    "                      end='\\r',\n",
    "                      flush=True)\n",
    "\n",
    "    print(f'Accuracy of the network on the {total} '\n",
    "          f'test images: {100 * correct // total}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4c48da-0289-4350-8641-62c207d44143",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18762958-4bb5-4a9e-a642-e5cecbc0f8f1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce24b86-e4e5-442a-876a-782db427e0c3",
   "metadata": {},
   "source": [
    "# ResNet18 from scrath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b72a3-8fd8-45fe-8353-e77cdc5f99d6",
   "metadata": {},
   "source": [
    "## Definition and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b373932-506b-45a0-9301-d182e038d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: resnet with random weights.\n",
    "model = torchvision.models.resnet18(weights=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8627587-6558-4637-b5b2-f8e0cdc7b3ea",
   "metadata": {},
   "source": [
    "## Adjust final layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d714e83-002f-4f1a-b240-cf7e80ae41ca",
   "metadata": {},
   "source": [
    "Type: linear not softmax for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ad1ef-8697-41ab-a1af-1b6f615715c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check old final layer.\n",
    "print(model.fc)\n",
    "\n",
    "# Get the number of input features to the layer.\n",
    "num_ftrs = model.fc.in_features\n",
    "print(num_ftrs)\n",
    "\n",
    "# Adjust the final layer to the current number of classes.\n",
    "model.fc = torch.nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "# Check new final layer.\n",
    "print(model.fc)\n",
    "\n",
    "# Freezing all the network except the final layer.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Model structure.\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(expt.batch_size, 3, expt.input_size, expt.input_size),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fdf194-24c8-45c3-bf12-d6ac176df30e",
   "metadata": {},
   "source": [
    "## Loss fcn and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea9cdf-c59e-4e10-94b5-f6017bda668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: cross-entropy loss.\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizers: specified in the torch.optim package\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ee9848-8c21-489d-8adc-2fc0e0bff9b0",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba464d96-1913-43ef-96c4-59b5fdf9b65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_history = train_model(\n",
    "    model,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs=expt.epochs,\n",
    "    save_best_model=True\n",
    ")\n",
    "\n",
    "plot_losses(loss_history, 'Model w/o pretrained weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0504b3-ae1c-4836-87e9-3c45e93b92d7",
   "metadata": {},
   "source": [
    "## Check performance on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5515fcfa-ed16-42f9-8b70-992fde11c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_on_test(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978fc629-e5a5-4608-bab6-ceee0b554bed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d0dd0-1d74-45aa-b3ca-0b12d79ca712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "conf_mat, class_accuracy = utils.create_confusion_matrix(\n",
    "    model,\n",
    "    dataloader_test,\n",
    "    device,\n",
    "    class_names\n",
    ")\n",
    "\n",
    "# Bar plot for accuracy values.\n",
    "utils.simple_bar_plot(range(len(class_names)),\n",
    "                      class_accuracy,\n",
    "                      'Classes',\n",
    "                      'Accuracy (%)',\n",
    "                      'class_accuracy',\n",
    "                      fig_size=(15, 5),\n",
    "                      save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d101e8-426c-408d-a5fc-345d08a4434d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d76c1c-8bf2-4b5e-ae24-9fd71ab6b7b0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b22ad-185d-4251-8545-744f9e403c59",
   "metadata": {},
   "source": [
    "# ResNet18 with pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e46b01-7e1d-4215-b2ae-c0afa84c82ac",
   "metadata": {},
   "source": [
    "## Definition and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472cdf9a-2854-4bd0-8ef5-4e5d179f0019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: resnet with pretrained weights.\n",
    "del model\n",
    "model = torchvision.models.resnet18(\n",
    "    weights=torchvision.models.ResNet18_Weights.DEFAULT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb9f8c6-dc14-4557-9ed2-b9d6084093b5",
   "metadata": {},
   "source": [
    "## Adjust final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a63f366-3feb-40fa-bbcf-117fbca74817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check old final layer.\n",
    "print(model.fc)\n",
    "\n",
    "# Get the number of input features to the layer.\n",
    "num_ftrs = model.fc.in_features\n",
    "print(num_ftrs)\n",
    "\n",
    "# Adjust the final layer to the current number of classes.\n",
    "model.fc = torch.nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "# Parameters of newly constructed modules\n",
    "# have requires_grad=True by default.\n",
    "# Check new final layer.\n",
    "print(model.fc)\n",
    "\n",
    "# Freezing all the network except the final layer.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Model structure.\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(expt.batch_size, 3, expt.input_size, expt.input_size),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e916e25-8b38-4e14-beb4-f311126e01f1",
   "metadata": {},
   "source": [
    "## Loss fcn and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaccb2dc-7957-4857-9bf7-b9eab949bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: cross-entropy loss.\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizers: specified in the torch.optim package\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425ec5c5-ddc4-4938-9720-8e07068997d0",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea3d48-0270-41dc-a48d-15953ffb23e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_history = train_model(\n",
    "    model,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs=expt.epochs,\n",
    "    save_best_model=True\n",
    ")\n",
    "\n",
    "plot_losses(loss_history, 'Model w/ pretrained weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a40815-9743-42c6-8643-a963ce8533e6",
   "metadata": {},
   "source": [
    "## Check performance on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9e847-5b2e-49fc-ad8e-92529b5410e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_on_test(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9ab91b-c609-44a1-bfd7-61a456c6a22b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4790a3a2-2350-49a7-9461-dbcca50335e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "conf_mat, class_accuracy = utils.create_confusion_matrix(\n",
    "    model,\n",
    "    dataloader_test,\n",
    "    device,\n",
    "    class_names\n",
    ")\n",
    "\n",
    "# Bar plot for accuracy values.\n",
    "utils.simple_bar_plot(range(len(class_names)),\n",
    "                      class_accuracy,\n",
    "                      'Classes',\n",
    "                      'Accuracy (%)',\n",
    "                      'class_accuracy',\n",
    "                      fig_size=(15, 5),\n",
    "                      save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bba927-e499-45b7-9d32-bd5e83b8d257",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a486bc-8b38-451a-9424-477585524559",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f806d186-1c7c-4423-8337-5d7f9433c746",
   "metadata": {},
   "source": [
    "# SSL model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1839bbef-1ec9-4899-972b-9d6db8f2613c",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42234674-8005-4fcd-a76f-5d54f586fb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State model class.\n",
    "resnet18 = torchvision.models.resnet18(weights=None)\n",
    "\n",
    "# Only backbone (w/o final fc layer).\n",
    "pt_backbone = torch.nn.Sequential(*list(resnet18.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147bd03f-ee69-4664-a0f3-57ea6aa78331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of trained models.\n",
    "model_list = []\n",
    "for root, dirs, files in os.walk('pytorch_models/simsiam/'):\n",
    "    for i, filename in enumerate(sorted(files, reverse=True)):\n",
    "        model_list.append(root + filename)\n",
    "        print(f'{i:02}: {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad21f18d-da7d-4007-a8be-edd49331ed69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model.\n",
    "idx = 1\n",
    "print(model_list[idx])\n",
    "pt_backbone.load_state_dict(torch.load(model_list[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b953213-478a-41fc-8f77-c418c5cf9def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model is loaded on GPU.\n",
    "next(pt_backbone.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bebf71e-7453-442a-898a-1a38825e025b",
   "metadata": {},
   "source": [
    "## Checking the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d413d46-02cf-49a2-9a86-b39fbfaac08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First convolutional layer weights.\n",
    "# print(backbone)\n",
    "print(pt_backbone[0])\n",
    "print(pt_backbone[0].weight[63])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd91df-abe1-42d3-ace9-8a8b45fbb0f8",
   "metadata": {},
   "source": [
    "## Adding a final linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b768a0a1-85c5-40a4-b843-4d50d44fd161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a linear layer on top of the model (linear classifier).\n",
    "model_ssl = torch.nn.Sequential(\n",
    "    pt_backbone,\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(in_features=512, out_features=len(class_names), bias=True),\n",
    "    # torch.nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "# Freezing all the network except the final layer.\n",
    "for param in model_ssl.parameters():\n",
    "    param.requires_grad = False\n",
    "# for param in model_ssl[0][7].parameters():\n",
    "#     param.requires_grad = True\n",
    "for param in model_ssl[2].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Model structure.\n",
    "summary(\n",
    "    model_ssl,\n",
    "    input_size=(expt.batch_size, 3, expt.input_size, expt.input_size),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80c0096-fb2f-4183-bdab-dfc345be59c7",
   "metadata": {},
   "source": [
    "## Loss fcn and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f3ed4b-1948-4843-96ca-b4cced958a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: cross-entropy loss.\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizers: specified in the torch.optim package\n",
    "optimizer = torch.optim.Adam(model_ssl.parameters(),\n",
    "                             lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a106ebc3-d159-45f8-b956-abd33add0552",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c9d4f1-bc8a-45fe-88f5-dbcb71b0c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ssl, loss_history = train_model(\n",
    "    model_ssl,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs=expt.epochs,\n",
    "    save_best_model=True\n",
    ")\n",
    "\n",
    "plot_losses(loss_history, 'Model w/ ssl pretrained weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7815545a-4949-41fa-b208-774516170576",
   "metadata": {},
   "source": [
    "## Checking the weights after training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea1ae5-4c44-4c2a-8efe-ac210a30ed79",
   "metadata": {},
   "source": [
    "They should have remained the same (frozen) except for the final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f242c-38db-4d11-b84b-4bbab655297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First convolutional layer weights.\n",
    "# print(backbone)\n",
    "print(pt_backbone[0])\n",
    "print(pt_backbone[0].weight[63])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9dff9a-1277-4301-b08e-8152110abe26",
   "metadata": {},
   "source": [
    "## Check performance on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2636a4a8-8ee4-4861-9aa8-920f0df40b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_on_test(model_ssl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fc6156-7506-449e-bc56-873c23aaf091",
   "metadata": {
    "tags": []
   },
   "source": [
    "## F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5024fea-751f-40a7-93ac-3a897285f89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "conf_mat, class_accuracy = utils.create_confusion_matrix(\n",
    "    model_ssl,\n",
    "    dataloader_test,\n",
    "    device,\n",
    "    class_names\n",
    ")\n",
    "\n",
    "# Bar plot for accuracy values.\n",
    "utils.simple_bar_plot(range(len(class_names)),\n",
    "                      class_accuracy,\n",
    "                      'Classes',\n",
    "                      'Accuracy (%)',\n",
    "                      'class_accuracy',\n",
    "                      fig_size=(15, 5),\n",
    "                      save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ad0aa-d143-42dd-96f9-63c9cf6ad81f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d238c6eb-d2e8-419d-b24c-1c828f995abe",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lulc-venv",
   "language": "python",
   "name": "lulc-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
