{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "293858ae-5611-498e-afd6-acddd993850f",
   "metadata": {},
   "source": [
    "**USING RESNET18 WITH AND WITHOUT PRETRAINED WEIGHTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90375b5c-0b66-445d-9260-f68b8bf991df",
   "metadata": {},
   "source": [
    "**LOADING THE SSL MODEL AND TRAINING A CLASSIFIER ON TOP OF IT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e9469c-2666-4529-9eaf-1a1925b6eef0",
   "metadata": {},
   "source": [
    "Reference 1: https://pytorch.org/tutorials/beginner/introyt/trainingyt.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26195bb6-2965-4abd-b858-161c062294b6",
   "metadata": {},
   "source": [
    "Reference 2: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b7dd78-3b06-441e-9cb8-4ca54a7b955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d06a82-af2e-4dc0-a873-1a2a225e284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f718a851-e231-49d4-a6a6-d88e72c46d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility.\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24803b53-5c6f-4603-9e46-74b468dc6a4b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3123cba7-2168-4887-bf98-a65fa199db70",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d3b8f7-6c4c-47ec-a517-76e02872c1a6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c4791a-9d48-4508-8338-79dabc7c1754",
   "metadata": {},
   "source": [
    "## Libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017c251f-635b-4c62-a485-7a7783aed523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import lightly\n",
    "from lightly.models.modules.heads import SimSiamPredictionHead\n",
    "from lightly.models.modules.heads import SimSiamProjectionHead\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "# Training checks.\n",
    "import time\n",
    "\n",
    "# Showing images in the notebook.\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80aa854-ce45-46ef-806a-18a1fac093f7",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15910bd0-a14d-4352-832d-d5787ec9d860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training on GPU.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bf93d6-efdf-429b-8521-41c0a35f4838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamenters.\n",
    "input_size = 224  # old_input_size = 256\n",
    "batch_size = 128   # old_batch_size = 128\n",
    "num_workers = 8\n",
    "\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977f3f16-a19f-48f2-beab-cb5c97159106",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d55f4a9-b9a2-40da-a96e-cf95c22eea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed torch and numpy.\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "# Enable CUDNN deterministic mode.\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Issues a warning if it is not met.\n",
    "torch.use_deterministic_algorithms(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4440ad27-f875-4730-8c3a-c583a34a817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dataloaders.\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1964f0c0-fdc2-42cb-879e-8fb4c1053e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable deterministic behavior using external GPU.\n",
    "# %env CUBLAS_WORKSPACE_CONFIG=:4096:8\n",
    "# %env CUBLAS_WORKSPACE_CONFIG=:16:8\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':16:8'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d940bd-cf06-40e7-aedd-65ff1f9980d7",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bcd19d-b8ff-423a-a2de-5ed81895d678",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce58376-03c3-4e2d-be6d-8e5d50072143",
   "metadata": {},
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96744e7-0259-40bf-93aa-619e333de2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_target = 'datasets/Sentinel2GlobalLULC_full_ratio_seed=' \\\n",
    "                  + str(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4022454b-8858-4b93-98b7-742b14ffbe51",
   "metadata": {},
   "source": [
    "## Custom tranforms (w/o normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9816d93-e2ce-4842-8707-aa3956045aa0",
   "metadata": {},
   "source": [
    "Define the augmentations for self-supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58793b73-fe2c-406b-b1d0-5bca993956f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentations for the train dataset.\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((input_size, input_size)),\n",
    "    torchvision.transforms.RandomResizedCrop(size=input_size,\n",
    "                                             scale=(0.2, 1.0)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "    torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "    torchvision.transforms.GaussianBlur(21),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Data augmentations for the val and test datasets.\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((input_size, input_size)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac31fc9-ef1b-49ff-bce1-6b913422346d",
   "metadata": {},
   "source": [
    "## ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b48ae6-b974-41a3-99b0-4fccdd6a62fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the three datasets.\n",
    "train_data = torchvision.datasets.ImageFolder(data_dir_target + '/train/',\n",
    "                                              transform=train_transform)\n",
    "\n",
    "val_data = torchvision.datasets.ImageFolder(data_dir_target + '/val/',\n",
    "                                            transform=test_transform)\n",
    "\n",
    "test_data = torchvision.datasets.ImageFolder(data_dir_target + '/test/',\n",
    "                                             transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3518a1-2aeb-4e8d-bfde-7c30f4df195a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get classes and number.\n",
    "class_names = train_data.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660ba5f0-e15f-47c3-b614-bf44c75c67e3",
   "metadata": {},
   "source": [
    "## PyTorch dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a77009-440f-45af-8bd1-feaa61adef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader for training.\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")\n",
    "\n",
    "# Dataloader for validating.\n",
    "dataloader_val = torch.utils.data.DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")\n",
    "\n",
    "# Dataloader for embedding.\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    "    worker_init_fn=seed_worker,\n",
    "    generator=g\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edeaaff0-6d50-4888-85cd-63de0902668d",
   "metadata": {},
   "source": [
    "## Check the balance and size of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1aa664a-1c20-4aef-876a-327fdaee8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check samples per class in train dataset.\n",
    "print(np.unique(train_data.targets, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c5f14-2cc4-4867-9bcf-a053e94d082c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check samples per class in test dataset.\n",
    "print(np.unique(test_data.targets, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1562cd9-5ba7-4e07-aa5b-143c703a644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some stats from the train dataloader.\n",
    "print('N samples in train dataset: ' + str(len(dataloader_train.sampler)))\n",
    "print('N samples in train dataset: ' + str(len(dataloader_train.dataset)))\n",
    "print('N batches in train dataset: ' + str(len(dataloader_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e5780-0557-4a29-834b-41f00cf56ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some stats from the val dataloader.\n",
    "print('N samples in val dataset: ' + str(len(dataloader_val.dataset)))\n",
    "print('N batches in val dataset: ' + str(len(dataloader_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1ca802-c715-45e4-93cc-62eaaab062b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some stats from the test dataloader.\n",
    "print('N samples in val dataset: ' + str(len(dataloader_test.dataset)))\n",
    "print('N batches in val dataset: ' + str(len(dataloader_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81896199-fd6d-4e19-8be0-c1389ca70a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the size of each dataset.\n",
    "print(len(train_data.targets))\n",
    "print(len(val_data.targets))\n",
    "print(len(test_data.targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc00d03-ff40-4c82-8982-27aff5d9927f",
   "metadata": {},
   "source": [
    "## See some samples (pytorch dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e34469-dddd-42fa-ba43-6f5da105f6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(dataloader_train))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(torch.permute(img, (1, 2, 0)), cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {class_names[label]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06196e35-2417-40f2-9bad-f197103911de",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb2512f-dd8c-4bcf-b5b6-fbb648845fd5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c8e405-4183-4e6b-97f6-34edd7fbf17b",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437632b1-b33e-46a7-9c0c-5c0046318faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function.\n",
    "def train_model(model, criterion, optimizer, device, epochs=10):\n",
    "    \"\"\"\n",
    "    Main training function.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"Using {device} device\")\n",
    "\n",
    "    # Avoiding \"CUDA out of memory\" in PyTorch.\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Loss history.\n",
    "    loss_values = {}\n",
    "    loss_values['train'] = []\n",
    "    loss_values['val'] = []\n",
    "    total_time = 0\n",
    "\n",
    "    # Model to GPU if available.\n",
    "    model.to(device)\n",
    "\n",
    "    # Iterating over the epochs.\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # Initialize training loss.\n",
    "        running_train_loss = 0.0\n",
    "\n",
    "        # Start timer.\n",
    "        since = time.time()\n",
    "\n",
    "        for i, data in enumerate(dataloader_train):\n",
    "\n",
    "            # Get the inputs; data is a list of [inputs, labels].\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Enable training.\n",
    "            model.train()\n",
    "\n",
    "            # Zero the parameter gradients.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward: make predictions.\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute the loss and its gradients.\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Averaged loss across all training examples * batch_size.\n",
    "            running_train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            if i % 5000 == 4999:\n",
    "                print(f'T[{epoch + 1}, {i + 1:5d}]')\n",
    "\n",
    "            # Adjust learning weights.\n",
    "            optimizer.step()\n",
    "\n",
    "        # Loss averaged across all training examples for the current epoch.\n",
    "        epoch_train_loss = running_train_loss / len(dataloader_train.sampler)\n",
    "\n",
    "        # Change model to evaluation mode.\n",
    "        model.eval()\n",
    "\n",
    "        # Initialize validating loss.\n",
    "        running_val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for j, vdata in enumerate(dataloader_val):\n",
    "\n",
    "                # Get the inputs; data is a list of [inputs, labels].\n",
    "                vinputs, vlabels = vdata[0].to(device), vdata[1].to(device)\n",
    "\n",
    "                # Forward: make predictions.\n",
    "                voutputs = model(vinputs)\n",
    "\n",
    "                # Compute the loss (w/o gradients).\n",
    "                vloss = criterion(voutputs, vlabels)\n",
    "\n",
    "                # Averaged loss across all validating examples * batch_size.\n",
    "                running_val_loss += vloss.item() * vinputs.size(0)\n",
    "\n",
    "                if j % 1000 == 999:\n",
    "                    print(f'V[{epoch + 1}, {j + 1:5d}]')\n",
    "\n",
    "        # Loss averaged across all validating examples for the current epoch.\n",
    "        epoch_val_loss = running_val_loss / len(dataloader_val.sampler)\n",
    "\n",
    "        # Append loss values.\n",
    "        loss_values['train'].append(epoch_train_loss)\n",
    "        loss_values['val'].append(epoch_val_loss)\n",
    "\n",
    "        # End timer.\n",
    "        time_elapsed = time.time() - since\n",
    "        total_time += time_elapsed\n",
    "\n",
    "        # Show stats.\n",
    "        print(f'Epoch: {epoch} | '\n",
    "              f'Train loss: {epoch_train_loss:.4f} | '\n",
    "              f'Val loss: {epoch_val_loss:.4f} | '\n",
    "              f'Elapsed: {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "\n",
    "    print(f'\\nTraining completed in {total_time // 60:.0f}m '\n",
    "          f'{total_time % 60:.0f}s')\n",
    "\n",
    "    return loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3a7f82-4423-4d81-85a8-0ecbaba41c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(loss_history, title='', save_fig=False):\n",
    "    \"\"\"\n",
    "    Function for plotting the training and validation losses\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    plt.plot(loss_history['train'], label='Train')\n",
    "    plt.plot(loss_history['val'], label='Validation')\n",
    "    plt.xlabel('Epoch', labelpad=15)\n",
    "    plt.ylabel('Loss', labelpad=15)\n",
    "    plt.title(title)\n",
    "    plt.gcf().subplots_adjust(bottom=0.15)\n",
    "    plt.gcf().subplots_adjust(left=0.15)\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if save_fig:\n",
    "        fig.savefig('plt_loss_values.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ff272e-4786-4a49-b7fc-73ce774a88af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_on_test(model, device):\n",
    "    \"\"\"\n",
    "    Function to evaluate the performance\n",
    "    of the model on the test dataset.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Avoiding \"CUDA out of memory\" in PyTorch.\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Since we're not training, we don't need to calculate\n",
    "    # the gradients for our outputs with torch.no_grad():\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(dataloader_test):\n",
    "\n",
    "            # Dataset.\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Calculate outputs by running images through the network.\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # The class with the highest energy is what we\n",
    "            # choose as prediction.\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Progress bar.\n",
    "            if i % 50 == 49:\n",
    "                print(f'Progress: {100 * i // len(dataloader_test)}%',\n",
    "                      end='\\r',\n",
    "                      flush=True)\n",
    "\n",
    "    print(f'Accuracy of the network on the {total} '\n",
    "          f'test images: {100 * correct // total}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df4c48da-0289-4350-8641-62c207d44143",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18762958-4bb5-4a9e-a642-e5cecbc0f8f1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce24b86-e4e5-442a-876a-782db427e0c3",
   "metadata": {},
   "source": [
    "# ResNet18 from scrath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b72a3-8fd8-45fe-8353-e77cdc5f99d6",
   "metadata": {},
   "source": [
    "## Definition and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b373932-506b-45a0-9301-d182e038d965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: resnet with random weights.\n",
    "model = torchvision.models.resnet18(weights=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8627587-6558-4637-b5b2-f8e0cdc7b3ea",
   "metadata": {},
   "source": [
    "## Adjust final layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d714e83-002f-4f1a-b240-cf7e80ae41ca",
   "metadata": {},
   "source": [
    "Type: linear not softmax for the moment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974ad1ef-8697-41ab-a1af-1b6f615715c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check old final layer.\n",
    "print(model.fc)\n",
    "\n",
    "# Get the number of input features to the layer.\n",
    "num_ftrs = model.fc.in_features\n",
    "print(num_ftrs)\n",
    "\n",
    "# Adjust the final layer to the current number of classes.\n",
    "model.fc = torch.nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "# Check new final layer.\n",
    "print(model.fc)\n",
    "\n",
    "# Freezing all the network except the final layer.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Model structure.\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(batch_size, 3, input_size, input_size),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fdf194-24c8-45c3-bf12-d6ac176df30e",
   "metadata": {},
   "source": [
    "## Loss fcn and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea9cdf-c59e-4e10-94b5-f6017bda668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: cross-entropy loss.\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizers: specified in the torch.optim package\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ee9848-8c21-489d-8adc-2fc0e0bff9b0",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba464d96-1913-43ef-96c4-59b5fdf9b65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = train_model(\n",
    "    model,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "plot_losses(loss_history, 'Model w/o pretrained weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0504b3-ae1c-4836-87e9-3c45e93b92d7",
   "metadata": {},
   "source": [
    "## Check performance on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5515fcfa-ed16-42f9-8b70-992fde11c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_on_test(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d101e8-426c-408d-a5fc-345d08a4434d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d76c1c-8bf2-4b5e-ae24-9fd71ab6b7b0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4b22ad-185d-4251-8545-744f9e403c59",
   "metadata": {},
   "source": [
    "# ResNet18 with pretrained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e46b01-7e1d-4215-b2ae-c0afa84c82ac",
   "metadata": {},
   "source": [
    "## Definition and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472cdf9a-2854-4bd0-8ef5-4e5d179f0019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: resnet with pretrained weights.\n",
    "del model\n",
    "model = torchvision.models.resnet18(\n",
    "    weights=torchvision.models.ResNet18_Weights.DEFAULT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb9f8c6-dc14-4557-9ed2-b9d6084093b5",
   "metadata": {},
   "source": [
    "## Adjust final layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a63f366-3feb-40fa-bbcf-117fbca74817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check old final layer.\n",
    "print(model.fc)\n",
    "\n",
    "# Get the number of input features to the layer.\n",
    "num_ftrs = model.fc.in_features\n",
    "print(num_ftrs)\n",
    "\n",
    "# Adjust the final layer to the current number of classes.\n",
    "model.fc = torch.nn.Linear(num_ftrs, len(class_names))\n",
    "\n",
    "# Parameters of newly constructed modules\n",
    "# have requires_grad=True by default.\n",
    "# Check new final layer.\n",
    "print(model.fc)\n",
    "\n",
    "# Freezing all the network except the final layer.\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Model structure.\n",
    "summary(\n",
    "    model,\n",
    "    input_size=(batch_size, 3, input_size, input_size),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e916e25-8b38-4e14-beb4-f311126e01f1",
   "metadata": {},
   "source": [
    "## Loss fcn and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaccb2dc-7957-4857-9bf7-b9eab949bee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: cross-entropy loss.\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizers: specified in the torch.optim package\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425ec5c5-ddc4-4938-9720-8e07068997d0",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ea3d48-0270-41dc-a48d-15953ffb23e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = train_model(\n",
    "    model,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "plot_losses(loss_history, 'Model w/ pretrained weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a40815-9743-42c6-8643-a963ce8533e6",
   "metadata": {},
   "source": [
    "## Check performance on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d9e847-5b2e-49fc-ad8e-92529b5410e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_on_test(model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bba927-e499-45b7-9d32-bd5e83b8d257",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a486bc-8b38-451a-9424-477585524559",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f806d186-1c7c-4423-8337-5d7f9433c746",
   "metadata": {},
   "source": [
    "# SSL model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1839bbef-1ec9-4899-972b-9d6db8f2613c",
   "metadata": {},
   "source": [
    "## Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7760fc7-5b30-4490-8ac5-70ab237d6dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State model class.\n",
    "resnet18 = torchvision.models.resnet18(weights=None)\n",
    "\n",
    "# Only backbone (w/o final fc layer).\n",
    "pt_backbone = torch.nn.Sequential(*list(resnet18.children())[:-1])\n",
    "\n",
    "# Loading model.\n",
    "filename = 'pytorch_models/simsiam_backbone_resnet18'\n",
    "pt_backbone.load_state_dict(torch.load(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b953213-478a-41fc-8f77-c418c5cf9def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model is loaded on GPU.\n",
    "next(pt_backbone.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bebf71e-7453-442a-898a-1a38825e025b",
   "metadata": {},
   "source": [
    "## Checking the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d413d46-02cf-49a2-9a86-b39fbfaac08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First convolutional layer weights.\n",
    "# print(backbone)\n",
    "print(pt_backbone[0])\n",
    "print(pt_backbone[0].weight[63])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd91df-abe1-42d3-ace9-8a8b45fbb0f8",
   "metadata": {},
   "source": [
    "## Adding a final linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b768a0a1-85c5-40a4-b843-4d50d44fd161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a linear layer on top of the model (linear classifier).\n",
    "model_ssl = torch.nn.Sequential(\n",
    "    pt_backbone,\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(in_features=512, out_features=len(class_names), bias=True),\n",
    "    # torch.nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "# Freezing all the network except the final layer.\n",
    "for param in model_ssl.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model_ssl[2].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Model structure.\n",
    "summary(\n",
    "    model_ssl,\n",
    "    input_size=(batch_size, 3, input_size, input_size),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80c0096-fb2f-4183-bdab-dfc345be59c7",
   "metadata": {},
   "source": [
    "## Loss fcn and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f3ed4b-1948-4843-96ca-b4cced958a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function: cross-entropy loss.\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizers: specified in the torch.optim package\n",
    "optimizer = torch.optim.Adam(model_ssl.parameters(),\n",
    "                             lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a106ebc3-d159-45f8-b956-abd33add0552",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c9d4f1-bc8a-45fe-88f5-dbcb71b0c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = train_model(\n",
    "    model_ssl,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    epochs=EPOCHS\n",
    ")\n",
    "\n",
    "plot_losses(loss_history, 'Model w/ ssl pretrained weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7815545a-4949-41fa-b208-774516170576",
   "metadata": {},
   "source": [
    "## Checking the weights after training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea1ae5-4c44-4c2a-8efe-ac210a30ed79",
   "metadata": {},
   "source": [
    "They should have remained the same (frozen) except for the final layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f242c-38db-4d11-b84b-4bbab655297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First convolutional layer weights.\n",
    "# print(backbone)\n",
    "print(pt_backbone[0])\n",
    "print(pt_backbone[0].weight[63])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9dff9a-1277-4301-b08e-8152110abe26",
   "metadata": {},
   "source": [
    "## Check performance on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2636a4a8-8ee4-4861-9aa8-920f0df40b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_on_test(model_ssl, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1f373b-af92-4595-8676-46728d926f92",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eca1e9-6cc7-4cdc-881a-1551111223fa",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cac558-c4a4-489a-9036-1a3e1a01dcfe",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ad0aa-d143-42dd-96f9-63c9cf6ad81f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b11e4a-d913-4508-80ad-b7d45eb0a66e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3094e101-bd6d-46b0-85ee-ea4f54b73c8d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6141892-5b73-4968-98e2-61837b6a244f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fe40ed-ca86-4418-8cec-1500c0ae480e",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f27b2f-fe4c-4309-8fa4-991b2e03aaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a linear layer on top of the model (linear classifier).\n",
    "model_ft = torch.nn.Sequential(\n",
    "    pretrained_model,\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(in_features=512, out_features=num_classes, bias=True),\n",
    "    # torch.nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a3d5c8-c1de-480b-876e-fe1fdf9f69e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model_ft, input_size=(batch_size, 3, input_size, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eafe15c-247d-4bd4-804d-47f34880d071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = torch.optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860b3244-9d30-41ce-ae4d-5e75cfbebd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e100de22-9e17-4d1c-87fb-a6c965834b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure(figsize=(10, 16))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {class_names[preds[j]]} |\\n'\n",
    "                             f'real: {class_names[labels.cpu().data[j]]}')\n",
    "                \n",
    "                plt.imshow(torch.permute(inputs.cpu().data[j], (1, 2, 0)))\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2fe63a-4c23-4c74-92db-905a9d403c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(model_ft, num_images=8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lulc-venv",
   "language": "python",
   "name": "lulc-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
