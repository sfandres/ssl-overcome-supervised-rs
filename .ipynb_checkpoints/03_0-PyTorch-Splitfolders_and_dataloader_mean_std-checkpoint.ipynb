{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdfe9a2-c9bd-4888-8328-957001cd2d3d",
   "metadata": {},
   "source": [
    "**DATASET HANDLING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190f7cd-02a9-4b8e-8b35-f27fffee6fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a0ac0-39cf-4d54-8a6e-93215e337037",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff0cfd2-d886-4359-bc50-79d5e25297d1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de6edb0-d5dc-4168-a31a-bdb56be4ab5e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25072781-af02-4f95-b232-2f83ae72b0a5",
   "metadata": {},
   "source": [
    "# Dataset stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb9dbab-94e5-4549-87ab-6725a3b8d1fe",
   "metadata": {},
   "source": [
    "I use this code to check the resulting number of samples per class after splitting the target dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d08339-c54e-4622-8920-635314295344",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4379417e-0911-4747-b3e9-6bb897531bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d88e1-ae09-499d-a20b-1724268cc26b",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de7c911-200d-4f8c-b62f-65255f04c53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target dataset.\n",
    "initial_dir_dataset = ('datasets/0_Raw/'\n",
    "                       'Sentinel2GlobalLULC_full_raw/'\n",
    "                       'Sentinel2LULC_JPEG/')\n",
    "\n",
    "# Loading the three datasets.\n",
    "data = torchvision.datasets.ImageFolder(initial_dir_dataset)\n",
    "\n",
    "# Get classes and number of samples per class.\n",
    "class_names = data.classes\n",
    "samples_per_class = np.unique(data.targets, return_counts=True)[1]\n",
    "\n",
    "# Building the dataframe.\n",
    "df = pd.DataFrame(class_names, columns=['Class'])\n",
    "df.set_index('Class', drop=True, inplace=True)\n",
    "df['100%_samples'] = samples_per_class\n",
    "df['E1-T-95%'] = (df['100%_samples']*0.95).astype(int)\n",
    "df['E1-V-1.75%'] = (df['100%_samples']*0.175).astype(int)\n",
    "df['E1-T-3.25%'] = (df['100%_samples']*0.325).astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980098f6-8d45-4873-bd68-fc9c1dee3ed3",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca21427c-8634-4b89-ac05-b0f02d0476c1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c39d1a-c859-45ec-bb95-d1aaaf526436",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Split the dataset folder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0707550a-b222-4ec8-925c-e9b096557b12",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1492e460-62a9-43f5-980e-d097abb3f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import splitfolders\n",
    "import utils\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5683c5d6-3773-4de9-b42b-75c9be60546c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = utils.Experiment()\n",
    "exp.reproducibility()\n",
    "print(exp.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa54bc2-1d7d-4864-9233-e82477d98e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_dir_dataset = ('datasets/0_Raw/'\n",
    "                       'Sentinel2GlobalLULC_full_raw/'\n",
    "                       'Sentinel2LULC_JPEG/')\n",
    "\n",
    "print(initial_dir_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebbf3a5-2956-4b33-9c19-aebcd44d59bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imbalanced dataset (entire dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906d1aa3-0712-4599-994b-3dc5b3e36093",
   "metadata": {},
   "source": [
    "### Create the ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061c93ca-1cad-4c5e-a038-a12e9714fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target division according to the train dataset.\n",
    "train = [.99, .9, .7, .5, .3, .1, .01, .001]\n",
    "val, test = [], []\n",
    "\n",
    "# List of ratios to create the datasets.\n",
    "ratios = []\n",
    "\n",
    "# Iterate over the splits:\n",
    "for i, train_s in enumerate(train):\n",
    "\n",
    "    # Append number of validation and test samples.\n",
    "    val_s = round((1 - train_s) * .2, 4)\n",
    "    test_s = round(1 - train_s - val_s, 4)\n",
    "    val.append(val_s)\n",
    "    test.append(test_s)\n",
    "\n",
    "    # Stats.\n",
    "    sum_s = train_s + val_s + test_s\n",
    "    print(f'{i}- train: {train_s:.3f}   '\n",
    "          f'val: {val_s:.4f}   '\n",
    "          f'test: {test_s:.4f}   '\n",
    "          f'sum: {sum_s}')\n",
    "\n",
    "    # Save the ratio in a list.\n",
    "    ratios.append((train_s,\n",
    "                   val_s,\n",
    "                   test_s))\n",
    "\n",
    "# Print the list of ratios\n",
    "print(ratios)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e46071b-99d7-41df-a684-83f5c4c0b366",
   "metadata": {},
   "source": [
    "### Create the folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e330924f-4239-4088-a1bf-c2bf9b3ef536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split with a ratio.\n",
    "# To only split into training and validation set,\n",
    "# set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "# ratio = (.7, .1, .2)\n",
    "# ratio = (.01, .01, .98)\n",
    "\n",
    "output_dir_datasets = 'datasets'\n",
    "\n",
    "for ratio in ratios:\n",
    "\n",
    "    # Forming dataset's name.\n",
    "    dataset_name = (f'Sentinel2GlobalLULC'\n",
    "                    f'-ratio={ratio}'\n",
    "                    f'-seed={exp.seed}')\n",
    "\n",
    "    print(f'Building dataset {dataset_name}...')\n",
    "\n",
    "    # Split the dataset (default values).\n",
    "    splitfolders.ratio(initial_dir_dataset,\n",
    "                       output=os.path.join(output_dir_datasets,\n",
    "                                           dataset_name),\n",
    "                       seed=exp.seed,\n",
    "                       ratio=ratio,\n",
    "                       group_prefix=None,\n",
    "                       move=False)\n",
    "\n",
    "    print('Completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b141bd-c8f8-4939-a7c4-08638a19a307",
   "metadata": {},
   "source": [
    "## Val and test balanced (entire dataset)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73cbb6b8-2305-4c3c-9a24-8941a9f4ce6b",
   "metadata": {},
   "source": [
    "# Split val/test with a fixed number of items, e.g. `(100, 100)`, for each set.\n",
    "# To only split into train-val set, use a single number to `fixed`, i.e., `10`.\n",
    "# Set 3 values, e.g. `(300, 100, 100)`, to limit the number of training values.\n",
    "\n",
    "fixed = (100, 150)\n",
    "dataset_name = f'datasets/Sentinel2GlobalLULC_full' \\\n",
    "               f'-fixed={fixed}' \\\n",
    "               f'-seed={SEED}'\n",
    "\n",
    "splitfolders.fixed(data_dir_initial,\n",
    "                   output=dataset_name,\n",
    "                   seed=SEED,\n",
    "                   fixed=fixed,\n",
    "                   oversample=False,  # Does not duplicate train samples.\n",
    "                   group_prefix=None,\n",
    "                   move=False)  # Default values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2b026d-e12b-482d-934d-acca828a0c3b",
   "metadata": {},
   "source": [
    "I cannot give more samples to the validation and test datasets since the class with fewer samples has only 353 (27)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a70fbbf-0ee4-4db3-87e8-d99c4419809f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09562a1-4066-42e1-a525-90b2ecbf3c91",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596485c2-1e41-4924-aeae-2fdab33abd12",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compute the mean and std of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6442ba-d2a0-466a-b1c8-ae2d2648a92e",
   "metadata": {},
   "source": [
    "## Libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8098771-cad2-4577-9b54-3ed8458ba6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d1a3a0-6b70-4b81-9af3-cf6746b534b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(listdir_fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72026024-e0bf-4cb6-8c60-27e9b2a0ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(get_mean_std_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eff356-1df3-4c32-9b2a-ad2ddf6e76dc",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2306440a-afe8-43ee-8e65-a9aeab418b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = utils.Experiment()\n",
    "exp.reproducibility()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b5e75-6a50-483a-a4a7-4b285a13d274",
   "metadata": {},
   "source": [
    "## Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8cd902-27f0-4646-b463-35e6a0664f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of trained models.\n",
    "datasets_dir = 'datasets/'\n",
    "\n",
    "# Get the subsets with full path.\n",
    "data_dirs = utils.listdir_fullpath(datasets_dir)\n",
    "\n",
    "# Leave out unwanted subsets.\n",
    "data_dirs = data_dirs[2:]\n",
    "for dirs in data_dirs:\n",
    "    print(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c55be-f02e-46d1-859c-b2379febfa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization.\n",
    "splits = ['train', 'val', 'test']\n",
    "filename = 'dataset_mean_std.txt'\n",
    "\n",
    "# Loop over the datasets (except raw and clothing).\n",
    "for data_dir in data_dirs:\n",
    "\n",
    "    # Create path to the txt file.\n",
    "    filepath = os.path.join(data_dir, filename)\n",
    "\n",
    "    # Removing the old txt file if exists.\n",
    "    if os.path.exists(filepath):\n",
    "        os.remove(filepath)\n",
    "        print('Old txt file removed and new one created.')\n",
    "    else:\n",
    "        print('New txt file created.')\n",
    "\n",
    "    # Creating/opening the file.\n",
    "    f = open(filepath, 'w')\n",
    "\n",
    "    # Loading the datasets into a dic.\n",
    "    datasets = {x: torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x),\n",
    "        transform=torchvision.transforms.ToTensor()\n",
    "    ) for x in splits}\n",
    "\n",
    "    # Creating the dataloaders into a dic.\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(\n",
    "        datasets[x],\n",
    "        batch_size=128,\n",
    "        worker_init_fn=exp.seed_worker,\n",
    "        generator=exp.g\n",
    "    ) for x in splits}\n",
    "\n",
    "    # Loop over the train, val, and test datasets.\n",
    "    for x in splits:\n",
    "\n",
    "        # Computation.\n",
    "        print(f'{data_dir}/{x}/')\n",
    "        print(f'Samples to be processed: '\n",
    "              f'{len(dataloaders[x].dataset)}')\n",
    "        mean, std = utils.get_mean_std_dataloader(dataloaders[x])\n",
    "        print(mean)\n",
    "        print(std)\n",
    "\n",
    "        # Write to file.\n",
    "        f.write(f'{x}\\n')\n",
    "        f.write(f'{mean}\\n')\n",
    "        f.write(f'{std}\\n')\n",
    "\n",
    "    # Close file and print a space.\n",
    "    f.close()\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfcdc82-813f-49ba-a51d-fe045710e03c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1687776-490d-4d67-a323-a63276e70739",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lulc-venv",
   "language": "python",
   "name": "lulc-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
