{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdfe9a2-c9bd-4888-8328-957001cd2d3d",
   "metadata": {},
   "source": [
    "**DATASET HANDLING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190f7cd-02a9-4b8e-8b35-f27fffee6fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51a0ac0-39cf-4d54-8a6e-93215e337037",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4fb5df-2719-4007-b5fa-1ce43a06d73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility.\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980098f6-8d45-4873-bd68-fc9c1dee3ed3",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca21427c-8634-4b89-ac05-b0f02d0476c1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c39d1a-c859-45ec-bb95-d1aaaf526436",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Split the dataset folder"
   ]
  },
  {
   "cell_type": "raw",
   "id": "005d2f30-dd21-44ac-83ef-b9efccb39125",
   "metadata": {},
   "source": [
    "import splitfolders\n",
    "\n",
    "data_dir_initial = 'datasets/0_Raw/' \\\n",
    "                   'Sentinel2GlobalLULC_full_raw/' \\\n",
    "                   'Sentinel2LULC_JPEG/'\n",
    "\n",
    "print(data_dir_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebbf3a5-2956-4b33-9c19-aebcd44d59bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Full dataset (imbalanced)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80df4b38-ea7f-44db-ab5c-11e0ba081877",
   "metadata": {},
   "source": [
    "# Split with a ratio.\n",
    "# To only split into training and validation set,\n",
    "# set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "\n",
    "ratio = (.7, .1, .2)\n",
    "dataset_name = f'datasets/Sentinel2GlobalLULC_full' \\\n",
    "               f'-ratio={ratio}' \\\n",
    "               f'-seed={SEED}'\n",
    "\n",
    "splitfolders.ratio(data_dir_initial,\n",
    "                   output=dataset_name,\n",
    "                   seed=SEED,\n",
    "                   ratio=ratio,\n",
    "                   group_prefix=None,\n",
    "                   move=False)  # Default values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af15d6e2-2ff8-4fd2-8c84-3d78150200fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reduced dataset (imbalanced)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9420920c-1e4f-4f12-948c-6dfc473c709f",
   "metadata": {},
   "source": [
    "# Split with a ratio.\n",
    "# To only split into training and validation set,\n",
    "# set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "\n",
    "ratio = (.01, .01, .98)\n",
    "dataset_name = f'datasets/Sentinel2GlobalLULC_full' \\\n",
    "               f'-ratio={ratio}' \\\n",
    "               f'-seed={SEED}'\n",
    "\n",
    "splitfolders.ratio(data_dir_initial,\n",
    "                   output=dataset_name,\n",
    "                   seed=SEED,\n",
    "                   ratio=ratio,\n",
    "                   group_prefix=None,\n",
    "                   move=False)  # Default values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b141bd-c8f8-4939-a7c4-08638a19a307",
   "metadata": {},
   "source": [
    "## Full dataset (val and test balanced)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73cbb6b8-2305-4c3c-9a24-8941a9f4ce6b",
   "metadata": {},
   "source": [
    "# Split val/test with a fixed number of items, e.g. `(100, 100)`, for each set.\n",
    "# To only split into train-val set, use a single number to `fixed`, i.e., `10`.\n",
    "# Set 3 values, e.g. `(300, 100, 100)`, to limit the number of training values.\n",
    "\n",
    "fixed = (100, 150)\n",
    "dataset_name = f'datasets/Sentinel2GlobalLULC_full' \\\n",
    "               f'-fixed={fixed}' \\\n",
    "               f'-seed={SEED}'\n",
    "\n",
    "splitfolders.fixed(data_dir_initial,\n",
    "                   output=dataset_name,\n",
    "                   seed=SEED,\n",
    "                   fixed=fixed,\n",
    "                   oversample=False,  # Does not duplicate train samples.\n",
    "                   group_prefix=None,\n",
    "                   move=False)  # Default values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2b026d-e12b-482d-934d-acca828a0c3b",
   "metadata": {},
   "source": [
    "I cannot give more samples to the validation and test datasets since the class with fewer samples has only 353 (27)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a70fbbf-0ee4-4db3-87e8-d99c4419809f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09562a1-4066-42e1-a525-90b2ecbf3c91",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596485c2-1e41-4924-aeae-2fdab33abd12",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compute the mean and std of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6442ba-d2a0-466a-b1c8-ae2d2648a92e",
   "metadata": {},
   "source": [
    "## Libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8098771-cad2-4577-9b54-3ed8458ba6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d1a3a0-6b70-4b81-9af3-cf6746b534b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(listdir_fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72026024-e0bf-4cb6-8c60-27e9b2a0ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(get_mean_std_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eff356-1df3-4c32-9b2a-ad2ddf6e76dc",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2306440a-afe8-43ee-8e65-a9aeab418b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = utils.Experiment()\n",
    "exp.reproducibility()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b5e75-6a50-483a-a4a7-4b285a13d274",
   "metadata": {},
   "source": [
    "## Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8cd902-27f0-4646-b463-35e6a0664f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of trained models.\n",
    "datasets_dir = 'datasets/'\n",
    "\n",
    "# Get the subsets with full path.\n",
    "data_dirs = utils.listdir_fullpath(datasets_dir)\n",
    "\n",
    "# Leave out unwanted subsets.\n",
    "data_dirs = data_dirs[2:]\n",
    "for dirs in data_dirs:\n",
    "    print(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274c55be-f02e-46d1-859c-b2379febfa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization.\n",
    "splits = ['train', 'val', 'test']\n",
    "filename = 'dataset_mean_std.txt'\n",
    "\n",
    "# Loop over the datasets (except raw and clothing).\n",
    "for data_dir in data_dirs:\n",
    "\n",
    "    # Create path to the txt file.\n",
    "    filepath = os.path.join(data_dir, filename)\n",
    "\n",
    "    # Removing the old txt file if exists.\n",
    "    if os.path.exists(filepath):\n",
    "        os.remove(filepath)\n",
    "        print('Old txt file removed and new one created.')\n",
    "    else:\n",
    "        print('New txt file created.')\n",
    "\n",
    "    # Creating/opening the file.\n",
    "    f = open(filepath, 'w')\n",
    "\n",
    "    # Loading the datasets into a dic.\n",
    "    datasets = {x: torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x),\n",
    "        transform=torchvision.transforms.ToTensor()\n",
    "    ) for x in splits}\n",
    "\n",
    "    # Creating the dataloaders into a dic.\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(\n",
    "        datasets[x],\n",
    "        batch_size=128,\n",
    "        worker_init_fn=exp.seed_worker,\n",
    "        generator=exp.g\n",
    "    ) for x in splits}\n",
    "\n",
    "    # Loop over the train, val, and test datasets.\n",
    "    for x in splits:\n",
    "\n",
    "        # Computation.\n",
    "        print(f'{data_dir}/{x}/')\n",
    "        print(f'Samples processed: '\n",
    "              f'{len(dataloaders[x].dataset)}')\n",
    "        mean, std = utils.get_mean_std_dataloader(dataloaders[x])\n",
    "        print(mean)\n",
    "        print(std)\n",
    "\n",
    "        # Write to file.\n",
    "        f.write(x + '\\n')\n",
    "        f.write(str(mean) + '\\n')\n",
    "        f.write(str(std) + '\\n')\n",
    "\n",
    "    # Close file and print a space.\n",
    "    f.close()\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfcdc82-813f-49ba-a51d-fe045710e03c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1687776-490d-4d67-a323-a63276e70739",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lulc-venv",
   "language": "python",
   "name": "lulc-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
