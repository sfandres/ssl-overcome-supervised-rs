{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdfe9a2-c9bd-4888-8328-957001cd2d3d",
   "metadata": {},
   "source": [
    "**DATASET HANDLING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1190f7cd-02a9-4b8e-8b35-f27fffee6fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d51a0ac0-39cf-4d54-8a6e-93215e337037",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pycodestyle_on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff0cfd2-d886-4359-bc50-79d5e25297d1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de6edb0-d5dc-4168-a31a-bdb56be4ab5e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25072781-af02-4f95-b232-2f83ae72b0a5",
   "metadata": {},
   "source": [
    "# Dataset stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb9dbab-94e5-4549-87ab-6725a3b8d1fe",
   "metadata": {},
   "source": [
    "I use this code to check the resulting number of samples per class after splitting the target dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d08339-c54e-4622-8920-635314295344",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4379417e-0911-4747-b3e9-6bb897531bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sfandres/Documents/Git/lulc/lulc-venv/lib/python3.8/site-packages/torch/cuda/__init__.py:83: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d88e1-ae09-499d-a20b-1724268cc26b",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1de7c911-200d-4f8c-b62f-65255f04c53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>100%_samples</th>\n",
       "      <th>E1-T-95%</th>\n",
       "      <th>E1-V-1.75%</th>\n",
       "      <th>E1-T-3.25%</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01_BarrenLands___jpeg</th>\n",
       "      <td>14000</td>\n",
       "      <td>13300</td>\n",
       "      <td>2450</td>\n",
       "      <td>4550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02_MossAndLichen_jpeg</th>\n",
       "      <td>4656</td>\n",
       "      <td>4423</td>\n",
       "      <td>814</td>\n",
       "      <td>1513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03_Grasslands____jpeg</th>\n",
       "      <td>8869</td>\n",
       "      <td>8425</td>\n",
       "      <td>1552</td>\n",
       "      <td>2882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04_ShrublandOpen_jpeg</th>\n",
       "      <td>14000</td>\n",
       "      <td>13300</td>\n",
       "      <td>2450</td>\n",
       "      <td>4550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05_SrublandClose_jpeg</th>\n",
       "      <td>11937</td>\n",
       "      <td>11340</td>\n",
       "      <td>2088</td>\n",
       "      <td>3879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06_ForestsOpDeBr_jpeg</th>\n",
       "      <td>4437</td>\n",
       "      <td>4215</td>\n",
       "      <td>776</td>\n",
       "      <td>1442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07_ForestsClDeBr_jpeg</th>\n",
       "      <td>1348</td>\n",
       "      <td>1280</td>\n",
       "      <td>235</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08_ForestsDeDeBr_jpeg</th>\n",
       "      <td>14000</td>\n",
       "      <td>13300</td>\n",
       "      <td>2450</td>\n",
       "      <td>4550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09_ForestsOpDeNe_jpeg</th>\n",
       "      <td>10438</td>\n",
       "      <td>9916</td>\n",
       "      <td>1826</td>\n",
       "      <td>3392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10_ForestsClDeNe_jpeg</th>\n",
       "      <td>6380</td>\n",
       "      <td>6061</td>\n",
       "      <td>1116</td>\n",
       "      <td>2073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11_ForestsDeDeNe_jpeg</th>\n",
       "      <td>2880</td>\n",
       "      <td>2736</td>\n",
       "      <td>503</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12_ForestsOpEvBr_jpeg</th>\n",
       "      <td>567</td>\n",
       "      <td>538</td>\n",
       "      <td>99</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13_ForestsClEvBr_jpeg</th>\n",
       "      <td>1258</td>\n",
       "      <td>1195</td>\n",
       "      <td>220</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14_ForestsDeEvBr_jpeg</th>\n",
       "      <td>14000</td>\n",
       "      <td>13300</td>\n",
       "      <td>2450</td>\n",
       "      <td>4550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15_ForestsOpEvNe_jpeg</th>\n",
       "      <td>3914</td>\n",
       "      <td>3718</td>\n",
       "      <td>684</td>\n",
       "      <td>1272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16_ForestsClEvNe_jpeg</th>\n",
       "      <td>3872</td>\n",
       "      <td>3678</td>\n",
       "      <td>677</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17_ForestsDeEvNe_jpeg</th>\n",
       "      <td>13991</td>\n",
       "      <td>13291</td>\n",
       "      <td>2448</td>\n",
       "      <td>4547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18_WetlandMangro_jpeg</th>\n",
       "      <td>416</td>\n",
       "      <td>395</td>\n",
       "      <td>72</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19_WetlandSwamps_jpeg</th>\n",
       "      <td>487</td>\n",
       "      <td>462</td>\n",
       "      <td>85</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20_WetlandMarshl_jpeg</th>\n",
       "      <td>4205</td>\n",
       "      <td>3994</td>\n",
       "      <td>735</td>\n",
       "      <td>1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21_WaterBodyMari_jpeg</th>\n",
       "      <td>14000</td>\n",
       "      <td>13300</td>\n",
       "      <td>2450</td>\n",
       "      <td>4550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22_WaterBodyCont_jpeg</th>\n",
       "      <td>14000</td>\n",
       "      <td>13300</td>\n",
       "      <td>2450</td>\n",
       "      <td>4550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23_PermanentSnow_jpeg</th>\n",
       "      <td>14000</td>\n",
       "      <td>13300</td>\n",
       "      <td>2450</td>\n",
       "      <td>4550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24_CropSeasWater_jpeg</th>\n",
       "      <td>2004</td>\n",
       "      <td>1903</td>\n",
       "      <td>350</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25_CropCereaIrri_jpeg</th>\n",
       "      <td>842</td>\n",
       "      <td>799</td>\n",
       "      <td>147</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26_CropCereaRain_jpeg</th>\n",
       "      <td>1020</td>\n",
       "      <td>969</td>\n",
       "      <td>178</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27_CropBroadIrri_jpeg</th>\n",
       "      <td>353</td>\n",
       "      <td>335</td>\n",
       "      <td>61</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28_CropBroadRain_jpeg</th>\n",
       "      <td>413</td>\n",
       "      <td>392</td>\n",
       "      <td>72</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29_UrbanBlUpArea_jpeg</th>\n",
       "      <td>12590</td>\n",
       "      <td>11960</td>\n",
       "      <td>2203</td>\n",
       "      <td>4091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       100%_samples  E1-T-95%  E1-V-1.75%  E1-T-3.25%\n",
       "Class                                                                \n",
       "01_BarrenLands___jpeg         14000     13300        2450        4550\n",
       "02_MossAndLichen_jpeg          4656      4423         814        1513\n",
       "03_Grasslands____jpeg          8869      8425        1552        2882\n",
       "04_ShrublandOpen_jpeg         14000     13300        2450        4550\n",
       "05_SrublandClose_jpeg         11937     11340        2088        3879\n",
       "06_ForestsOpDeBr_jpeg          4437      4215         776        1442\n",
       "07_ForestsClDeBr_jpeg          1348      1280         235         438\n",
       "08_ForestsDeDeBr_jpeg         14000     13300        2450        4550\n",
       "09_ForestsOpDeNe_jpeg         10438      9916        1826        3392\n",
       "10_ForestsClDeNe_jpeg          6380      6061        1116        2073\n",
       "11_ForestsDeDeNe_jpeg          2880      2736         503         936\n",
       "12_ForestsOpEvBr_jpeg           567       538          99         184\n",
       "13_ForestsClEvBr_jpeg          1258      1195         220         408\n",
       "14_ForestsDeEvBr_jpeg         14000     13300        2450        4550\n",
       "15_ForestsOpEvNe_jpeg          3914      3718         684        1272\n",
       "16_ForestsClEvNe_jpeg          3872      3678         677        1258\n",
       "17_ForestsDeEvNe_jpeg         13991     13291        2448        4547\n",
       "18_WetlandMangro_jpeg           416       395          72         135\n",
       "19_WetlandSwamps_jpeg           487       462          85         158\n",
       "20_WetlandMarshl_jpeg          4205      3994         735        1366\n",
       "21_WaterBodyMari_jpeg         14000     13300        2450        4550\n",
       "22_WaterBodyCont_jpeg         14000     13300        2450        4550\n",
       "23_PermanentSnow_jpeg         14000     13300        2450        4550\n",
       "24_CropSeasWater_jpeg          2004      1903         350         651\n",
       "25_CropCereaIrri_jpeg           842       799         147         273\n",
       "26_CropCereaRain_jpeg          1020       969         178         331\n",
       "27_CropBroadIrri_jpeg           353       335          61         114\n",
       "28_CropBroadRain_jpeg           413       392          72         134\n",
       "29_UrbanBlUpArea_jpeg         12590     11960        2203        4091"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target dataset.\n",
    "data_dir_target = 'datasets/0_Raw/' \\\n",
    "                  'Sentinel2GlobalLULC_full_raw/' \\\n",
    "                  'Sentinel2LULC_JPEG/'\n",
    "\n",
    "# Loading the three datasets.\n",
    "data = torchvision.datasets.ImageFolder(data_dir_target)\n",
    "\n",
    "# Get classes and number of samples per class.\n",
    "class_names = data.classes\n",
    "samples_per_class = np.unique(data.targets, return_counts=True)[1]\n",
    "\n",
    "# Building the dataframe.\n",
    "df = pd.DataFrame(class_names, columns=['Class'])\n",
    "df.set_index('Class', drop=True, inplace=True)\n",
    "df['100%_samples'] = samples_per_class\n",
    "df['E1-T-95%'] = (df['100%_samples']*0.95).astype(int)\n",
    "df['E1-V-1.75%'] = (df['100%_samples']*0.175).astype(int)\n",
    "df['E1-T-3.25%'] = (df['100%_samples']*0.325).astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980098f6-8d45-4873-bd68-fc9c1dee3ed3",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca21427c-8634-4b89-ac05-b0f02d0476c1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c39d1a-c859-45ec-bb95-d1aaaf526436",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Split the dataset folder"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1a2bfc9f-c151-4792-b84b-44f5bff7c6bb",
   "metadata": {},
   "source": [
    "# Reproducibility.\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "raw",
   "id": "005d2f30-dd21-44ac-83ef-b9efccb39125",
   "metadata": {},
   "source": [
    "import splitfolders\n",
    "\n",
    "data_dir_initial = 'datasets/0_Raw/' \\\n",
    "                   'Sentinel2GlobalLULC_full_raw/' \\\n",
    "                   'Sentinel2LULC_JPEG/'\n",
    "\n",
    "print(data_dir_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebbf3a5-2956-4b33-9c19-aebcd44d59bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Full dataset (imbalanced)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80df4b38-ea7f-44db-ab5c-11e0ba081877",
   "metadata": {},
   "source": [
    "# Split with a ratio.\n",
    "# To only split into training and validation set,\n",
    "# set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "\n",
    "ratio = (.7, .1, .2)\n",
    "dataset_name = f'datasets/Sentinel2GlobalLULC_full' \\\n",
    "               f'-ratio={ratio}' \\\n",
    "               f'-seed={SEED}'\n",
    "\n",
    "splitfolders.ratio(data_dir_initial,\n",
    "                   output=dataset_name,\n",
    "                   seed=SEED,\n",
    "                   ratio=ratio,\n",
    "                   group_prefix=None,\n",
    "                   move=False)  # Default values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af15d6e2-2ff8-4fd2-8c84-3d78150200fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reduced dataset (imbalanced)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9420920c-1e4f-4f12-948c-6dfc473c709f",
   "metadata": {},
   "source": [
    "# Split with a ratio.\n",
    "# To only split into training and validation set,\n",
    "# set a tuple to `ratio`, i.e, `(.8, .2)`.\n",
    "\n",
    "ratio = (.01, .01, .98)\n",
    "dataset_name = f'datasets/Sentinel2GlobalLULC_full' \\\n",
    "               f'-ratio={ratio}' \\\n",
    "               f'-seed={SEED}'\n",
    "\n",
    "splitfolders.ratio(data_dir_initial,\n",
    "                   output=dataset_name,\n",
    "                   seed=SEED,\n",
    "                   ratio=ratio,\n",
    "                   group_prefix=None,\n",
    "                   move=False)  # Default values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b141bd-c8f8-4939-a7c4-08638a19a307",
   "metadata": {},
   "source": [
    "## Full dataset (val and test balanced)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "73cbb6b8-2305-4c3c-9a24-8941a9f4ce6b",
   "metadata": {},
   "source": [
    "# Split val/test with a fixed number of items, e.g. `(100, 100)`, for each set.\n",
    "# To only split into train-val set, use a single number to `fixed`, i.e., `10`.\n",
    "# Set 3 values, e.g. `(300, 100, 100)`, to limit the number of training values.\n",
    "\n",
    "fixed = (100, 150)\n",
    "dataset_name = f'datasets/Sentinel2GlobalLULC_full' \\\n",
    "               f'-fixed={fixed}' \\\n",
    "               f'-seed={SEED}'\n",
    "\n",
    "splitfolders.fixed(data_dir_initial,\n",
    "                   output=dataset_name,\n",
    "                   seed=SEED,\n",
    "                   fixed=fixed,\n",
    "                   oversample=False,  # Does not duplicate train samples.\n",
    "                   group_prefix=None,\n",
    "                   move=False)  # Default values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2b026d-e12b-482d-934d-acca828a0c3b",
   "metadata": {},
   "source": [
    "I cannot give more samples to the validation and test datasets since the class with fewer samples has only 353 (27)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a70fbbf-0ee4-4db3-87e8-d99c4419809f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09562a1-4066-42e1-a525-90b2ecbf3c91",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596485c2-1e41-4924-aeae-2fdab33abd12",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Compute the mean and std of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6442ba-d2a0-466a-b1c8-ae2d2648a92e",
   "metadata": {},
   "source": [
    "## Libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8098771-cad2-4577-9b54-3ed8458ba6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14d1a3a0-6b70-4b81-9af3-cf6746b534b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(listdir_fullpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72026024-e0bf-4cb6-8c60-27e9b2a0ac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(get_mean_std_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57eff356-1df3-4c32-9b2a-ad2ddf6e76dc",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2306440a-afe8-43ee-8e65-a9aeab418b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = utils.Experiment()\n",
    "exp.reproducibility()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8b5e75-6a50-483a-a4a7-4b285a13d274",
   "metadata": {},
   "source": [
    "## Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d8cd902-27f0-4646-b463-35e6a0664f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/Sentinel2GlobalLULC_full-fixed=(100, 150)-seed=42\n",
      "datasets/Sentinel2GlobalLULC_full-ratio=(0.01, 0.01, 0.98)-seed=42\n",
      "datasets/Sentinel2GlobalLULC_full-ratio=(0.7, 0.1, 0.2)-seed=42\n"
     ]
    }
   ],
   "source": [
    "# List of trained models.\n",
    "datasets_dir = 'datasets/'\n",
    "\n",
    "# Get the subsets with full path.\n",
    "data_dirs = utils.listdir_fullpath(datasets_dir)\n",
    "\n",
    "# Leave out unwanted subsets.\n",
    "data_dirs = data_dirs[2:]\n",
    "for dirs in data_dirs:\n",
    "    print(dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274c55be-f02e-46d1-859c-b2379febfa29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old txt file removed and new one created.\n",
      "datasets/Sentinel2GlobalLULC_full-fixed=(100, 150)-seed=42/train/\n",
      "Samples processed: 187627\n",
      "tensor([0.3350, 0.3388, 0.3616])\n",
      "tensor([0.2996, 0.2394, 0.2130])\n",
      "datasets/Sentinel2GlobalLULC_full-fixed=(100, 150)-seed=42/val/\n",
      "Samples processed: 2900\n",
      "tensor([0.2768, 0.2996, 0.3267])\n",
      "tensor([0.2352, 0.1857, 0.1670])\n",
      "datasets/Sentinel2GlobalLULC_full-fixed=(100, 150)-seed=42/test/\n",
      "Samples processed: 4350\n",
      "tensor([0.2741, 0.2973, 0.3245])\n",
      "tensor([0.2338, 0.1833, 0.1643])\n",
      "\n",
      "Old txt file removed and new one created.\n",
      "datasets/Sentinel2GlobalLULC_full-ratio=(0.01, 0.01, 0.98)-seed=42/train/\n",
      "Samples processed: 1938\n",
      "tensor([0.3341, 0.3395, 0.3636])\n",
      "tensor([0.2904, 0.2328, 0.2091])\n",
      "datasets/Sentinel2GlobalLULC_full-ratio=(0.01, 0.01, 0.98)-seed=42/val/\n",
      "Samples processed: 1938\n",
      "tensor([0.3357, 0.3382, 0.3616])\n",
      "tensor([0.2942, 0.2330, 0.2069])\n",
      "datasets/Sentinel2GlobalLULC_full-ratio=(0.01, 0.01, 0.98)-seed=42/test/\n",
      "Samples processed: 191001\n",
      "tensor([0.3327, 0.3372, 0.3603])\n",
      "tensor([0.2976, 0.2376, 0.2115])\n",
      "\n",
      "Old txt file removed and new one created.\n",
      "datasets/Sentinel2GlobalLULC_full-ratio=(0.7, 0.1, 0.2)-seed=42/train/\n",
      "Samples processed: 136403\n",
      "tensor([0.3329, 0.3373, 0.3603])\n",
      "tensor([0.2978, 0.2377, 0.2115])\n",
      "datasets/Sentinel2GlobalLULC_full-ratio=(0.7, 0.1, 0.2)-seed=42/val/\n",
      "Samples processed: 19478\n",
      "tensor([0.3318, 0.3363, 0.3597])\n",
      "tensor([0.2962, 0.2364, 0.2104])\n",
      "datasets/Sentinel2GlobalLULC_full-ratio=(0.7, 0.1, 0.2)-seed=42/test/\n",
      "Samples processed: 38996\n",
      "tensor([0.3328, 0.3375, 0.3605])\n",
      "tensor([0.2974, 0.2378, 0.2118])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialization.\n",
    "splits = ['train', 'val', 'test']\n",
    "filename = 'dataset_mean_std.txt'\n",
    "\n",
    "# Loop over the datasets (except raw and clothing).\n",
    "for data_dir in data_dirs:\n",
    "\n",
    "    # Create path to the txt file.\n",
    "    filepath = os.path.join(data_dir, filename)\n",
    "\n",
    "    # Removing the old txt file if exists.\n",
    "    if os.path.exists(filepath):\n",
    "        os.remove(filepath)\n",
    "        print('Old txt file removed and new one created.')\n",
    "    else:\n",
    "        print('New txt file created.')\n",
    "\n",
    "    # Creating/opening the file.\n",
    "    f = open(filepath, 'w')\n",
    "\n",
    "    # Loading the datasets into a dic.\n",
    "    datasets = {x: torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x),\n",
    "        transform=torchvision.transforms.ToTensor()\n",
    "    ) for x in splits}\n",
    "\n",
    "    # Creating the dataloaders into a dic.\n",
    "    dataloaders = {x: torch.utils.data.DataLoader(\n",
    "        datasets[x],\n",
    "        batch_size=128,\n",
    "        worker_init_fn=exp.seed_worker,\n",
    "        generator=exp.g\n",
    "    ) for x in splits}\n",
    "\n",
    "    # Loop over the train, val, and test datasets.\n",
    "    for x in splits:\n",
    "\n",
    "        # Computation.\n",
    "        print(f'{data_dir}/{x}/')\n",
    "        print(f'Samples to be processed: '\n",
    "              f'{len(dataloaders[x].dataset)}')\n",
    "        mean, std = utils.get_mean_std_dataloader(dataloaders[x])\n",
    "        print(mean)\n",
    "        print(std)\n",
    "\n",
    "        # Write to file.\n",
    "        f.write(f'{x}\\n')\n",
    "        f.write(f'{mean}\\n')\n",
    "        f.write(f'{std}\\n')\n",
    "\n",
    "    # Close file and print a space.\n",
    "    f.close()\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfcdc82-813f-49ba-a51d-fe045710e03c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1687776-490d-4d67-a323-a63276e70739",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lulc-venv",
   "language": "python",
   "name": "lulc-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
