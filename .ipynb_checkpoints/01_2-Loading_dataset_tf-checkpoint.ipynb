{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a45666-0767-454a-95c0-cb0bba962a9c",
   "metadata": {},
   "source": [
    "**PLAYING WITH THE TENSORFLOW API**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857047b6-0c47-4db4-8565-8be6490a4830",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510e028b-734a-4717-bb86-4fb7c25234b0",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b840970f-1d7a-4268-b519-00959104eaac",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f240f-3d46-4aa5-8b2d-68c80699d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential libraries.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import dataframe_image as dfi\n",
    "\n",
    "# Modules.\n",
    "import tensorflow.keras.layers as tfl\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Disable GPU.\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '-1'\n",
    "\n",
    "# Information.\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb513eb-7bab-454b-9908-9362f2a64a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33efd72-429d-4fa7-b6d4-a244d4a36a23",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be791cf0-76f7-428b-b06a-e8c7e15df019",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e461355d-fc35-41f2-9ff4-a70cf3ad9354",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0ec6c0-b484-4acb-819e-1f549bfc526f",
   "metadata": {},
   "source": [
    "## Split into training and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5fcce3-1187-4dcf-a9f9-5c8c513a6d60",
   "metadata": {},
   "source": [
    "When training and evaluating deep learning models in Keras, generating a dataset from image files stored on disk is simple and fast. Call `image_data_set_from_directory()` to read from the directory and create both training and validation datasets. \n",
    "\n",
    "If you're specifying a validation split, you'll also need to specify the subset for each portion. Just set the training set to `subset='training'` and the validation set to `subset='validation'`.\n",
    "\n",
    "You'll also set your seeds to match each other, so your training and validation sets don't overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d026eadb-b788-49fc-93eb-c69a29d34971",
   "metadata": {},
   "source": [
    "Then calling image_dataset_from_directory(main_directory, labels='inferred') will return a tf.data.Dataset that yields batches of images from the subdirectories class_a and class_b, together with labels 0 and 1 (0 corresponding to class_a and 1 corresponding to class_b)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1719085-284a-4666-88e1-d4f4f1b82712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Samples info.\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "path_dir = 'Sentinel2GlobalLULC/Sentinel2LULC_JPEG/' # /home/sfandres/Downloads/Sentinel-dataset/'    \n",
    "\n",
    "# Dataset info.\n",
    "split_train_val = 0.1    # 0.1\n",
    "shuffle = True\n",
    "\n",
    "# Train set.\n",
    "train_dataset = image_dataset_from_directory(path_dir,\n",
    "                                             label_mode='categorical',\n",
    "                                             batch_size=BATCH_SIZE,\n",
    "                                             image_size=IMG_SIZE,\n",
    "                                             shuffle=shuffle,\n",
    "                                             seed=42,\n",
    "                                             validation_split=split_train_val,\n",
    "                                             subset='training')\n",
    "\n",
    "# Validation set.\n",
    "validation_dataset = image_dataset_from_directory(path_dir,\n",
    "                                                  label_mode='categorical',\n",
    "                                                  batch_size=BATCH_SIZE,\n",
    "                                                  image_size=IMG_SIZE,\n",
    "                                                  shuffle=shuffle,\n",
    "                                                  seed=42,\n",
    "                                                  validation_split=split_train_val,\n",
    "                                                  subset='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88172005-9527-4ad3-9752-d488b293acea",
   "metadata": {},
   "source": [
    "As the original dataset doesn't contain a test set, you will create one. To do so, determine how many batches of data are available in the validation set using tf.data.experimental.cardinality, then move 20% of them to a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5883e8eb-3354-4c3e-be36-e7cf518d2bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set.\n",
    "ratio_val_test = 3    # 18\n",
    "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
    "test_dataset = validation_dataset.take(val_batches // ratio_val_test)\n",
    "validation_dataset = validation_dataset.skip(val_batches // ratio_val_test)\n",
    "\n",
    "validation_dataset, test_dataset = test_dataset, validation_dataset\n",
    "\n",
    "# # Show stats.\n",
    "# print('Training batches: %d' % tf.data.experimental.cardinality(train_dataset))\n",
    "# print('Training samples: ' + str(len(train_dataset) * BATCH_SIZE))\n",
    "\n",
    "# print('\\nValidation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
    "# print('Validation samples: ' + str(len(validation_dataset) * BATCH_SIZE))\n",
    "\n",
    "# print('\\nTest batches: %d' % tf.data.experimental.cardinality(test_dataset))\n",
    "# print('Test samples: ' + str(len(test_dataset) * BATCH_SIZE))\n",
    "\n",
    "# print('\\nTotal approx.: ' + str((len(train_dataset) + len(validation_dataset) + len(test_dataset)) * BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fdf82ec-f098-420e-8651-b564cbf6f08f",
   "metadata": {},
   "source": [
    "## Some stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8aff7f-0913-4f9d-8088-8b8ffa1acb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with the different classes.\n",
    "class_names = train_dataset.class_names\n",
    "n_classes = len(class_names)\n",
    "\n",
    "# Show more stats.\n",
    "print('Classes: ', class_names)\n",
    "print('Number of classes: ', n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810a44b3-789f-4046-894c-9733d18ca258",
   "metadata": {},
   "source": [
    "## Show some examples from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb96ffa2-d9e9-4655-bb8d-38d0be074c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example.\n",
    "plt.figure(figsize=(15, 10))\n",
    "for images, labels in train_dataset.take(1):    # Take a batch.\n",
    "    for i in range(9):                          # Take nine images.\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        # plt.title(class_names[labels[i]])                # No one-hot.\n",
    "        plt.title(class_names[np.argmax(labels[i])])       # One-hot.\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5f9f61-e861-4448-b019-213f50c82b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if the dataset is balanced\n",
    "# labels = []\n",
    "\n",
    "# for x, y in train_dataset:\n",
    "#     # If one hot encoded, then apply argmax.\n",
    "#     labels.append(np.argmax(y, axis=-1))\n",
    "\n",
    "#     # Not one hot encoded.\n",
    "#     # labels.append(y.numpy())\n",
    "\n",
    "# # Concatenate asuming dataset was batched.\n",
    "# labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "# # Count unique labels.\n",
    "# labels, n_samples = np.unique(labels, return_counts=True)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# bars = ax.barh(class_names, n_samples)\n",
    "# ax.bar_label(bars)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8c0240-b663-4ed1-a9cb-dbbf8c6b2886",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03582380-7d99-4ea0-aba0-f7e45c05283e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d560de5-758d-448b-bf59-4943b9ce69a6",
   "metadata": {},
   "source": [
    "# Preprocesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c57e382-d670-410f-9a71-88c2560ce96c",
   "metadata": {},
   "source": [
    "## Configure the dataset for performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99500df-1716-44fb-8da7-fcb4de4bd3b2",
   "metadata": {},
   "source": [
    "Using `prefetch()` prevents a memory bottleneck that can occur when reading from disk. It sets aside some data and keeps it ready for when it's needed, by creating a source dataset from your input data, applying a transformation to preprocess it, then iterating over the dataset one element at a time. Because the iteration is streaming, the data doesn't need to fit into memory.\n",
    "\n",
    "You can set the number of elements to prefetch manually, or you can use `tf.data.experimental.AUTOTUNE` to choose the parameters automatically. Autotune prompts `tf.data` to tune that value dynamically at runtime, by tracking the time spent in each operation and feeding those times into an optimization algorithm. The optimization algorithm tries to find the best allocation of its CPU budget across all tunable operations.\n",
    "\n",
    "Use buffered prefetching to load images from disk without having I/O become blocking. To learn more about this method see the data performance guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0512a10c-68bf-4df2-8d28-8218e95d078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7641ef29-6885-41ca-9b5c-8f2c0d5d2906",
   "metadata": {},
   "source": [
    "## Check if dataset is balanced (three datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc29d76-6459-4717-bfae-7668f2bbb9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = [train_dataset,\n",
    "                  validation_dataset,\n",
    "                  test_dataset]\n",
    "\n",
    "ds_labels = {}\n",
    "ds_samples = {}\n",
    "\n",
    "for ds, i in zip(target_dataset, range(len(target_dataset))):\n",
    "    labels = []\n",
    "    for x, y in ds:\n",
    "        # If one hot encoded, then apply argmax.\n",
    "        labels.append(np.argmax(y, axis=-1))\n",
    "\n",
    "        # Not one hot encoded.\n",
    "        # labels.append(y.numpy())\n",
    "\n",
    "    # Concatenate asuming dataset was batched.\n",
    "    labels = np.concatenate(labels, axis=0)\n",
    "\n",
    "    # Count unique labels.\n",
    "    ds_labels[i], ds_samples[i] = np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f287cfd-db01-4193-ac2f-17a49d2d5521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up subplot.\n",
    "fig, ax = plt.subplots(1, 3, sharex='col', sharey='row')\n",
    "\n",
    "# Set width and height.\n",
    "fig.set_figwidth(22)\n",
    "fig.set_figheight(10)\n",
    "\n",
    "for i in range(len(target_dataset)):\n",
    "    bars = ax[i].barh(class_names, ds_samples[i])    # class_names\n",
    "    ax[i].bar_label(bars)\n",
    "    ax[i].set_xlim(0, max(ds_samples[i]) + 2000/(1+i*2))\n",
    "\n",
    "# Hide x labels and tick labels for top plots\n",
    "# and y ticks for right plots.\n",
    "for axs in ax.flat:\n",
    "    axs.label_outer()\n",
    "    axs.set(xlabel='N samples')\n",
    "    axs.grid(color='gray', linestyle=':', linewidth=.5)\n",
    "    # axs.legend(loc='best')\n",
    "\n",
    "# Show stats.\n",
    "print('Training batches: %d' % tf.data.experimental.cardinality(train_dataset))\n",
    "print('Training samples: ' + str(len(train_dataset) * BATCH_SIZE))\n",
    "\n",
    "print('\\nValidation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
    "print('Validation samples: ' + str(len(validation_dataset) * BATCH_SIZE))\n",
    "\n",
    "print('\\nTest batches: %d' % tf.data.experimental.cardinality(test_dataset))\n",
    "print('Test samples: ' + str(len(test_dataset) * BATCH_SIZE))\n",
    "\n",
    "print('\\nTotal approx.: ' + str((len(train_dataset) + len(validation_dataset) + len(test_dataset)) * BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e5bb3c-e0ab-44f3-bfa7-cba93b2c0c5a",
   "metadata": {},
   "source": [
    "## Use data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b3bd70-bff3-4ecd-8e33-7f23caa0d185",
   "metadata": {},
   "source": [
    "To increase diversity in the training set and help your model learn the data better, it's standard practice to augment the images by transforming them, i.e., randomly flipping and rotating them. Keras' Sequential API offers a straightforward method for these kinds of data augmentations, with built-in, customizable preprocessing layers. These layers are saved with the rest of your model and can be re-used later.  Ahh, so convenient! \n",
    "\n",
    "As always, you're invited to read the official docs, which you can find for data augmentation [here](https://www.tensorflow.org/tutorials/images/data_augmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31390e9-5da5-4887-8f6e-fdad5d8608ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This does not improve the results but I think it\n",
    "# is due to the nature of the dataset samples.\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "    tfl.RandomFlip(\"horizontal_and_vertical\", seed=42),\n",
    "    tfl.RandomRotation(0.2, seed=42),\n",
    "    tfl.RandomZoom(0.1, seed=42),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e368cefb-6150-47f9-914c-f912decf49c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, label in train_dataset.take(1):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    first_image, first_label = image[0], label[0]\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "        plt.imshow(augmented_image[0] / 255)\n",
    "        plt.title(class_names[np.argmax(first_label)])\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97006836-0f7d-4570-baaa-55fea03a8247",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226f2bbe-9cbc-459e-85f5-5b540c874f76",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd3aff0-df49-4c03-b164-4a1e80cc9bac",
   "metadata": {},
   "source": [
    "# Create the base model from the pre-trained CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d863cb0e-447e-4d19-acd1-1dd6cac113eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet import ResNet50, preprocess_input, decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b7d2ff-8c98-437e-80f4-248b95163aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aug = False\n",
    "model_name = 'ResNet50'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d3d782-5f3f-4d5f-8a81-87bc04c1ace6",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d861457-ddcc-4d3b-b8d1-c2856a0828ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(data_aug=False):\n",
    "\n",
    "    # Create the base model from the pre-trained model ResNet50\n",
    "    input_shape = IMG_SIZE + (3,)\n",
    "\n",
    "    # Loading the pre-trained model without the top layers.\n",
    "    base_model = ResNet50(include_top=False,\n",
    "                          weights='imagenet',\n",
    "                          input_shape=input_shape)\n",
    "\n",
    "    # Freeze the base model.\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Create the input layer.\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Apply data augmentation to the inputs.\n",
    "    if data_aug:\n",
    "        inputs = data_augmentation(inputs, training=True)\n",
    "\n",
    "    # Data preprocessing using the same weights the model was trained on.\n",
    "    x = preprocess_input(inputs)\n",
    "\n",
    "    # Set training to False to avoid keeping track of statistics in the batch norm layer.\n",
    "    x = base_model(x, training=False)\n",
    "\n",
    "    # Add the new Binary classification layers.\n",
    "    # Use global avg pooling to summarize the info in each channel.\n",
    "    x = tfl.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Include dropout to avoid overfitting.\n",
    "    x = tfl.Dropout(0.2)(x)\n",
    "\n",
    "    # Output layer.\n",
    "    x = tfl.Flatten()(x)\n",
    "    outputs = tfl.Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create model.\n",
    "    model = tf.keras.Model(inputs, outputs, name=model_name)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22d384a-1a00-4c03-a65d-4649c8c2f33d",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e5303-a3bd-420f-b353-a0fb21d71398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback: New print during fit.\n",
    "class PrintValTrainRatioCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\" - val/train: {:.2f}\".format(logs[\"val_loss\"] / logs[\"loss\"]))\n",
    "\n",
    "cb_val_train_ratio = PrintValTrainRatioCallback()\n",
    "\n",
    "# TensorBoard logs callback.\n",
    "def get_run_logdir(root_logdir):\n",
    "    import time\n",
    "    run_id = time.strftime('run-%Y_%m_%d-%H_%M_%S')\n",
    "    run_id = run_id + '-' + (model_name) + '-Data_aug_' + str(data_aug)\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, 'my_logs')\n",
    "run_logdir = get_run_logdir(root_logdir) # e.g., './my_logs/run_2019_06_07-15_15_22'\n",
    "\n",
    "cb_tensorboard = tf.keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "# Checkpoint callback: epoch in the file name.\n",
    "checkpoint_path =  model_name + '-epoch-{epoch:02d}-loss-{loss:.3f}-val_loss-{val_loss:.3f}-val_acc-{val_categorical_accuracy:.3f}.h5'\n",
    "checkpoint_filepath = os.path.join(run_logdir, checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    save_freq='epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f61387e-3b42-4685-9eb7-a4fe3fe59e03",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a84e35-f3d1-45cd-976f-bbf940505ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989bbcc-510d-4e78-8c3d-24ecda7c72e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new model instance.\n",
    "model = get_model(data_aug)\n",
    "\n",
    "# Compile.\n",
    "base_learning_rate = 0.001    # 0.001\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy(),\n",
    "                       tfa.metrics.F1Score(num_classes=n_classes, average='macro')])    # bigger penalisation when your model does not perform well with the minority classes.\n",
    "\n",
    "# Summary.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f60f9-b2c9-46f1-9524-c4e67c104bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with the new callback.\n",
    "initial_epochs = 10\n",
    "history = model.fit(train_dataset,\n",
    "                    epochs=initial_epochs,\n",
    "                    validation_data=validation_dataset,\n",
    "                    callbacks=[cb_val_train_ratio,\n",
    "                               cb_tensorboard,\n",
    "                               cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba1a7e6-d3fa-4042-b808-ba6a26971503",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['categorical_accuracy']\n",
    "val_acc = history.history['val_categorical_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.grid(color='gray', linestyle=':', linewidth=.8)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.grid(color='gray', linestyle=':', linewidth=.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096c80d3-d00c-4bc5-9ea4-a2ac11f3c51c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a139673-9b85-4038-abde-4ff3b3c275d2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979c3fc8-0055-4cd9-8929-b5e4470585e8",
   "metadata": {},
   "source": [
    "# Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7e5885-21b4-4a1d-8537-89e512c724fb",
   "metadata": {},
   "source": [
    "## Un-freeze the top layers of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa291f1-e4d2-4976-9482-2cd004bd4323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un-freeze the base_model.\n",
    "base_model = model.layers[3]     # model.get_layer('resnet50')\n",
    "base_model.trainable = True\n",
    "\n",
    "# Let's take a look to see how many layers are in the base model.\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards.\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the 'fine_tune_at' layer.\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Summary again.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab7fa8b-90ea-4bd4-a2e7-afbfdb806218",
   "metadata": {},
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185d99fb-207c-4648-8a9e-895db7f341e9",
   "metadata": {},
   "source": [
    "As you are training a much larger model and want to readapt the pretrained weights, it is important to use a lower learning rate at this stage. Otherwise, your model could overfit very quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ee99f0-9ce5-40f5-a97e-96b7d11467da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New compilation with lower lr.\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate / 10),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.CategoricalAccuracy(),\n",
    "                       tfa.metrics.F1Score(num_classes=n_classes, average='macro')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4afdadf-1468-42bf-a42d-a6a57f58d775",
   "metadata": {},
   "source": [
    "## Continue training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64db16cf-72bc-455e-addc-c468d6595d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tune_epochs = 10\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         validation_data=validation_dataset,\n",
    "                         callbacks=[cb_val_train_ratio,\n",
    "                                    cb_tensorboard,\n",
    "                                    cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f835cf03-3e86-4d0d-b8fb-c40903937c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc += history_fine.history['categorical_accuracy']\n",
    "val_acc += history_fine.history['val_categorical_accuracy']\n",
    "\n",
    "loss += history_fine.history['loss']\n",
    "val_loss += history_fine.history['val_loss']\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.grid(color='gray', linestyle=':', linewidth=.8)\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.ylim([0.8, 1])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.grid(color='gray', linestyle=':', linewidth=.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef25c7e-c88f-4099-b59e-908a6dd5db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'loss_accuracy_train_val.png'\n",
    "fig.savefig(os.path.join(run_logdir, filename),\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a930e0-9eeb-472b-9648-82c86d01975e",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494174fa-b39c-4a32-b46b-79fdf11ec768",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560ba827-cfe4-4b9d-bbc8-322306af4165",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec5ec02-4835-4468-b2ce-416edf7427bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1fc6a2-38f9-4775-b047-523f3a1fb66f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ab5af1-c345-41ec-bfc9-a5c49cdc5ee6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbef33e-0823-4cfb-9746-3a5f8daadb87",
   "metadata": {},
   "source": [
    "# Saving and loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5b9f28-3601-47c5-88d7-b6de5d456e35",
   "metadata": {},
   "source": [
    "## When only the weights had been saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6026f561-3e92-4a23-87b6-a4a4f0014687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually save only weights.\n",
    "# model.save_weights(\"weights.h5\")\n",
    "\n",
    "# Load only weights.\n",
    "# reconstructed_model = get_model()\n",
    "# reconstructed_model.load_weights(\"weights.h5\")\n",
    "# reconstructed_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "#                             loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "#                             metrics=[tf.keras.metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9242b2-20cd-49b9-97a9-5f40478340d2",
   "metadata": {},
   "source": [
    "## When the whole model had been sabed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1936bda7-61f4-4694-a957-f9fb342b0bc5",
   "metadata": {},
   "source": [
    "Keras also supports saving a single HDF5 file containing the model's architecture, weights values, and compile() information. It is a light-weight alternative to SavedModel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95330c47-33f0-448d-ab93-f8fafa209d07",
   "metadata": {},
   "source": [
    "If saving only weights I get an error related to saving trainable and non-trainable weights all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b1dfd-744b-4792-9e04-661629b12e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling `save('my_model.h5')` creates a h5 file `my_model.h5`.\n",
    "# model.save(\"my_model\")\n",
    "\n",
    "# It can be used to reconstruct the model identically.\n",
    "# new_model = tf.keras.models.load_model(\"my_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b3353a-2450-4005-8a15-31eb31d1a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the resulting checkpoints (whole model with .h5) and choose the latest one.\n",
    "files_in_logdir = os.listdir(run_logdir)\n",
    "models = [file for file in files_in_logdir if file.endswith(\".h5\")]\n",
    "latest_model_name = sorted(models, reverse=True)[0]\n",
    "model_path = os.path.join(run_logdir, latest_model_name)\n",
    "print(model_path)\n",
    "\n",
    "# Load again the model.\n",
    "reconstructed_model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Reconstructed model summary.\n",
    "reconstructed_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28771ce9-e7af-4eb4-982a-6e69cf35c1f1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7f845f-bca7-4959-ab99-7580848efe3d",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669012ba-f639-4461-8c4c-4c911b7ee1e0",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846ca002-52f7-49de-a8ae-66facf7ad489",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca3cc1c-674d-451b-b3fc-adc3aae63035",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8d3d1c-e785-46da-87c2-12cd8b0e097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if necessary.\n",
    "# loss, accuracy = reconstructed_model.evaluate(target_dataset)\n",
    "# print('Reconstructed model\\n'\n",
    "#       + '- Loss on test: ' + str(round(loss, 6))\n",
    "#       + '\\n- Acc on test: ' + str(round(accuracy, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00316b45-d5c6-4a4e-960c-9d1cdee3042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if necessary.\n",
    "loss, accuracy = model.evaluate(target_dataset)\n",
    "print('Current model\\n'\n",
    "      + '- Loss on test: ' + str(round(loss, 6))\n",
    "      + '\\n- Acc on test: ' + str(round(accuracy, 6)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14dfc5d-fbd8-40a2-b31b-abcd2a216059",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0ba657-5bb0-45dd-89ff-44328d8fd1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []    # Store predicted labels.\n",
    "y_true = []    # Store true labels.\n",
    "\n",
    "# Iterate over the dataset.\n",
    "for image_batch, label_batch in target_dataset:    # Use dataset.unbatch() with repeat.\n",
    "    \n",
    "    # Append true labels.\n",
    "    y_true.append(label_batch)\n",
    "    \n",
    "    # Compute predictions.\n",
    "    preds = model.predict(image_batch, verbose=0)\n",
    "    \n",
    "    # Append predicted labels.\n",
    "    y_pred.append(np.argmax(preds, axis=-1))\n",
    "\n",
    "# Convert the true and predicted labels into tensors.\n",
    "correct_labels = tf.concat([item for item in y_true], axis=0)\n",
    "predicted_labels = tf.concat([item for item in y_pred], axis=0)\n",
    "\n",
    "# Convert from one-hot.\n",
    "correct_labels = tf.argmax(correct_labels, axis=1)\n",
    "\n",
    "# Compute confusion matrix and decode labels.\n",
    "cm = tf.math.confusion_matrix(correct_labels, predicted_labels)\n",
    "labels = [class_names[i] for i in range(n_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f0c151-3d89-4ce7-9254-63d8ffd13b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (22, 12))\n",
    "sns_plot = sns.heatmap(cm, annot=True, xticklabels=labels, yticklabels=labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9762b802-6bca-4d58-8f5b-d396ca8d7157",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns_plot.get_figure()\n",
    "filename = 'confusion_matrix.png'\n",
    "fig.savefig(os.path.join(run_logdir, filename),\n",
    "            bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac61d81-d8a5-4589-9261-df242937fb72",
   "metadata": {},
   "source": [
    "## F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81f0328-1b7e-4002-b456-6204e1366300",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(correct_labels, predicted_labels, target_names=labels))\n",
    "\n",
    "report_dict = classification_report(correct_labels, predicted_labels, target_names=labels, output_dict=True)\n",
    "df = pd.DataFrame(report_dict).T\n",
    "\n",
    "filename = 'metrics_evaluation.png'\n",
    "dfi.export(df,\n",
    "           os.path.join(run_logdir, filename), \n",
    "           max_rows=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714fd1c2-36d8-4940-bbfe-ac6ebfa70840",
   "metadata": {},
   "source": [
    "## Test time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28c1a23-cc79-4efa-a260-19daf8adb330",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in target_dataset.take(1):    # only take first element of dataset, batch in this case as it is prefetched\n",
    "    \n",
    "    # Batch id.\n",
    "    idx = 2\n",
    "    numpy_batch_images = images.numpy()\n",
    "    numpy_batch_labels = labels.numpy()\n",
    "    \n",
    "    # Plot target img.\n",
    "    plt.imshow(numpy_batch_images[idx].astype(\"uint8\"))\n",
    "    print(class_names[np.argmax(numpy_batch_labels[idx])])\n",
    "    \n",
    "    # Prediction.\n",
    "    predictions = model.predict(numpy_batch_images)[idx]\n",
    "    print('\\n', predictions)\n",
    "    print(class_names[np.argmax(predictions)], predictions[np.argmax(predictions)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9220137-96f1-4eec-98fe-cf6f32d957f6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beebf76-1963-444a-80e6-7f33b761a94f",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497cd1a2-d044-4d45-925f-07e21ebf75cb",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f071792e-b3a4-4769-97e8-fb951d4ee306",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4991301-7995-4608-acf1-6f5c46e70ff3",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da501134-77ca-4bb1-a0dd-eb76aefd1df2",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lulc-venv",
   "language": "python",
   "name": "lulc-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
