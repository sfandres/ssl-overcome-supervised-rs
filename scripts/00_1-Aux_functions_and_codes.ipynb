{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5791228a-95b5-450b-ae4e-b20e78bc047e",
   "metadata": {},
   "source": [
    "**AUX FUNCTIONS AND CODES**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e24b79-d640-42ce-a6d6-3b4c69ddcb9c",
   "metadata": {},
   "source": [
    "Here I keep the codes that I have developed but no longer use. They may not work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ddcb8a-229c-4f55-aa72-3e3102c8b811",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e51b97-e27b-43a5-bd4f-074f27d47af4",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d133dfb-be3b-4229-b8e2-d4630b30411e",
   "metadata": {},
   "source": [
    "# Iterating over the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25bcaa5-c296-440b-b01c-7b4e4fc864b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa01e483-e325-48ea-b43f-f50ea3ce521e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single example.\n",
    "# source_path = 'datasets/Sentinel2GlobalLULC_full_raw/Sentinel2LULC_JPEG/01_BarrenLands___jpeg/' \n",
    "# image = Image.open(source_path + \"1_BarrenLands___100.0__1_0.1_(+43.5345146251,-113.3788872915)_US_Idaho_Butte-County_Arco.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c578e7-9a4c-4cde-9262-fe639a795ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global example.\n",
    "source_path = 'datasets/Sentinel2GlobalLULC_full_raw/Sentinel2LULC_JPEG/' \n",
    "\n",
    "img_data_array = img_class_array = []\n",
    "IMG_HEIGHT = IMG_WIDTH = 224\n",
    "\n",
    "classes = sorted(os.listdir(source_path))\n",
    "print(classes)\n",
    "\n",
    "# Iterating over the classes (only two in this case).\n",
    "for folder in classes[:2]:\n",
    "\n",
    "    # Iterating over the images.\n",
    "    for file in os.listdir(os.path.join(source_path, folder)):\n",
    "        \n",
    "        # Creating image path.        \n",
    "        image_path = os.path.join(source_path, folder, file)\n",
    "\n",
    "        # Img to array.\n",
    "        image = np.array(Image.open(image_path))\n",
    "\n",
    "        # Resize.\n",
    "        # image = np.resize(image, (IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "        # Cast to float.\n",
    "        image = image.astype('float32')\n",
    "\n",
    "        # Normalization (0-1).\n",
    "        image /= 255\n",
    "\n",
    "        # Filling the arrays.\n",
    "        img_data_array.append(image)\n",
    "        curr_class = int(folder[:2])\n",
    "        img_class_array.append(curr_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0750e3a8-6a36-4937-a87c-eca40c8df288",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e8bdf5-4918-4e17-82a8-df87b7697c16",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5b1cbe-4a8c-476e-8715-a1a575296dce",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6df977-df6e-471b-8329-f4b98a0f9598",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    numpy.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(0)\n",
    "\n",
    "DataLoader(train_dataset,\n",
    "           batch_size=batch_size,\n",
    "           num_workers=num_workers,\n",
    "           worker_init_fn=seed_worker,\n",
    "           generator=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfce90d-7c42-404b-86ad-43cf145a9dd2",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11443c92-3eef-468d-9682-83739ca3ec79",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe7cb89-2da5-45d7-878f-367e779de112",
   "metadata": {},
   "source": [
    "## Dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e50ae3-9247-4504-be2a-b7b778663c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "full_dataset = datasets.ImageFolder(root='datasets/Sentinel2GlobalLULC/Sentinel2LULC_JPEG/',\n",
    "                                    transform=transform)\n",
    "\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                              batch_size=32,\n",
    "                              shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             batch_size=32,\n",
    "                             shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cfeed4-7260-4463-a9ea-def32981a98c",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46438419-fd3c-47bd-85bc-d373ac9ca248",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdd9c0b-68de-41fc-8eb2-b9a40f036b79",
   "metadata": {},
   "source": [
    "## Show examples from some random batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa56b508-4b2d-4caa-b2cc-4ef98c3f1efc",
   "metadata": {},
   "source": [
    "### Iter and next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4dbf62-d210-4790-8edd-e35431d54815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))\n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img.permute(1, 2, 0), cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3ab36c-5075-41bf-8049-b95eae872590",
   "metadata": {},
   "source": [
    "### Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00985fb-f9a6-4b46-b42a-9812c47fcc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing Data and Targets in a PyTorch DataLoader\n",
    "for idx, (image, label) in enumerate(train_dataloader):\n",
    "    img = image[0].squeeze()\n",
    "    label = label[0]\n",
    "    plt.title(\"Label: \" + str(int(label)))\n",
    "    plt.imshow(img.permute(1, 2, 0), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aeadbe-86bd-42ed-8b00-dee4ece7cac5",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b4e794-1963-40af-b3bb-66bc3433c9e6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fade81a3-7fbb-4ac6-85d8-034d3cccd1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lulc-venv",
   "language": "python",
   "name": "lulc-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
