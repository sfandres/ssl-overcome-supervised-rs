IP Head: 192.168.7.53:6379
STARTING HEAD at aap04
2024-01-07 17:14:56,259	INFO usage_lib.py:461 -- Usage stats collection is enabled by default without user confirmation because this terminal is detected to be non-interactive. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.
2024-01-07 17:14:56,259	INFO scripts.py:710 -- Local node IP: 192.168.7.53
2024-01-07 17:14:58,894	SUCC scripts.py:747 -- --------------------
2024-01-07 17:14:58,894	SUCC scripts.py:748 -- Ray runtime started.
2024-01-07 17:14:58,894	SUCC scripts.py:749 -- --------------------
2024-01-07 17:14:58,894	INFO scripts.py:751 -- Next steps
2024-01-07 17:14:58,894	INFO scripts.py:752 -- To connect to this Ray runtime from another node, run
2024-01-07 17:14:58,894	INFO scripts.py:755 --   ray start --address='192.168.7.53:6379'
2024-01-07 17:14:58,894	INFO scripts.py:771 -- Alternatively, use the following Python code:
2024-01-07 17:14:58,895	INFO scripts.py:773 -- import ray
2024-01-07 17:14:58,895	INFO scripts.py:777 -- ray.init(address='auto', _node_ip_address='192.168.7.53')
2024-01-07 17:14:58,895	INFO scripts.py:790 -- To see the status of the cluster, use
2024-01-07 17:14:58,895	INFO scripts.py:791 --   ray status
2024-01-07 17:14:58,895	INFO scripts.py:801 -- If connection fails, check your firewall settings and network configuration.
2024-01-07 17:14:58,895	INFO scripts.py:809 -- To terminate the Ray runtime, run
2024-01-07 17:14:58,895	INFO scripts.py:810 --   ray stop
2024-01-07 17:14:58,895	INFO scripts.py:891 -- --block
2024-01-07 17:14:58,895	INFO scripts.py:892 -- This command will now block forever until terminated by a signal.
2024-01-07 17:14:58,896	INFO scripts.py:895 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.

torch initial seed:              3434598755725016270
torch current seed:              42
torch.cuda.is_available():       True
torch.cuda.device_count():       4
torch.cuda.current_device():     0
torch.cuda.device(0):            <torch.cuda.device object at 0x7fcc6dde30d0>
torch.cuda.get_device_name(0):   Tesla V100-PCIE-32GB
torch.backends.cudnn.benchmark:  False
os.sched_getaffinity:            72
os.cpu_count():                  72

model_name:          BarlowTwins
task_name:           multilabel
backbone_name:       resnet18
input_data:          None
dataset_name:        Sentinel2AndaluciaLULC
dataset_level:       Level_N2
train_rate:          10
epochs:              100
learning_rate:       0.01
save_every:          5
batch_size:          32
num_workers:         4
ini_weights:         random
seed:                42
dropout:             None
transfer_learning:   LP
show:                False
verbose:             False
balanced_dataset:    False
torch_compile:       False
distributed:         False
ray_tune:            gridsearch
load_best_hyperparameters: False
grace_period:        75
num_samples_trials:  1
gpus_per_trial:      1


Model resnet18 with pretrained weights using BarlowTwins SSL
Model loaded from snapshot_BarlowTwins_resnet18_bd=False_iw=random.pt
Model name:        BarlowTwins
Backbone name:     resnet18
Hidden layer dim.: 256
Output layer dim.: 128
No dropout layer
New final fully-connected layer: Linear(in_features=512, out_features=10, bias=True)
Linear probing adjusted
Device: 0

Setting a new configuration using tune.grid_search

2024-01-07 17:15:42,396	INFO worker.py:1364 -- Connecting to existing Ray cluster at address: 192.168.7.53:6379...
2024-01-07 17:15:42,418	INFO worker.py:1553 -- Connected to Ray cluster.
2024-01-07 17:16:02,734	WARNING worker.py:1866 -- Warning: The actor ImplicitFunc is very large (44 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.
== Status ==
Current time: 2024-01-07 17:16:02 (running for 00:00:19.35)
Memory usage on this node: 13.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (23 PENDING, 1 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |
|-------------------+----------+--------------------+--------+------------+----------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |
| train_01e98_00001 | PENDING  |                    | 0.001  |       0.99 |         0      |
| train_01e98_00002 | PENDING  |                    | 0.01   |       0.99 |         0      |
| train_01e98_00003 | PENDING  |                    | 0.1    |       0.99 |         0      |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+--------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11611)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11611)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=11611)[0m Configuration completed!
[2m[36m(func pid=11611)[0m New optimizer parameters:
[2m[36m(func pid=11611)[0m SGD (
[2m[36m(func pid=11611)[0m Parameter Group 0
[2m[36m(func pid=11611)[0m     dampening: 0
[2m[36m(func pid=11611)[0m     differentiable: False
[2m[36m(func pid=11611)[0m     foreach: None
[2m[36m(func pid=11611)[0m     lr: 0.0001
[2m[36m(func pid=11611)[0m     maximize: False
[2m[36m(func pid=11611)[0m     momentum: 0.99
[2m[36m(func pid=11611)[0m     nesterov: False
[2m[36m(func pid=11611)[0m     weight_decay: 0
[2m[36m(func pid=11611)[0m )
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8974 | Steps: 4 | Val loss: 0.7020 | Batch size: 32 | lr: 0.0001 | Duration: 5.13s
[2m[36m(func pid=11611)[0m rmse: 0.18239006400108337
[2m[36m(func pid=11611)[0m mae:  0.13426139950752258
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.266, 0.106, 0.339, 0.112, 0.19, 0.294, 0.143, 0.144, 0.112]
== Status ==
Current time: 2024-01-07 17:16:13 (running for 00:00:29.67)
Memory usage on this node: 15.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (22 PENDING, 2 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |
|-------------------+----------+--------------------+--------+------------+----------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |
| train_01e98_00002 | PENDING  |                    | 0.01   |       0.99 |         0      |
| train_01e98_00003 | PENDING  |                    | 0.1    |       0.99 |         0      |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+--------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11990)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=11990)[0m Configuration completed!
[2m[36m(func pid=11990)[0m New optimizer parameters:
[2m[36m(func pid=11990)[0m SGD (
[2m[36m(func pid=11990)[0m Parameter Group 0
[2m[36m(func pid=11990)[0m     dampening: 0
[2m[36m(func pid=11990)[0m     differentiable: False
[2m[36m(func pid=11990)[0m     foreach: None
[2m[36m(func pid=11990)[0m     lr: 0.001
[2m[36m(func pid=11990)[0m     maximize: False
[2m[36m(func pid=11990)[0m     momentum: 0.99
[2m[36m(func pid=11990)[0m     nesterov: False
[2m[36m(func pid=11990)[0m     weight_decay: 0
[2m[36m(func pid=11990)[0m )
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8913 | Steps: 4 | Val loss: 0.6935 | Batch size: 32 | lr: 0.001 | Duration: 4.70s
[2m[36m(func pid=11990)[0m rmse: 0.18228115141391754
[2m[36m(func pid=11990)[0m mae:  0.13416428864002228
[2m[36m(func pid=11990)[0m rmse_per_class: [0.116, 0.266, 0.107, 0.339, 0.112, 0.19, 0.294, 0.143, 0.143, 0.113]
== Status ==
Current time: 2024-01-07 17:16:22 (running for 00:00:38.59)
Memory usage on this node: 18.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (21 PENDING, 3 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |
|-------------------+----------+--------------------+--------+------------+----------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |
| train_01e98_00003 | PENDING  |                    | 0.1    |       0.99 |         0      |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+--------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12418)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=12418)[0m Configuration completed!
[2m[36m(func pid=12418)[0m New optimizer parameters:
[2m[36m(func pid=12418)[0m SGD (
[2m[36m(func pid=12418)[0m Parameter Group 0
[2m[36m(func pid=12418)[0m     dampening: 0
[2m[36m(func pid=12418)[0m     differentiable: False
[2m[36m(func pid=12418)[0m     foreach: None
[2m[36m(func pid=12418)[0m     lr: 0.01
[2m[36m(func pid=12418)[0m     maximize: False
[2m[36m(func pid=12418)[0m     momentum: 0.99
[2m[36m(func pid=12418)[0m     nesterov: False
[2m[36m(func pid=12418)[0m     weight_decay: 0
[2m[36m(func pid=12418)[0m )
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8664 | Steps: 4 | Val loss: 0.6261 | Batch size: 32 | lr: 0.01 | Duration: 4.53s
[2m[36m(func pid=12418)[0m rmse: 0.18246696889400482
[2m[36m(func pid=12418)[0m mae:  0.1342996209859848
[2m[36m(func pid=12418)[0m rmse_per_class: [0.117, 0.267, 0.106, 0.339, 0.112, 0.191, 0.294, 0.143, 0.143, 0.113]
== Status ==
Current time: 2024-01-07 17:16:31 (running for 00:00:47.75)
Memory usage on this node: 20.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |
|-------------------+----------+--------------------+--------+------------+----------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+--------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12847)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12847)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=12847)[0m Configuration completed!
[2m[36m(func pid=12847)[0m New optimizer parameters:
[2m[36m(func pid=12847)[0m SGD (
[2m[36m(func pid=12847)[0m Parameter Group 0
[2m[36m(func pid=12847)[0m     dampening: 0
[2m[36m(func pid=12847)[0m     differentiable: False
[2m[36m(func pid=12847)[0m     foreach: None
[2m[36m(func pid=12847)[0m     lr: 0.1
[2m[36m(func pid=12847)[0m     maximize: False
[2m[36m(func pid=12847)[0m     momentum: 0.99
[2m[36m(func pid=12847)[0m     nesterov: False
[2m[36m(func pid=12847)[0m     weight_decay: 0
[2m[36m(func pid=12847)[0m )
[2m[36m(func pid=12847)[0m 
== Status ==
Current time: 2024-01-07 17:16:39 (running for 00:00:55.61)
Memory usage on this node: 22.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |        |        |                      |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.891 |  0.182 |                    1 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |        |        |                      |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |        |        |                      |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.7053 | Steps: 4 | Val loss: 0.4714 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.8773 | Steps: 4 | Val loss: 0.6658 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.8911 | Steps: 4 | Val loss: 0.6947 | Batch size: 32 | lr: 0.0001 | Duration: 3.13s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.6908 | Steps: 4 | Val loss: 0.3406 | Batch size: 32 | lr: 0.1 | Duration: 4.97s
== Status ==
Current time: 2024-01-07 17:16:44 (running for 00:01:00.68)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.897 |  0.182 |                    1 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.891 |  0.182 |                    1 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.866 |  0.182 |                    1 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |        |        |                      |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.1812254786491394
[2m[36m(func pid=12418)[0m mae:  0.13333295285701752
[2m[36m(func pid=12418)[0m rmse_per_class: [0.118, 0.267, 0.103, 0.338, 0.106, 0.19, 0.292, 0.142, 0.142, 0.114]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.18167316913604736
[2m[36m(func pid=11990)[0m mae:  0.13371381163597107
[2m[36m(func pid=11990)[0m rmse_per_class: [0.117, 0.266, 0.104, 0.339, 0.112, 0.19, 0.294, 0.142, 0.143, 0.111]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.18174177408218384
[2m[36m(func pid=11611)[0m mae:  0.13378138840198517
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.266, 0.104, 0.339, 0.113, 0.19, 0.294, 0.141, 0.143, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.18007603287696838
[2m[36m(func pid=12847)[0m mae:  0.1323937624692917
[2m[36m(func pid=12847)[0m rmse_per_class: [0.122, 0.267, 0.1, 0.338, 0.095, 0.192, 0.284, 0.144, 0.143, 0.115]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.8366 | Steps: 4 | Val loss: 0.6295 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.5171 | Steps: 4 | Val loss: 0.3528 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.8924 | Steps: 4 | Val loss: 0.6903 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.4495 | Steps: 4 | Val loss: 0.3882 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
== Status ==
Current time: 2024-01-07 17:16:49 (running for 00:01:06.25)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.891 |  0.182 |                    2 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.877 |  0.182 |                    2 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.517 |  0.179 |                    3 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.691 |  0.18  |                    1 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.1786481887102127
[2m[36m(func pid=12418)[0m mae:  0.13119837641716003
[2m[36m(func pid=12418)[0m rmse_per_class: [0.12, 0.265, 0.097, 0.333, 0.096, 0.189, 0.289, 0.14, 0.14, 0.117]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.18111392855644226
[2m[36m(func pid=11990)[0m mae:  0.13327860832214355
[2m[36m(func pid=11990)[0m rmse_per_class: [0.117, 0.265, 0.102, 0.338, 0.111, 0.189, 0.294, 0.141, 0.143, 0.111]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.18122084438800812
[2m[36m(func pid=11611)[0m mae:  0.13335248827934265
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.265, 0.102, 0.338, 0.113, 0.189, 0.294, 0.141, 0.142, 0.111]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.1648089438676834
[2m[36m(func pid=12847)[0m mae:  0.11895124614238739
[2m[36m(func pid=12847)[0m rmse_per_class: [0.112, 0.254, 0.065, 0.334, 0.068, 0.189, 0.251, 0.134, 0.139, 0.103]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4258 | Steps: 4 | Val loss: 0.3148 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.7872 | Steps: 4 | Val loss: 0.5815 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8851 | Steps: 4 | Val loss: 0.6849 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
== Status ==
Current time: 2024-01-07 17:16:55 (running for 00:01:11.47)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.892 |  0.181 |                    3 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.837 |  0.181 |                    3 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.426 |  0.175 |                    4 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.449 |  0.165 |                    2 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.17482087016105652
[2m[36m(func pid=12418)[0m mae:  0.12801218032836914
[2m[36m(func pid=12418)[0m rmse_per_class: [0.121, 0.261, 0.09, 0.325, 0.083, 0.189, 0.284, 0.137, 0.139, 0.119]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.18034279346466064
[2m[36m(func pid=11990)[0m mae:  0.13265100121498108
[2m[36m(func pid=11990)[0m rmse_per_class: [0.116, 0.264, 0.099, 0.338, 0.11, 0.189, 0.294, 0.14, 0.143, 0.111]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.6121 | Steps: 4 | Val loss: 0.4909 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=11611)[0m rmse: 0.18077969551086426
[2m[36m(func pid=11611)[0m mae:  0.13293902575969696
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.264, 0.101, 0.338, 0.113, 0.189, 0.294, 0.14, 0.142, 0.11]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.15752238035202026
[2m[36m(func pid=12847)[0m mae:  0.10767567157745361
[2m[36m(func pid=12847)[0m rmse_per_class: [0.094, 0.236, 0.046, 0.328, 0.054, 0.188, 0.267, 0.131, 0.142, 0.089]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7256 | Steps: 4 | Val loss: 0.5345 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4206 | Steps: 4 | Val loss: 0.3340 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.8787 | Steps: 4 | Val loss: 0.6768 | Batch size: 32 | lr: 0.0001 | Duration: 3.08s
== Status ==
Current time: 2024-01-07 17:17:00 (running for 00:01:16.80)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.885 |  0.181 |                    4 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.726 |  0.18  |                    5 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.426 |  0.175 |                    4 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.612 |  0.158 |                    3 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.17965662479400635
[2m[36m(func pid=11990)[0m mae:  0.13210061192512512
[2m[36m(func pid=11990)[0m rmse_per_class: [0.116, 0.262, 0.098, 0.337, 0.108, 0.189, 0.294, 0.14, 0.143, 0.111]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.17142371833324432
[2m[36m(func pid=12418)[0m mae:  0.125104159116745
[2m[36m(func pid=12418)[0m rmse_per_class: [0.122, 0.257, 0.084, 0.318, 0.071, 0.189, 0.279, 0.136, 0.138, 0.12]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.7304 | Steps: 4 | Val loss: 0.5061 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=11611)[0m rmse: 0.18042071163654327
[2m[36m(func pid=11611)[0m mae:  0.1326247751712799
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.263, 0.101, 0.337, 0.112, 0.189, 0.294, 0.14, 0.142, 0.11]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.6609 | Steps: 4 | Val loss: 0.4864 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4550 | Steps: 4 | Val loss: 0.3692 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=12847)[0m rmse: 0.17520426213741302
[2m[36m(func pid=12847)[0m mae:  0.11231045424938202
[2m[36m(func pid=12847)[0m rmse_per_class: [0.074, 0.234, 0.046, 0.348, 0.056, 0.194, 0.422, 0.141, 0.153, 0.085]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.8672 | Steps: 4 | Val loss: 0.6699 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=12418)[0m rmse: 0.16644009947776794
[2m[36m(func pid=12418)[0m mae:  0.12090154737234116
[2m[36m(func pid=12418)[0m rmse_per_class: [0.12, 0.248, 0.076, 0.311, 0.063, 0.188, 0.273, 0.133, 0.137, 0.116]
[2m[36m(func pid=12418)[0m 
== Status ==
Current time: 2024-01-07 17:17:05 (running for 00:01:22.04)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.879 |  0.18  |                    5 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.726 |  0.18  |                    5 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.455 |  0.166 |                    6 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.73  |  0.175 |                    4 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.1788736879825592
[2m[36m(func pid=11990)[0m mae:  0.13144096732139587
[2m[36m(func pid=11990)[0m rmse_per_class: [0.116, 0.261, 0.096, 0.336, 0.105, 0.189, 0.293, 0.14, 0.142, 0.11]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7204 | Steps: 4 | Val loss: 0.4246 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=11611)[0m rmse: 0.18017180263996124
[2m[36m(func pid=11611)[0m mae:  0.13242022693157196
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.263, 0.1, 0.337, 0.111, 0.19, 0.294, 0.14, 0.142, 0.109]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.5052 | Steps: 4 | Val loss: 0.4094 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.6063 | Steps: 4 | Val loss: 0.4414 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=12847)[0m rmse: 0.1859956979751587
[2m[36m(func pid=12847)[0m mae:  0.11879482120275497
[2m[36m(func pid=12847)[0m rmse_per_class: [0.073, 0.234, 0.048, 0.363, 0.056, 0.193, 0.508, 0.148, 0.146, 0.09]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.8612 | Steps: 4 | Val loss: 0.6616 | Batch size: 32 | lr: 0.0001 | Duration: 3.08s
== Status ==
Current time: 2024-01-07 17:17:10 (running for 00:01:27.42)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.867 |  0.18  |                    6 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.661 |  0.179 |                    6 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.505 |  0.162 |                    7 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.72  |  0.186 |                    5 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.16165921092033386
[2m[36m(func pid=12418)[0m mae:  0.11659683287143707
[2m[36m(func pid=12418)[0m rmse_per_class: [0.119, 0.239, 0.067, 0.306, 0.058, 0.187, 0.265, 0.13, 0.135, 0.112]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.17826201021671295
[2m[36m(func pid=11990)[0m mae:  0.13100433349609375
[2m[36m(func pid=11990)[0m rmse_per_class: [0.116, 0.261, 0.093, 0.335, 0.103, 0.188, 0.293, 0.14, 0.142, 0.11]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.5843 | Steps: 4 | Val loss: 0.3395 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=11611)[0m rmse: 0.18031135201454163
[2m[36m(func pid=11611)[0m mae:  0.13255921006202698
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.263, 0.1, 0.338, 0.111, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5447 | Steps: 4 | Val loss: 0.4377 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5463 | Steps: 4 | Val loss: 0.4004 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=12847)[0m rmse: 0.1688956618309021
[2m[36m(func pid=12847)[0m mae:  0.10711465775966644
[2m[36m(func pid=12847)[0m rmse_per_class: [0.067, 0.225, 0.048, 0.354, 0.056, 0.165, 0.344, 0.144, 0.198, 0.088]
[2m[36m(func pid=12847)[0m 
== Status ==
Current time: 2024-01-07 17:17:16 (running for 00:01:32.55)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.861 |  0.18  |                    7 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.606 |  0.178 |                    7 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.545 |  0.158 |                    8 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.584 |  0.169 |                    6 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.8448 | Steps: 4 | Val loss: 0.6521 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=12418)[0m rmse: 0.15785062313079834
[2m[36m(func pid=12418)[0m mae:  0.11279107630252838
[2m[36m(func pid=12418)[0m rmse_per_class: [0.118, 0.235, 0.058, 0.302, 0.056, 0.185, 0.254, 0.127, 0.133, 0.112]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.17765554785728455
[2m[36m(func pid=11990)[0m mae:  0.13048335909843445
[2m[36m(func pid=11990)[0m rmse_per_class: [0.116, 0.259, 0.093, 0.335, 0.1, 0.189, 0.292, 0.14, 0.142, 0.11]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4583 | Steps: 4 | Val loss: 0.3420 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=11611)[0m rmse: 0.18021926283836365
[2m[36m(func pid=11611)[0m mae:  0.13250014185905457
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.262, 0.099, 0.338, 0.11, 0.19, 0.294, 0.141, 0.143, 0.11]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5954 | Steps: 4 | Val loss: 0.4643 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5058 | Steps: 4 | Val loss: 0.3692 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=12847)[0m rmse: 0.15517640113830566
[2m[36m(func pid=12847)[0m mae:  0.10120538622140884
[2m[36m(func pid=12847)[0m rmse_per_class: [0.077, 0.22, 0.04, 0.322, 0.056, 0.174, 0.223, 0.12, 0.239, 0.079]
[2m[36m(func pid=12847)[0m 
== Status ==
Current time: 2024-01-07 17:17:21 (running for 00:01:37.71)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.845 |  0.18  |                    8 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.546 |  0.178 |                    8 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.595 |  0.155 |                    9 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.458 |  0.155 |                    7 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.1547427922487259
[2m[36m(func pid=12418)[0m mae:  0.10933403670787811
[2m[36m(func pid=12418)[0m rmse_per_class: [0.118, 0.23, 0.05, 0.298, 0.055, 0.184, 0.244, 0.126, 0.132, 0.11]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.8306 | Steps: 4 | Val loss: 0.6409 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=11990)[0m rmse: 0.17707496881484985
[2m[36m(func pid=11990)[0m mae:  0.12996633350849152
[2m[36m(func pid=11990)[0m rmse_per_class: [0.116, 0.258, 0.093, 0.333, 0.096, 0.189, 0.292, 0.14, 0.142, 0.111]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4714 | Steps: 4 | Val loss: 0.3905 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.6061 | Steps: 4 | Val loss: 0.4776 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=11611)[0m rmse: 0.18005938827991486
[2m[36m(func pid=11611)[0m mae:  0.1323692351579666
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.262, 0.099, 0.338, 0.109, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4672 | Steps: 4 | Val loss: 0.3454 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=12847)[0m rmse: 0.1564367413520813
[2m[36m(func pid=12847)[0m mae:  0.10169694572687149
[2m[36m(func pid=12847)[0m rmse_per_class: [0.116, 0.223, 0.028, 0.258, 0.056, 0.202, 0.301, 0.124, 0.149, 0.107]
[2m[36m(func pid=12847)[0m 
== Status ==
Current time: 2024-01-07 17:17:26 (running for 00:01:42.88)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.831 |  0.18  |                    9 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.506 |  0.177 |                    9 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.606 |  0.151 |                   10 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.471 |  0.156 |                    8 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.151034876704216
[2m[36m(func pid=12418)[0m mae:  0.10472530126571655
[2m[36m(func pid=12418)[0m rmse_per_class: [0.112, 0.227, 0.045, 0.298, 0.055, 0.183, 0.232, 0.124, 0.131, 0.103]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.17623093724250793
[2m[36m(func pid=11990)[0m mae:  0.12929266691207886
[2m[36m(func pid=11990)[0m rmse_per_class: [0.116, 0.257, 0.091, 0.332, 0.093, 0.188, 0.291, 0.14, 0.142, 0.111]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.8196 | Steps: 4 | Val loss: 0.6289 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5207 | Steps: 4 | Val loss: 0.4056 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.6366 | Steps: 4 | Val loss: 0.4787 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4411 | Steps: 4 | Val loss: 0.3285 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=11611)[0m rmse: 0.17990753054618835
[2m[36m(func pid=11611)[0m mae:  0.13222701847553253
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.261, 0.099, 0.338, 0.109, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.1716904640197754
[2m[36m(func pid=12847)[0m mae:  0.1066996306180954
[2m[36m(func pid=12847)[0m rmse_per_class: [0.118, 0.247, 0.026, 0.257, 0.056, 0.159, 0.319, 0.202, 0.124, 0.21]
[2m[36m(func pid=12847)[0m 
== Status ==
Current time: 2024-01-07 17:17:31 (running for 00:01:48.22)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.82  |  0.18  |                   10 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.467 |  0.176 |                   10 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.637 |  0.15  |                   11 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.521 |  0.172 |                    9 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.14986981451511383
[2m[36m(func pid=12418)[0m mae:  0.10185663402080536
[2m[36m(func pid=12418)[0m rmse_per_class: [0.111, 0.229, 0.042, 0.298, 0.055, 0.183, 0.226, 0.124, 0.131, 0.099]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.17523427307605743
[2m[36m(func pid=11990)[0m mae:  0.1284821480512619
[2m[36m(func pid=11990)[0m rmse_per_class: [0.117, 0.256, 0.089, 0.331, 0.09, 0.188, 0.29, 0.139, 0.142, 0.11]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.8013 | Steps: 4 | Val loss: 0.6173 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.5065 | Steps: 4 | Val loss: 0.3770 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.6112 | Steps: 4 | Val loss: 0.4693 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4212 | Steps: 4 | Val loss: 0.3182 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=11611)[0m rmse: 0.17994418740272522
[2m[36m(func pid=11611)[0m mae:  0.13220791518688202
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.261, 0.099, 0.337, 0.109, 0.19, 0.294, 0.141, 0.143, 0.109]
[2m[36m(func pid=11611)[0m 
== Status ==
Current time: 2024-01-07 17:17:36 (running for 00:01:53.29)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.801 |  0.18  |                   11 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.441 |  0.175 |                   11 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.637 |  0.15  |                   11 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.506 |  0.196 |                   10 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12847)[0m rmse: 0.19634881615638733
[2m[36m(func pid=12847)[0m mae:  0.11257914453744888
[2m[36m(func pid=12847)[0m rmse_per_class: [0.126, 0.264, 0.084, 0.282, 0.062, 0.172, 0.282, 0.264, 0.129, 0.298]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.14923660457134247
[2m[36m(func pid=12418)[0m mae:  0.0989931970834732
[2m[36m(func pid=12418)[0m rmse_per_class: [0.107, 0.234, 0.041, 0.302, 0.056, 0.183, 0.224, 0.124, 0.131, 0.092]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.1744900792837143
[2m[36m(func pid=11990)[0m mae:  0.1278584897518158
[2m[36m(func pid=11990)[0m rmse_per_class: [0.117, 0.254, 0.088, 0.33, 0.086, 0.188, 0.289, 0.141, 0.141, 0.111]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.7888 | Steps: 4 | Val loss: 0.6058 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4441 | Steps: 4 | Val loss: 0.3969 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.5916 | Steps: 4 | Val loss: 0.4489 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4105 | Steps: 4 | Val loss: 0.3142 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=11611)[0m rmse: 0.17993256449699402
[2m[36m(func pid=11611)[0m mae:  0.13218319416046143
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.261, 0.099, 0.338, 0.109, 0.19, 0.294, 0.141, 0.143, 0.109]
[2m[36m(func pid=11611)[0m 
== Status ==
Current time: 2024-01-07 17:17:42 (running for 00:01:58.83)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.789 |  0.18  |                   12 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.421 |  0.174 |                   12 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.592 |  0.15  |                   13 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.506 |  0.196 |                   10 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.1500689685344696
[2m[36m(func pid=12418)[0m mae:  0.0971510261297226
[2m[36m(func pid=12418)[0m rmse_per_class: [0.105, 0.24, 0.041, 0.307, 0.056, 0.181, 0.229, 0.123, 0.132, 0.087]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.20313146710395813
[2m[36m(func pid=12847)[0m mae:  0.11069881916046143
[2m[36m(func pid=12847)[0m rmse_per_class: [0.101, 0.266, 0.196, 0.318, 0.147, 0.189, 0.281, 0.159, 0.131, 0.244]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.17382647097110748
[2m[36m(func pid=11990)[0m mae:  0.1273382306098938
[2m[36m(func pid=11990)[0m rmse_per_class: [0.117, 0.254, 0.088, 0.33, 0.082, 0.187, 0.288, 0.14, 0.141, 0.111]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.7710 | Steps: 4 | Val loss: 0.5920 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.6019 | Steps: 4 | Val loss: 0.4150 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4460 | Steps: 4 | Val loss: 0.4556 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4076 | Steps: 4 | Val loss: 0.3136 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=11611)[0m rmse: 0.17971394956111908
[2m[36m(func pid=11611)[0m mae:  0.13200989365577698
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.261, 0.098, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.15179720520973206
[2m[36m(func pid=12418)[0m mae:  0.09556052833795547
[2m[36m(func pid=12418)[0m rmse_per_class: [0.098, 0.251, 0.043, 0.309, 0.056, 0.181, 0.242, 0.122, 0.133, 0.082]
[2m[36m(func pid=12418)[0m 
== Status ==
Current time: 2024-01-07 17:17:47 (running for 00:02:03.98)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.771 |  0.18  |                   13 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.41  |  0.174 |                   13 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.602 |  0.152 |                   14 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.444 |  0.203 |                   11 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.17267125844955444
[2m[36m(func pid=11990)[0m mae:  0.12641772627830505
[2m[36m(func pid=11990)[0m rmse_per_class: [0.117, 0.252, 0.086, 0.328, 0.079, 0.187, 0.287, 0.14, 0.141, 0.11]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.20971381664276123
[2m[36m(func pid=12847)[0m mae:  0.12160104513168335
[2m[36m(func pid=12847)[0m rmse_per_class: [0.075, 0.251, 0.223, 0.361, 0.179, 0.201, 0.42, 0.124, 0.132, 0.133]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7566 | Steps: 4 | Val loss: 0.5779 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.5793 | Steps: 4 | Val loss: 0.3786 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4068 | Steps: 4 | Val loss: 0.3168 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.5164 | Steps: 4 | Val loss: 0.4681 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=11611)[0m rmse: 0.17957398295402527
[2m[36m(func pid=11611)[0m mae:  0.13191662728786469
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.26, 0.098, 0.338, 0.109, 0.19, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.15521377325057983
[2m[36m(func pid=12418)[0m mae:  0.09579157829284668
[2m[36m(func pid=12418)[0m rmse_per_class: [0.095, 0.265, 0.045, 0.318, 0.056, 0.182, 0.256, 0.122, 0.134, 0.079]
== Status ==
Current time: 2024-01-07 17:17:52 (running for 00:02:09.04)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.757 |  0.18  |                   14 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.408 |  0.173 |                   14 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.579 |  0.155 |                   15 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.446 |  0.21  |                   12 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.17174339294433594
[2m[36m(func pid=11990)[0m mae:  0.1256406456232071
[2m[36m(func pid=11990)[0m rmse_per_class: [0.117, 0.251, 0.084, 0.328, 0.076, 0.186, 0.285, 0.14, 0.14, 0.11]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.20458681881427765
[2m[36m(func pid=12847)[0m mae:  0.11862809956073761
[2m[36m(func pid=12847)[0m rmse_per_class: [0.074, 0.243, 0.218, 0.371, 0.205, 0.186, 0.386, 0.137, 0.132, 0.094]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.7394 | Steps: 4 | Val loss: 0.5638 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.4947 | Steps: 4 | Val loss: 0.3436 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.4102 | Steps: 4 | Val loss: 0.3209 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4843 | Steps: 4 | Val loss: 0.4336 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 17:17:57 (running for 00:02:14.10)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.757 |  0.18  |                   14 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.407 |  0.172 |                   15 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.495 |  0.157 |                   16 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.516 |  0.205 |                   13 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.15727029740810394
[2m[36m(func pid=12418)[0m mae:  0.09620780497789383
[2m[36m(func pid=12418)[0m rmse_per_class: [0.097, 0.273, 0.045, 0.322, 0.056, 0.181, 0.263, 0.123, 0.134, 0.078]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17957797646522522
[2m[36m(func pid=11611)[0m mae:  0.1319122612476349
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.26, 0.098, 0.337, 0.108, 0.19, 0.294, 0.141, 0.143, 0.109]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.17051680386066437
[2m[36m(func pid=11990)[0m mae:  0.12464432418346405
[2m[36m(func pid=11990)[0m rmse_per_class: [0.118, 0.249, 0.081, 0.327, 0.074, 0.186, 0.283, 0.139, 0.14, 0.109]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.19796916842460632
[2m[36m(func pid=12847)[0m mae:  0.11094824224710464
[2m[36m(func pid=12847)[0m rmse_per_class: [0.074, 0.286, 0.19, 0.361, 0.198, 0.196, 0.296, 0.14, 0.148, 0.089]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4928 | Steps: 4 | Val loss: 0.3144 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.7221 | Steps: 4 | Val loss: 0.5501 | Batch size: 32 | lr: 0.0001 | Duration: 3.11s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4150 | Steps: 4 | Val loss: 0.3268 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4968 | Steps: 4 | Val loss: 0.4187 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=12418)[0m rmse: 0.15750069916248322
[2m[36m(func pid=12418)[0m mae:  0.09588136523962021
[2m[36m(func pid=12418)[0m rmse_per_class: [0.098, 0.283, 0.045, 0.32, 0.056, 0.178, 0.26, 0.122, 0.135, 0.078]
== Status ==
Current time: 2024-01-07 17:18:02 (running for 00:02:19.37)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.739 |  0.18  |                   15 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.41  |  0.171 |                   16 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.493 |  0.158 |                   17 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.484 |  0.198 |                   14 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17941626906394958
[2m[36m(func pid=11611)[0m mae:  0.13175494968891144
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.26, 0.098, 0.337, 0.108, 0.19, 0.294, 0.141, 0.143, 0.109]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.16929607093334198
[2m[36m(func pid=11990)[0m mae:  0.1235848218202591
[2m[36m(func pid=11990)[0m rmse_per_class: [0.118, 0.247, 0.079, 0.325, 0.071, 0.186, 0.282, 0.138, 0.14, 0.109]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.19821438193321228
[2m[36m(func pid=12847)[0m mae:  0.1122741550207138
[2m[36m(func pid=12847)[0m rmse_per_class: [0.077, 0.29, 0.122, 0.33, 0.141, 0.267, 0.276, 0.141, 0.242, 0.095]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4347 | Steps: 4 | Val loss: 0.2949 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.7041 | Steps: 4 | Val loss: 0.5393 | Batch size: 32 | lr: 0.0001 | Duration: 3.23s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4240 | Steps: 4 | Val loss: 0.3332 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.4288 | Steps: 4 | Val loss: 0.4134 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 17:18:08 (running for 00:02:24.60)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.722 |  0.179 |                   16 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.415 |  0.169 |                   17 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.435 |  0.154 |                   18 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.497 |  0.198 |                   15 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.15416938066482544
[2m[36m(func pid=12418)[0m mae:  0.09398985654115677
[2m[36m(func pid=12418)[0m rmse_per_class: [0.095, 0.281, 0.045, 0.315, 0.056, 0.17, 0.249, 0.118, 0.135, 0.078]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.16809269785881042
[2m[36m(func pid=11990)[0m mae:  0.12252666056156158
[2m[36m(func pid=11990)[0m rmse_per_class: [0.117, 0.246, 0.076, 0.323, 0.069, 0.185, 0.28, 0.137, 0.139, 0.109]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17951561510562897
[2m[36m(func pid=11611)[0m mae:  0.13179993629455566
[2m[36m(func pid=11611)[0m rmse_per_class: [0.115, 0.26, 0.098, 0.337, 0.108, 0.189, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.18510901927947998
[2m[36m(func pid=12847)[0m mae:  0.11086435616016388
[2m[36m(func pid=12847)[0m rmse_per_class: [0.079, 0.219, 0.048, 0.301, 0.092, 0.275, 0.283, 0.139, 0.31, 0.105]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.4079 | Steps: 4 | Val loss: 0.2868 | Batch size: 32 | lr: 0.01 | Duration: 2.65s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.4320 | Steps: 4 | Val loss: 0.3390 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.6872 | Steps: 4 | Val loss: 0.5250 | Batch size: 32 | lr: 0.0001 | Duration: 3.13s
== Status ==
Current time: 2024-01-07 17:18:13 (running for 00:02:29.62)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.704 |  0.18  |                   17 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.424 |  0.168 |                   18 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.408 |  0.149 |                   19 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.429 |  0.185 |                   16 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.14915046095848083
[2m[36m(func pid=12418)[0m mae:  0.09210123121738434
[2m[36m(func pid=12418)[0m rmse_per_class: [0.111, 0.253, 0.044, 0.308, 0.056, 0.161, 0.233, 0.113, 0.133, 0.08]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4227 | Steps: 4 | Val loss: 0.4083 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=11990)[0m rmse: 0.1671425998210907
[2m[36m(func pid=11990)[0m mae:  0.12172553688287735
[2m[36m(func pid=11990)[0m rmse_per_class: [0.116, 0.246, 0.074, 0.322, 0.068, 0.183, 0.278, 0.136, 0.139, 0.109]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17964810132980347
[2m[36m(func pid=11611)[0m mae:  0.13196031749248505
[2m[36m(func pid=11611)[0m rmse_per_class: [0.115, 0.261, 0.098, 0.337, 0.108, 0.189, 0.294, 0.14, 0.144, 0.111]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4318 | Steps: 4 | Val loss: 0.2916 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=12847)[0m rmse: 0.17127904295921326
[2m[36m(func pid=12847)[0m mae:  0.10334029048681259
[2m[36m(func pid=12847)[0m rmse_per_class: [0.084, 0.224, 0.026, 0.276, 0.058, 0.22, 0.25, 0.132, 0.304, 0.137]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4395 | Steps: 4 | Val loss: 0.3450 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.6672 | Steps: 4 | Val loss: 0.5130 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 17:18:18 (running for 00:02:34.84)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.687 |  0.18  |                   18 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.432 |  0.167 |                   19 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.432 |  0.145 |                   20 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.423 |  0.171 |                   17 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.14509528875350952
[2m[36m(func pid=12418)[0m mae:  0.09078945219516754
[2m[36m(func pid=12418)[0m rmse_per_class: [0.12, 0.237, 0.042, 0.299, 0.056, 0.153, 0.22, 0.11, 0.131, 0.083]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3727 | Steps: 4 | Val loss: 0.3880 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=11990)[0m rmse: 0.1660676896572113
[2m[36m(func pid=11990)[0m mae:  0.12078152596950531
[2m[36m(func pid=11990)[0m rmse_per_class: [0.116, 0.246, 0.072, 0.32, 0.066, 0.182, 0.277, 0.136, 0.139, 0.108]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17925921082496643
[2m[36m(func pid=11611)[0m mae:  0.1315840482711792
[2m[36m(func pid=11611)[0m rmse_per_class: [0.115, 0.261, 0.097, 0.336, 0.108, 0.189, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4389 | Steps: 4 | Val loss: 0.3049 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=12847)[0m rmse: 0.1613139510154724
[2m[36m(func pid=12847)[0m mae:  0.09457496553659439
[2m[36m(func pid=12847)[0m rmse_per_class: [0.087, 0.236, 0.025, 0.272, 0.057, 0.18, 0.228, 0.126, 0.21, 0.191]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4573 | Steps: 4 | Val loss: 0.3521 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
== Status ==
Current time: 2024-01-07 17:18:23 (running for 00:02:39.96)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.667 |  0.179 |                   19 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.439 |  0.166 |                   20 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.439 |  0.142 |                   21 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.373 |  0.161 |                   18 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.14244019985198975
[2m[36m(func pid=12418)[0m mae:  0.09066756069660187
[2m[36m(func pid=12418)[0m rmse_per_class: [0.115, 0.229, 0.04, 0.281, 0.056, 0.152, 0.215, 0.11, 0.128, 0.097]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.6532 | Steps: 4 | Val loss: 0.4977 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3993 | Steps: 4 | Val loss: 0.4098 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=11990)[0m rmse: 0.16441507637500763
[2m[36m(func pid=11990)[0m mae:  0.11935535818338394
[2m[36m(func pid=11990)[0m rmse_per_class: [0.115, 0.243, 0.068, 0.318, 0.064, 0.181, 0.274, 0.135, 0.137, 0.107]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17898507416248322
[2m[36m(func pid=11611)[0m mae:  0.1313970386981964
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.261, 0.096, 0.336, 0.107, 0.189, 0.293, 0.14, 0.143, 0.11]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4754 | Steps: 4 | Val loss: 0.3211 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=12847)[0m rmse: 0.17229369282722473
[2m[36m(func pid=12847)[0m mae:  0.10003416240215302
[2m[36m(func pid=12847)[0m rmse_per_class: [0.099, 0.243, 0.026, 0.278, 0.058, 0.188, 0.234, 0.161, 0.192, 0.244]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4609 | Steps: 4 | Val loss: 0.3594 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 17:18:28 (running for 00:02:45.15)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.653 |  0.179 |                   20 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.457 |  0.164 |                   21 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.475 |  0.143 |                   22 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.399 |  0.172 |                   19 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.14349231123924255
[2m[36m(func pid=12418)[0m mae:  0.09270551055669785
[2m[36m(func pid=12418)[0m rmse_per_class: [0.111, 0.223, 0.039, 0.273, 0.056, 0.154, 0.226, 0.111, 0.128, 0.114]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.6394 | Steps: 4 | Val loss: 0.4872 | Batch size: 32 | lr: 0.0001 | Duration: 3.17s
[2m[36m(func pid=11990)[0m rmse: 0.16308246552944183
[2m[36m(func pid=11990)[0m mae:  0.1181492805480957
[2m[36m(func pid=11990)[0m rmse_per_class: [0.114, 0.242, 0.066, 0.316, 0.063, 0.181, 0.272, 0.135, 0.137, 0.106]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4383 | Steps: 4 | Val loss: 0.4161 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4433 | Steps: 4 | Val loss: 0.3353 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=11611)[0m rmse: 0.17894300818443298
[2m[36m(func pid=11611)[0m mae:  0.13136820495128632
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.261, 0.095, 0.336, 0.106, 0.189, 0.293, 0.14, 0.143, 0.11]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.18656475841999054
[2m[36m(func pid=12847)[0m mae:  0.1088174358010292
[2m[36m(func pid=12847)[0m rmse_per_class: [0.093, 0.241, 0.029, 0.289, 0.061, 0.198, 0.252, 0.283, 0.176, 0.243]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4790 | Steps: 4 | Val loss: 0.3653 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 17:18:33 (running for 00:02:50.42)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.639 |  0.179 |                   21 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.461 |  0.163 |                   22 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.443 |  0.147 |                   23 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.438 |  0.187 |                   20 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.14692376554012299
[2m[36m(func pid=12418)[0m mae:  0.09699945151805878
[2m[36m(func pid=12418)[0m rmse_per_class: [0.105, 0.221, 0.033, 0.268, 0.056, 0.155, 0.247, 0.111, 0.138, 0.134]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.6255 | Steps: 4 | Val loss: 0.4750 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=11990)[0m rmse: 0.16186198592185974
[2m[36m(func pid=11990)[0m mae:  0.11697472631931305
[2m[36m(func pid=11990)[0m rmse_per_class: [0.114, 0.24, 0.064, 0.315, 0.061, 0.18, 0.269, 0.135, 0.136, 0.104]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4209 | Steps: 4 | Val loss: 0.4331 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4325 | Steps: 4 | Val loss: 0.3457 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=11611)[0m rmse: 0.17894577980041504
[2m[36m(func pid=11611)[0m mae:  0.131418377161026
[2m[36m(func pid=11611)[0m rmse_per_class: [0.115, 0.261, 0.095, 0.336, 0.105, 0.189, 0.293, 0.14, 0.145, 0.11]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4799 | Steps: 4 | Val loss: 0.3711 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=12847)[0m rmse: 0.19802746176719666
[2m[36m(func pid=12847)[0m mae:  0.11559344828128815
[2m[36m(func pid=12847)[0m rmse_per_class: [0.088, 0.255, 0.031, 0.307, 0.062, 0.197, 0.283, 0.347, 0.192, 0.218]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.15181496739387512== Status ==
Current time: 2024-01-07 17:18:39 (running for 00:02:55.91)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.625 |  0.179 |                   22 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.479 |  0.162 |                   23 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.433 |  0.152 |                   24 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.421 |  0.198 |                   21 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)



[2m[36m(func pid=12418)[0m mae:  0.10147210210561752
[2m[36m(func pid=12418)[0m rmse_per_class: [0.092, 0.225, 0.03, 0.266, 0.056, 0.157, 0.267, 0.112, 0.162, 0.15]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.6103 | Steps: 4 | Val loss: 0.4635 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=11990)[0m rmse: 0.16087833046913147
[2m[36m(func pid=11990)[0m mae:  0.11604919284582138
[2m[36m(func pid=11990)[0m rmse_per_class: [0.113, 0.238, 0.063, 0.315, 0.06, 0.18, 0.268, 0.134, 0.136, 0.103]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4503 | Steps: 4 | Val loss: 0.4281 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4445 | Steps: 4 | Val loss: 0.3482 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=11611)[0m rmse: 0.17895923554897308
[2m[36m(func pid=11611)[0m mae:  0.13143189251422882
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.261, 0.095, 0.336, 0.104, 0.189, 0.293, 0.141, 0.144, 0.11]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4874 | Steps: 4 | Val loss: 0.3739 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=12847)[0m rmse: 0.19596253335475922
[2m[36m(func pid=12847)[0m mae:  0.11253468692302704
[2m[36m(func pid=12847)[0m rmse_per_class: [0.094, 0.295, 0.032, 0.326, 0.054, 0.197, 0.283, 0.269, 0.23, 0.179]
[2m[36m(func pid=12847)[0m 
== Status ==
Current time: 2024-01-07 17:18:44 (running for 00:03:00.99)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.61  |  0.179 |                   23 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.48  |  0.161 |                   24 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.444 |  0.158 |                   25 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.45  |  0.196 |                   22 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.15765415132045746
[2m[36m(func pid=12418)[0m mae:  0.10564820468425751
[2m[36m(func pid=12418)[0m rmse_per_class: [0.082, 0.233, 0.028, 0.268, 0.056, 0.162, 0.282, 0.114, 0.193, 0.158]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.1597692221403122
[2m[36m(func pid=11990)[0m mae:  0.11494278907775879
[2m[36m(func pid=11990)[0m rmse_per_class: [0.111, 0.238, 0.061, 0.314, 0.059, 0.179, 0.265, 0.133, 0.135, 0.102]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.5910 | Steps: 4 | Val loss: 0.4531 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4232 | Steps: 4 | Val loss: 0.3454 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4459 | Steps: 4 | Val loss: 0.4096 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
[2m[36m(func pid=11611)[0m rmse: 0.17901352047920227
[2m[36m(func pid=11611)[0m mae:  0.13147473335266113
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.261, 0.096, 0.336, 0.103, 0.189, 0.293, 0.141, 0.144, 0.111]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4772 | Steps: 4 | Val loss: 0.3788 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 17:18:49 (running for 00:03:06.06)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.591 |  0.179 |                   24 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.487 |  0.16  |                   25 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.423 |  0.163 |                   26 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.45  |  0.196 |                   22 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.16344903409481049
[2m[36m(func pid=12418)[0m mae:  0.10930031538009644
[2m[36m(func pid=12418)[0m rmse_per_class: [0.072, 0.242, 0.026, 0.269, 0.056, 0.162, 0.291, 0.115, 0.232, 0.169]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.18597862124443054
[2m[36m(func pid=12847)[0m mae:  0.10842497646808624
[2m[36m(func pid=12847)[0m rmse_per_class: [0.085, 0.304, 0.031, 0.333, 0.053, 0.234, 0.272, 0.162, 0.253, 0.134]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.15921328961849213
[2m[36m(func pid=11990)[0m mae:  0.11447285115718842
[2m[36m(func pid=11990)[0m rmse_per_class: [0.112, 0.236, 0.061, 0.314, 0.058, 0.18, 0.262, 0.133, 0.135, 0.102]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.5815 | Steps: 4 | Val loss: 0.4421 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4382 | Steps: 4 | Val loss: 0.3335 | Batch size: 32 | lr: 0.01 | Duration: 2.65s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3878 | Steps: 4 | Val loss: 0.3908 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4893 | Steps: 4 | Val loss: 0.3829 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=11611)[0m rmse: 0.17887431383132935
[2m[36m(func pid=11611)[0m mae:  0.13134320080280304
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.261, 0.096, 0.336, 0.102, 0.189, 0.293, 0.14, 0.144, 0.111]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.16587987542152405
[2m[36m(func pid=12418)[0m mae:  0.10977964103221893
[2m[36m(func pid=12418)[0m rmse_per_class: [0.066, 0.246, 0.025, 0.263, 0.056, 0.16, 0.297, 0.116, 0.258, 0.172]
[2m[36m(func pid=12418)[0m 
== Status ==
Current time: 2024-01-07 17:18:55 (running for 00:03:12.23)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.581 |  0.179 |                   25 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.477 |  0.159 |                   26 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.438 |  0.166 |                   27 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.388 |  0.174 |                   24 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12847)[0m rmse: 0.1741594672203064
[2m[36m(func pid=12847)[0m mae:  0.10431431233882904
[2m[36m(func pid=12847)[0m rmse_per_class: [0.082, 0.23, 0.03, 0.319, 0.052, 0.306, 0.256, 0.134, 0.224, 0.109]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.1579095870256424
[2m[36m(func pid=11990)[0m mae:  0.11323533207178116
[2m[36m(func pid=11990)[0m rmse_per_class: [0.111, 0.236, 0.059, 0.313, 0.057, 0.178, 0.26, 0.132, 0.135, 0.1]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.5633 | Steps: 4 | Val loss: 0.4283 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3898 | Steps: 4 | Val loss: 0.3225 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4430 | Steps: 4 | Val loss: 0.4059 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.5015 | Steps: 4 | Val loss: 0.3840 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=12418)[0m rmse: 0.1689509153366089
[2m[36m(func pid=12418)[0m mae:  0.10980862379074097
[2m[36m(func pid=12418)[0m rmse_per_class: [0.063, 0.249, 0.032, 0.267, 0.056, 0.158, 0.29, 0.12, 0.277, 0.177]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.178638756275177
[2m[36m(func pid=11611)[0m mae:  0.13122184574604034
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.261, 0.095, 0.336, 0.101, 0.189, 0.292, 0.14, 0.144, 0.11]
[2m[36m(func pid=11611)[0m 
== Status ==
Current time: 2024-01-07 17:19:01 (running for 00:03:17.93)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.563 |  0.179 |                   26 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.489 |  0.158 |                   27 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.39  |  0.169 |                   28 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.443 |  0.17  |                   25 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12847)[0m rmse: 0.17039504647254944
[2m[36m(func pid=12847)[0m mae:  0.10257197916507721
[2m[36m(func pid=12847)[0m rmse_per_class: [0.078, 0.233, 0.03, 0.295, 0.053, 0.279, 0.25, 0.142, 0.23, 0.116]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.15688559412956238
[2m[36m(func pid=11990)[0m mae:  0.11214125156402588
[2m[36m(func pid=11990)[0m rmse_per_class: [0.111, 0.234, 0.057, 0.312, 0.057, 0.177, 0.257, 0.131, 0.134, 0.099]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3760 | Steps: 4 | Val loss: 0.3184 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.5549 | Steps: 4 | Val loss: 0.4200 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4165 | Steps: 4 | Val loss: 0.4090 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4977 | Steps: 4 | Val loss: 0.3822 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=12418)[0m rmse: 0.17111527919769287
[2m[36m(func pid=12418)[0m mae:  0.10908769071102142
[2m[36m(func pid=12418)[0m rmse_per_class: [0.065, 0.248, 0.051, 0.271, 0.056, 0.158, 0.28, 0.122, 0.278, 0.182]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.1784140020608902
[2m[36m(func pid=11611)[0m mae:  0.1310112178325653
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.26, 0.094, 0.336, 0.101, 0.189, 0.292, 0.14, 0.145, 0.111]
[2m[36m(func pid=11611)[0m 
== Status ==
Current time: 2024-01-07 17:19:07 (running for 00:03:23.49)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.555 |  0.178 |                   27 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.498 |  0.156 |                   29 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.376 |  0.171 |                   29 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.443 |  0.17  |                   25 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.15579180419445038
[2m[36m(func pid=11990)[0m mae:  0.1110147014260292
[2m[36m(func pid=11990)[0m rmse_per_class: [0.109, 0.234, 0.056, 0.312, 0.056, 0.175, 0.254, 0.13, 0.134, 0.098]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.17302058637142181
[2m[36m(func pid=12847)[0m mae:  0.10137535631656647
[2m[36m(func pid=12847)[0m rmse_per_class: [0.085, 0.247, 0.031, 0.305, 0.064, 0.209, 0.253, 0.145, 0.254, 0.138]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3764 | Steps: 4 | Val loss: 0.3181 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.5441 | Steps: 4 | Val loss: 0.4095 | Batch size: 32 | lr: 0.0001 | Duration: 3.17s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4971 | Steps: 4 | Val loss: 0.3789 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4371 | Steps: 4 | Val loss: 0.4066 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=12418)[0m rmse: 0.16960617899894714
[2m[36m(func pid=12418)[0m mae:  0.10508032143115997
[2m[36m(func pid=12418)[0m rmse_per_class: [0.066, 0.248, 0.077, 0.272, 0.056, 0.158, 0.26, 0.131, 0.247, 0.182]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17804184556007385
[2m[36m(func pid=11611)[0m mae:  0.13075652718544006
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.259, 0.093, 0.336, 0.099, 0.189, 0.292, 0.14, 0.145, 0.111]
[2m[36m(func pid=11611)[0m 
== Status ==
Current time: 2024-01-07 17:19:12 (running for 00:03:28.61)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.544 |  0.178 |                   28 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.497 |  0.155 |                   30 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.376 |  0.17  |                   30 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.417 |  0.173 |                   26 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.15477561950683594
[2m[36m(func pid=11990)[0m mae:  0.10997454077005386
[2m[36m(func pid=11990)[0m rmse_per_class: [0.108, 0.234, 0.055, 0.311, 0.055, 0.175, 0.25, 0.129, 0.134, 0.098]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.18345049023628235
[2m[36m(func pid=12847)[0m mae:  0.10364093631505966
[2m[36m(func pid=12847)[0m rmse_per_class: [0.113, 0.251, 0.036, 0.316, 0.089, 0.199, 0.268, 0.14, 0.258, 0.165]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3881 | Steps: 4 | Val loss: 0.3228 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.5348 | Steps: 4 | Val loss: 0.4008 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4906 | Steps: 4 | Val loss: 0.3765 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=12418)[0m rmse: 0.1664164811372757
[2m[36m(func pid=12418)[0m mae:  0.10076490789651871
[2m[36m(func pid=12418)[0m rmse_per_class: [0.07, 0.246, 0.117, 0.273, 0.055, 0.159, 0.239, 0.128, 0.208, 0.17]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4270 | Steps: 4 | Val loss: 0.4143 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
[2m[36m(func pid=11611)[0m rmse: 0.17803797125816345
[2m[36m(func pid=11611)[0m mae:  0.13070625066757202
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.259, 0.094, 0.336, 0.098, 0.189, 0.292, 0.141, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
== Status ==
Current time: 2024-01-07 17:19:17 (running for 00:03:33.99)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.535 |  0.178 |                   29 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.491 |  0.154 |                   31 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.388 |  0.166 |                   31 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.437 |  0.183 |                   27 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.153896301984787
[2m[36m(func pid=11990)[0m mae:  0.10907790809869766
[2m[36m(func pid=11990)[0m rmse_per_class: [0.107, 0.234, 0.053, 0.31, 0.055, 0.174, 0.247, 0.128, 0.134, 0.097]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.1987077295780182
[2m[36m(func pid=12847)[0m mae:  0.10998483747243881
[2m[36m(func pid=12847)[0m rmse_per_class: [0.172, 0.255, 0.052, 0.313, 0.132, 0.203, 0.278, 0.145, 0.255, 0.183]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3683 | Steps: 4 | Val loss: 0.3274 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.5189 | Steps: 4 | Val loss: 0.3934 | Batch size: 32 | lr: 0.0001 | Duration: 3.11s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4939 | Steps: 4 | Val loss: 0.3776 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=12418)[0m rmse: 0.1627853810787201
[2m[36m(func pid=12418)[0m mae:  0.09700962156057358
[2m[36m(func pid=12418)[0m rmse_per_class: [0.073, 0.237, 0.151, 0.275, 0.054, 0.159, 0.224, 0.122, 0.177, 0.157]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4158 | Steps: 4 | Val loss: 0.4312 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=11611)[0m rmse: 0.17799730598926544
[2m[36m(func pid=11611)[0m mae:  0.1307082325220108
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.259, 0.093, 0.336, 0.098, 0.189, 0.292, 0.141, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
== Status ==
Current time: 2024-01-07 17:19:22 (running for 00:03:39.19)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.519 |  0.178 |                   30 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.494 |  0.153 |                   32 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.368 |  0.163 |                   32 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.427 |  0.199 |                   28 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.15268473327159882
[2m[36m(func pid=11990)[0m mae:  0.10791082680225372
[2m[36m(func pid=11990)[0m rmse_per_class: [0.106, 0.231, 0.052, 0.308, 0.055, 0.173, 0.247, 0.127, 0.133, 0.095]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3906 | Steps: 4 | Val loss: 0.3337 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=12847)[0m rmse: 0.21002566814422607
[2m[36m(func pid=12847)[0m mae:  0.11744628101587296
[2m[36m(func pid=12847)[0m rmse_per_class: [0.143, 0.252, 0.076, 0.331, 0.159, 0.205, 0.264, 0.283, 0.203, 0.185]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4956 | Steps: 4 | Val loss: 0.3779 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.5144 | Steps: 4 | Val loss: 0.3875 | Batch size: 32 | lr: 0.0001 | Duration: 3.14s
[2m[36m(func pid=12418)[0m rmse: 0.16210675239562988
[2m[36m(func pid=12418)[0m mae:  0.09594762325286865
[2m[36m(func pid=12418)[0m rmse_per_class: [0.072, 0.231, 0.189, 0.283, 0.054, 0.159, 0.219, 0.117, 0.153, 0.143]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3597 | Steps: 4 | Val loss: 0.4684 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 17:19:27 (running for 00:03:44.35)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.519 |  0.178 |                   30 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.496 |  0.152 |                   33 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.391 |  0.162 |                   33 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.416 |  0.21  |                   29 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.1518707573413849
[2m[36m(func pid=11990)[0m mae:  0.10697980970144272
[2m[36m(func pid=11990)[0m rmse_per_class: [0.105, 0.229, 0.05, 0.309, 0.055, 0.172, 0.246, 0.127, 0.133, 0.094]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.1779470145702362
[2m[36m(func pid=11611)[0m mae:  0.13062819838523865
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.259, 0.093, 0.335, 0.098, 0.189, 0.292, 0.141, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3907 | Steps: 4 | Val loss: 0.3331 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=12847)[0m rmse: 0.2088470458984375
[2m[36m(func pid=12847)[0m mae:  0.1229509487748146
[2m[36m(func pid=12847)[0m rmse_per_class: [0.097, 0.25, 0.094, 0.343, 0.14, 0.198, 0.268, 0.375, 0.166, 0.158]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4928 | Steps: 4 | Val loss: 0.3709 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4989 | Steps: 4 | Val loss: 0.3780 | Batch size: 32 | lr: 0.0001 | Duration: 3.12s
[2m[36m(func pid=12418)[0m rmse: 0.1618417203426361
[2m[36m(func pid=12418)[0m mae:  0.09564216434955597
[2m[36m(func pid=12418)[0m rmse_per_class: [0.068, 0.23, 0.198, 0.293, 0.056, 0.162, 0.237, 0.111, 0.138, 0.127]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3738 | Steps: 4 | Val loss: 0.4357 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 17:19:33 (running for 00:03:49.72)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.514 |  0.178 |                   31 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.493 |  0.151 |                   34 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.391 |  0.162 |                   34 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.36  |  0.209 |                   30 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.15134422481060028
[2m[36m(func pid=11990)[0m mae:  0.10615565627813339
[2m[36m(func pid=11990)[0m rmse_per_class: [0.103, 0.231, 0.049, 0.308, 0.054, 0.171, 0.243, 0.126, 0.133, 0.094]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17750787734985352
[2m[36m(func pid=11611)[0m mae:  0.13028012216091156
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.258, 0.092, 0.335, 0.097, 0.189, 0.291, 0.141, 0.143, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4231 | Steps: 4 | Val loss: 0.3282 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=12847)[0m rmse: 0.19044089317321777
[2m[36m(func pid=12847)[0m mae:  0.11134392023086548
[2m[36m(func pid=12847)[0m rmse_per_class: [0.097, 0.251, 0.097, 0.327, 0.117, 0.194, 0.251, 0.271, 0.151, 0.148]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4988 | Steps: 4 | Val loss: 0.3667 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=12418)[0m rmse: 0.1620796173810959
[2m[36m(func pid=12418)[0m mae:  0.0952594205737114
[2m[36m(func pid=12418)[0m rmse_per_class: [0.069, 0.228, 0.191, 0.298, 0.062, 0.162, 0.256, 0.109, 0.132, 0.114]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4917 | Steps: 4 | Val loss: 0.3726 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3707 | Steps: 4 | Val loss: 0.4099 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 17:19:38 (running for 00:03:55.00)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.499 |  0.178 |                   32 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.499 |  0.15  |                   35 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.423 |  0.162 |                   35 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.374 |  0.19  |                   31 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.15029746294021606
[2m[36m(func pid=11990)[0m mae:  0.10520830005407333
[2m[36m(func pid=11990)[0m rmse_per_class: [0.103, 0.229, 0.048, 0.307, 0.054, 0.169, 0.243, 0.125, 0.133, 0.093]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17728778719902039
[2m[36m(func pid=11611)[0m mae:  0.13013669848442078
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.259, 0.091, 0.335, 0.097, 0.189, 0.291, 0.141, 0.143, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4060 | Steps: 4 | Val loss: 0.3188 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=12847)[0m rmse: 0.17831501364707947
[2m[36m(func pid=12847)[0m mae:  0.10229142010211945
[2m[36m(func pid=12847)[0m rmse_per_class: [0.109, 0.259, 0.113, 0.306, 0.093, 0.192, 0.249, 0.146, 0.152, 0.164]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4760 | Steps: 4 | Val loss: 0.3644 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=12418)[0m rmse: 0.16095414757728577
[2m[36m(func pid=12418)[0m mae:  0.09413070976734161
[2m[36m(func pid=12418)[0m rmse_per_class: [0.068, 0.228, 0.161, 0.299, 0.071, 0.163, 0.276, 0.11, 0.13, 0.103]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4845 | Steps: 4 | Val loss: 0.3666 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 17:19:43 (running for 00:04:00.14)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.492 |  0.177 |                   33 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.476 |  0.149 |                   36 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.406 |  0.161 |                   36 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.371 |  0.178 |                   32 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.1493569165468216
[2m[36m(func pid=11990)[0m mae:  0.1042260155081749
[2m[36m(func pid=11990)[0m rmse_per_class: [0.102, 0.226, 0.047, 0.306, 0.054, 0.168, 0.242, 0.124, 0.132, 0.091]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3794 | Steps: 4 | Val loss: 0.4186 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3881 | Steps: 4 | Val loss: 0.3175 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=11611)[0m rmse: 0.17715415358543396
[2m[36m(func pid=11611)[0m mae:  0.13004718720912933
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.258, 0.091, 0.334, 0.095, 0.188, 0.291, 0.141, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.17911021411418915
[2m[36m(func pid=12847)[0m mae:  0.10248615592718124
[2m[36m(func pid=12847)[0m rmse_per_class: [0.125, 0.253, 0.128, 0.307, 0.078, 0.185, 0.249, 0.131, 0.159, 0.176]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4769 | Steps: 4 | Val loss: 0.3599 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=12418)[0m rmse: 0.1643817126750946
[2m[36m(func pid=12418)[0m mae:  0.09642823785543442
[2m[36m(func pid=12418)[0m rmse_per_class: [0.068, 0.229, 0.146, 0.313, 0.082, 0.164, 0.304, 0.113, 0.13, 0.094]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4770 | Steps: 4 | Val loss: 0.3621 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 17:19:48 (running for 00:04:05.33)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.484 |  0.177 |                   34 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.477 |  0.148 |                   37 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.388 |  0.164 |                   37 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.379 |  0.179 |                   33 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14848795533180237
[2m[36m(func pid=11990)[0m mae:  0.10311432927846909
[2m[36m(func pid=11990)[0m rmse_per_class: [0.101, 0.226, 0.046, 0.304, 0.054, 0.166, 0.242, 0.124, 0.132, 0.09]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3615 | Steps: 4 | Val loss: 0.4219 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3898 | Steps: 4 | Val loss: 0.3147 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=11611)[0m rmse: 0.17690493166446686
[2m[36m(func pid=11611)[0m mae:  0.12984703481197357
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.258, 0.09, 0.335, 0.095, 0.188, 0.291, 0.14, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4666 | Steps: 4 | Val loss: 0.3552 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=12847)[0m rmse: 0.19285161793231964
[2m[36m(func pid=12847)[0m mae:  0.10795609652996063
[2m[36m(func pid=12847)[0m rmse_per_class: [0.153, 0.253, 0.149, 0.318, 0.088, 0.194, 0.261, 0.137, 0.182, 0.193]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.16560876369476318
[2m[36m(func pid=12418)[0m mae:  0.09720189869403839
[2m[36m(func pid=12418)[0m rmse_per_class: [0.067, 0.23, 0.127, 0.319, 0.099, 0.165, 0.312, 0.116, 0.131, 0.091]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4722 | Steps: 4 | Val loss: 0.3586 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 17:19:54 (running for 00:04:10.78)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.477 |  0.177 |                   35 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.467 |  0.148 |                   38 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.39  |  0.166 |                   38 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.361 |  0.193 |                   34 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14782699942588806
[2m[36m(func pid=11990)[0m mae:  0.10229412466287613
[2m[36m(func pid=11990)[0m rmse_per_class: [0.099, 0.225, 0.045, 0.305, 0.054, 0.165, 0.241, 0.123, 0.132, 0.089]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3704 | Steps: 4 | Val loss: 0.4384 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3931 | Steps: 4 | Val loss: 0.3089 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=11611)[0m rmse: 0.17686431109905243
[2m[36m(func pid=11611)[0m mae:  0.12982258200645447
[2m[36m(func pid=11611)[0m rmse_per_class: [0.115, 0.259, 0.09, 0.335, 0.095, 0.188, 0.29, 0.14, 0.145, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4870 | Steps: 4 | Val loss: 0.3486 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=12418)[0m rmse: 0.164321631193161
[2m[36m(func pid=12418)[0m mae:  0.0961933583021164
[2m[36m(func pid=12418)[0m rmse_per_class: [0.067, 0.228, 0.112, 0.319, 0.119, 0.163, 0.302, 0.115, 0.13, 0.087]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.20433767139911652
[2m[36m(func pid=12847)[0m mae:  0.11405526101589203
[2m[36m(func pid=12847)[0m rmse_per_class: [0.231, 0.256, 0.164, 0.327, 0.089, 0.197, 0.267, 0.139, 0.21, 0.164]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4624 | Steps: 4 | Val loss: 0.3530 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
== Status ==
Current time: 2024-01-07 17:19:59 (running for 00:04:16.15)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.472 |  0.177 |                   36 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.487 |  0.147 |                   39 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.393 |  0.164 |                   39 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.37  |  0.204 |                   35 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14737403392791748
[2m[36m(func pid=11990)[0m mae:  0.1014888733625412
[2m[36m(func pid=11990)[0m rmse_per_class: [0.098, 0.225, 0.045, 0.306, 0.054, 0.163, 0.241, 0.122, 0.132, 0.088]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3796 | Steps: 4 | Val loss: 0.3037 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3947 | Steps: 4 | Val loss: 0.4550 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=11611)[0m rmse: 0.17681249976158142
[2m[36m(func pid=11611)[0m mae:  0.1297454535961151
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.258, 0.09, 0.335, 0.095, 0.188, 0.29, 0.14, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4645 | Steps: 4 | Val loss: 0.3408 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=12418)[0m rmse: 0.1610296666622162
[2m[36m(func pid=12418)[0m mae:  0.09397462755441666
[2m[36m(func pid=12418)[0m rmse_per_class: [0.066, 0.239, 0.096, 0.314, 0.131, 0.162, 0.274, 0.114, 0.129, 0.086]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.20930275321006775
[2m[36m(func pid=12847)[0m mae:  0.11603681743144989
[2m[36m(func pid=12847)[0m rmse_per_class: [0.256, 0.263, 0.168, 0.334, 0.078, 0.195, 0.266, 0.135, 0.234, 0.164]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4542 | Steps: 4 | Val loss: 0.3474 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 17:20:04 (running for 00:04:21.45)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.462 |  0.177 |                   37 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.464 |  0.147 |                   40 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.38  |  0.161 |                   40 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.395 |  0.209 |                   36 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14680707454681396
[2m[36m(func pid=11990)[0m mae:  0.10060052573680878
[2m[36m(func pid=11990)[0m rmse_per_class: [0.097, 0.224, 0.045, 0.304, 0.054, 0.163, 0.24, 0.122, 0.131, 0.087]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3491 | Steps: 4 | Val loss: 0.3000 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3314 | Steps: 4 | Val loss: 0.4281 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=11611)[0m rmse: 0.17659470438957214
[2m[36m(func pid=11611)[0m mae:  0.12952640652656555
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.258, 0.091, 0.334, 0.094, 0.188, 0.29, 0.14, 0.143, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.1574966162443161
[2m[36m(func pid=12418)[0m mae:  0.09271162003278732
[2m[36m(func pid=12418)[0m rmse_per_class: [0.064, 0.244, 0.083, 0.3, 0.151, 0.164, 0.24, 0.117, 0.128, 0.084]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4506 | Steps: 4 | Val loss: 0.3355 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=12847)[0m rmse: 0.19885265827178955
[2m[36m(func pid=12847)[0m mae:  0.11007069051265717
[2m[36m(func pid=12847)[0m rmse_per_class: [0.217, 0.263, 0.122, 0.337, 0.064, 0.189, 0.278, 0.141, 0.221, 0.157]
[2m[36m(func pid=12847)[0m 
== Status ==
Current time: 2024-01-07 17:20:10 (running for 00:04:26.65)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.454 |  0.177 |                   38 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.451 |  0.147 |                   41 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.349 |  0.157 |                   41 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.331 |  0.199 |                   37 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.1466062366962433
[2m[36m(func pid=11990)[0m mae:  0.10044139623641968
[2m[36m(func pid=11990)[0m rmse_per_class: [0.096, 0.224, 0.044, 0.305, 0.054, 0.164, 0.238, 0.122, 0.131, 0.087]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4530 | Steps: 4 | Val loss: 0.3438 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3987 | Steps: 4 | Val loss: 0.2986 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3460 | Steps: 4 | Val loss: 0.4112 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4445 | Steps: 4 | Val loss: 0.3292 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
[2m[36m(func pid=12418)[0m rmse: 0.15374578535556793
[2m[36m(func pid=12418)[0m mae:  0.09121902287006378
[2m[36m(func pid=12418)[0m rmse_per_class: [0.066, 0.246, 0.072, 0.285, 0.152, 0.167, 0.226, 0.114, 0.128, 0.083]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.1765042543411255
[2m[36m(func pid=11611)[0m mae:  0.1294579952955246
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.258, 0.09, 0.334, 0.093, 0.188, 0.291, 0.139, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.19331702589988708
[2m[36m(func pid=12847)[0m mae:  0.10762647539377213
[2m[36m(func pid=12847)[0m rmse_per_class: [0.168, 0.265, 0.092, 0.331, 0.064, 0.202, 0.265, 0.182, 0.213, 0.151]
[2m[36m(func pid=12847)[0m 
== Status ==
Current time: 2024-01-07 17:20:15 (running for 00:04:31.85)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.453 |  0.177 |                   39 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.444 |  0.146 |                   42 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.399 |  0.154 |                   42 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.346 |  0.193 |                   38 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14562983810901642
[2m[36m(func pid=11990)[0m mae:  0.09928826987743378
[2m[36m(func pid=11990)[0m rmse_per_class: [0.095, 0.222, 0.043, 0.304, 0.055, 0.163, 0.237, 0.121, 0.131, 0.087]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3540 | Steps: 4 | Val loss: 0.3001 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4486 | Steps: 4 | Val loss: 0.3405 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3934 | Steps: 4 | Val loss: 0.4390 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=12418)[0m rmse: 0.15342989563941956
[2m[36m(func pid=12418)[0m mae:  0.09198255836963654
[2m[36m(func pid=12418)[0m rmse_per_class: [0.068, 0.242, 0.065, 0.278, 0.154, 0.169, 0.226, 0.113, 0.134, 0.085]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4387 | Steps: 4 | Val loss: 0.3229 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=11611)[0m rmse: 0.17648842930793762
[2m[36m(func pid=11611)[0m mae:  0.12946684658527374
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.258, 0.09, 0.334, 0.092, 0.189, 0.29, 0.14, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.19435158371925354
[2m[36m(func pid=12847)[0m mae:  0.1119145005941391
[2m[36m(func pid=12847)[0m rmse_per_class: [0.145, 0.263, 0.096, 0.35, 0.062, 0.204, 0.259, 0.225, 0.208, 0.13]
[2m[36m(func pid=12847)[0m 
== Status ==
Current time: 2024-01-07 17:20:20 (running for 00:04:37.18)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.449 |  0.176 |                   40 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.439 |  0.145 |                   43 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.354 |  0.153 |                   43 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.393 |  0.194 |                   39 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14505457878112793
[2m[36m(func pid=11990)[0m mae:  0.0986039787530899
[2m[36m(func pid=11990)[0m rmse_per_class: [0.093, 0.221, 0.043, 0.303, 0.055, 0.161, 0.237, 0.12, 0.131, 0.086]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3636 | Steps: 4 | Val loss: 0.2970 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4416 | Steps: 4 | Val loss: 0.3371 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3646 | Steps: 4 | Val loss: 0.4289 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=12418)[0m rmse: 0.1522093564271927
[2m[36m(func pid=12418)[0m mae:  0.09246058017015457
[2m[36m(func pid=12418)[0m rmse_per_class: [0.071, 0.227, 0.053, 0.27, 0.147, 0.174, 0.235, 0.11, 0.145, 0.09]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4483 | Steps: 4 | Val loss: 0.3139 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=11611)[0m rmse: 0.17638346552848816
[2m[36m(func pid=11611)[0m mae:  0.12938480079174042
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.257, 0.089, 0.334, 0.092, 0.188, 0.29, 0.14, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.19096501171588898
[2m[36m(func pid=12847)[0m mae:  0.11102650314569473
[2m[36m(func pid=12847)[0m rmse_per_class: [0.125, 0.261, 0.083, 0.334, 0.059, 0.189, 0.264, 0.239, 0.213, 0.142]
[2m[36m(func pid=12847)[0m 
== Status ==
Current time: 2024-01-07 17:20:25 (running for 00:04:42.34)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.442 |  0.176 |                   41 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.448 |  0.144 |                   44 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.364 |  0.152 |                   44 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.365 |  0.191 |                   40 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14423921704292297
[2m[36m(func pid=11990)[0m mae:  0.09759514033794403
[2m[36m(func pid=11990)[0m rmse_per_class: [0.091, 0.221, 0.043, 0.301, 0.055, 0.161, 0.235, 0.119, 0.131, 0.086]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3557 | Steps: 4 | Val loss: 0.3061 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4380 | Steps: 4 | Val loss: 0.3348 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=12418)[0m rmse: 0.15500035881996155
[2m[36m(func pid=12418)[0m mae:  0.09525817632675171
[2m[36m(func pid=12418)[0m rmse_per_class: [0.077, 0.223, 0.043, 0.265, 0.144, 0.179, 0.256, 0.111, 0.159, 0.093]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3409 | Steps: 4 | Val loss: 0.4219 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4187 | Steps: 4 | Val loss: 0.3082 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=11611)[0m rmse: 0.17624981701374054
[2m[36m(func pid=11611)[0m mae:  0.12924501299858093
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.257, 0.09, 0.333, 0.092, 0.188, 0.29, 0.14, 0.145, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.19061407446861267
[2m[36m(func pid=12847)[0m mae:  0.11023978888988495
[2m[36m(func pid=12847)[0m rmse_per_class: [0.13, 0.263, 0.074, 0.31, 0.058, 0.183, 0.273, 0.217, 0.226, 0.171]
[2m[36m(func pid=12847)[0m 
== Status ==
Current time: 2024-01-07 17:20:31 (running for 00:04:47.63)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.438 |  0.176 |                   42 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.419 |  0.144 |                   45 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.356 |  0.155 |                   45 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.341 |  0.191 |                   41 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14425122737884521
[2m[36m(func pid=11990)[0m mae:  0.09761329740285873
[2m[36m(func pid=11990)[0m rmse_per_class: [0.091, 0.222, 0.042, 0.302, 0.055, 0.159, 0.236, 0.119, 0.131, 0.086]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3293 | Steps: 4 | Val loss: 0.3093 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4319 | Steps: 4 | Val loss: 0.3312 | Batch size: 32 | lr: 0.0001 | Duration: 3.08s
[2m[36m(func pid=12418)[0m rmse: 0.15546047687530518
[2m[36m(func pid=12418)[0m mae:  0.09617091715335846
[2m[36m(func pid=12418)[0m rmse_per_class: [0.075, 0.217, 0.034, 0.262, 0.128, 0.179, 0.269, 0.114, 0.179, 0.096]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3385 | Steps: 4 | Val loss: 0.4135 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4210 | Steps: 4 | Val loss: 0.3016 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=11611)[0m rmse: 0.17603228986263275
[2m[36m(func pid=11611)[0m mae:  0.1291487216949463
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.257, 0.089, 0.334, 0.09, 0.188, 0.29, 0.14, 0.145, 0.113]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.14321790635585785
[2m[36m(func pid=11990)[0m mae:  0.09659363329410553
[2m[36m(func pid=11990)[0m rmse_per_class: [0.091, 0.22, 0.042, 0.298, 0.055, 0.158, 0.233, 0.119, 0.131, 0.085]
== Status ==
Current time: 2024-01-07 17:20:36 (running for 00:04:52.91)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.432 |  0.176 |                   43 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.421 |  0.143 |                   46 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.329 |  0.155 |                   46 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.341 |  0.191 |                   41 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)

[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3495 | Steps: 4 | Val loss: 0.3175 | Batch size: 32 | lr: 0.01 | Duration: 2.91s

[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.186027392745018
[2m[36m(func pid=12847)[0m mae:  0.1060413345694542
[2m[36m(func pid=12847)[0m rmse_per_class: [0.129, 0.266, 0.063, 0.292, 0.064, 0.188, 0.259, 0.167, 0.234, 0.199]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4311 | Steps: 4 | Val loss: 0.3304 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=12418)[0m rmse: 0.1599201261997223
[2m[36m(func pid=12418)[0m mae:  0.09999897330999374
[2m[36m(func pid=12418)[0m rmse_per_class: [0.083, 0.214, 0.029, 0.269, 0.127, 0.174, 0.279, 0.123, 0.201, 0.101]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4176 | Steps: 4 | Val loss: 0.2945 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3434 | Steps: 4 | Val loss: 0.4022 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
[2m[36m(func pid=11611)[0m rmse: 0.17583906650543213
[2m[36m(func pid=11611)[0m mae:  0.12902098894119263
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.257, 0.088, 0.334, 0.089, 0.188, 0.289, 0.139, 0.145, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.14271262288093567
[2m[36m(func pid=11990)[0m mae:  0.0960119217634201
[2m[36m(func pid=11990)[0m rmse_per_class: [0.089, 0.219, 0.042, 0.299, 0.055, 0.158, 0.232, 0.118, 0.13, 0.085]
== Status ==
Current time: 2024-01-07 17:20:41 (running for 00:04:58.37)
Memory usage on this node: 24.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.431 |  0.176 |                   44 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.418 |  0.143 |                   47 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.349 |  0.16  |                   47 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.339 |  0.186 |                   42 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3589 | Steps: 4 | Val loss: 0.3263 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.18437559902668
[2m[36m(func pid=12847)[0m mae:  0.1040969118475914
[2m[36m(func pid=12847)[0m rmse_per_class: [0.115, 0.269, 0.068, 0.295, 0.077, 0.19, 0.251, 0.134, 0.235, 0.209]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.1638413667678833
[2m[36m(func pid=12418)[0m mae:  0.10313324630260468
[2m[36m(func pid=12418)[0m rmse_per_class: [0.089, 0.215, 0.028, 0.275, 0.13, 0.178, 0.289, 0.122, 0.207, 0.106]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4301 | Steps: 4 | Val loss: 0.3271 | Batch size: 32 | lr: 0.0001 | Duration: 3.23s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4167 | Steps: 4 | Val loss: 0.2902 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3510 | Steps: 4 | Val loss: 0.3968 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3545 | Steps: 4 | Val loss: 0.3260 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 17:20:47 (running for 00:05:03.64)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.431 |  0.176 |                   44 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.417 |  0.142 |                   48 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.359 |  0.164 |                   48 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.343 |  0.184 |                   43 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11611)[0m rmse: 0.1755325198173523
[2m[36m(func pid=11611)[0m mae:  0.12877556681632996
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.256, 0.088, 0.334, 0.088, 0.187, 0.289, 0.139, 0.144, 0.113]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.14204141497612
[2m[36m(func pid=11990)[0m mae:  0.09529618918895721
[2m[36m(func pid=11990)[0m rmse_per_class: [0.088, 0.218, 0.042, 0.297, 0.055, 0.156, 0.232, 0.118, 0.13, 0.084]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.1887442022562027
[2m[36m(func pid=12847)[0m mae:  0.10439310222864151
[2m[36m(func pid=12847)[0m rmse_per_class: [0.103, 0.273, 0.076, 0.309, 0.095, 0.193, 0.268, 0.133, 0.226, 0.212]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.1644974946975708
[2m[36m(func pid=12418)[0m mae:  0.10323604196310043
[2m[36m(func pid=12418)[0m rmse_per_class: [0.087, 0.215, 0.026, 0.274, 0.12, 0.173, 0.289, 0.129, 0.217, 0.115]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3967 | Steps: 4 | Val loss: 0.2852 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4233 | Steps: 4 | Val loss: 0.3248 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3371 | Steps: 4 | Val loss: 0.4017 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 17:20:52 (running for 00:05:08.85)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.43  |  0.176 |                   45 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.397 |  0.142 |                   49 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.355 |  0.164 |                   49 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.351 |  0.189 |                   44 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14160600304603577
[2m[36m(func pid=11990)[0m mae:  0.09477675706148148
[2m[36m(func pid=11990)[0m rmse_per_class: [0.087, 0.218, 0.041, 0.297, 0.055, 0.156, 0.23, 0.118, 0.13, 0.084]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3423 | Steps: 4 | Val loss: 0.3263 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=11611)[0m rmse: 0.17534244060516357
[2m[36m(func pid=11611)[0m mae:  0.12862063944339752
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.256, 0.088, 0.334, 0.087, 0.187, 0.288, 0.14, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.19467692077159882
[2m[36m(func pid=12847)[0m mae:  0.10590453445911407
[2m[36m(func pid=12847)[0m rmse_per_class: [0.108, 0.278, 0.078, 0.31, 0.111, 0.218, 0.271, 0.136, 0.206, 0.231]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.1673475205898285
[2m[36m(func pid=12418)[0m mae:  0.10483702272176743
[2m[36m(func pid=12418)[0m rmse_per_class: [0.091, 0.221, 0.026, 0.279, 0.1, 0.171, 0.285, 0.139, 0.234, 0.128]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3949 | Steps: 4 | Val loss: 0.2803 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4213 | Steps: 4 | Val loss: 0.3223 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3503 | Steps: 4 | Val loss: 0.3947 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3036 | Steps: 4 | Val loss: 0.3179 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 17:20:57 (running for 00:05:14.28)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.423 |  0.175 |                   46 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.395 |  0.141 |                   50 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.342 |  0.167 |                   50 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.337 |  0.195 |                   45 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14140041172504425
[2m[36m(func pid=11990)[0m mae:  0.09443112462759018
[2m[36m(func pid=11990)[0m rmse_per_class: [0.087, 0.219, 0.041, 0.297, 0.055, 0.155, 0.229, 0.117, 0.13, 0.084]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17491868138313293
[2m[36m(func pid=11611)[0m mae:  0.12827977538108826
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.256, 0.087, 0.334, 0.086, 0.187, 0.287, 0.139, 0.144, 0.111]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.19447419047355652
[2m[36m(func pid=12847)[0m mae:  0.10540401935577393
[2m[36m(func pid=12847)[0m rmse_per_class: [0.117, 0.278, 0.076, 0.301, 0.134, 0.264, 0.253, 0.134, 0.189, 0.197]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.16518540680408478
[2m[36m(func pid=12418)[0m mae:  0.10315273702144623
[2m[36m(func pid=12418)[0m rmse_per_class: [0.084, 0.22, 0.025, 0.277, 0.09, 0.168, 0.277, 0.14, 0.232, 0.138]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3871 | Steps: 4 | Val loss: 0.2754 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4216 | Steps: 4 | Val loss: 0.3212 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3563 | Steps: 4 | Val loss: 0.3863 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3258 | Steps: 4 | Val loss: 0.3099 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 17:21:03 (running for 00:05:19.67)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.421 |  0.175 |                   47 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.387 |  0.141 |                   51 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.304 |  0.165 |                   51 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.35  |  0.194 |                   46 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.1411503106355667
[2m[36m(func pid=11990)[0m mae:  0.0943177193403244
[2m[36m(func pid=11990)[0m rmse_per_class: [0.086, 0.219, 0.041, 0.296, 0.055, 0.155, 0.228, 0.117, 0.13, 0.084]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.1750807762145996
[2m[36m(func pid=11611)[0m mae:  0.12840357422828674
[2m[36m(func pid=11611)[0m rmse_per_class: [0.118, 0.256, 0.087, 0.333, 0.086, 0.187, 0.288, 0.139, 0.145, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.19337745010852814
[2m[36m(func pid=12847)[0m mae:  0.10555990785360336
[2m[36m(func pid=12847)[0m rmse_per_class: [0.119, 0.273, 0.076, 0.299, 0.148, 0.27, 0.251, 0.134, 0.186, 0.177]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.16440339386463165
[2m[36m(func pid=12418)[0m mae:  0.1015862226486206
[2m[36m(func pid=12418)[0m rmse_per_class: [0.085, 0.222, 0.025, 0.28, 0.08, 0.165, 0.267, 0.148, 0.222, 0.15]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3663 | Steps: 4 | Val loss: 0.2706 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4189 | Steps: 4 | Val loss: 0.3200 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3330 | Steps: 4 | Val loss: 0.3727 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3318 | Steps: 4 | Val loss: 0.3103 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 17:21:08 (running for 00:05:24.90)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.422 |  0.175 |                   48 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.366 |  0.141 |                   52 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.326 |  0.164 |                   52 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.356 |  0.193 |                   47 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.1409803330898285
[2m[36m(func pid=11990)[0m mae:  0.0943358764052391
[2m[36m(func pid=11990)[0m rmse_per_class: [0.086, 0.221, 0.041, 0.295, 0.055, 0.155, 0.226, 0.116, 0.13, 0.084]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17485804855823517
[2m[36m(func pid=11611)[0m mae:  0.12820933759212494
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.256, 0.086, 0.333, 0.086, 0.188, 0.287, 0.14, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.1904486119747162
[2m[36m(func pid=12847)[0m mae:  0.104402557015419
[2m[36m(func pid=12847)[0m rmse_per_class: [0.133, 0.27, 0.078, 0.297, 0.153, 0.234, 0.251, 0.146, 0.189, 0.153]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.16574712097644806
[2m[36m(func pid=12418)[0m mae:  0.10141672939062119
[2m[36m(func pid=12418)[0m rmse_per_class: [0.091, 0.227, 0.025, 0.285, 0.074, 0.162, 0.251, 0.158, 0.211, 0.172]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3730 | Steps: 4 | Val loss: 0.2688 | Batch size: 32 | lr: 0.001 | Duration: 2.69s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4162 | Steps: 4 | Val loss: 0.3181 | Batch size: 32 | lr: 0.0001 | Duration: 3.10s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3247 | Steps: 4 | Val loss: 0.3035 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3269 | Steps: 4 | Val loss: 0.3745 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=11990)[0m rmse: 0.14178112149238586
[2m[36m(func pid=11990)[0m mae:  0.0951911062002182
[2m[36m(func pid=11990)[0m rmse_per_class: [0.089, 0.221, 0.041, 0.298, 0.055, 0.156, 0.226, 0.116, 0.13, 0.086]
== Status ==
Current time: 2024-01-07 17:21:13 (running for 00:05:30.04)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.419 |  0.175 |                   49 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.373 |  0.142 |                   53 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.332 |  0.166 |                   53 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.333 |  0.19  |                   48 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.1743977814912796
[2m[36m(func pid=11611)[0m mae:  0.12781423330307007
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.255, 0.085, 0.333, 0.085, 0.187, 0.286, 0.139, 0.145, 0.111]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.16165295243263245
[2m[36m(func pid=12418)[0m mae:  0.09808363020420074
[2m[36m(func pid=12418)[0m rmse_per_class: [0.078, 0.224, 0.025, 0.282, 0.068, 0.162, 0.238, 0.158, 0.185, 0.197]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.18820543587207794
[2m[36m(func pid=12847)[0m mae:  0.10419262945652008
[2m[36m(func pid=12847)[0m rmse_per_class: [0.127, 0.256, 0.081, 0.294, 0.113, 0.192, 0.252, 0.195, 0.227, 0.145]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3728 | Steps: 4 | Val loss: 0.2663 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4182 | Steps: 4 | Val loss: 0.3178 | Batch size: 32 | lr: 0.0001 | Duration: 3.10s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3261 | Steps: 4 | Val loss: 0.3064 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 17:21:19 (running for 00:05:35.48)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.416 |  0.174 |                   50 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.373 |  0.141 |                   54 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.325 |  0.162 |                   54 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.327 |  0.188 |                   49 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14145596325397491
[2m[36m(func pid=11990)[0m mae:  0.09498388320207596
[2m[36m(func pid=11990)[0m rmse_per_class: [0.09, 0.222, 0.04, 0.296, 0.055, 0.155, 0.225, 0.115, 0.13, 0.086]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2807 | Steps: 4 | Val loss: 0.3933 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=11611)[0m rmse: 0.17450837790966034
[2m[36m(func pid=11611)[0m mae:  0.12794777750968933
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.256, 0.085, 0.333, 0.084, 0.187, 0.287, 0.139, 0.145, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.16156354546546936
[2m[36m(func pid=12418)[0m mae:  0.09777078032493591
[2m[36m(func pid=12418)[0m rmse_per_class: [0.079, 0.222, 0.025, 0.29, 0.063, 0.165, 0.235, 0.148, 0.17, 0.218]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.17987306416034698
[2m[36m(func pid=12847)[0m mae:  0.1041228175163269
[2m[36m(func pid=12847)[0m rmse_per_class: [0.094, 0.244, 0.083, 0.288, 0.081, 0.185, 0.256, 0.219, 0.235, 0.114]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3821 | Steps: 4 | Val loss: 0.2643 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2908 | Steps: 4 | Val loss: 0.3076 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4125 | Steps: 4 | Val loss: 0.3168 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 17:21:24 (running for 00:05:40.95)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.418 |  0.175 |                   51 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.382 |  0.141 |                   55 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.326 |  0.162 |                   55 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.281 |  0.18  |                   50 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14134462177753448
[2m[36m(func pid=11990)[0m mae:  0.09486814588308334
[2m[36m(func pid=11990)[0m rmse_per_class: [0.088, 0.223, 0.04, 0.294, 0.055, 0.156, 0.226, 0.115, 0.13, 0.087]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3315 | Steps: 4 | Val loss: 0.4017 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=12418)[0m rmse: 0.16128042340278625
[2m[36m(func pid=12418)[0m mae:  0.09696969389915466
[2m[36m(func pid=12418)[0m rmse_per_class: [0.08, 0.221, 0.025, 0.294, 0.062, 0.166, 0.237, 0.141, 0.159, 0.227]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17435342073440552
[2m[36m(func pid=11611)[0m mae:  0.12779416143894196
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.255, 0.085, 0.333, 0.084, 0.187, 0.286, 0.14, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3717 | Steps: 4 | Val loss: 0.2633 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=12847)[0m rmse: 0.17779992520809174
[2m[36m(func pid=12847)[0m mae:  0.10431341081857681
[2m[36m(func pid=12847)[0m rmse_per_class: [0.077, 0.24, 0.091, 0.282, 0.064, 0.181, 0.265, 0.218, 0.235, 0.125]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3508 | Steps: 4 | Val loss: 0.3080 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
== Status ==
Current time: 2024-01-07 17:21:29 (running for 00:05:46.21)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.412 |  0.174 |                   52 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.372 |  0.141 |                   56 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.291 |  0.161 |                   56 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.332 |  0.178 |                   51 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4117 | Steps: 4 | Val loss: 0.3159 | Batch size: 32 | lr: 0.0001 | Duration: 3.08s
[2m[36m(func pid=11990)[0m rmse: 0.1410926878452301
[2m[36m(func pid=11990)[0m mae:  0.0948614776134491
[2m[36m(func pid=11990)[0m rmse_per_class: [0.087, 0.222, 0.04, 0.295, 0.055, 0.155, 0.225, 0.114, 0.131, 0.087]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3325 | Steps: 4 | Val loss: 0.3914 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=12418)[0m rmse: 0.1604030877351761
[2m[36m(func pid=12418)[0m mae:  0.09596962481737137
[2m[36m(func pid=12418)[0m rmse_per_class: [0.075, 0.221, 0.025, 0.299, 0.056, 0.165, 0.248, 0.141, 0.151, 0.223]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.1740575134754181
[2m[36m(func pid=11611)[0m mae:  0.1275763213634491
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.255, 0.084, 0.333, 0.083, 0.187, 0.286, 0.14, 0.145, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3694 | Steps: 4 | Val loss: 0.2626 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=12847)[0m rmse: 0.17727676033973694
[2m[36m(func pid=12847)[0m mae:  0.10355080664157867
[2m[36m(func pid=12847)[0m rmse_per_class: [0.074, 0.247, 0.101, 0.291, 0.058, 0.186, 0.272, 0.186, 0.215, 0.143]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3318 | Steps: 4 | Val loss: 0.3039 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 17:21:34 (running for 00:05:51.28)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.412 |  0.174 |                   53 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.369 |  0.141 |                   57 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.351 |  0.16  |                   57 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.332 |  0.177 |                   52 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14090654253959656
[2m[36m(func pid=11990)[0m mae:  0.0952400490641594
[2m[36m(func pid=11990)[0m rmse_per_class: [0.088, 0.221, 0.039, 0.294, 0.055, 0.155, 0.226, 0.114, 0.131, 0.088]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4096 | Steps: 4 | Val loss: 0.3154 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3093 | Steps: 4 | Val loss: 0.3759 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=12418)[0m rmse: 0.15811772644519806
[2m[36m(func pid=12418)[0m mae:  0.09405804425477982
[2m[36m(func pid=12418)[0m rmse_per_class: [0.074, 0.218, 0.026, 0.299, 0.055, 0.166, 0.261, 0.132, 0.146, 0.204]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3589 | Steps: 4 | Val loss: 0.2624 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=11611)[0m rmse: 0.17398467659950256
[2m[36m(func pid=11611)[0m mae:  0.12753038108348846
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.254, 0.084, 0.332, 0.083, 0.188, 0.286, 0.139, 0.145, 0.113]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.17967262864112854
[2m[36m(func pid=12847)[0m mae:  0.10282430797815323
[2m[36m(func pid=12847)[0m rmse_per_class: [0.074, 0.243, 0.12, 0.295, 0.057, 0.198, 0.253, 0.153, 0.216, 0.187]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3433 | Steps: 4 | Val loss: 0.2996 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 17:21:40 (running for 00:05:56.60)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.41  |  0.174 |                   54 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.359 |  0.141 |                   58 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.332 |  0.158 |                   58 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.309 |  0.18  |                   53 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14099721610546112
[2m[36m(func pid=11990)[0m mae:  0.09561814367771149
[2m[36m(func pid=11990)[0m rmse_per_class: [0.089, 0.221, 0.039, 0.292, 0.055, 0.155, 0.226, 0.114, 0.131, 0.088]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4090 | Steps: 4 | Val loss: 0.3142 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=12418)[0m rmse: 0.1556701362133026
[2m[36m(func pid=12418)[0m mae:  0.09222942590713501
[2m[36m(func pid=12418)[0m rmse_per_class: [0.073, 0.216, 0.026, 0.296, 0.054, 0.167, 0.27, 0.127, 0.138, 0.189]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3305 | Steps: 4 | Val loss: 0.3816 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3629 | Steps: 4 | Val loss: 0.2614 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=11611)[0m rmse: 0.17351552844047546
[2m[36m(func pid=11611)[0m mae:  0.1271016001701355
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.254, 0.084, 0.332, 0.082, 0.187, 0.285, 0.138, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3402 | Steps: 4 | Val loss: 0.2913 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=12847)[0m rmse: 0.18475084006786346
[2m[36m(func pid=12847)[0m mae:  0.10454593598842621
[2m[36m(func pid=12847)[0m rmse_per_class: [0.078, 0.246, 0.125, 0.313, 0.057, 0.208, 0.253, 0.14, 0.209, 0.219]
[2m[36m(func pid=12847)[0m 
== Status ==
Current time: 2024-01-07 17:21:45 (running for 00:06:01.88)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.409 |  0.174 |                   55 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.363 |  0.14  |                   59 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.343 |  0.156 |                   59 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.331 |  0.185 |                   54 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14006778597831726
[2m[36m(func pid=11990)[0m mae:  0.09495460987091064
[2m[36m(func pid=11990)[0m rmse_per_class: [0.088, 0.22, 0.038, 0.287, 0.055, 0.153, 0.227, 0.114, 0.131, 0.088]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4082 | Steps: 4 | Val loss: 0.3139 | Batch size: 32 | lr: 0.0001 | Duration: 3.15s
[2m[36m(func pid=12418)[0m rmse: 0.15018288791179657
[2m[36m(func pid=12418)[0m mae:  0.0888620987534523
[2m[36m(func pid=12418)[0m rmse_per_class: [0.067, 0.216, 0.026, 0.289, 0.052, 0.161, 0.262, 0.126, 0.135, 0.169]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2909 | Steps: 4 | Val loss: 0.3789 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3619 | Steps: 4 | Val loss: 0.2620 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=11611)[0m rmse: 0.17343011498451233
[2m[36m(func pid=11611)[0m mae:  0.12707065045833588
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.254, 0.083, 0.332, 0.082, 0.187, 0.286, 0.139, 0.144, 0.111]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3152 | Steps: 4 | Val loss: 0.2900 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=12847)[0m rmse: 0.18206234276294708
[2m[36m(func pid=12847)[0m mae:  0.10268843173980713
[2m[36m(func pid=12847)[0m rmse_per_class: [0.082, 0.248, 0.105, 0.326, 0.057, 0.209, 0.268, 0.138, 0.189, 0.198]
[2m[36m(func pid=12847)[0m 
== Status ==
Current time: 2024-01-07 17:21:50 (running for 00:06:07.12)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.408 |  0.173 |                   56 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.362 |  0.14  |                   60 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.34  |  0.15  |                   60 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.291 |  0.182 |                   55 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14005444943904877
[2m[36m(func pid=11990)[0m mae:  0.0951494351029396
[2m[36m(func pid=11990)[0m rmse_per_class: [0.087, 0.22, 0.037, 0.287, 0.055, 0.153, 0.227, 0.113, 0.131, 0.089]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.14918379485607147
[2m[36m(func pid=12418)[0m mae:  0.08804003894329071
[2m[36m(func pid=12418)[0m rmse_per_class: [0.069, 0.22, 0.027, 0.291, 0.052, 0.161, 0.26, 0.122, 0.136, 0.153]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4087 | Steps: 4 | Val loss: 0.3138 | Batch size: 32 | lr: 0.0001 | Duration: 3.12s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3345 | Steps: 4 | Val loss: 0.3697 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3645 | Steps: 4 | Val loss: 0.2622 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3376 | Steps: 4 | Val loss: 0.2860 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=11611)[0m rmse: 0.1734844148159027
[2m[36m(func pid=11611)[0m mae:  0.12710754573345184
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.254, 0.083, 0.332, 0.082, 0.187, 0.285, 0.139, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.17851825058460236
[2m[36m(func pid=12847)[0m mae:  0.10011879354715347
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12847)[0m rmse_per_class: [0.096, 0.254, 0.084, 0.322, 0.058, 0.204, 0.26, 0.146, 0.184, 0.177]
[2m[36m(func pid=12847)[0m 
== Status ==
Current time: 2024-01-07 17:21:55 (running for 00:06:12.27)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.409 |  0.173 |                   57 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.365 |  0.14  |                   61 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.315 |  0.149 |                   61 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.334 |  0.179 |                   56 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.13970574736595154
[2m[36m(func pid=11990)[0m mae:  0.09500758349895477
[2m[36m(func pid=11990)[0m rmse_per_class: [0.087, 0.219, 0.036, 0.284, 0.055, 0.153, 0.228, 0.113, 0.132, 0.09]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.14607764780521393
[2m[36m(func pid=12418)[0m mae:  0.08613063395023346
[2m[36m(func pid=12418)[0m rmse_per_class: [0.068, 0.234, 0.028, 0.288, 0.054, 0.16, 0.248, 0.12, 0.135, 0.126]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4068 | Steps: 4 | Val loss: 0.3139 | Batch size: 32 | lr: 0.0001 | Duration: 3.18s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3036 | Steps: 4 | Val loss: 0.3644 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3677 | Steps: 4 | Val loss: 0.2636 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3406 | Steps: 4 | Val loss: 0.2831 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 17:22:00 (running for 00:06:17.42)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.407 |  0.174 |                   58 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.365 |  0.14  |                   61 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.338 |  0.146 |                   62 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.334 |  0.179 |                   56 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11611)[0m rmse: 0.17360909283161163
[2m[36m(func pid=11611)[0m mae:  0.12721656262874603
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.254, 0.084, 0.332, 0.081, 0.187, 0.285, 0.139, 0.144, 0.113]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.14016960561275482
[2m[36m(func pid=11990)[0m mae:  0.09568332135677338
[2m[36m(func pid=11990)[0m rmse_per_class: [0.089, 0.22, 0.036, 0.28, 0.055, 0.153, 0.231, 0.113, 0.132, 0.092]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.17837107181549072
[2m[36m(func pid=12847)[0m mae:  0.10021702945232391
[2m[36m(func pid=12847)[0m rmse_per_class: [0.113, 0.268, 0.064, 0.315, 0.066, 0.196, 0.247, 0.179, 0.196, 0.139]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.14443472027778625
[2m[36m(func pid=12418)[0m mae:  0.08559013158082962
[2m[36m(func pid=12418)[0m rmse_per_class: [0.067, 0.243, 0.028, 0.283, 0.054, 0.16, 0.236, 0.118, 0.137, 0.119]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3650 | Steps: 4 | Val loss: 0.2658 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4080 | Steps: 4 | Val loss: 0.3130 | Batch size: 32 | lr: 0.0001 | Duration: 3.13s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3162 | Steps: 4 | Val loss: 0.3738 | Batch size: 32 | lr: 0.1 | Duration: 3.20s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3259 | Steps: 4 | Val loss: 0.2803 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 17:22:06 (running for 00:06:22.85)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.407 |  0.174 |                   58 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.365 |  0.141 |                   63 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.341 |  0.144 |                   63 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.304 |  0.178 |                   57 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14091195166110992
[2m[36m(func pid=11990)[0m mae:  0.09635082632303238
[2m[36m(func pid=11990)[0m rmse_per_class: [0.089, 0.222, 0.035, 0.281, 0.055, 0.154, 0.231, 0.113, 0.135, 0.095]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.1731051504611969
[2m[36m(func pid=11611)[0m mae:  0.12674665451049805
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.254, 0.083, 0.331, 0.082, 0.187, 0.285, 0.139, 0.144, 0.111]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.1807401329278946
[2m[36m(func pid=12847)[0m mae:  0.10449223220348358
[2m[36m(func pid=12847)[0m rmse_per_class: [0.111, 0.287, 0.048, 0.313, 0.079, 0.182, 0.262, 0.224, 0.19, 0.111]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.14338746666908264
[2m[36m(func pid=12418)[0m mae:  0.08557305485010147
[2m[36m(func pid=12418)[0m rmse_per_class: [0.067, 0.244, 0.027, 0.28, 0.053, 0.162, 0.233, 0.117, 0.138, 0.113]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3468 | Steps: 4 | Val loss: 0.2677 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4083 | Steps: 4 | Val loss: 0.3123 | Batch size: 32 | lr: 0.0001 | Duration: 3.15s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3337 | Steps: 4 | Val loss: 0.3919 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3463 | Steps: 4 | Val loss: 0.2780 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 17:22:11 (running for 00:06:28.12)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.408 |  0.173 |                   59 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.347 |  0.142 |                   64 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.326 |  0.143 |                   64 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.316 |  0.181 |                   58 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.1417996883392334
[2m[36m(func pid=11990)[0m mae:  0.0974319651722908
[2m[36m(func pid=11990)[0m rmse_per_class: [0.09, 0.221, 0.034, 0.281, 0.055, 0.154, 0.234, 0.113, 0.136, 0.098]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17271284759044647
[2m[36m(func pid=11611)[0m mae:  0.12645640969276428
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.253, 0.082, 0.331, 0.08, 0.187, 0.284, 0.139, 0.144, 0.11]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.17873436212539673
[2m[36m(func pid=12847)[0m mae:  0.10523728281259537
[2m[36m(func pid=12847)[0m rmse_per_class: [0.103, 0.274, 0.042, 0.3, 0.105, 0.179, 0.264, 0.231, 0.189, 0.101]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.1423061639070511
[2m[36m(func pid=12418)[0m mae:  0.08547874540090561
[2m[36m(func pid=12418)[0m rmse_per_class: [0.068, 0.242, 0.028, 0.277, 0.053, 0.163, 0.233, 0.118, 0.142, 0.098]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3511 | Steps: 4 | Val loss: 0.2682 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4039 | Steps: 4 | Val loss: 0.3124 | Batch size: 32 | lr: 0.0001 | Duration: 3.11s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3563 | Steps: 4 | Val loss: 0.3731 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3155 | Steps: 4 | Val loss: 0.2779 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 17:22:16 (running for 00:06:33.38)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.408 |  0.173 |                   60 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.351 |  0.142 |                   65 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.346 |  0.142 |                   65 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.334 |  0.179 |                   59 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14164488017559052
[2m[36m(func pid=11990)[0m mae:  0.09736260026693344
[2m[36m(func pid=11990)[0m rmse_per_class: [0.09, 0.222, 0.034, 0.279, 0.055, 0.154, 0.236, 0.113, 0.137, 0.097]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.1726735532283783
[2m[36m(func pid=11611)[0m mae:  0.12647037208080292
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.253, 0.082, 0.33, 0.08, 0.186, 0.285, 0.139, 0.144, 0.111]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.17363449931144714
[2m[36m(func pid=12847)[0m mae:  0.10126592218875885
[2m[36m(func pid=12847)[0m rmse_per_class: [0.103, 0.236, 0.04, 0.283, 0.12, 0.183, 0.247, 0.198, 0.216, 0.109]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.1430981159210205
[2m[36m(func pid=12418)[0m mae:  0.08651354908943176
[2m[36m(func pid=12418)[0m rmse_per_class: [0.068, 0.241, 0.028, 0.275, 0.052, 0.17, 0.238, 0.118, 0.142, 0.098]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3624 | Steps: 4 | Val loss: 0.2714 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4066 | Steps: 4 | Val loss: 0.3128 | Batch size: 32 | lr: 0.0001 | Duration: 3.10s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2962 | Steps: 4 | Val loss: 0.2784 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3296 | Steps: 4 | Val loss: 0.3694 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 17:22:22 (running for 00:06:38.62)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.173 |                   61 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.362 |  0.143 |                   66 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.316 |  0.143 |                   66 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.356 |  0.174 |                   60 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14296239614486694
[2m[36m(func pid=11990)[0m mae:  0.09863920509815216
[2m[36m(func pid=11990)[0m rmse_per_class: [0.09, 0.221, 0.033, 0.284, 0.055, 0.156, 0.238, 0.113, 0.139, 0.102]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.14498835802078247
[2m[36m(func pid=12418)[0m mae:  0.08843223750591278
[2m[36m(func pid=12418)[0m rmse_per_class: [0.07, 0.232, 0.03, 0.274, 0.052, 0.182, 0.248, 0.118, 0.146, 0.099]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.1727631390094757
[2m[36m(func pid=11611)[0m mae:  0.1265503168106079
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.253, 0.082, 0.331, 0.08, 0.186, 0.285, 0.139, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.1726769506931305
[2m[36m(func pid=12847)[0m mae:  0.10034283250570297
[2m[36m(func pid=12847)[0m rmse_per_class: [0.11, 0.24, 0.039, 0.279, 0.117, 0.185, 0.236, 0.153, 0.253, 0.116]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3598 | Steps: 4 | Val loss: 0.2728 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2965 | Steps: 4 | Val loss: 0.2785 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4079 | Steps: 4 | Val loss: 0.3128 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3559 | Steps: 4 | Val loss: 0.3722 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
== Status ==
Current time: 2024-01-07 17:22:27 (running for 00:06:43.79)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.407 |  0.173 |                   62 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.36  |  0.143 |                   67 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.296 |  0.145 |                   67 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.33  |  0.173 |                   61 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.1432948261499405
[2m[36m(func pid=11990)[0m mae:  0.09894177317619324
[2m[36m(func pid=11990)[0m rmse_per_class: [0.089, 0.222, 0.033, 0.28, 0.055, 0.155, 0.244, 0.112, 0.14, 0.103]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.14632955193519592
[2m[36m(func pid=12418)[0m mae:  0.08964104950428009
[2m[36m(func pid=12418)[0m rmse_per_class: [0.071, 0.227, 0.032, 0.274, 0.053, 0.187, 0.252, 0.12, 0.152, 0.097]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17268314957618713
[2m[36m(func pid=11611)[0m mae:  0.12645846605300903
[2m[36m(func pid=11611)[0m rmse_per_class: [0.115, 0.253, 0.083, 0.331, 0.079, 0.185, 0.285, 0.138, 0.146, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.17418503761291504
[2m[36m(func pid=12847)[0m mae:  0.10022054612636566
[2m[36m(func pid=12847)[0m rmse_per_class: [0.11, 0.262, 0.038, 0.279, 0.092, 0.188, 0.23, 0.142, 0.254, 0.145]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3604 | Steps: 4 | Val loss: 0.2723 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3213 | Steps: 4 | Val loss: 0.2788 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4068 | Steps: 4 | Val loss: 0.3128 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
== Status ==
Current time: 2024-01-07 17:22:32 (running for 00:06:48.93)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.408 |  0.173 |                   63 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.36  |  0.143 |                   68 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.297 |  0.146 |                   68 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.356 |  0.174 |                   62 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14280085265636444
[2m[36m(func pid=11990)[0m mae:  0.0988539308309555
[2m[36m(func pid=11990)[0m rmse_per_class: [0.09, 0.222, 0.033, 0.276, 0.055, 0.154, 0.245, 0.111, 0.141, 0.101]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3332 | Steps: 4 | Val loss: 0.3888 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=12418)[0m rmse: 0.14793071150779724
[2m[36m(func pid=12418)[0m mae:  0.09083350002765656
[2m[36m(func pid=12418)[0m rmse_per_class: [0.071, 0.216, 0.034, 0.271, 0.052, 0.197, 0.254, 0.123, 0.163, 0.1]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17265941202640533
[2m[36m(func pid=11611)[0m mae:  0.12648269534111023
[2m[36m(func pid=11611)[0m rmse_per_class: [0.115, 0.253, 0.082, 0.331, 0.079, 0.185, 0.285, 0.138, 0.145, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.18252363801002502
[2m[36m(func pid=12847)[0m mae:  0.10465482622385025
[2m[36m(func pid=12847)[0m rmse_per_class: [0.126, 0.271, 0.056, 0.289, 0.068, 0.205, 0.233, 0.141, 0.268, 0.168]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3644 | Steps: 4 | Val loss: 0.2736 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2829 | Steps: 4 | Val loss: 0.2806 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
== Status ==
Current time: 2024-01-07 17:22:37 (running for 00:06:54.14)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.407 |  0.173 |                   64 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.364 |  0.144 |                   69 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.321 |  0.148 |                   69 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.333 |  0.183 |                   63 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.1435098648071289
[2m[36m(func pid=11990)[0m mae:  0.0995577871799469
[2m[36m(func pid=11990)[0m rmse_per_class: [0.088, 0.221, 0.033, 0.276, 0.055, 0.154, 0.247, 0.111, 0.143, 0.107]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4034 | Steps: 4 | Val loss: 0.3126 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3505 | Steps: 4 | Val loss: 0.4098 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=12418)[0m rmse: 0.14961901307106018
[2m[36m(func pid=12418)[0m mae:  0.09225010871887207
[2m[36m(func pid=12418)[0m rmse_per_class: [0.077, 0.209, 0.038, 0.274, 0.052, 0.194, 0.256, 0.122, 0.179, 0.095]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3513 | Steps: 4 | Val loss: 0.2754 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=12847)[0m rmse: 0.19625629484653473
[2m[36m(func pid=12847)[0m mae:  0.11117826402187347
[2m[36m(func pid=12847)[0m rmse_per_class: [0.158, 0.273, 0.117, 0.302, 0.054, 0.207, 0.239, 0.144, 0.277, 0.192]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17241252958774567
[2m[36m(func pid=11611)[0m mae:  0.12630444765090942
[2m[36m(func pid=11611)[0m rmse_per_class: [0.115, 0.251, 0.082, 0.331, 0.079, 0.186, 0.285, 0.138, 0.146, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3067 | Steps: 4 | Val loss: 0.2803 | Batch size: 32 | lr: 0.01 | Duration: 2.67s
[2m[36m(func pid=11990)[0m rmse: 0.144771546125412
[2m[36m(func pid=11990)[0m mae:  0.10062788426876068
[2m[36m(func pid=11990)[0m rmse_per_class: [0.091, 0.222, 0.033, 0.276, 0.055, 0.153, 0.25, 0.111, 0.146, 0.111]
== Status ==
Current time: 2024-01-07 17:22:42 (running for 00:06:59.36)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.403 |  0.172 |                   65 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.351 |  0.145 |                   70 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.283 |  0.15  |                   70 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.35  |  0.196 |                   64 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3395 | Steps: 4 | Val loss: 0.4069 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4032 | Steps: 4 | Val loss: 0.3122 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=12418)[0m rmse: 0.15048018097877502
[2m[36m(func pid=12418)[0m mae:  0.09273935854434967
[2m[36m(func pid=12418)[0m rmse_per_class: [0.079, 0.207, 0.04, 0.272, 0.055, 0.197, 0.253, 0.126, 0.18, 0.097]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3597 | Steps: 4 | Val loss: 0.2748 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=11611)[0m rmse: 0.17214439809322357
[2m[36m(func pid=11611)[0m mae:  0.1260889321565628
[2m[36m(func pid=11611)[0m rmse_per_class: [0.115, 0.252, 0.082, 0.331, 0.078, 0.185, 0.284, 0.137, 0.145, 0.113]
[2m[36m(func pid=12847)[0m rmse: 0.19760051369667053
[2m[36m(func pid=12847)[0m mae:  0.11143966019153595
[2m[36m(func pid=12847)[0m rmse_per_class: [0.149, 0.255, 0.197, 0.313, 0.054, 0.2, 0.246, 0.162, 0.239, 0.16]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2777 | Steps: 4 | Val loss: 0.2838 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 17:22:48 (running for 00:07:04.58)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.403 |  0.172 |                   66 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.36  |  0.145 |                   71 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.307 |  0.15  |                   71 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.339 |  0.198 |                   65 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.1447797566652298
[2m[36m(func pid=11990)[0m mae:  0.10060397535562515
[2m[36m(func pid=11990)[0m rmse_per_class: [0.09, 0.222, 0.033, 0.276, 0.054, 0.152, 0.251, 0.111, 0.148, 0.11]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.1524343192577362
[2m[36m(func pid=12418)[0m mae:  0.0939297303557396
[2m[36m(func pid=12418)[0m rmse_per_class: [0.083, 0.205, 0.043, 0.272, 0.056, 0.186, 0.251, 0.127, 0.2, 0.1]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3503 | Steps: 4 | Val loss: 0.4171 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4010 | Steps: 4 | Val loss: 0.3126 | Batch size: 32 | lr: 0.0001 | Duration: 3.08s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3518 | Steps: 4 | Val loss: 0.2757 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2956 | Steps: 4 | Val loss: 0.2855 | Batch size: 32 | lr: 0.01 | Duration: 2.66s
[2m[36m(func pid=11611)[0m rmse: 0.1721530258655548
[2m[36m(func pid=11611)[0m mae:  0.126088485121727
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.253, 0.081, 0.331, 0.077, 0.185, 0.283, 0.138, 0.145, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.19606152176856995
[2m[36m(func pid=12847)[0m mae:  0.1121344342827797
[2m[36m(func pid=12847)[0m rmse_per_class: [0.113, 0.241, 0.195, 0.326, 0.054, 0.18, 0.252, 0.202, 0.216, 0.18]
[2m[36m(func pid=12847)[0m 
== Status ==
Current time: 2024-01-07 17:22:53 (running for 00:07:09.70)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.401 |  0.172 |                   67 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.352 |  0.146 |                   72 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.278 |  0.152 |                   72 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.35  |  0.196 |                   66 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14556412398815155
[2m[36m(func pid=11990)[0m mae:  0.10126982629299164
[2m[36m(func pid=11990)[0m rmse_per_class: [0.09, 0.222, 0.033, 0.276, 0.054, 0.152, 0.255, 0.111, 0.148, 0.113]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.15309515595436096
[2m[36m(func pid=12418)[0m mae:  0.09447922557592392
[2m[36m(func pid=12418)[0m rmse_per_class: [0.087, 0.206, 0.047, 0.276, 0.062, 0.176, 0.244, 0.129, 0.207, 0.096]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3807 | Steps: 4 | Val loss: 0.4151 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4058 | Steps: 4 | Val loss: 0.3120 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3553 | Steps: 4 | Val loss: 0.2760 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2820 | Steps: 4 | Val loss: 0.2902 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=12847)[0m rmse: 0.1873076856136322
[2m[36m(func pid=12847)[0m mae:  0.10851049423217773
[2m[36m(func pid=12847)[0m rmse_per_class: [0.105, 0.268, 0.136, 0.327, 0.055, 0.176, 0.25, 0.2, 0.193, 0.163]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17186813056468964
[2m[36m(func pid=11611)[0m mae:  0.12582501769065857
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.252, 0.08, 0.331, 0.077, 0.185, 0.283, 0.138, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
== Status ==
Current time: 2024-01-07 17:22:58 (running for 00:07:14.98)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.406 |  0.172 |                   68 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.355 |  0.146 |                   73 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.296 |  0.153 |                   73 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.381 |  0.187 |                   67 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14617785811424255
[2m[36m(func pid=11990)[0m mae:  0.10170064866542816
[2m[36m(func pid=11990)[0m rmse_per_class: [0.089, 0.222, 0.033, 0.275, 0.054, 0.153, 0.258, 0.111, 0.149, 0.118]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.157537579536438
[2m[36m(func pid=12418)[0m mae:  0.09628273546695709
[2m[36m(func pid=12418)[0m rmse_per_class: [0.092, 0.208, 0.058, 0.28, 0.079, 0.17, 0.242, 0.133, 0.211, 0.102]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3645 | Steps: 4 | Val loss: 0.3982 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4049 | Steps: 4 | Val loss: 0.3120 | Batch size: 32 | lr: 0.0001 | Duration: 3.18s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3478 | Steps: 4 | Val loss: 0.2777 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2813 | Steps: 4 | Val loss: 0.2955 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=12847)[0m rmse: 0.17595843970775604
[2m[36m(func pid=12847)[0m mae:  0.10247260332107544
[2m[36m(func pid=12847)[0m rmse_per_class: [0.115, 0.265, 0.109, 0.311, 0.054, 0.172, 0.239, 0.174, 0.18, 0.14]
[2m[36m(func pid=12847)[0m 
== Status ==
Current time: 2024-01-07 17:23:03 (running for 00:07:20.06)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.405 |  0.172 |                   69 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.355 |  0.146 |                   73 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.282 |  0.158 |                   74 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.365 |  0.176 |                   68 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11611)[0m rmse: 0.17163172364234924
[2m[36m(func pid=11611)[0m mae:  0.1256551444530487
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.252, 0.079, 0.33, 0.077, 0.185, 0.283, 0.138, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.1477472484111786
[2m[36m(func pid=11990)[0m mae:  0.10299740731716156
[2m[36m(func pid=11990)[0m rmse_per_class: [0.09, 0.221, 0.034, 0.276, 0.054, 0.153, 0.262, 0.111, 0.152, 0.123]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.15971168875694275
[2m[36m(func pid=12418)[0m mae:  0.09757466614246368
[2m[36m(func pid=12418)[0m rmse_per_class: [0.09, 0.209, 0.062, 0.285, 0.085, 0.167, 0.239, 0.134, 0.223, 0.104]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3455 | Steps: 4 | Val loss: 0.3507 | Batch size: 32 | lr: 0.1 | Duration: 3.19s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3461 | Steps: 4 | Val loss: 0.2778 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4037 | Steps: 4 | Val loss: 0.3118 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2897 | Steps: 4 | Val loss: 0.2952 | Batch size: 32 | lr: 0.01 | Duration: 2.65s
== Status ==
Current time: 2024-01-07 17:23:08 (running for 00:07:25.28)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: -0.1510000005364418
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.405 |  0.172 |                   69 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.346 |  0.148 |                   75 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.281 |  0.16  |                   75 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.365 |  0.176 |                   68 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14837253093719482
[2m[36m(func pid=11990)[0m mae:  0.10351315885782242
[2m[36m(func pid=11990)[0m rmse_per_class: [0.089, 0.222, 0.034, 0.276, 0.054, 0.153, 0.263, 0.111, 0.154, 0.126]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.16002550721168518
[2m[36m(func pid=12847)[0m mae:  0.09228275716304779
[2m[36m(func pid=12847)[0m rmse_per_class: [0.1, 0.241, 0.082, 0.283, 0.052, 0.176, 0.232, 0.151, 0.172, 0.109]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.15993954241275787
[2m[36m(func pid=12418)[0m mae:  0.09702710807323456
[2m[36m(func pid=12418)[0m rmse_per_class: [0.084, 0.209, 0.064, 0.286, 0.095, 0.166, 0.232, 0.135, 0.22, 0.11]
[2m[36m(func pid=11611)[0m rmse: 0.17146284878253937
[2m[36m(func pid=11611)[0m mae:  0.12552717328071594
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.253, 0.078, 0.33, 0.077, 0.184, 0.282, 0.138, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.3541 | Steps: 4 | Val loss: 0.2803 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2926 | Steps: 4 | Val loss: 0.3426 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2959 | Steps: 4 | Val loss: 0.2977 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4034 | Steps: 4 | Val loss: 0.3124 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 17:23:14 (running for 00:07:30.72)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: -0.1510000005364418
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   70 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.346 |  0.148 |                   75 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.29  |  0.16  |                   76 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.345 |  0.16  |                   69 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.1505652219057083
[2m[36m(func pid=11990)[0m mae:  0.10528899729251862
[2m[36m(func pid=11990)[0m rmse_per_class: [0.087, 0.223, 0.036, 0.282, 0.053, 0.154, 0.263, 0.112, 0.161, 0.134]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.16196312010288239
[2m[36m(func pid=12418)[0m mae:  0.09779015928506851
[2m[36m(func pid=12418)[0m rmse_per_class: [0.087, 0.212, 0.066, 0.287, 0.098, 0.169, 0.23, 0.137, 0.217, 0.117]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.16045060753822327
[2m[36m(func pid=12847)[0m mae:  0.0916547179222107
[2m[36m(func pid=12847)[0m rmse_per_class: [0.09, 0.235, 0.055, 0.28, 0.053, 0.199, 0.24, 0.143, 0.185, 0.124]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17160043120384216
[2m[36m(func pid=11611)[0m mae:  0.12560848891735077
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.252, 0.079, 0.33, 0.077, 0.185, 0.283, 0.137, 0.145, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2787 | Steps: 4 | Val loss: 0.2942 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.3617 | Steps: 4 | Val loss: 0.2804 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2977 | Steps: 4 | Val loss: 0.3611 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4013 | Steps: 4 | Val loss: 0.3122 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 17:23:19 (running for 00:07:35.99)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: -0.1510000005364418
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.403 |  0.172 |                   71 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.354 |  0.151 |                   76 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.279 |  0.161 |                   78 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.293 |  0.16  |                   70 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.16101773083209991
[2m[36m(func pid=12418)[0m mae:  0.0967082753777504
[2m[36m(func pid=12418)[0m rmse_per_class: [0.082, 0.211, 0.068, 0.28, 0.105, 0.171, 0.228, 0.136, 0.206, 0.124]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.1509266197681427
[2m[36m(func pid=11990)[0m mae:  0.10555437952280045
[2m[36m(func pid=11990)[0m rmse_per_class: [0.088, 0.223, 0.037, 0.279, 0.053, 0.156, 0.266, 0.112, 0.16, 0.134]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.17391325533390045
[2m[36m(func pid=12847)[0m mae:  0.09766402840614319
[2m[36m(func pid=12847)[0m rmse_per_class: [0.095, 0.25, 0.04, 0.284, 0.086, 0.219, 0.249, 0.146, 0.224, 0.147]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17157892882823944
[2m[36m(func pid=11611)[0m mae:  0.12555894255638123
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.253, 0.08, 0.33, 0.077, 0.185, 0.282, 0.137, 0.145, 0.113]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.3155 | Steps: 4 | Val loss: 0.2991 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.3561 | Steps: 4 | Val loss: 0.2791 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2982 | Steps: 4 | Val loss: 0.3881 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4069 | Steps: 4 | Val loss: 0.3121 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
== Status ==
Current time: 2024-01-07 17:23:24 (running for 00:07:41.31)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: -0.1510000005364418
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.401 |  0.172 |                   72 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.362 |  0.151 |                   77 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.315 |  0.164 |                   79 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.298 |  0.174 |                   71 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.16384056210517883
[2m[36m(func pid=12418)[0m mae:  0.09795738756656647
[2m[36m(func pid=12418)[0m rmse_per_class: [0.076, 0.215, 0.071, 0.284, 0.103, 0.17, 0.221, 0.14, 0.212, 0.147]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.1506684124469757
[2m[36m(func pid=11990)[0m mae:  0.1051434651017189
[2m[36m(func pid=11990)[0m rmse_per_class: [0.087, 0.223, 0.038, 0.277, 0.053, 0.154, 0.268, 0.112, 0.16, 0.135]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.1876794695854187
[2m[36m(func pid=12847)[0m mae:  0.10558903217315674
[2m[36m(func pid=12847)[0m rmse_per_class: [0.09, 0.254, 0.038, 0.283, 0.146, 0.221, 0.262, 0.152, 0.278, 0.152]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17124290764331818
[2m[36m(func pid=11611)[0m mae:  0.12529221177101135
[2m[36m(func pid=11611)[0m rmse_per_class: [0.116, 0.253, 0.079, 0.329, 0.076, 0.185, 0.281, 0.137, 0.144, 0.112]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2826 | Steps: 4 | Val loss: 0.2966 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.3519 | Steps: 4 | Val loss: 0.2797 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3281 | Steps: 4 | Val loss: 0.3976 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4017 | Steps: 4 | Val loss: 0.3119 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 17:23:30 (running for 00:07:46.60)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: -0.1510000005364418
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.407 |  0.171 |                   73 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.356 |  0.151 |                   78 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.283 |  0.162 |                   80 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.298 |  0.188 |                   72 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.16244402527809143
[2m[36m(func pid=12418)[0m mae:  0.09703937917947769
[2m[36m(func pid=12418)[0m rmse_per_class: [0.074, 0.214, 0.086, 0.289, 0.099, 0.17, 0.22, 0.136, 0.19, 0.147]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.15186257660388947
[2m[36m(func pid=11990)[0m mae:  0.10598796606063843
[2m[36m(func pid=11990)[0m rmse_per_class: [0.087, 0.223, 0.042, 0.277, 0.053, 0.155, 0.269, 0.111, 0.161, 0.139]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.19396568834781647
[2m[36m(func pid=12847)[0m mae:  0.10927714407444
[2m[36m(func pid=12847)[0m rmse_per_class: [0.098, 0.245, 0.046, 0.294, 0.184, 0.204, 0.259, 0.16, 0.296, 0.154]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17090144753456116
[2m[36m(func pid=11611)[0m mae:  0.12505513429641724
[2m[36m(func pid=11611)[0m rmse_per_class: [0.117, 0.252, 0.078, 0.329, 0.075, 0.184, 0.282, 0.137, 0.145, 0.111]
[2m[36m(func pid=11611)[0m 
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.3005 | Steps: 4 | Val loss: 0.2972 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.3410 | Steps: 4 | Val loss: 0.2783 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3864 | Steps: 4 | Val loss: 0.4170 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=11611)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4044 | Steps: 4 | Val loss: 0.3121 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 17:23:35 (running for 00:07:51.76)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: -0.1510000005364418
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | RUNNING  | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.402 |  0.171 |                   74 |
| train_01e98_00001 | RUNNING  | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.352 |  0.152 |                   79 |
| train_01e98_00002 | RUNNING  | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.301 |  0.163 |                   81 |
| train_01e98_00003 | RUNNING  | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.328 |  0.194 |                   73 |
| train_01e98_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.1628882735967636
[2m[36m(func pid=12418)[0m mae:  0.09711459279060364
[2m[36m(func pid=12418)[0m rmse_per_class: [0.073, 0.215, 0.088, 0.29, 0.097, 0.171, 0.22, 0.133, 0.183, 0.159]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.15109017491340637
[2m[36m(func pid=11990)[0m mae:  0.10507788509130478
[2m[36m(func pid=11990)[0m rmse_per_class: [0.084, 0.223, 0.042, 0.274, 0.053, 0.155, 0.27, 0.112, 0.159, 0.138]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12847)[0m rmse: 0.19335158169269562
[2m[36m(func pid=12847)[0m mae:  0.11069066822528839
[2m[36m(func pid=12847)[0m rmse_per_class: [0.102, 0.238, 0.046, 0.325, 0.147, 0.191, 0.252, 0.165, 0.319, 0.148]
[2m[36m(func pid=12847)[0m 
[2m[36m(func pid=11611)[0m rmse: 0.17085406184196472
[2m[36m(func pid=11611)[0m mae:  0.12498588860034943
[2m[36m(func pid=11611)[0m rmse_per_class: [0.115, 0.252, 0.079, 0.33, 0.074, 0.184, 0.282, 0.136, 0.146, 0.111]
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2804 | Steps: 4 | Val loss: 0.2961 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.3520 | Steps: 4 | Val loss: 0.2769 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=12847)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3172 | Steps: 4 | Val loss: 0.4098 | Batch size: 32 | lr: 0.1 | Duration: 3.23s
[2m[36m(func pid=12418)[0m rmse: 0.1627156287431717
[2m[36m(func pid=12418)[0m mae:  0.09665746241807938
[2m[36m(func pid=12418)[0m rmse_per_class: [0.071, 0.216, 0.09, 0.291, 0.102, 0.17, 0.22, 0.129, 0.178, 0.16]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.15073677897453308
[2m[36m(func pid=11990)[0m mae:  0.10463991016149521
[2m[36m(func pid=11990)[0m rmse_per_class: [0.084, 0.222, 0.046, 0.273, 0.053, 0.154, 0.269, 0.112, 0.16, 0.133]
[2m[36m(func pid=12847)[0m rmse: 0.1857067048549652
[2m[36m(func pid=12847)[0m mae:  0.10728125274181366
[2m[36m(func pid=12847)[0m rmse_per_class: [0.117, 0.256, 0.046, 0.343, 0.09, 0.184, 0.246, 0.16, 0.274, 0.139]
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.3085 | Steps: 4 | Val loss: 0.2950 | Batch size: 32 | lr: 0.01 | Duration: 2.68s
[2m[36m(func pid=12418)[0m rmse: 0.1625167429447174
[2m[36m(func pid=12418)[0m mae:  0.09653054177761078
[2m[36m(func pid=12418)[0m rmse_per_class: [0.069, 0.218, 0.091, 0.293, 0.098, 0.165, 0.219, 0.13, 0.174, 0.168]
== Status ==
Current time: 2024-01-07 17:23:40 (running for 00:07:56.92)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.341 |  0.151 |                   80 |
| train_01e98_00002 | RUNNING    | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.28  |  0.163 |                   82 |
| train_01e98_00003 | RUNNING    | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.386 |  0.193 |                   74 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


== Status ==
Current time: 2024-01-07 17:23:46 (running for 00:08:03.10)
Memory usage on this node: 23.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (19 PENDING, 3 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.341 |  0.151 |                   80 |
| train_01e98_00002 | RUNNING    | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.28  |  0.163 |                   82 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=31109)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=31109)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=31109)[0m Configuration completed!
[2m[36m(func pid=31109)[0m New optimizer parameters:
[2m[36m(func pid=31109)[0m SGD (
[2m[36m(func pid=31109)[0m Parameter Group 0
[2m[36m(func pid=31109)[0m     dampening: 0
[2m[36m(func pid=31109)[0m     differentiable: False
[2m[36m(func pid=31109)[0m     foreach: None
[2m[36m(func pid=31109)[0m     lr: 0.0001
[2m[36m(func pid=31109)[0m     maximize: False
[2m[36m(func pid=31109)[0m     momentum: 0.9
[2m[36m(func pid=31109)[0m     nesterov: False
[2m[36m(func pid=31109)[0m     weight_decay: 0
[2m[36m(func pid=31109)[0m )
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.3487 | Steps: 4 | Val loss: 0.2801 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2908 | Steps: 4 | Val loss: 0.2942 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8978 | Steps: 4 | Val loss: 0.7097 | Batch size: 32 | lr: 0.0001 | Duration: 4.55s
[2m[36m(func pid=12418)[0m rmse: 0.1626095026731491
[2m[36m(func pid=12418)[0m mae:  0.09632090479135513
[2m[36m(func pid=12418)[0m rmse_per_class: [0.07, 0.219, 0.098, 0.289, 0.104, 0.165, 0.224, 0.124, 0.164, 0.167]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m rmse: 0.15344877541065216
[2m[36m(func pid=11990)[0m mae:  0.10671918094158173
[2m[36m(func pid=11990)[0m rmse_per_class: [0.085, 0.225, 0.054, 0.286, 0.054, 0.154, 0.268, 0.111, 0.164, 0.133]
[2m[36m(func pid=31109)[0m rmse: 0.1828189194202423
[2m[36m(func pid=31109)[0m mae:  0.1345725953578949
[2m[36m(func pid=31109)[0m rmse_per_class: [0.117, 0.267, 0.107, 0.339, 0.113, 0.191, 0.294, 0.144, 0.143, 0.113]
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2903 | Steps: 4 | Val loss: 0.2862 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 17:23:51 (running for 00:08:08.34)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.352 |  0.151 |                   81 |
| train_01e98_00002 | RUNNING    | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.291 |  0.163 |                   84 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |        |        |                      |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=31653)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31653)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=31653)[0m Configuration completed!
[2m[36m(func pid=31653)[0m New optimizer parameters:
[2m[36m(func pid=31653)[0m SGD (
[2m[36m(func pid=31653)[0m Parameter Group 0
[2m[36m(func pid=31653)[0m     dampening: 0
[2m[36m(func pid=31653)[0m     differentiable: False
[2m[36m(func pid=31653)[0m     foreach: None
[2m[36m(func pid=31653)[0m     lr: 0.001
[2m[36m(func pid=31653)[0m     maximize: False
[2m[36m(func pid=31653)[0m     momentum: 0.9
[2m[36m(func pid=31653)[0m     nesterov: False
[2m[36m(func pid=31653)[0m     weight_decay: 0
[2m[36m(func pid=31653)[0m )
[2m[36m(func pid=31653)[0m 
== Status ==
Current time: 2024-01-07 17:23:57 (running for 00:08:13.63)
Memory usage on this node: 24.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.349 |  0.153 |                   82 |
| train_01e98_00002 | RUNNING    | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.29  |  0.159 |                   85 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.898 |  0.183 |                    1 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.1586369276046753
[2m[36m(func pid=12418)[0m mae:  0.09388121962547302
[2m[36m(func pid=12418)[0m rmse_per_class: [0.072, 0.219, 0.095, 0.281, 0.105, 0.165, 0.226, 0.122, 0.154, 0.148]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.3374 | Steps: 4 | Val loss: 0.2802 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.8894 | Steps: 4 | Val loss: 0.7057 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2879 | Steps: 4 | Val loss: 0.2865 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8929 | Steps: 4 | Val loss: 0.6978 | Batch size: 32 | lr: 0.001 | Duration: 4.58s
[2m[36m(func pid=11990)[0m rmse: 0.15399926900863647
[2m[36m(func pid=11990)[0m mae:  0.1069435253739357
[2m[36m(func pid=11990)[0m rmse_per_class: [0.085, 0.225, 0.058, 0.286, 0.054, 0.155, 0.266, 0.112, 0.164, 0.134]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.18233907222747803
[2m[36m(func pid=31109)[0m mae:  0.13423524796962738
[2m[36m(func pid=31109)[0m rmse_per_class: [0.117, 0.266, 0.104, 0.34, 0.114, 0.19, 0.294, 0.142, 0.143, 0.112]
[2m[36m(func pid=31109)[0m 
== Status ==
Current time: 2024-01-07 17:24:02 (running for 00:08:18.97)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.337 |  0.154 |                   83 |
| train_01e98_00002 | RUNNING    | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.288 |  0.159 |                   86 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.889 |  0.182 |                    2 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |        |        |                      |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.1594727784395218
[2m[36m(func pid=12418)[0m mae:  0.09438283741474152
[2m[36m(func pid=12418)[0m rmse_per_class: [0.073, 0.219, 0.104, 0.278, 0.102, 0.167, 0.233, 0.118, 0.151, 0.15]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.18268874287605286
[2m[36m(func pid=31653)[0m mae:  0.13447323441505432
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.267, 0.107, 0.34, 0.113, 0.19, 0.294, 0.144, 0.143, 0.113]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.3329 | Steps: 4 | Val loss: 0.2806 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.8906 | Steps: 4 | Val loss: 0.6943 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2898 | Steps: 4 | Val loss: 0.2846 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.8761 | Steps: 4 | Val loss: 0.6723 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=11990)[0m rmse: 0.1545843482017517
[2m[36m(func pid=11990)[0m mae:  0.10711950063705444
[2m[36m(func pid=11990)[0m rmse_per_class: [0.086, 0.226, 0.06, 0.288, 0.054, 0.155, 0.264, 0.113, 0.164, 0.135]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.18138478696346283
[2m[36m(func pid=31109)[0m mae:  0.1334746778011322
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.265, 0.103, 0.339, 0.112, 0.19, 0.294, 0.141, 0.143, 0.111]
[2m[36m(func pid=31109)[0m 
== Status ==
Current time: 2024-01-07 17:24:07 (running for 00:08:24.10)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.333 |  0.155 |                   84 |
| train_01e98_00002 | RUNNING    | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.29  |  0.158 |                   87 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.891 |  0.181 |                    3 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.893 |  0.183 |                    1 |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.15840992331504822
[2m[36m(func pid=12418)[0m mae:  0.0938100516796112
[2m[36m(func pid=12418)[0m rmse_per_class: [0.073, 0.217, 0.097, 0.275, 0.099, 0.169, 0.236, 0.116, 0.147, 0.155]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.1817755550146103
[2m[36m(func pid=31653)[0m mae:  0.13378386199474335
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.266, 0.104, 0.339, 0.113, 0.19, 0.294, 0.142, 0.143, 0.112]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.3369 | Steps: 4 | Val loss: 0.2794 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8897 | Steps: 4 | Val loss: 0.6873 | Batch size: 32 | lr: 0.0001 | Duration: 3.12s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2781 | Steps: 4 | Val loss: 0.2849 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.8469 | Steps: 4 | Val loss: 0.6447 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=11990)[0m rmse: 0.15367838740348816
[2m[36m(func pid=11990)[0m mae:  0.10628481954336166
[2m[36m(func pid=11990)[0m rmse_per_class: [0.084, 0.227, 0.06, 0.285, 0.055, 0.155, 0.262, 0.113, 0.162, 0.132]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.18063467741012573
[2m[36m(func pid=31109)[0m mae:  0.13282573223114014
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.264, 0.102, 0.338, 0.111, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.1587604582309723
[2m[36m(func pid=12418)[0m mae:  0.0941157191991806
[2m[36m(func pid=12418)[0m rmse_per_class: [0.074, 0.219, 0.103, 0.278, 0.102, 0.173, 0.238, 0.116, 0.142, 0.143]
== Status ==
Current time: 2024-01-07 17:24:12 (running for 00:08:29.39)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.337 |  0.154 |                   85 |
| train_01e98_00002 | RUNNING    | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.278 |  0.159 |                   88 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.89  |  0.181 |                    4 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.876 |  0.182 |                    2 |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.18091218173503876
[2m[36m(func pid=31653)[0m mae:  0.133063405752182
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.265, 0.103, 0.338, 0.112, 0.189, 0.294, 0.14, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.3379 | Steps: 4 | Val loss: 0.2788 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.8828 | Steps: 4 | Val loss: 0.6861 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2769 | Steps: 4 | Val loss: 0.2807 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8180 | Steps: 4 | Val loss: 0.6174 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=11990)[0m rmse: 0.15359872579574585
[2m[36m(func pid=11990)[0m mae:  0.10602562129497528
[2m[36m(func pid=11990)[0m rmse_per_class: [0.086, 0.226, 0.063, 0.28, 0.055, 0.158, 0.262, 0.113, 0.162, 0.131]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.18047702312469482
[2m[36m(func pid=31109)[0m mae:  0.1326638013124466
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.263, 0.101, 0.337, 0.111, 0.19, 0.294, 0.14, 0.142, 0.11]
[2m[36m(func pid=31109)[0m 
== Status ==
Current time: 2024-01-07 17:24:18 (running for 00:08:34.65)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.338 |  0.154 |                   86 |
| train_01e98_00002 | RUNNING    | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.277 |  0.156 |                   89 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.883 |  0.18  |                    5 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.847 |  0.181 |                    3 |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.15560190379619598
[2m[36m(func pid=12418)[0m mae:  0.09219832718372345
[2m[36m(func pid=12418)[0m rmse_per_class: [0.073, 0.218, 0.097, 0.272, 0.093, 0.173, 0.237, 0.115, 0.136, 0.14]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.18062719702720642
[2m[36m(func pid=31653)[0m mae:  0.1328245848417282
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.264, 0.101, 0.337, 0.111, 0.189, 0.294, 0.141, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.3328 | Steps: 4 | Val loss: 0.2767 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.8789 | Steps: 4 | Val loss: 0.6850 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2832 | Steps: 4 | Val loss: 0.2766 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7799 | Steps: 4 | Val loss: 0.5876 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=11990)[0m rmse: 0.15184977650642395
[2m[36m(func pid=11990)[0m mae:  0.10446985810995102
[2m[36m(func pid=11990)[0m rmse_per_class: [0.083, 0.225, 0.068, 0.277, 0.057, 0.156, 0.259, 0.111, 0.158, 0.123]
[2m[36m(func pid=11990)[0m 
== Status ==
Current time: 2024-01-07 17:24:23 (running for 00:08:39.67)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.333 |  0.152 |                   87 |
| train_01e98_00002 | RUNNING    | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.283 |  0.152 |                   90 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.883 |  0.18  |                    5 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.818 |  0.181 |                    4 |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.1523638665676117
[2m[36m(func pid=12418)[0m mae:  0.08993525803089142
[2m[36m(func pid=12418)[0m rmse_per_class: [0.073, 0.217, 0.092, 0.268, 0.083, 0.173, 0.233, 0.115, 0.138, 0.132]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.18024621903896332
[2m[36m(func pid=31109)[0m mae:  0.1324186772108078
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.263, 0.101, 0.337, 0.111, 0.19, 0.294, 0.14, 0.142, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.1799965798854828
[2m[36m(func pid=31653)[0m mae:  0.1323152482509613
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.263, 0.099, 0.337, 0.11, 0.189, 0.294, 0.14, 0.142, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.3372 | Steps: 4 | Val loss: 0.2760 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2739 | Steps: 4 | Val loss: 0.2743 | Batch size: 32 | lr: 0.01 | Duration: 2.69s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.8711 | Steps: 4 | Val loss: 0.6823 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.7441 | Steps: 4 | Val loss: 0.5620 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=11990)[0m rmse: 0.15107408165931702
[2m[36m(func pid=11990)[0m mae:  0.10385186970233917
[2m[36m(func pid=11990)[0m rmse_per_class: [0.078, 0.227, 0.068, 0.281, 0.058, 0.156, 0.254, 0.113, 0.157, 0.121]
[2m[36m(func pid=11990)[0m 
== Status ==
Current time: 2024-01-07 17:24:28 (running for 00:08:44.69)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.337 |  0.151 |                   88 |
| train_01e98_00002 | RUNNING    | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.274 |  0.151 |                   91 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.879 |  0.18  |                    6 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.78  |  0.18  |                    5 |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.1507263332605362
[2m[36m(func pid=12418)[0m mae:  0.08871392905712128
[2m[36m(func pid=12418)[0m rmse_per_class: [0.073, 0.216, 0.088, 0.265, 0.076, 0.174, 0.229, 0.116, 0.139, 0.13]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.18014317750930786
[2m[36m(func pid=31109)[0m mae:  0.1323726922273636
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.262, 0.1, 0.337, 0.111, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.1797596663236618
[2m[36m(func pid=31653)[0m mae:  0.13209107518196106
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.262, 0.099, 0.337, 0.109, 0.189, 0.294, 0.141, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.3285 | Steps: 4 | Val loss: 0.2761 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2817 | Steps: 4 | Val loss: 0.2732 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.8684 | Steps: 4 | Val loss: 0.6762 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.7146 | Steps: 4 | Val loss: 0.5374 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=11990)[0m rmse: 0.1507609784603119
[2m[36m(func pid=11990)[0m mae:  0.10329119116067886
[2m[36m(func pid=11990)[0m rmse_per_class: [0.076, 0.226, 0.071, 0.282, 0.06, 0.154, 0.252, 0.113, 0.154, 0.12]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=12418)[0m rmse: 0.14939787983894348
[2m[36m(func pid=12418)[0m mae:  0.08818987011909485
[2m[36m(func pid=12418)[0m rmse_per_class: [0.074, 0.215, 0.087, 0.264, 0.071, 0.173, 0.231, 0.114, 0.14, 0.127]
[2m[36m(func pid=12418)[0m 
== Status ==
Current time: 2024-01-07 17:24:33 (running for 00:08:49.85)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.328 |  0.151 |                   89 |
| train_01e98_00002 | RUNNING    | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.282 |  0.149 |                   92 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.871 |  0.18  |                    7 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.744 |  0.18  |                    6 |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=31109)[0m rmse: 0.1799432784318924
[2m[36m(func pid=31109)[0m mae:  0.1321929544210434
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.262, 0.1, 0.337, 0.111, 0.19, 0.294, 0.14, 0.142, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17929284274578094
[2m[36m(func pid=31653)[0m mae:  0.13167080283164978
[2m[36m(func pid=31653)[0m rmse_per_class: [0.115, 0.261, 0.098, 0.336, 0.108, 0.189, 0.293, 0.14, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.3351 | Steps: 4 | Val loss: 0.2772 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2709 | Steps: 4 | Val loss: 0.2713 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.8647 | Steps: 4 | Val loss: 0.6706 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=11990)[0m rmse: 0.15148241817951202
[2m[36m(func pid=11990)[0m mae:  0.1037331074476242
[2m[36m(func pid=11990)[0m rmse_per_class: [0.076, 0.226, 0.077, 0.285, 0.063, 0.155, 0.25, 0.111, 0.153, 0.119]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.6854 | Steps: 4 | Val loss: 0.5174 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 17:24:38 (running for 00:08:55.18)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.335 |  0.151 |                   90 |
| train_01e98_00002 | RUNNING    | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.271 |  0.148 |                   93 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.868 |  0.18  |                    8 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.715 |  0.179 |                    7 |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.1475919783115387
[2m[36m(func pid=12418)[0m mae:  0.08748891949653625
[2m[36m(func pid=12418)[0m rmse_per_class: [0.076, 0.216, 0.08, 0.262, 0.066, 0.172, 0.229, 0.113, 0.141, 0.121]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17995566129684448
[2m[36m(func pid=31109)[0m mae:  0.13218222558498383
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.262, 0.099, 0.337, 0.111, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.1791982650756836
[2m[36m(func pid=31653)[0m mae:  0.13168345391750336
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.261, 0.096, 0.336, 0.107, 0.189, 0.293, 0.14, 0.143, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.3444 | Steps: 4 | Val loss: 0.2765 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2778 | Steps: 4 | Val loss: 0.2717 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.8602 | Steps: 4 | Val loss: 0.6683 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.6577 | Steps: 4 | Val loss: 0.4972 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=11990)[0m rmse: 0.1508598029613495
[2m[36m(func pid=11990)[0m mae:  0.10294375568628311
[2m[36m(func pid=11990)[0m rmse_per_class: [0.075, 0.226, 0.077, 0.284, 0.065, 0.155, 0.248, 0.112, 0.149, 0.119]
[2m[36m(func pid=11990)[0m 
== Status ==
Current time: 2024-01-07 17:24:44 (running for 00:09:00.55)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.344 |  0.151 |                   91 |
| train_01e98_00002 | RUNNING    | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.278 |  0.148 |                   94 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.865 |  0.18  |                    9 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.685 |  0.179 |                    8 |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.1481853872537613
[2m[36m(func pid=12418)[0m mae:  0.08754073828458786
[2m[36m(func pid=12418)[0m rmse_per_class: [0.078, 0.218, 0.08, 0.26, 0.065, 0.169, 0.228, 0.115, 0.145, 0.125]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17996013164520264
[2m[36m(func pid=31109)[0m mae:  0.13219335675239563
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.111, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.1788015216588974
[2m[36m(func pid=31653)[0m mae:  0.13129130005836487
[2m[36m(func pid=31653)[0m rmse_per_class: [0.115, 0.26, 0.096, 0.336, 0.106, 0.189, 0.293, 0.14, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.3311 | Steps: 4 | Val loss: 0.2773 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2953 | Steps: 4 | Val loss: 0.2723 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.8577 | Steps: 4 | Val loss: 0.6659 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=11990)[0m rmse: 0.15142162144184113
[2m[36m(func pid=11990)[0m mae:  0.10319948196411133
[2m[36m(func pid=11990)[0m rmse_per_class: [0.074, 0.225, 0.079, 0.284, 0.068, 0.155, 0.247, 0.112, 0.148, 0.122]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.6328 | Steps: 4 | Val loss: 0.4796 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 17:24:49 (running for 00:09:05.61)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.331 |  0.151 |                   92 |
| train_01e98_00002 | RUNNING    | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.295 |  0.148 |                   95 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.86  |  0.18  |                   10 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.658 |  0.179 |                    9 |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.1480267196893692
[2m[36m(func pid=12418)[0m mae:  0.0877559632062912
[2m[36m(func pid=12418)[0m rmse_per_class: [0.084, 0.219, 0.079, 0.263, 0.064, 0.168, 0.23, 0.115, 0.144, 0.116]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.18011300265789032
[2m[36m(func pid=31109)[0m mae:  0.1323389858007431
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.1, 0.337, 0.11, 0.19, 0.296, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.1788017600774765
[2m[36m(func pid=31653)[0m mae:  0.1312706023454666
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.336, 0.106, 0.189, 0.293, 0.14, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.3269 | Steps: 4 | Val loss: 0.2777 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2730 | Steps: 4 | Val loss: 0.2725 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.8527 | Steps: 4 | Val loss: 0.6627 | Batch size: 32 | lr: 0.0001 | Duration: 3.12s
[2m[36m(func pid=11990)[0m rmse: 0.15121886134147644
[2m[36m(func pid=11990)[0m mae:  0.10287847369909286
[2m[36m(func pid=11990)[0m rmse_per_class: [0.074, 0.227, 0.079, 0.289, 0.07, 0.154, 0.243, 0.112, 0.145, 0.12]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.6109 | Steps: 4 | Val loss: 0.4613 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 17:24:54 (running for 00:09:10.86)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.327 |  0.151 |                   93 |
| train_01e98_00002 | RUNNING    | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.273 |  0.148 |                   96 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.858 |  0.18  |                   11 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.633 |  0.179 |                   10 |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.1483435332775116
[2m[36m(func pid=12418)[0m mae:  0.08817405253648758
[2m[36m(func pid=12418)[0m rmse_per_class: [0.089, 0.218, 0.078, 0.264, 0.062, 0.164, 0.23, 0.116, 0.147, 0.116]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.18012432754039764
[2m[36m(func pid=31109)[0m mae:  0.13235363364219666
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.101, 0.337, 0.11, 0.19, 0.296, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17870180308818817
[2m[36m(func pid=31653)[0m mae:  0.13117992877960205
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.336, 0.104, 0.189, 0.293, 0.141, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.3175 | Steps: 4 | Val loss: 0.2774 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2766 | Steps: 4 | Val loss: 0.2769 | Batch size: 32 | lr: 0.01 | Duration: 2.69s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.8484 | Steps: 4 | Val loss: 0.6587 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=11990)[0m rmse: 0.15100720524787903
[2m[36m(func pid=11990)[0m mae:  0.10241589695215225
[2m[36m(func pid=11990)[0m rmse_per_class: [0.072, 0.227, 0.085, 0.288, 0.075, 0.155, 0.238, 0.112, 0.145, 0.113]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.5915 | Steps: 4 | Val loss: 0.4462 | Batch size: 32 | lr: 0.001 | Duration: 3.20s
== Status ==
Current time: 2024-01-07 17:24:59 (running for 00:09:16.16)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.318 |  0.151 |                   94 |
| train_01e98_00002 | RUNNING    | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.277 |  0.151 |                   97 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.853 |  0.18  |                   12 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.611 |  0.179 |                   11 |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.15106706321239471
[2m[36m(func pid=12418)[0m mae:  0.09029452502727509
[2m[36m(func pid=12418)[0m rmse_per_class: [0.106, 0.218, 0.071, 0.27, 0.055, 0.162, 0.232, 0.12, 0.162, 0.114]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.18001024425029755
[2m[36m(func pid=31109)[0m mae:  0.13225436210632324
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.1, 0.337, 0.11, 0.19, 0.295, 0.139, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.1783495992422104
[2m[36m(func pid=31653)[0m mae:  0.13083530962467194
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.336, 0.103, 0.189, 0.292, 0.14, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.3354 | Steps: 4 | Val loss: 0.2758 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.3201 | Steps: 4 | Val loss: 0.2794 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.8435 | Steps: 4 | Val loss: 0.6540 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=11990)[0m rmse: 0.14965911209583282
[2m[36m(func pid=11990)[0m mae:  0.10110374540090561
[2m[36m(func pid=11990)[0m rmse_per_class: [0.072, 0.225, 0.084, 0.285, 0.077, 0.154, 0.238, 0.111, 0.141, 0.11]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.5738 | Steps: 4 | Val loss: 0.4334 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 17:25:04 (running for 00:09:21.36)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.335 |  0.15  |                   95 |
| train_01e98_00002 | RUNNING    | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.32  |  0.152 |                   98 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.848 |  0.18  |                   13 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.591 |  0.178 |                   12 |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.1522492617368698
[2m[36m(func pid=12418)[0m mae:  0.09103177487850189
[2m[36m(func pid=12418)[0m rmse_per_class: [0.115, 0.22, 0.06, 0.269, 0.051, 0.16, 0.23, 0.126, 0.173, 0.118]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.18009169399738312
[2m[36m(func pid=31109)[0m mae:  0.13236388564109802
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.261, 0.1, 0.338, 0.11, 0.19, 0.295, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17811961472034454
[2m[36m(func pid=31653)[0m mae:  0.13064536452293396
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.259, 0.095, 0.335, 0.103, 0.189, 0.292, 0.14, 0.142, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.3308 | Steps: 4 | Val loss: 0.2749 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2828 | Steps: 4 | Val loss: 0.2831 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.8386 | Steps: 4 | Val loss: 0.6514 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=11990)[0m rmse: 0.14866900444030762
[2m[36m(func pid=11990)[0m mae:  0.10009171813726425
[2m[36m(func pid=11990)[0m rmse_per_class: [0.069, 0.226, 0.087, 0.286, 0.075, 0.155, 0.23, 0.113, 0.14, 0.106]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.5537 | Steps: 4 | Val loss: 0.4188 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 17:25:10 (running for 00:09:26.56)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.331 |  0.149 |                   96 |
| train_01e98_00002 | RUNNING    | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.283 |  0.155 |                   99 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.844 |  0.18  |                   14 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.574 |  0.178 |                   13 |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.15517164766788483
[2m[36m(func pid=12418)[0m mae:  0.09334871917963028
[2m[36m(func pid=12418)[0m rmse_per_class: [0.126, 0.218, 0.059, 0.278, 0.051, 0.159, 0.233, 0.127, 0.181, 0.119]
[2m[36m(func pid=12418)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.18000182509422302
[2m[36m(func pid=31109)[0m mae:  0.1322856992483139
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.261, 0.099, 0.338, 0.11, 0.19, 0.295, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.1777450442314148
[2m[36m(func pid=31653)[0m mae:  0.1304067075252533
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.259, 0.093, 0.336, 0.102, 0.188, 0.292, 0.14, 0.142, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.3303 | Steps: 4 | Val loss: 0.2754 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=12418)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2757 | Steps: 4 | Val loss: 0.2856 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.8297 | Steps: 4 | Val loss: 0.6469 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=11990)[0m rmse: 0.14824017882347107
[2m[36m(func pid=11990)[0m mae:  0.09946027398109436
[2m[36m(func pid=11990)[0m rmse_per_class: [0.067, 0.227, 0.09, 0.287, 0.077, 0.154, 0.226, 0.113, 0.139, 0.102]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.5399 | Steps: 4 | Val loss: 0.4080 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 17:25:15 (running for 00:09:31.73)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (18 PENDING, 3 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.33  |  0.148 |                   97 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.839 |  0.18  |                   15 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.554 |  0.178 |                   14 |
| train_01e98_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=12418)[0m rmse: 0.15610870718955994
[2m[36m(func pid=12418)[0m mae:  0.09412875026464462
[2m[36m(func pid=12418)[0m rmse_per_class: [0.119, 0.22, 0.051, 0.28, 0.049, 0.158, 0.231, 0.129, 0.196, 0.128]
[2m[36m(func pid=31109)[0m rmse: 0.17990581691265106
[2m[36m(func pid=31109)[0m mae:  0.132186621427536
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.261, 0.099, 0.338, 0.11, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17728714644908905
[2m[36m(func pid=31653)[0m mae:  0.12999245524406433
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.259, 0.093, 0.334, 0.101, 0.188, 0.291, 0.14, 0.142, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.3416 | Steps: 4 | Val loss: 0.2735 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=11990)[0m rmse: 0.14683322608470917
[2m[36m(func pid=11990)[0m mae:  0.09831630438566208
[2m[36m(func pid=11990)[0m rmse_per_class: [0.068, 0.227, 0.079, 0.288, 0.08, 0.152, 0.224, 0.114, 0.138, 0.098]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.5341 | Steps: 4 | Val loss: 0.3996 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.8277 | Steps: 4 | Val loss: 0.6429 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=31653)[0m rmse: 0.1772429496049881
[2m[36m(func pid=31653)[0m mae:  0.12994787096977234
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.258, 0.094, 0.334, 0.099, 0.189, 0.29, 0.139, 0.142, 0.109]
[2m[36m(func pid=31109)[0m rmse: 0.17991408705711365
[2m[36m(func pid=31109)[0m mae:  0.13217219710350037
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.261, 0.099, 0.337, 0.11, 0.19, 0.295, 0.14, 0.143, 0.109]
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.3370 | Steps: 4 | Val loss: 0.2744 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 17:25:20 (running for 00:09:37.01)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.342 |  0.147 |                   98 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.83  |  0.18  |                   16 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.54  |  0.177 |                   15 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=35640)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=35640)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=35640)[0m Configuration completed!
[2m[36m(func pid=35640)[0m New optimizer parameters:
[2m[36m(func pid=35640)[0m SGD (
[2m[36m(func pid=35640)[0m Parameter Group 0
[2m[36m(func pid=35640)[0m     dampening: 0
[2m[36m(func pid=35640)[0m     differentiable: False
[2m[36m(func pid=35640)[0m     foreach: None
[2m[36m(func pid=35640)[0m     lr: 0.01
[2m[36m(func pid=35640)[0m     maximize: False
[2m[36m(func pid=35640)[0m     momentum: 0.9
[2m[36m(func pid=35640)[0m     nesterov: False
[2m[36m(func pid=35640)[0m     weight_decay: 0
[2m[36m(func pid=35640)[0m )
[2m[36m(func pid=35640)[0m 
== Status ==
Current time: 2024-01-07 17:25:26 (running for 00:09:42.51)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00001 | RUNNING    | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.337 |  0.148 |                   99 |
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.828 |  0.18  |                   17 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.534 |  0.177 |                   16 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |        |        |                      |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.1477966159582138
[2m[36m(func pid=11990)[0m mae:  0.09910844266414642
[2m[36m(func pid=11990)[0m rmse_per_class: [0.067, 0.228, 0.084, 0.289, 0.089, 0.153, 0.225, 0.11, 0.137, 0.096]
[2m[36m(func pid=11990)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.5203 | Steps: 4 | Val loss: 0.3928 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.8254 | Steps: 4 | Val loss: 0.6382 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8679 | Steps: 4 | Val loss: 0.6338 | Batch size: 32 | lr: 0.01 | Duration: 4.60s
[2m[36m(func pid=11990)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.3445 | Steps: 4 | Val loss: 0.2744 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=31653)[0m rmse: 0.17716652154922485
[2m[36m(func pid=31653)[0m mae:  0.12990418076515198
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.259, 0.093, 0.334, 0.099, 0.188, 0.29, 0.14, 0.142, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17990906536579132
[2m[36m(func pid=31109)[0m mae:  0.13213586807250977
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.111, 0.19, 0.295, 0.14, 0.143, 0.108]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.18255922198295593
[2m[36m(func pid=35640)[0m mae:  0.13440921902656555
[2m[36m(func pid=35640)[0m rmse_per_class: [0.117, 0.267, 0.107, 0.339, 0.111, 0.191, 0.294, 0.144, 0.144, 0.113]
[2m[36m(func pid=35640)[0m 
== Status ==
Current time: 2024-01-07 17:25:31 (running for 00:09:47.65)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (17 PENDING, 3 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.825 |  0.18  |                   18 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.52  |  0.177 |                   17 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.868 |  0.183 |                    1 |
| train_01e98_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=11990)[0m rmse: 0.14741094410419464
[2m[36m(func pid=11990)[0m mae:  0.0986417680978775
[2m[36m(func pid=11990)[0m rmse_per_class: [0.066, 0.229, 0.078, 0.291, 0.089, 0.152, 0.224, 0.111, 0.136, 0.097]
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.5130 | Steps: 4 | Val loss: 0.3861 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.8203 | Steps: 4 | Val loss: 0.6358 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.7256 | Steps: 4 | Val loss: 0.5046 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=31653)[0m rmse: 0.17713633179664612
[2m[36m(func pid=31653)[0m mae:  0.1299043595790863
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.259, 0.092, 0.334, 0.099, 0.188, 0.291, 0.14, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.18011996150016785
[2m[36m(func pid=31109)[0m mae:  0.1322890818119049
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.1, 0.338, 0.111, 0.19, 0.295, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.18166182935237885
[2m[36m(func pid=35640)[0m mae:  0.13385699689388275
[2m[36m(func pid=35640)[0m rmse_per_class: [0.119, 0.266, 0.102, 0.339, 0.108, 0.19, 0.295, 0.141, 0.144, 0.113]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.5054 | Steps: 4 | Val loss: 0.3802 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.8155 | Steps: 4 | Val loss: 0.6312 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.5726 | Steps: 4 | Val loss: 0.4021 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=36548)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=36548)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=36548)[0m Configuration completed!
[2m[36m(func pid=36548)[0m New optimizer parameters:
[2m[36m(func pid=36548)[0m SGD (
[2m[36m(func pid=36548)[0m Parameter Group 0
[2m[36m(func pid=36548)[0m     dampening: 0
[2m[36m(func pid=36548)[0m     differentiable: False
[2m[36m(func pid=36548)[0m     foreach: None
[2m[36m(func pid=36548)[0m     lr: 0.1
[2m[36m(func pid=36548)[0m     maximize: False
[2m[36m(func pid=36548)[0m     momentum: 0.9
[2m[36m(func pid=36548)[0m     nesterov: False
[2m[36m(func pid=36548)[0m     weight_decay: 0
[2m[36m(func pid=36548)[0m )
[2m[36m(func pid=36548)[0m 
== Status ==
Current time: 2024-01-07 17:25:39 (running for 00:09:56.38)
Memory usage on this node: 24.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.82  |  0.18  |                   19 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.505 |  0.177 |                   19 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.726 |  0.182 |                    2 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=31653)[0m rmse: 0.17697454988956451
[2m[36m(func pid=31653)[0m mae:  0.1297796070575714
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.258, 0.092, 0.334, 0.098, 0.188, 0.29, 0.14, 0.143, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.1800277978181839
[2m[36m(func pid=31109)[0m mae:  0.1322394460439682
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.338, 0.111, 0.189, 0.295, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.18072041869163513
[2m[36m(func pid=35640)[0m mae:  0.13321465253829956
[2m[36m(func pid=35640)[0m rmse_per_class: [0.119, 0.264, 0.1, 0.338, 0.102, 0.189, 0.294, 0.141, 0.145, 0.115]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4962 | Steps: 4 | Val loss: 0.3752 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.8102 | Steps: 4 | Val loss: 0.6278 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.6926 | Steps: 4 | Val loss: 0.3530 | Batch size: 32 | lr: 0.1 | Duration: 4.19s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4738 | Steps: 4 | Val loss: 0.3470 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 17:25:45 (running for 00:10:01.73)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.815 |  0.18  |                   20 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.496 |  0.177 |                   20 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.573 |  0.181 |                    3 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |        |        |                      |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=31653)[0m rmse: 0.1770847737789154
[2m[36m(func pid=31653)[0m mae:  0.1298334002494812
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.258, 0.093, 0.334, 0.097, 0.189, 0.291, 0.139, 0.144, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17996419966220856
[2m[36m(func pid=31109)[0m mae:  0.13215620815753937
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.338, 0.111, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.1803796887397766
[2m[36m(func pid=36548)[0m mae:  0.1326800286769867
[2m[36m(func pid=36548)[0m rmse_per_class: [0.121, 0.267, 0.101, 0.337, 0.094, 0.19, 0.288, 0.147, 0.143, 0.115]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.17920652031898499
[2m[36m(func pid=35640)[0m mae:  0.13203400373458862
[2m[36m(func pid=35640)[0m rmse_per_class: [0.118, 0.262, 0.098, 0.336, 0.093, 0.189, 0.293, 0.14, 0.147, 0.116]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4911 | Steps: 4 | Val loss: 0.3709 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.8086 | Steps: 4 | Val loss: 0.6246 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.4222 | Steps: 4 | Val loss: 0.3370 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4281 | Steps: 4 | Val loss: 0.3238 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 17:25:50 (running for 00:10:07.12)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.81  |  0.18  |                   21 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.491 |  0.177 |                   21 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.474 |  0.179 |                    4 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.693 |  0.18  |                    1 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=31653)[0m rmse: 0.1770184189081192
[2m[36m(func pid=31653)[0m mae:  0.12983708083629608
[2m[36m(func pid=31653)[0m rmse_per_class: [0.115, 0.258, 0.092, 0.334, 0.098, 0.188, 0.291, 0.139, 0.143, 0.111]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.1799006462097168
[2m[36m(func pid=31109)[0m mae:  0.13212518393993378
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.261, 0.099, 0.338, 0.111, 0.19, 0.294, 0.14, 0.142, 0.108]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.1679900586605072
[2m[36m(func pid=36548)[0m mae:  0.12233946472406387
[2m[36m(func pid=36548)[0m rmse_per_class: [0.117, 0.259, 0.074, 0.331, 0.067, 0.181, 0.269, 0.14, 0.136, 0.106]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.17706912755966187
[2m[36m(func pid=35640)[0m mae:  0.13025856018066406
[2m[36m(func pid=35640)[0m rmse_per_class: [0.118, 0.259, 0.092, 0.335, 0.087, 0.188, 0.29, 0.139, 0.148, 0.116]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4831 | Steps: 4 | Val loss: 0.3658 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.8037 | Steps: 4 | Val loss: 0.6214 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.4868 | Steps: 4 | Val loss: 0.3529 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4137 | Steps: 4 | Val loss: 0.3157 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 17:25:55 (running for 00:10:12.23)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.809 |  0.18  |                   22 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.483 |  0.177 |                   22 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.428 |  0.177 |                    5 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.422 |  0.168 |                    2 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=31653)[0m rmse: 0.17700134217739105
[2m[36m(func pid=31653)[0m mae:  0.12985435128211975
[2m[36m(func pid=31653)[0m rmse_per_class: [0.115, 0.258, 0.091, 0.333, 0.098, 0.188, 0.291, 0.14, 0.143, 0.112]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.1798199713230133
[2m[36m(func pid=31109)[0m mae:  0.13206079602241516
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.261, 0.099, 0.338, 0.111, 0.19, 0.293, 0.141, 0.142, 0.108]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.15310163795948029
[2m[36m(func pid=36548)[0m mae:  0.10824006795883179
[2m[36m(func pid=36548)[0m rmse_per_class: [0.098, 0.241, 0.052, 0.31, 0.056, 0.172, 0.248, 0.128, 0.132, 0.093]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.17463304102420807
[2m[36m(func pid=35640)[0m mae:  0.12820720672607422
[2m[36m(func pid=35640)[0m rmse_per_class: [0.118, 0.257, 0.086, 0.332, 0.081, 0.187, 0.286, 0.138, 0.147, 0.114]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4759 | Steps: 4 | Val loss: 0.3620 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.7979 | Steps: 4 | Val loss: 0.6186 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4811 | Steps: 4 | Val loss: 0.3078 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4003 | Steps: 4 | Val loss: 0.3129 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 17:26:01 (running for 00:10:17.51)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.804 |  0.18  |                   23 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.476 |  0.177 |                   23 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.414 |  0.175 |                    6 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.487 |  0.153 |                    3 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=31653)[0m rmse: 0.176731139421463
[2m[36m(func pid=31653)[0m mae:  0.12964020669460297
[2m[36m(func pid=31653)[0m rmse_per_class: [0.115, 0.259, 0.091, 0.333, 0.096, 0.189, 0.291, 0.139, 0.144, 0.111]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17972400784492493
[2m[36m(func pid=31109)[0m mae:  0.13198643922805786
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.261, 0.098, 0.338, 0.11, 0.19, 0.293, 0.141, 0.142, 0.108]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.14183109998703003
[2m[36m(func pid=36548)[0m mae:  0.09537919610738754
[2m[36m(func pid=36548)[0m rmse_per_class: [0.085, 0.225, 0.042, 0.278, 0.054, 0.164, 0.231, 0.123, 0.131, 0.086]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.17247126996517181
[2m[36m(func pid=35640)[0m mae:  0.1263776570558548
[2m[36m(func pid=35640)[0m rmse_per_class: [0.118, 0.254, 0.081, 0.33, 0.078, 0.186, 0.283, 0.136, 0.145, 0.114]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4706 | Steps: 4 | Val loss: 0.3581 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.7966 | Steps: 4 | Val loss: 0.6173 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4146 | Steps: 4 | Val loss: 0.2610 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4089 | Steps: 4 | Val loss: 0.3114 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 17:26:06 (running for 00:10:22.99)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.798 |  0.18  |                   24 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.471 |  0.176 |                   24 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.4   |  0.172 |                    7 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.481 |  0.142 |                    4 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=31653)[0m rmse: 0.17642587423324585
[2m[36m(func pid=31653)[0m mae:  0.12939143180847168
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.258, 0.09, 0.333, 0.096, 0.189, 0.289, 0.139, 0.145, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.18003135919570923
[2m[36m(func pid=31109)[0m mae:  0.1322513073682785
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.261, 0.099, 0.338, 0.11, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.1388082355260849
[2m[36m(func pid=36548)[0m mae:  0.09034020453691483
[2m[36m(func pid=36548)[0m rmse_per_class: [0.077, 0.219, 0.039, 0.268, 0.054, 0.16, 0.233, 0.123, 0.132, 0.084]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.17011871933937073
[2m[36m(func pid=35640)[0m mae:  0.12440697848796844
[2m[36m(func pid=35640)[0m rmse_per_class: [0.119, 0.252, 0.075, 0.326, 0.074, 0.184, 0.28, 0.135, 0.142, 0.113]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4620 | Steps: 4 | Val loss: 0.3544 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.3789 | Steps: 4 | Val loss: 0.2597 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.7898 | Steps: 4 | Val loss: 0.6130 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.4025 | Steps: 4 | Val loss: 0.3106 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 17:26:11 (running for 00:10:28.29)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.797 |  0.18  |                   25 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.462 |  0.176 |                   25 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.409 |  0.17  |                    8 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.415 |  0.139 |                    5 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=31653)[0m rmse: 0.17633165419101715
[2m[36m(func pid=31653)[0m mae:  0.1293220818042755
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.257, 0.089, 0.334, 0.096, 0.188, 0.29, 0.139, 0.144, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.1369953155517578
[2m[36m(func pid=36548)[0m mae:  0.09149883687496185
[2m[36m(func pid=36548)[0m rmse_per_class: [0.08, 0.219, 0.034, 0.27, 0.053, 0.162, 0.225, 0.114, 0.129, 0.083]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17978113889694214
[2m[36m(func pid=31109)[0m mae:  0.13207760453224182
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.338, 0.109, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.16909560561180115
[2m[36m(func pid=35640)[0m mae:  0.1235077977180481
[2m[36m(func pid=35640)[0m rmse_per_class: [0.12, 0.251, 0.073, 0.326, 0.072, 0.183, 0.277, 0.134, 0.142, 0.112]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4599 | Steps: 4 | Val loss: 0.3517 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.3581 | Steps: 4 | Val loss: 0.2758 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.7868 | Steps: 4 | Val loss: 0.6101 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4030 | Steps: 4 | Val loss: 0.3092 | Batch size: 32 | lr: 0.01 | Duration: 2.68s
[2m[36m(func pid=36548)[0m rmse: 0.1467217057943344
[2m[36m(func pid=36548)[0m mae:  0.10248701274394989
[2m[36m(func pid=36548)[0m rmse_per_class: [0.113, 0.217, 0.031, 0.288, 0.053, 0.154, 0.255, 0.113, 0.14, 0.103]
== Status ==
Current time: 2024-01-07 17:26:17 (running for 00:10:33.53)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.79  |  0.18  |                   26 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.462 |  0.176 |                   25 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.403 |  0.169 |                    9 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.358 |  0.147 |                    7 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.1761813759803772
[2m[36m(func pid=31653)[0m mae:  0.1291654258966446
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.256, 0.09, 0.333, 0.095, 0.188, 0.29, 0.139, 0.144, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17981061339378357
[2m[36m(func pid=31109)[0m mae:  0.13209162652492523
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.11, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.16821731626987457
[2m[36m(func pid=35640)[0m mae:  0.12273599952459335
[2m[36m(func pid=35640)[0m rmse_per_class: [0.121, 0.25, 0.073, 0.327, 0.07, 0.182, 0.274, 0.134, 0.142, 0.11]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.3433 | Steps: 4 | Val loss: 0.2921 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4577 | Steps: 4 | Val loss: 0.3485 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.7826 | Steps: 4 | Val loss: 0.6093 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3973 | Steps: 4 | Val loss: 0.3065 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=36548)[0m rmse: 0.16035306453704834
[2m[36m(func pid=36548)[0m mae:  0.11192364990711212
[2m[36m(func pid=36548)[0m rmse_per_class: [0.124, 0.222, 0.037, 0.31, 0.06, 0.171, 0.263, 0.134, 0.165, 0.117]
== Status ==
Current time: 2024-01-07 17:26:22 (running for 00:10:38.92)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.787 |  0.18  |                   27 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.46  |  0.176 |                   26 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.403 |  0.168 |                   10 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.343 |  0.16  |                    8 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17600658535957336
[2m[36m(func pid=31653)[0m mae:  0.12903210520744324
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.256, 0.089, 0.333, 0.096, 0.188, 0.289, 0.139, 0.144, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17988444864749908
[2m[36m(func pid=31109)[0m mae:  0.13211873173713684
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.11, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.16687175631523132
[2m[36m(func pid=35640)[0m mae:  0.12163455784320831
[2m[36m(func pid=35640)[0m rmse_per_class: [0.119, 0.248, 0.071, 0.326, 0.068, 0.182, 0.272, 0.134, 0.143, 0.107]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.3397 | Steps: 4 | Val loss: 0.2867 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4549 | Steps: 4 | Val loss: 0.3449 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.7769 | Steps: 4 | Val loss: 0.6050 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.3967 | Steps: 4 | Val loss: 0.3039 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 17:26:27 (running for 00:10:44.22)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.783 |  0.18  |                   28 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.458 |  0.176 |                   27 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.397 |  0.167 |                   11 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.34  |  0.159 |                    9 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.15856292843818665
[2m[36m(func pid=36548)[0m mae:  0.10804040729999542
[2m[36m(func pid=36548)[0m rmse_per_class: [0.094, 0.223, 0.068, 0.303, 0.091, 0.166, 0.251, 0.13, 0.15, 0.109]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17584607005119324
[2m[36m(func pid=31653)[0m mae:  0.12892618775367737
[2m[36m(func pid=31653)[0m rmse_per_class: [0.115, 0.257, 0.089, 0.333, 0.095, 0.187, 0.289, 0.139, 0.143, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17988041043281555
[2m[36m(func pid=31109)[0m mae:  0.13217923045158386
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.098, 0.337, 0.11, 0.189, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.16593633592128754
[2m[36m(func pid=35640)[0m mae:  0.12079989910125732
[2m[36m(func pid=35640)[0m rmse_per_class: [0.118, 0.248, 0.07, 0.327, 0.067, 0.18, 0.27, 0.132, 0.143, 0.106]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3278 | Steps: 4 | Val loss: 0.2744 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4490 | Steps: 4 | Val loss: 0.3445 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.7726 | Steps: 4 | Val loss: 0.6010 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.3904 | Steps: 4 | Val loss: 0.3019 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 17:26:32 (running for 00:10:49.40)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.777 |  0.18  |                   29 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.455 |  0.176 |                   28 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.397 |  0.166 |                   12 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.328 |  0.15  |                   10 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14982275664806366
[2m[36m(func pid=36548)[0m mae:  0.1003953367471695
[2m[36m(func pid=36548)[0m rmse_per_class: [0.074, 0.217, 0.08, 0.285, 0.099, 0.155, 0.238, 0.109, 0.136, 0.105]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17593179643154144
[2m[36m(func pid=31653)[0m mae:  0.12898091971874237
[2m[36m(func pid=31653)[0m rmse_per_class: [0.115, 0.257, 0.09, 0.333, 0.094, 0.188, 0.289, 0.138, 0.145, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.1798044741153717
[2m[36m(func pid=31109)[0m mae:  0.13213303685188293
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.109, 0.189, 0.294, 0.14, 0.143, 0.111]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.1650100201368332
[2m[36m(func pid=35640)[0m mae:  0.12001212686300278
[2m[36m(func pid=35640)[0m rmse_per_class: [0.117, 0.247, 0.069, 0.324, 0.065, 0.179, 0.268, 0.132, 0.143, 0.107]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3299 | Steps: 4 | Val loss: 0.2628 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4474 | Steps: 4 | Val loss: 0.3410 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.7726 | Steps: 4 | Val loss: 0.5997 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.3858 | Steps: 4 | Val loss: 0.3002 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 17:26:38 (running for 00:10:54.51)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.773 |  0.18  |                   30 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.449 |  0.176 |                   29 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.39  |  0.165 |                   13 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.33  |  0.141 |                   11 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14094138145446777
[2m[36m(func pid=36548)[0m mae:  0.09375056624412537
[2m[36m(func pid=36548)[0m rmse_per_class: [0.064, 0.212, 0.054, 0.274, 0.075, 0.152, 0.22, 0.112, 0.146, 0.1]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17548145353794098
[2m[36m(func pid=31653)[0m mae:  0.12857452034950256
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.257, 0.089, 0.332, 0.094, 0.188, 0.289, 0.138, 0.144, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.1800203174352646
[2m[36m(func pid=31109)[0m mae:  0.13230553269386292
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.338, 0.11, 0.189, 0.295, 0.14, 0.143, 0.111]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.16439493000507355
[2m[36m(func pid=35640)[0m mae:  0.11942021548748016
[2m[36m(func pid=35640)[0m rmse_per_class: [0.116, 0.247, 0.067, 0.325, 0.063, 0.178, 0.266, 0.131, 0.143, 0.107]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.3090 | Steps: 4 | Val loss: 0.2605 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4494 | Steps: 4 | Val loss: 0.3401 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.7667 | Steps: 4 | Val loss: 0.5961 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.3808 | Steps: 4 | Val loss: 0.2967 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 17:26:43 (running for 00:10:59.84)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.773 |  0.18  |                   31 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.447 |  0.175 |                   30 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.386 |  0.164 |                   14 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.309 |  0.139 |                   12 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.1392240673303604
[2m[36m(func pid=36548)[0m mae:  0.09266205132007599
[2m[36m(func pid=36548)[0m rmse_per_class: [0.068, 0.212, 0.035, 0.269, 0.065, 0.151, 0.222, 0.114, 0.146, 0.11]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.1756870448589325
[2m[36m(func pid=31653)[0m mae:  0.12876830995082855
[2m[36m(func pid=31653)[0m rmse_per_class: [0.115, 0.258, 0.09, 0.332, 0.093, 0.188, 0.288, 0.138, 0.145, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17986465990543365
[2m[36m(func pid=31109)[0m mae:  0.13215970993041992
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.26, 0.099, 0.338, 0.109, 0.189, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.16274702548980713
[2m[36m(func pid=35640)[0m mae:  0.11803241819143295
[2m[36m(func pid=35640)[0m rmse_per_class: [0.113, 0.246, 0.064, 0.319, 0.062, 0.177, 0.265, 0.129, 0.143, 0.109]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.3169 | Steps: 4 | Val loss: 0.2579 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4396 | Steps: 4 | Val loss: 0.3363 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.7644 | Steps: 4 | Val loss: 0.5925 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3926 | Steps: 4 | Val loss: 0.2937 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 17:26:48 (running for 00:11:04.94)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.767 |  0.18  |                   32 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.449 |  0.176 |                   31 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.381 |  0.163 |                   15 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.317 |  0.138 |                   13 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.1376238465309143
[2m[36m(func pid=36548)[0m mae:  0.09074175357818604
[2m[36m(func pid=36548)[0m rmse_per_class: [0.075, 0.215, 0.032, 0.263, 0.057, 0.149, 0.221, 0.109, 0.139, 0.118]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17509374022483826
[2m[36m(func pid=31653)[0m mae:  0.12821491062641144
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.257, 0.088, 0.331, 0.093, 0.188, 0.288, 0.139, 0.144, 0.108]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17972955107688904
[2m[36m(func pid=31109)[0m mae:  0.1320398449897766
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.098, 0.337, 0.11, 0.189, 0.294, 0.14, 0.143, 0.111]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.16132524609565735
[2m[36m(func pid=35640)[0m mae:  0.1168190985918045
[2m[36m(func pid=35640)[0m rmse_per_class: [0.109, 0.244, 0.062, 0.318, 0.061, 0.175, 0.263, 0.128, 0.142, 0.112]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.3032 | Steps: 4 | Val loss: 0.2612 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4402 | Steps: 4 | Val loss: 0.3348 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.7588 | Steps: 4 | Val loss: 0.5892 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3747 | Steps: 4 | Val loss: 0.2929 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=36548)[0m rmse: 0.14058749377727509
[2m[36m(func pid=36548)[0m mae:  0.09236882627010345
[2m[36m(func pid=36548)[0m rmse_per_class: [0.072, 0.217, 0.03, 0.261, 0.061, 0.15, 0.229, 0.11, 0.133, 0.143]
== Status ==
Current time: 2024-01-07 17:26:53 (running for 00:11:10.14)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.764 |  0.18  |                   33 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.44  |  0.175 |                   32 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.393 |  0.161 |                   16 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.303 |  0.141 |                   14 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17511668801307678
[2m[36m(func pid=31653)[0m mae:  0.12826864421367645
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.257, 0.088, 0.331, 0.093, 0.188, 0.288, 0.138, 0.144, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.16117271780967712
[2m[36m(func pid=35640)[0m mae:  0.1167919859290123
[2m[36m(func pid=35640)[0m rmse_per_class: [0.106, 0.242, 0.062, 0.317, 0.061, 0.175, 0.263, 0.128, 0.142, 0.115]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17963656783103943
[2m[36m(func pid=31109)[0m mae:  0.13196015357971191
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.26, 0.098, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.3160 | Steps: 4 | Val loss: 0.2657 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4364 | Steps: 4 | Val loss: 0.3324 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3779 | Steps: 4 | Val loss: 0.2917 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.7568 | Steps: 4 | Val loss: 0.5855 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 17:26:58 (running for 00:11:15.28)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.759 |  0.18  |                   34 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.44  |  0.175 |                   33 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.375 |  0.161 |                   17 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.316 |  0.143 |                   15 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14333052933216095
[2m[36m(func pid=36548)[0m mae:  0.09432663023471832
[2m[36m(func pid=36548)[0m rmse_per_class: [0.075, 0.214, 0.032, 0.275, 0.064, 0.151, 0.231, 0.113, 0.136, 0.143]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17492136359214783
[2m[36m(func pid=31653)[0m mae:  0.1280733048915863
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.257, 0.087, 0.33, 0.093, 0.188, 0.287, 0.139, 0.142, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.16034938395023346
[2m[36m(func pid=35640)[0m mae:  0.11616633832454681
[2m[36m(func pid=35640)[0m rmse_per_class: [0.105, 0.241, 0.061, 0.317, 0.061, 0.173, 0.262, 0.128, 0.141, 0.113]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17962130904197693
[2m[36m(func pid=31109)[0m mae:  0.13197730481624603
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.098, 0.337, 0.109, 0.189, 0.294, 0.14, 0.143, 0.111]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3026 | Steps: 4 | Val loss: 0.2608 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4338 | Steps: 4 | Val loss: 0.3309 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3799 | Steps: 4 | Val loss: 0.2899 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.7508 | Steps: 4 | Val loss: 0.5836 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 17:27:03 (running for 00:11:20.41)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.757 |  0.18  |                   35 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.436 |  0.175 |                   34 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.378 |  0.16  |                   18 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.303 |  0.139 |                   16 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.13925793766975403
[2m[36m(func pid=36548)[0m mae:  0.09139742702245712
[2m[36m(func pid=36548)[0m rmse_per_class: [0.07, 0.211, 0.032, 0.272, 0.064, 0.151, 0.228, 0.111, 0.143, 0.112]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17470800876617432
[2m[36m(func pid=31653)[0m mae:  0.1279750019311905
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.256, 0.086, 0.331, 0.092, 0.187, 0.287, 0.138, 0.143, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.15942052006721497
[2m[36m(func pid=35640)[0m mae:  0.11547338962554932
[2m[36m(func pid=35640)[0m rmse_per_class: [0.103, 0.238, 0.06, 0.316, 0.062, 0.172, 0.262, 0.127, 0.14, 0.113]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17959417402744293
[2m[36m(func pid=31109)[0m mae:  0.13191236555576324
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.098, 0.337, 0.11, 0.189, 0.294, 0.14, 0.142, 0.111]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3280 | Steps: 4 | Val loss: 0.2592 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4350 | Steps: 4 | Val loss: 0.3304 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3760 | Steps: 4 | Val loss: 0.2896 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.7494 | Steps: 4 | Val loss: 0.5791 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 17:27:09 (running for 00:11:25.50)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.751 |  0.18  |                   36 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.434 |  0.175 |                   35 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.38  |  0.159 |                   19 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.328 |  0.138 |                   17 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.13816645741462708
[2m[36m(func pid=36548)[0m mae:  0.09008069336414337
[2m[36m(func pid=36548)[0m rmse_per_class: [0.066, 0.214, 0.033, 0.274, 0.068, 0.15, 0.216, 0.109, 0.147, 0.104]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17443802952766418
[2m[36m(func pid=31653)[0m mae:  0.12773747742176056
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.256, 0.085, 0.331, 0.092, 0.187, 0.287, 0.138, 0.143, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.15896432101726532
[2m[36m(func pid=35640)[0m mae:  0.11511911451816559
[2m[36m(func pid=35640)[0m rmse_per_class: [0.102, 0.237, 0.06, 0.319, 0.063, 0.171, 0.262, 0.126, 0.14, 0.111]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17960666120052338
[2m[36m(func pid=31109)[0m mae:  0.13193008303642273
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.261, 0.098, 0.336, 0.109, 0.189, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.2983 | Steps: 4 | Val loss: 0.2645 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4320 | Steps: 4 | Val loss: 0.3294 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3712 | Steps: 4 | Val loss: 0.2891 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.7476 | Steps: 4 | Val loss: 0.5779 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 17:27:14 (running for 00:11:30.70)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.749 |  0.18  |                   37 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.435 |  0.174 |                   36 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.376 |  0.159 |                   20 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.298 |  0.143 |                   18 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14308729767799377
[2m[36m(func pid=36548)[0m mae:  0.09279526025056839
[2m[36m(func pid=36548)[0m rmse_per_class: [0.07, 0.217, 0.044, 0.283, 0.092, 0.151, 0.219, 0.108, 0.147, 0.1]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.15845604240894318
[2m[36m(func pid=35640)[0m mae:  0.11480093002319336
[2m[36m(func pid=35640)[0m rmse_per_class: [0.101, 0.234, 0.062, 0.319, 0.063, 0.172, 0.262, 0.125, 0.14, 0.108]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.1745378077030182
[2m[36m(func pid=31653)[0m mae:  0.1278201788663864
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.255, 0.086, 0.331, 0.091, 0.188, 0.287, 0.138, 0.143, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17969411611557007
[2m[36m(func pid=31109)[0m mae:  0.1320066601037979
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.2962 | Steps: 4 | Val loss: 0.2729 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3755 | Steps: 4 | Val loss: 0.2862 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4290 | Steps: 4 | Val loss: 0.3273 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 17:27:19 (running for 00:11:35.98)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.748 |  0.18  |                   38 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.432 |  0.175 |                   37 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.371 |  0.158 |                   21 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.296 |  0.151 |                   19 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.15055707097053528
[2m[36m(func pid=36548)[0m mae:  0.09750573337078094
[2m[36m(func pid=36548)[0m rmse_per_class: [0.07, 0.219, 0.066, 0.284, 0.108, 0.153, 0.233, 0.108, 0.148, 0.116]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.7418 | Steps: 4 | Val loss: 0.5740 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=35640)[0m rmse: 0.1565820276737213
[2m[36m(func pid=35640)[0m mae:  0.11321058124303818
[2m[36m(func pid=35640)[0m rmse_per_class: [0.099, 0.232, 0.061, 0.315, 0.063, 0.17, 0.261, 0.124, 0.139, 0.103]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17429068684577942
[2m[36m(func pid=31653)[0m mae:  0.127613827586174
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.255, 0.087, 0.33, 0.09, 0.187, 0.287, 0.138, 0.143, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17955031991004944
[2m[36m(func pid=31109)[0m mae:  0.1318996250629425
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.261, 0.098, 0.337, 0.108, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3045 | Steps: 4 | Val loss: 0.2745 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3727 | Steps: 4 | Val loss: 0.2856 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4259 | Steps: 4 | Val loss: 0.3262 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 17:27:24 (running for 00:11:40.99)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.742 |  0.18  |                   39 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.429 |  0.174 |                   38 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.376 |  0.157 |                   22 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.304 |  0.152 |                   20 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.15233653783798218
[2m[36m(func pid=36548)[0m mae:  0.0985790342092514
[2m[36m(func pid=36548)[0m rmse_per_class: [0.08, 0.218, 0.08, 0.286, 0.096, 0.153, 0.237, 0.11, 0.143, 0.122]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.7410 | Steps: 4 | Val loss: 0.5713 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=35640)[0m rmse: 0.1562519371509552
[2m[36m(func pid=35640)[0m mae:  0.11291009187698364
[2m[36m(func pid=35640)[0m rmse_per_class: [0.097, 0.234, 0.064, 0.313, 0.063, 0.168, 0.259, 0.124, 0.139, 0.102]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17400644719600677
[2m[36m(func pid=31653)[0m mae:  0.12738630175590515
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.254, 0.086, 0.33, 0.091, 0.187, 0.286, 0.137, 0.142, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.1794581264257431
[2m[36m(func pid=31109)[0m mae:  0.13179528713226318
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.098, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3096 | Steps: 4 | Val loss: 0.2658 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3654 | Steps: 4 | Val loss: 0.2869 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4269 | Steps: 4 | Val loss: 0.3250 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 17:27:29 (running for 00:11:46.34)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.741 |  0.179 |                   40 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.426 |  0.174 |                   39 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.373 |  0.156 |                   23 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.31  |  0.145 |                   21 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14543697237968445
[2m[36m(func pid=36548)[0m mae:  0.09383420646190643
[2m[36m(func pid=36548)[0m rmse_per_class: [0.088, 0.214, 0.066, 0.282, 0.071, 0.151, 0.227, 0.11, 0.135, 0.11]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.7378 | Steps: 4 | Val loss: 0.5679 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=35640)[0m rmse: 0.15717953443527222
[2m[36m(func pid=35640)[0m mae:  0.11347955465316772
[2m[36m(func pid=35640)[0m rmse_per_class: [0.095, 0.234, 0.066, 0.317, 0.064, 0.169, 0.259, 0.123, 0.139, 0.105]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.1738339066505432
[2m[36m(func pid=31653)[0m mae:  0.1272435337305069
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.255, 0.085, 0.331, 0.09, 0.187, 0.285, 0.137, 0.142, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17949876189231873
[2m[36m(func pid=31109)[0m mae:  0.1318635493516922
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.261, 0.097, 0.337, 0.109, 0.189, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3012 | Steps: 4 | Val loss: 0.2594 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4236 | Steps: 4 | Val loss: 0.3236 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3622 | Steps: 4 | Val loss: 0.2865 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 17:27:35 (running for 00:11:51.48)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.738 |  0.179 |                   41 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.427 |  0.174 |                   40 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.365 |  0.157 |                   24 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.301 |  0.139 |                   22 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.139216810464859
[2m[36m(func pid=36548)[0m mae:  0.08978905528783798
[2m[36m(func pid=36548)[0m rmse_per_class: [0.07, 0.212, 0.045, 0.275, 0.068, 0.151, 0.224, 0.106, 0.132, 0.109]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.7338 | Steps: 4 | Val loss: 0.5664 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=35640)[0m rmse: 0.1568548083305359
[2m[36m(func pid=35640)[0m mae:  0.11317944526672363
[2m[36m(func pid=35640)[0m rmse_per_class: [0.095, 0.232, 0.065, 0.316, 0.064, 0.169, 0.259, 0.122, 0.139, 0.107]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17389269173145294
[2m[36m(func pid=31653)[0m mae:  0.12731990218162537
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.255, 0.085, 0.331, 0.09, 0.187, 0.285, 0.137, 0.143, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3199 | Steps: 4 | Val loss: 0.2633 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=31109)[0m rmse: 0.1796562820672989
[2m[36m(func pid=31109)[0m mae:  0.13199220597743988
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.262, 0.098, 0.337, 0.108, 0.189, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
== Status ==
Current time: 2024-01-07 17:27:40 (running for 00:11:56.68)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.734 |  0.18  |                   42 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.424 |  0.174 |                   41 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.362 |  0.157 |                   25 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.32  |  0.143 |                   23 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3631 | Steps: 4 | Val loss: 0.2849 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=36548)[0m rmse: 0.14258500933647156
[2m[36m(func pid=36548)[0m mae:  0.09250769019126892
[2m[36m(func pid=36548)[0m rmse_per_class: [0.063, 0.213, 0.046, 0.278, 0.07, 0.154, 0.229, 0.106, 0.148, 0.119]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4209 | Steps: 4 | Val loss: 0.3222 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.7262 | Steps: 4 | Val loss: 0.5625 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=31653)[0m rmse: 0.17364001274108887
[2m[36m(func pid=31653)[0m mae:  0.12711231410503387
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.255, 0.085, 0.331, 0.089, 0.187, 0.285, 0.137, 0.143, 0.109]
[2m[36m(func pid=35640)[0m rmse: 0.15599773824214935
[2m[36m(func pid=35640)[0m mae:  0.11237849295139313
[2m[36m(func pid=35640)[0m rmse_per_class: [0.097, 0.232, 0.064, 0.313, 0.063, 0.168, 0.256, 0.121, 0.138, 0.107]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3065 | Steps: 4 | Val loss: 0.2708 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=31109)[0m rmse: 0.17940224707126617
[2m[36m(func pid=31109)[0m mae:  0.131772980093956
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.261, 0.097, 0.337, 0.109, 0.189, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
== Status ==
Current time: 2024-01-07 17:27:45 (running for 00:12:02.04)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.726 |  0.179 |                   43 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.421 |  0.174 |                   42 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.363 |  0.156 |                   26 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.306 |  0.147 |                   24 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3636 | Steps: 4 | Val loss: 0.2844 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=36548)[0m rmse: 0.14725160598754883
[2m[36m(func pid=36548)[0m mae:  0.0961347222328186
[2m[36m(func pid=36548)[0m rmse_per_class: [0.061, 0.212, 0.04, 0.282, 0.062, 0.154, 0.231, 0.108, 0.205, 0.117]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4209 | Steps: 4 | Val loss: 0.3221 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.7250 | Steps: 4 | Val loss: 0.5600 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=31653)[0m rmse: 0.17364826798439026
[2m[36m(func pid=31653)[0m mae:  0.12711086869239807
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.256, 0.086, 0.331, 0.089, 0.186, 0.285, 0.137, 0.142, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.15597832202911377
[2m[36m(func pid=35640)[0m mae:  0.11224649846553802
[2m[36m(func pid=35640)[0m rmse_per_class: [0.099, 0.232, 0.061, 0.312, 0.062, 0.168, 0.256, 0.12, 0.138, 0.111]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.2915 | Steps: 4 | Val loss: 0.2658 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=31109)[0m rmse: 0.17926287651062012
[2m[36m(func pid=31109)[0m mae:  0.13162462413311005
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.261, 0.097, 0.337, 0.108, 0.19, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
== Status ==
Current time: 2024-01-07 17:27:50 (running for 00:12:07.29)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.725 |  0.179 |                   44 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.421 |  0.174 |                   43 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.364 |  0.156 |                   27 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.291 |  0.143 |                   25 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4189 | Steps: 4 | Val loss: 0.3224 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3576 | Steps: 4 | Val loss: 0.2837 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=36548)[0m rmse: 0.14326269924640656
[2m[36m(func pid=36548)[0m mae:  0.09254281222820282
[2m[36m(func pid=36548)[0m rmse_per_class: [0.062, 0.21, 0.037, 0.28, 0.06, 0.152, 0.229, 0.11, 0.177, 0.114]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.7214 | Steps: 4 | Val loss: 0.5585 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=35640)[0m rmse: 0.15579627454280853
[2m[36m(func pid=35640)[0m mae:  0.1121278777718544
[2m[36m(func pid=35640)[0m rmse_per_class: [0.1, 0.231, 0.06, 0.308, 0.063, 0.168, 0.258, 0.121, 0.138, 0.112]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17402034997940063
[2m[36m(func pid=31653)[0m mae:  0.12746202945709229
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.256, 0.086, 0.331, 0.088, 0.186, 0.285, 0.138, 0.143, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.2839 | Steps: 4 | Val loss: 0.2590 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=31109)[0m rmse: 0.17948684096336365
[2m[36m(func pid=31109)[0m mae:  0.13180437684059143
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.261, 0.098, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.13919541239738464
[2m[36m(func pid=36548)[0m mae:  0.0886693075299263
[2m[36m(func pid=36548)[0m rmse_per_class: [0.067, 0.208, 0.039, 0.265, 0.069, 0.152, 0.228, 0.108, 0.137, 0.12]
== Status ==
Current time: 2024-01-07 17:27:55 (running for 00:12:12.43)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.721 |  0.179 |                   45 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.419 |  0.174 |                   44 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.358 |  0.156 |                   28 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.284 |  0.139 |                   26 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3665 | Steps: 4 | Val loss: 0.2798 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4202 | Steps: 4 | Val loss: 0.3209 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.7201 | Steps: 4 | Val loss: 0.5558 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=35640)[0m rmse: 0.15316279232501984
[2m[36m(func pid=35640)[0m mae:  0.10984766483306885
[2m[36m(func pid=35640)[0m rmse_per_class: [0.098, 0.231, 0.055, 0.302, 0.063, 0.165, 0.255, 0.119, 0.136, 0.107]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.2864 | Steps: 4 | Val loss: 0.2589 | Batch size: 32 | lr: 0.1 | Duration: 2.65s
[2m[36m(func pid=31653)[0m rmse: 0.1736171692609787
[2m[36m(func pid=31653)[0m mae:  0.12708453834056854
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.256, 0.086, 0.33, 0.088, 0.185, 0.285, 0.137, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17947670817375183
[2m[36m(func pid=31109)[0m mae:  0.1317969262599945
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.261, 0.098, 0.337, 0.108, 0.19, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
== Status ==
Current time: 2024-01-07 17:28:01 (running for 00:12:17.50)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.72  |  0.179 |                   46 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.42  |  0.174 |                   45 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.366 |  0.153 |                   29 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.14  |                   27 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.13959304988384247
[2m[36m(func pid=36548)[0m mae:  0.08820541948080063
[2m[36m(func pid=36548)[0m rmse_per_class: [0.075, 0.211, 0.045, 0.271, 0.073, 0.152, 0.222, 0.11, 0.127, 0.111]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3576 | Steps: 4 | Val loss: 0.2789 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4199 | Steps: 4 | Val loss: 0.3195 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.7154 | Steps: 4 | Val loss: 0.5530 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.2969 | Steps: 4 | Val loss: 0.2627 | Batch size: 32 | lr: 0.1 | Duration: 2.68s
[2m[36m(func pid=35640)[0m rmse: 0.15258575975894928
[2m[36m(func pid=35640)[0m mae:  0.10933725535869598
[2m[36m(func pid=35640)[0m rmse_per_class: [0.097, 0.229, 0.056, 0.299, 0.064, 0.165, 0.256, 0.119, 0.136, 0.106]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17311207950115204
[2m[36m(func pid=31653)[0m mae:  0.12664631009101868
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.255, 0.085, 0.331, 0.086, 0.185, 0.285, 0.136, 0.143, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17932677268981934
[2m[36m(func pid=31109)[0m mae:  0.1316913217306137
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.261, 0.097, 0.337, 0.108, 0.19, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
== Status ==
Current time: 2024-01-07 17:28:06 (running for 00:12:22.50)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.715 |  0.179 |                   47 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.42  |  0.173 |                   46 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.358 |  0.153 |                   30 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.297 |  0.142 |                   28 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14178858697414398
[2m[36m(func pid=36548)[0m mae:  0.08937696367502213
[2m[36m(func pid=36548)[0m rmse_per_class: [0.067, 0.216, 0.046, 0.279, 0.074, 0.153, 0.22, 0.113, 0.126, 0.124]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3527 | Steps: 4 | Val loss: 0.2778 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4175 | Steps: 4 | Val loss: 0.3182 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.7157 | Steps: 4 | Val loss: 0.5527 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.2998 | Steps: 4 | Val loss: 0.2633 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=35640)[0m rmse: 0.15161862969398499
[2m[36m(func pid=35640)[0m mae:  0.10855404287576675
[2m[36m(func pid=35640)[0m rmse_per_class: [0.096, 0.227, 0.056, 0.298, 0.065, 0.164, 0.255, 0.119, 0.135, 0.102]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17283771932125092
[2m[36m(func pid=31653)[0m mae:  0.12645255029201508
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.254, 0.083, 0.33, 0.086, 0.185, 0.284, 0.137, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17947496473789215
[2m[36m(func pid=31109)[0m mae:  0.13180257380008698
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.097, 0.337, 0.109, 0.19, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
== Status ==
Current time: 2024-01-07 17:28:11 (running for 00:12:27.51)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.716 |  0.179 |                   48 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.418 |  0.173 |                   47 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.353 |  0.152 |                   31 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.3   |  0.145 |                   29 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14474593102931976
[2m[36m(func pid=36548)[0m mae:  0.09150334447622299
[2m[36m(func pid=36548)[0m rmse_per_class: [0.065, 0.213, 0.063, 0.279, 0.086, 0.152, 0.224, 0.112, 0.131, 0.123]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3520 | Steps: 4 | Val loss: 0.2770 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4149 | Steps: 4 | Val loss: 0.3177 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.7130 | Steps: 4 | Val loss: 0.5499 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.2947 | Steps: 4 | Val loss: 0.2724 | Batch size: 32 | lr: 0.1 | Duration: 2.70s
[2m[36m(func pid=35640)[0m rmse: 0.1508215069770813
[2m[36m(func pid=35640)[0m mae:  0.10785631835460663
[2m[36m(func pid=35640)[0m rmse_per_class: [0.096, 0.225, 0.055, 0.299, 0.065, 0.163, 0.255, 0.118, 0.134, 0.098]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17282743752002716
[2m[36m(func pid=31653)[0m mae:  0.12648925185203552
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.253, 0.083, 0.33, 0.086, 0.185, 0.284, 0.137, 0.143, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.1794034242630005
[2m[36m(func pid=31109)[0m mae:  0.13176549971103668
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.26, 0.097, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
== Status ==
Current time: 2024-01-07 17:28:16 (running for 00:12:32.57)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.713 |  0.179 |                   49 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.415 |  0.173 |                   48 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.352 |  0.151 |                   32 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.295 |  0.151 |                   30 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.15121297538280487
[2m[36m(func pid=36548)[0m mae:  0.09678848087787628
[2m[36m(func pid=36548)[0m rmse_per_class: [0.062, 0.213, 0.061, 0.286, 0.084, 0.155, 0.238, 0.112, 0.161, 0.139]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3590 | Steps: 4 | Val loss: 0.2781 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4146 | Steps: 4 | Val loss: 0.3174 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.7066 | Steps: 4 | Val loss: 0.5478 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3097 | Steps: 4 | Val loss: 0.2742 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=35640)[0m rmse: 0.15164315700531006
[2m[36m(func pid=35640)[0m mae:  0.10853362083435059
[2m[36m(func pid=35640)[0m rmse_per_class: [0.095, 0.227, 0.055, 0.303, 0.066, 0.163, 0.254, 0.118, 0.135, 0.099]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17270807921886444
[2m[36m(func pid=31653)[0m mae:  0.1263560652732849
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.254, 0.082, 0.33, 0.086, 0.185, 0.283, 0.137, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
== Status ==
Current time: 2024-01-07 17:28:21 (running for 00:12:37.70)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.707 |  0.179 |                   50 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.415 |  0.173 |                   49 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.359 |  0.152 |                   33 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.295 |  0.151 |                   30 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=31109)[0m rmse: 0.17929565906524658
[2m[36m(func pid=31109)[0m mae:  0.1316620111465454
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.337, 0.109, 0.19, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.15193286538124084
[2m[36m(func pid=36548)[0m mae:  0.09791721403598785
[2m[36m(func pid=36548)[0m rmse_per_class: [0.063, 0.215, 0.054, 0.29, 0.071, 0.157, 0.241, 0.117, 0.186, 0.126]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3503 | Steps: 4 | Val loss: 0.2773 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4146 | Steps: 4 | Val loss: 0.3176 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3010 | Steps: 4 | Val loss: 0.2717 | Batch size: 32 | lr: 0.1 | Duration: 2.62s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.7064 | Steps: 4 | Val loss: 0.5443 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=35640)[0m rmse: 0.1510922759771347
[2m[36m(func pid=35640)[0m mae:  0.10808553546667099
[2m[36m(func pid=35640)[0m rmse_per_class: [0.096, 0.227, 0.055, 0.302, 0.066, 0.163, 0.252, 0.118, 0.136, 0.097]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17281250655651093
[2m[36m(func pid=31653)[0m mae:  0.12643016874790192
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.254, 0.082, 0.33, 0.087, 0.186, 0.284, 0.137, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
== Status ==
Current time: 2024-01-07 17:28:26 (running for 00:12:42.95)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.707 |  0.179 |                   50 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.415 |  0.173 |                   50 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.35  |  0.151 |                   34 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.301 |  0.151 |                   32 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=31109)[0m rmse: 0.17919883131980896
[2m[36m(func pid=31109)[0m mae:  0.13160163164138794
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.337, 0.108, 0.189, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.1506742686033249
[2m[36m(func pid=36548)[0m mae:  0.09640348702669144
[2m[36m(func pid=36548)[0m rmse_per_class: [0.077, 0.214, 0.069, 0.287, 0.064, 0.154, 0.23, 0.114, 0.177, 0.12]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3623 | Steps: 4 | Val loss: 0.2770 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4146 | Steps: 4 | Val loss: 0.3163 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3165 | Steps: 4 | Val loss: 0.2666 | Batch size: 32 | lr: 0.1 | Duration: 2.68s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.7006 | Steps: 4 | Val loss: 0.5407 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=35640)[0m rmse: 0.1509358435869217
[2m[36m(func pid=35640)[0m mae:  0.10792207717895508
[2m[36m(func pid=35640)[0m rmse_per_class: [0.095, 0.226, 0.054, 0.302, 0.065, 0.164, 0.252, 0.117, 0.136, 0.099]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.1726233810186386
[2m[36m(func pid=31653)[0m mae:  0.12626704573631287
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.254, 0.082, 0.33, 0.086, 0.186, 0.284, 0.137, 0.142, 0.109]
[2m[36m(func pid=31653)[0m 
== Status ==
Current time: 2024-01-07 17:28:31 (running for 00:12:48.00)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.706 |  0.179 |                   51 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.415 |  0.173 |                   51 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.362 |  0.151 |                   35 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.316 |  0.146 |                   33 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.1459907442331314
[2m[36m(func pid=36548)[0m mae:  0.09284400939941406
[2m[36m(func pid=36548)[0m rmse_per_class: [0.086, 0.213, 0.062, 0.284, 0.059, 0.153, 0.218, 0.124, 0.15, 0.11]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17920111119747162
[2m[36m(func pid=31109)[0m mae:  0.13161049783229828
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.338, 0.108, 0.189, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3444 | Steps: 4 | Val loss: 0.2778 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4135 | Steps: 4 | Val loss: 0.3155 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2933 | Steps: 4 | Val loss: 0.2690 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.7029 | Steps: 4 | Val loss: 0.5380 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=35640)[0m rmse: 0.15124323964118958
[2m[36m(func pid=35640)[0m mae:  0.10815266519784927
[2m[36m(func pid=35640)[0m rmse_per_class: [0.093, 0.226, 0.053, 0.305, 0.065, 0.163, 0.251, 0.117, 0.138, 0.1]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17254573106765747
[2m[36m(func pid=31653)[0m mae:  0.12621334195137024
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.253, 0.082, 0.33, 0.086, 0.186, 0.284, 0.137, 0.142, 0.109]
[2m[36m(func pid=31653)[0m 
== Status ==
Current time: 2024-01-07 17:28:36 (running for 00:12:53.23)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.701 |  0.179 |                   52 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.414 |  0.173 |                   52 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.344 |  0.151 |                   36 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.293 |  0.148 |                   34 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14767077565193176
[2m[36m(func pid=36548)[0m mae:  0.09413941204547882
[2m[36m(func pid=36548)[0m rmse_per_class: [0.073, 0.208, 0.086, 0.289, 0.058, 0.154, 0.222, 0.121, 0.164, 0.101]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.1792415976524353
[2m[36m(func pid=31109)[0m mae:  0.1315983682870865
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.337, 0.109, 0.189, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3513 | Steps: 4 | Val loss: 0.2775 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4129 | Steps: 4 | Val loss: 0.3156 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2800 | Steps: 4 | Val loss: 0.2657 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.6992 | Steps: 4 | Val loss: 0.5372 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=35640)[0m rmse: 0.15096300840377808
[2m[36m(func pid=35640)[0m mae:  0.10786028206348419
[2m[36m(func pid=35640)[0m rmse_per_class: [0.093, 0.226, 0.054, 0.305, 0.064, 0.164, 0.249, 0.117, 0.139, 0.099]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17229881882667542
[2m[36m(func pid=31653)[0m mae:  0.12600493431091309
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.253, 0.082, 0.33, 0.085, 0.186, 0.283, 0.137, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
== Status ==
Current time: 2024-01-07 17:28:41 (running for 00:12:58.44)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.703 |  0.179 |                   53 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.413 |  0.172 |                   53 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.351 |  0.151 |                   37 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.28  |  0.146 |                   35 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14560933411121368
[2m[36m(func pid=36548)[0m mae:  0.0921153575181961
[2m[36m(func pid=36548)[0m rmse_per_class: [0.063, 0.208, 0.085, 0.286, 0.057, 0.156, 0.223, 0.112, 0.151, 0.116]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17944224178791046
[2m[36m(func pid=31109)[0m mae:  0.1317557990550995
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.337, 0.108, 0.189, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3442 | Steps: 4 | Val loss: 0.2752 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4093 | Steps: 4 | Val loss: 0.3147 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2894 | Steps: 4 | Val loss: 0.2668 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.6935 | Steps: 4 | Val loss: 0.5344 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=35640)[0m rmse: 0.14934590458869934
[2m[36m(func pid=35640)[0m mae:  0.10660973936319351
[2m[36m(func pid=35640)[0m rmse_per_class: [0.092, 0.225, 0.052, 0.3, 0.063, 0.162, 0.249, 0.116, 0.139, 0.095]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17194655537605286
[2m[36m(func pid=31653)[0m mae:  0.12572376430034637
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.251, 0.081, 0.329, 0.085, 0.186, 0.283, 0.136, 0.142, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.147422656416893
[2m[36m(func pid=36548)[0m mae:  0.09275781363248825
[2m[36m(func pid=36548)[0m rmse_per_class: [0.064, 0.212, 0.087, 0.282, 0.059, 0.163, 0.224, 0.11, 0.142, 0.132]
== Status ==
Current time: 2024-01-07 17:28:47 (running for 00:13:03.70)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.699 |  0.179 |                   54 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.409 |  0.172 |                   54 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.344 |  0.149 |                   38 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.289 |  0.147 |                   36 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.1793385148048401
[2m[36m(func pid=31109)[0m mae:  0.13170360028743744
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.337, 0.108, 0.189, 0.293, 0.14, 0.142, 0.11]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3440 | Steps: 4 | Val loss: 0.2754 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4104 | Steps: 4 | Val loss: 0.3138 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2889 | Steps: 4 | Val loss: 0.2703 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.6939 | Steps: 4 | Val loss: 0.5315 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=35640)[0m rmse: 0.14924702048301697
[2m[36m(func pid=35640)[0m mae:  0.10650954395532608
[2m[36m(func pid=35640)[0m rmse_per_class: [0.09, 0.223, 0.051, 0.302, 0.063, 0.162, 0.248, 0.116, 0.141, 0.095]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17172130942344666
[2m[36m(func pid=31653)[0m mae:  0.12552472949028015
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.252, 0.081, 0.329, 0.085, 0.185, 0.282, 0.136, 0.142, 0.109]
[2m[36m(func pid=31653)[0m 
== Status ==
Current time: 2024-01-07 17:28:52 (running for 00:13:08.85)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.694 |  0.179 |                   55 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.41  |  0.172 |                   55 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.344 |  0.149 |                   39 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.289 |  0.15  |                   37 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.149574413895607
[2m[36m(func pid=36548)[0m mae:  0.09423014521598816
[2m[36m(func pid=36548)[0m rmse_per_class: [0.065, 0.217, 0.067, 0.279, 0.058, 0.157, 0.227, 0.111, 0.155, 0.161]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.1793908178806305
[2m[36m(func pid=31109)[0m mae:  0.13168814778327942
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.098, 0.337, 0.106, 0.189, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3585 | Steps: 4 | Val loss: 0.2759 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4041 | Steps: 4 | Val loss: 0.3129 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2999 | Steps: 4 | Val loss: 0.2754 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.6897 | Steps: 4 | Val loss: 0.5323 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=35640)[0m rmse: 0.14962650835514069
[2m[36m(func pid=35640)[0m mae:  0.10693327337503433
[2m[36m(func pid=35640)[0m rmse_per_class: [0.091, 0.222, 0.052, 0.302, 0.063, 0.163, 0.249, 0.116, 0.142, 0.096]
[2m[36m(func pid=35640)[0m 
== Status ==
Current time: 2024-01-07 17:28:57 (running for 00:13:13.94)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.694 |  0.179 |                   56 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.404 |  0.172 |                   56 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.358 |  0.15  |                   40 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.289 |  0.15  |                   37 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=31653)[0m rmse: 0.17162032425403595
[2m[36m(func pid=31653)[0m mae:  0.12546248733997345
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.252, 0.081, 0.328, 0.084, 0.185, 0.282, 0.136, 0.142, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.1522715538740158
[2m[36m(func pid=36548)[0m mae:  0.09617666900157928
[2m[36m(func pid=36548)[0m rmse_per_class: [0.063, 0.216, 0.055, 0.282, 0.068, 0.156, 0.227, 0.111, 0.167, 0.177]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17930546402931213
[2m[36m(func pid=31109)[0m mae:  0.13159404695034027
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.098, 0.337, 0.107, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3447 | Steps: 4 | Val loss: 0.2749 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4062 | Steps: 4 | Val loss: 0.3120 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2868 | Steps: 4 | Val loss: 0.2727 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.6845 | Steps: 4 | Val loss: 0.5285 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
[2m[36m(func pid=35640)[0m rmse: 0.1489378809928894
[2m[36m(func pid=35640)[0m mae:  0.10631422698497772
[2m[36m(func pid=35640)[0m rmse_per_class: [0.088, 0.222, 0.051, 0.303, 0.064, 0.163, 0.248, 0.116, 0.141, 0.094]
[2m[36m(func pid=35640)[0m 
== Status ==
Current time: 2024-01-07 17:29:02 (running for 00:13:19.04)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.69  |  0.179 |                   57 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.406 |  0.171 |                   57 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.345 |  0.149 |                   41 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.3   |  0.152 |                   38 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=31653)[0m rmse: 0.17129316926002502
[2m[36m(func pid=31653)[0m mae:  0.12517257034778595
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.251, 0.079, 0.328, 0.084, 0.185, 0.282, 0.136, 0.143, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.15074622631072998
[2m[36m(func pid=36548)[0m mae:  0.09496914595365524
[2m[36m(func pid=36548)[0m rmse_per_class: [0.067, 0.214, 0.049, 0.287, 0.08, 0.157, 0.226, 0.127, 0.152, 0.147]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17907848954200745
[2m[36m(func pid=31109)[0m mae:  0.13146576285362244
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.261, 0.097, 0.336, 0.107, 0.19, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3455 | Steps: 4 | Val loss: 0.2742 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4096 | Steps: 4 | Val loss: 0.3117 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2772 | Steps: 4 | Val loss: 0.2695 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.6811 | Steps: 4 | Val loss: 0.5270 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 17:29:07 (running for 00:13:24.12)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.684 |  0.179 |                   58 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.406 |  0.171 |                   57 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.345 |  0.149 |                   42 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.287 |  0.151 |                   39 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=35640)[0m rmse: 0.14853820204734802
[2m[36m(func pid=35640)[0m mae:  0.10594532638788223
[2m[36m(func pid=35640)[0m rmse_per_class: [0.089, 0.222, 0.052, 0.3, 0.063, 0.162, 0.246, 0.116, 0.142, 0.092]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17119470238685608
[2m[36m(func pid=31653)[0m mae:  0.12510624527931213
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.252, 0.079, 0.327, 0.083, 0.185, 0.282, 0.136, 0.142, 0.108]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.14737416803836823
[2m[36m(func pid=36548)[0m mae:  0.09349986910820007
[2m[36m(func pid=36548)[0m rmse_per_class: [0.071, 0.207, 0.041, 0.287, 0.082, 0.156, 0.222, 0.128, 0.159, 0.121]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17899516224861145
[2m[36m(func pid=31109)[0m mae:  0.1313488781452179
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.26, 0.097, 0.337, 0.107, 0.189, 0.293, 0.14, 0.142, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3424 | Steps: 4 | Val loss: 0.2752 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4058 | Steps: 4 | Val loss: 0.3121 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2871 | Steps: 4 | Val loss: 0.2666 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.6775 | Steps: 4 | Val loss: 0.5229 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 17:29:13 (running for 00:13:29.47)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.681 |  0.179 |                   59 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.41  |  0.171 |                   58 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.342 |  0.149 |                   43 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.277 |  0.147 |                   40 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=35640)[0m rmse: 0.1491328328847885
[2m[36m(func pid=35640)[0m mae:  0.10637561231851578
[2m[36m(func pid=35640)[0m rmse_per_class: [0.088, 0.225, 0.051, 0.303, 0.063, 0.162, 0.244, 0.115, 0.146, 0.094]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.1444954127073288
[2m[36m(func pid=36548)[0m mae:  0.09142504632472992
[2m[36m(func pid=36548)[0m rmse_per_class: [0.074, 0.209, 0.044, 0.29, 0.077, 0.153, 0.219, 0.118, 0.151, 0.11]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17135384678840637
[2m[36m(func pid=31653)[0m mae:  0.12529604136943817
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.252, 0.079, 0.328, 0.083, 0.185, 0.282, 0.137, 0.142, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17909039556980133
[2m[36m(func pid=31109)[0m mae:  0.13144436478614807
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.098, 0.337, 0.107, 0.19, 0.293, 0.14, 0.142, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3365 | Steps: 4 | Val loss: 0.2739 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2852 | Steps: 4 | Val loss: 0.2660 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4051 | Steps: 4 | Val loss: 0.3125 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.6733 | Steps: 4 | Val loss: 0.5209 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=35640)[0m rmse: 0.148309588432312
[2m[36m(func pid=35640)[0m mae:  0.105657197535038
[2m[36m(func pid=35640)[0m rmse_per_class: [0.086, 0.224, 0.051, 0.298, 0.063, 0.162, 0.244, 0.116, 0.145, 0.095]
== Status ==
Current time: 2024-01-07 17:29:18 (running for 00:13:34.73)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.678 |  0.179 |                   60 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.406 |  0.171 |                   59 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.337 |  0.148 |                   44 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.287 |  0.144 |                   41 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.14581149816513062
[2m[36m(func pid=36548)[0m mae:  0.09173499792814255
[2m[36m(func pid=36548)[0m rmse_per_class: [0.081, 0.208, 0.052, 0.279, 0.07, 0.164, 0.229, 0.11, 0.15, 0.116]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17153188586235046
[2m[36m(func pid=31653)[0m mae:  0.12541140615940094
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.252, 0.08, 0.328, 0.083, 0.185, 0.282, 0.136, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.1789698749780655
[2m[36m(func pid=31109)[0m mae:  0.13130204379558563
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.26, 0.097, 0.336, 0.108, 0.19, 0.293, 0.14, 0.142, 0.108]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3404 | Steps: 4 | Val loss: 0.2730 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2941 | Steps: 4 | Val loss: 0.2653 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4091 | Steps: 4 | Val loss: 0.3126 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 17:29:23 (running for 00:13:39.92)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.673 |  0.179 |                   61 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.405 |  0.172 |                   60 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.34  |  0.148 |                   45 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.285 |  0.146 |                   42 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.6757 | Steps: 4 | Val loss: 0.5189 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=35640)[0m rmse: 0.14770548045635223
[2m[36m(func pid=35640)[0m mae:  0.10491577535867691
[2m[36m(func pid=35640)[0m rmse_per_class: [0.084, 0.224, 0.049, 0.296, 0.063, 0.16, 0.244, 0.115, 0.142, 0.099]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.14597801864147186
[2m[36m(func pid=36548)[0m mae:  0.09157935529947281
[2m[36m(func pid=36548)[0m rmse_per_class: [0.07, 0.213, 0.054, 0.269, 0.059, 0.174, 0.231, 0.111, 0.147, 0.132]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.1717834770679474
[2m[36m(func pid=31653)[0m mae:  0.12561051547527313
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.252, 0.081, 0.329, 0.083, 0.185, 0.282, 0.137, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17892973124980927
[2m[36m(func pid=31109)[0m mae:  0.13132590055465698
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.336, 0.108, 0.19, 0.293, 0.14, 0.143, 0.108]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3344 | Steps: 4 | Val loss: 0.2729 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3106 | Steps: 4 | Val loss: 0.2688 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4047 | Steps: 4 | Val loss: 0.3120 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 17:29:28 (running for 00:13:45.16)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.676 |  0.179 |                   62 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.409 |  0.172 |                   61 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.334 |  0.148 |                   46 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.294 |  0.146 |                   43 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=35640)[0m rmse: 0.14771205186843872
[2m[36m(func pid=35640)[0m mae:  0.1048494353890419
[2m[36m(func pid=35640)[0m rmse_per_class: [0.086, 0.224, 0.05, 0.297, 0.063, 0.162, 0.242, 0.115, 0.141, 0.098]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.1476219892501831
[2m[36m(func pid=36548)[0m mae:  0.0926419198513031
[2m[36m(func pid=36548)[0m rmse_per_class: [0.062, 0.213, 0.056, 0.273, 0.057, 0.159, 0.228, 0.111, 0.176, 0.14]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.6740 | Steps: 4 | Val loss: 0.5177 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=31653)[0m rmse: 0.17163152992725372
[2m[36m(func pid=31653)[0m mae:  0.12548518180847168
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.252, 0.081, 0.329, 0.083, 0.184, 0.282, 0.136, 0.142, 0.111]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=31109)[0m rmse: 0.17891378700733185
[2m[36m(func pid=31109)[0m mae:  0.1313101351261139
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.336, 0.107, 0.19, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3444 | Steps: 4 | Val loss: 0.2730 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2783 | Steps: 4 | Val loss: 0.2746 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4089 | Steps: 4 | Val loss: 0.3107 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 17:29:33 (running for 00:13:50.43)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.674 |  0.179 |                   63 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.405 |  0.172 |                   62 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.334 |  0.148 |                   46 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.278 |  0.151 |                   45 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.15059325098991394
[2m[36m(func pid=36548)[0m mae:  0.09479732811450958
[2m[36m(func pid=36548)[0m rmse_per_class: [0.064, 0.212, 0.066, 0.276, 0.056, 0.159, 0.228, 0.11, 0.187, 0.149]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.14783832430839539
[2m[36m(func pid=35640)[0m mae:  0.1049131527543068
[2m[36m(func pid=35640)[0m rmse_per_class: [0.089, 0.224, 0.048, 0.299, 0.064, 0.16, 0.243, 0.115, 0.139, 0.098]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.6645 | Steps: 4 | Val loss: 0.5156 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=31653)[0m rmse: 0.17125800251960754
[2m[36m(func pid=31653)[0m mae:  0.125151127576828
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.252, 0.081, 0.328, 0.083, 0.184, 0.281, 0.136, 0.141, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3245 | Steps: 4 | Val loss: 0.2779 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=31109)[0m rmse: 0.17909595370292664
[2m[36m(func pid=31109)[0m mae:  0.1314966231584549
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.26, 0.097, 0.337, 0.107, 0.19, 0.293, 0.14, 0.143, 0.11]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3403 | Steps: 4 | Val loss: 0.2730 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4021 | Steps: 4 | Val loss: 0.3111 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=36548)[0m rmse: 0.15335312485694885
[2m[36m(func pid=36548)[0m mae:  0.09686078131198883
[2m[36m(func pid=36548)[0m rmse_per_class: [0.084, 0.212, 0.07, 0.283, 0.058, 0.161, 0.229, 0.112, 0.179, 0.147]
[2m[36m(func pid=36548)[0m 
== Status ==
Current time: 2024-01-07 17:29:39 (running for 00:13:55.71)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.665 |  0.179 |                   64 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.409 |  0.171 |                   63 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.344 |  0.148 |                   47 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.325 |  0.153 |                   46 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=35640)[0m rmse: 0.1478419005870819
[2m[36m(func pid=35640)[0m mae:  0.10487018525600433
[2m[36m(func pid=35640)[0m rmse_per_class: [0.086, 0.221, 0.048, 0.301, 0.064, 0.16, 0.244, 0.114, 0.138, 0.102]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.6660 | Steps: 4 | Val loss: 0.5138 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=31653)[0m rmse: 0.17131760716438293
[2m[36m(func pid=31653)[0m mae:  0.12527015805244446
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.252, 0.081, 0.329, 0.083, 0.183, 0.281, 0.135, 0.142, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3039 | Steps: 4 | Val loss: 0.2725 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=31109)[0m rmse: 0.1791575700044632
[2m[36m(func pid=31109)[0m mae:  0.13153474032878876
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.337, 0.107, 0.189, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3339 | Steps: 4 | Val loss: 0.2719 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4003 | Steps: 4 | Val loss: 0.3100 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 17:29:44 (running for 00:14:00.88)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.666 |  0.179 |                   65 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.171 |                   64 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.34  |  0.148 |                   48 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.304 |  0.149 |                   47 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14890959858894348
[2m[36m(func pid=36548)[0m mae:  0.09366067498922348
[2m[36m(func pid=36548)[0m rmse_per_class: [0.078, 0.214, 0.057, 0.286, 0.059, 0.156, 0.221, 0.135, 0.154, 0.128]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.1472165286540985
[2m[36m(func pid=35640)[0m mae:  0.10416227579116821
[2m[36m(func pid=35640)[0m rmse_per_class: [0.084, 0.221, 0.048, 0.3, 0.064, 0.159, 0.243, 0.114, 0.136, 0.102]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.6675 | Steps: 4 | Val loss: 0.5121 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=31653)[0m rmse: 0.17096716165542603
[2m[36m(func pid=31653)[0m mae:  0.12502899765968323
[2m[36m(func pid=31653)[0m rmse_per_class: [0.118, 0.253, 0.079, 0.329, 0.081, 0.183, 0.281, 0.135, 0.142, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3133 | Steps: 4 | Val loss: 0.2635 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=31109)[0m rmse: 0.17915210127830505
[2m[36m(func pid=31109)[0m mae:  0.1315198391675949
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.337, 0.108, 0.189, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3368 | Steps: 4 | Val loss: 0.2709 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4014 | Steps: 4 | Val loss: 0.3100 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 17:29:49 (running for 00:14:06.13)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.668 |  0.179 |                   66 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.4   |  0.171 |                   65 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.334 |  0.147 |                   49 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.313 |  0.143 |                   48 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14344267547130585
[2m[36m(func pid=36548)[0m mae:  0.09020727872848511
[2m[36m(func pid=36548)[0m rmse_per_class: [0.083, 0.212, 0.043, 0.264, 0.057, 0.153, 0.224, 0.133, 0.15, 0.115]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.14641201496124268
[2m[36m(func pid=35640)[0m mae:  0.10353946685791016
[2m[36m(func pid=35640)[0m rmse_per_class: [0.082, 0.222, 0.049, 0.297, 0.066, 0.158, 0.243, 0.113, 0.136, 0.098]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.6640 | Steps: 4 | Val loss: 0.5109 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=31653)[0m rmse: 0.1709882915019989
[2m[36m(func pid=31653)[0m mae:  0.12502740323543549
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.253, 0.08, 0.329, 0.08, 0.183, 0.28, 0.136, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2757 | Steps: 4 | Val loss: 0.2564 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3432 | Steps: 4 | Val loss: 0.2715 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=31109)[0m rmse: 0.17932811379432678
[2m[36m(func pid=31109)[0m mae:  0.1316119134426117
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.259, 0.097, 0.337, 0.108, 0.19, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4004 | Steps: 4 | Val loss: 0.3096 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 17:29:54 (running for 00:14:11.41)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.664 |  0.179 |                   67 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.401 |  0.171 |                   66 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.337 |  0.146 |                   50 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.276 |  0.136 |                   49 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.13610082864761353
[2m[36m(func pid=36548)[0m mae:  0.08598680049180984
[2m[36m(func pid=36548)[0m rmse_per_class: [0.07, 0.205, 0.039, 0.245, 0.058, 0.154, 0.235, 0.115, 0.139, 0.102]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.1467057764530182
[2m[36m(func pid=35640)[0m mae:  0.1034475564956665
[2m[36m(func pid=35640)[0m rmse_per_class: [0.081, 0.22, 0.049, 0.3, 0.068, 0.158, 0.243, 0.112, 0.136, 0.099]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.6592 | Steps: 4 | Val loss: 0.5091 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=31653)[0m rmse: 0.17077478766441345
[2m[36m(func pid=31653)[0m mae:  0.12487666308879852
[2m[36m(func pid=31653)[0m rmse_per_class: [0.117, 0.252, 0.08, 0.328, 0.08, 0.183, 0.28, 0.135, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2707 | Steps: 4 | Val loss: 0.2592 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3316 | Steps: 4 | Val loss: 0.2697 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=31109)[0m rmse: 0.17910467088222504
[2m[36m(func pid=31109)[0m mae:  0.13143190741539001
[2m[36m(func pid=31109)[0m rmse_per_class: [0.115, 0.26, 0.097, 0.337, 0.108, 0.189, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4062 | Steps: 4 | Val loss: 0.3096 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=36548)[0m rmse: 0.13855043053627014
[2m[36m(func pid=36548)[0m mae:  0.08716858178377151
[2m[36m(func pid=36548)[0m rmse_per_class: [0.064, 0.207, 0.04, 0.248, 0.063, 0.158, 0.239, 0.112, 0.144, 0.11]
[2m[36m(func pid=36548)[0m 
== Status ==
Current time: 2024-01-07 17:30:00 (running for 00:14:16.49)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.659 |  0.179 |                   68 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.4   |  0.171 |                   67 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.343 |  0.147 |                   51 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.271 |  0.139 |                   50 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=35640)[0m rmse: 0.14556124806404114
[2m[36m(func pid=35640)[0m mae:  0.102500781416893
[2m[36m(func pid=35640)[0m rmse_per_class: [0.078, 0.219, 0.048, 0.296, 0.067, 0.158, 0.242, 0.112, 0.137, 0.098]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.6578 | Steps: 4 | Val loss: 0.5072 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=31653)[0m rmse: 0.1708206683397293
[2m[36m(func pid=31653)[0m mae:  0.12482655048370361
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.253, 0.08, 0.328, 0.081, 0.183, 0.28, 0.135, 0.142, 0.112]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2941 | Steps: 4 | Val loss: 0.2646 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3353 | Steps: 4 | Val loss: 0.2691 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=31109)[0m rmse: 0.17915289103984833
[2m[36m(func pid=31109)[0m mae:  0.131486713886261
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.337, 0.108, 0.189, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4028 | Steps: 4 | Val loss: 0.3092 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 17:30:05 (running for 00:14:21.75)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.658 |  0.179 |                   69 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.406 |  0.171 |                   68 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.332 |  0.146 |                   52 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.294 |  0.143 |                   51 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.1429336667060852
[2m[36m(func pid=36548)[0m mae:  0.08963063359260559
[2m[36m(func pid=36548)[0m rmse_per_class: [0.062, 0.213, 0.04, 0.271, 0.069, 0.159, 0.229, 0.11, 0.151, 0.126]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.14519019424915314
[2m[36m(func pid=35640)[0m mae:  0.10229498147964478
[2m[36m(func pid=35640)[0m rmse_per_class: [0.079, 0.219, 0.048, 0.294, 0.066, 0.159, 0.24, 0.112, 0.137, 0.097]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.6562 | Steps: 4 | Val loss: 0.5058 | Batch size: 32 | lr: 0.0001 | Duration: 3.12s
[2m[36m(func pid=31653)[0m rmse: 0.1707243174314499
[2m[36m(func pid=31653)[0m mae:  0.1247524619102478
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.251, 0.08, 0.328, 0.08, 0.182, 0.28, 0.135, 0.142, 0.112]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2790 | Steps: 4 | Val loss: 0.2721 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3234 | Steps: 4 | Val loss: 0.2687 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=31109)[0m rmse: 0.1789672076702118
[2m[36m(func pid=31109)[0m mae:  0.1312899887561798
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.336, 0.107, 0.189, 0.294, 0.14, 0.142, 0.108]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3997 | Steps: 4 | Val loss: 0.3080 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 17:30:10 (running for 00:14:26.90)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.656 |  0.179 |                   70 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.403 |  0.171 |                   69 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.335 |  0.145 |                   53 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.279 |  0.147 |                   52 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14725372195243835
[2m[36m(func pid=36548)[0m mae:  0.09272535145282745
[2m[36m(func pid=36548)[0m rmse_per_class: [0.062, 0.21, 0.043, 0.293, 0.069, 0.157, 0.224, 0.113, 0.174, 0.129]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.1450314223766327
[2m[36m(func pid=35640)[0m mae:  0.10203870385885239
[2m[36m(func pid=35640)[0m rmse_per_class: [0.078, 0.218, 0.048, 0.293, 0.066, 0.16, 0.241, 0.113, 0.137, 0.097]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.6537 | Steps: 4 | Val loss: 0.5041 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=31653)[0m rmse: 0.17012900114059448
[2m[36m(func pid=31653)[0m mae:  0.12429281324148178
[2m[36m(func pid=31653)[0m rmse_per_class: [0.116, 0.25, 0.078, 0.328, 0.08, 0.183, 0.28, 0.135, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2794 | Steps: 4 | Val loss: 0.2753 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3356 | Steps: 4 | Val loss: 0.2668 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=31109)[0m rmse: 0.17904381453990936
[2m[36m(func pid=31109)[0m mae:  0.131352037191391
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.336, 0.107, 0.19, 0.294, 0.14, 0.142, 0.108]
[2m[36m(func pid=31109)[0m 
== Status ==
Current time: 2024-01-07 17:30:15 (running for 00:14:32.06)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.654 |  0.179 |                   71 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.4   |  0.17  |                   70 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.323 |  0.145 |                   54 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.279 |  0.15  |                   53 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3997 | Steps: 4 | Val loss: 0.3090 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=36548)[0m rmse: 0.1498146951198578
[2m[36m(func pid=36548)[0m mae:  0.09522651135921478
[2m[36m(func pid=36548)[0m rmse_per_class: [0.065, 0.21, 0.043, 0.284, 0.067, 0.157, 0.231, 0.122, 0.2, 0.119]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.14370694756507874
[2m[36m(func pid=35640)[0m mae:  0.10077681392431259
[2m[36m(func pid=35640)[0m rmse_per_class: [0.076, 0.217, 0.047, 0.288, 0.064, 0.16, 0.238, 0.113, 0.136, 0.098]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.6470 | Steps: 4 | Val loss: 0.5025 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=31653)[0m rmse: 0.17048265039920807
[2m[36m(func pid=31653)[0m mae:  0.12458635866641998
[2m[36m(func pid=31653)[0m rmse_per_class: [0.115, 0.252, 0.079, 0.328, 0.081, 0.182, 0.28, 0.135, 0.142, 0.111]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2872 | Steps: 4 | Val loss: 0.2723 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3386 | Steps: 4 | Val loss: 0.2664 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=31109)[0m rmse: 0.17899294197559357
[2m[36m(func pid=31109)[0m mae:  0.13133130967617035
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.336, 0.107, 0.189, 0.293, 0.14, 0.142, 0.109]
[2m[36m(func pid=31109)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.1492512971162796
[2m[36m(func pid=36548)[0m mae:  0.0946054607629776
[2m[36m(func pid=36548)[0m rmse_per_class: [0.068, 0.215, 0.05, 0.267, 0.069, 0.154, 0.239, 0.144, 0.18, 0.106]
[2m[36m(func pid=36548)[0m 
== Status ==
Current time: 2024-01-07 17:30:20 (running for 00:14:37.27)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.647 |  0.179 |                   72 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.4   |  0.17  |                   71 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.336 |  0.144 |                   55 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.287 |  0.149 |                   54 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3965 | Steps: 4 | Val loss: 0.3077 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=35640)[0m rmse: 0.14328990876674652
[2m[36m(func pid=35640)[0m mae:  0.10038403421640396
[2m[36m(func pid=35640)[0m rmse_per_class: [0.076, 0.218, 0.046, 0.288, 0.063, 0.158, 0.238, 0.113, 0.135, 0.097]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.6499 | Steps: 4 | Val loss: 0.5011 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=31653)[0m rmse: 0.16995760798454285
[2m[36m(func pid=31653)[0m mae:  0.12413760274648666
[2m[36m(func pid=31653)[0m rmse_per_class: [0.115, 0.252, 0.078, 0.327, 0.08, 0.183, 0.279, 0.134, 0.142, 0.109]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2718 | Steps: 4 | Val loss: 0.2659 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3294 | Steps: 4 | Val loss: 0.2665 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=31109)[0m rmse: 0.17895354330539703
[2m[36m(func pid=31109)[0m mae:  0.1313101053237915
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.336, 0.108, 0.189, 0.293, 0.14, 0.142, 0.109]
[2m[36m(func pid=31109)[0m 
== Status ==
Current time: 2024-01-07 17:30:26 (running for 00:14:42.48)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.65  |  0.179 |                   73 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.397 |  0.17  |                   72 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.339 |  0.143 |                   56 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.272 |  0.145 |                   55 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14519131183624268
[2m[36m(func pid=36548)[0m mae:  0.09159550815820694
[2m[36m(func pid=36548)[0m rmse_per_class: [0.075, 0.206, 0.061, 0.266, 0.07, 0.155, 0.245, 0.127, 0.152, 0.095]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3997 | Steps: 4 | Val loss: 0.3081 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=35640)[0m rmse: 0.14341306686401367
[2m[36m(func pid=35640)[0m mae:  0.10043944418430328
[2m[36m(func pid=35640)[0m rmse_per_class: [0.076, 0.219, 0.045, 0.288, 0.065, 0.157, 0.238, 0.112, 0.136, 0.098]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.6440 | Steps: 4 | Val loss: 0.4970 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=31653)[0m rmse: 0.17008987069129944
[2m[36m(func pid=31653)[0m mae:  0.1242544874548912
[2m[36m(func pid=31653)[0m rmse_per_class: [0.115, 0.251, 0.079, 0.328, 0.079, 0.183, 0.278, 0.134, 0.142, 0.11]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2832 | Steps: 4 | Val loss: 0.2666 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3398 | Steps: 4 | Val loss: 0.2662 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=31109)[0m rmse: 0.17885437607765198
[2m[36m(func pid=31109)[0m mae:  0.13125178217887878
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.336, 0.107, 0.189, 0.293, 0.14, 0.142, 0.109]
[2m[36m(func pid=31109)[0m 
== Status ==
Current time: 2024-01-07 17:30:31 (running for 00:14:47.67)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.15699999779462814
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00004 | RUNNING    | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   74 |
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.4   |  0.17  |                   73 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.329 |  0.143 |                   57 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.283 |  0.146 |                   56 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14608749747276306
[2m[36m(func pid=36548)[0m mae:  0.09169045090675354
[2m[36m(func pid=36548)[0m rmse_per_class: [0.087, 0.209, 0.078, 0.275, 0.066, 0.156, 0.238, 0.114, 0.139, 0.098]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3988 | Steps: 4 | Val loss: 0.3085 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=35640)[0m rmse: 0.1432732790708542
[2m[36m(func pid=35640)[0m mae:  0.1001824289560318
[2m[36m(func pid=35640)[0m rmse_per_class: [0.077, 0.218, 0.045, 0.286, 0.065, 0.156, 0.24, 0.112, 0.134, 0.099]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31109)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.6443 | Steps: 4 | Val loss: 0.4943 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=31653)[0m rmse: 0.1702134609222412
[2m[36m(func pid=31653)[0m mae:  0.12434174120426178
[2m[36m(func pid=31653)[0m rmse_per_class: [0.114, 0.253, 0.08, 0.327, 0.079, 0.184, 0.278, 0.134, 0.143, 0.111]
[2m[36m(func pid=31653)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3018 | Steps: 4 | Val loss: 0.2668 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3342 | Steps: 4 | Val loss: 0.2662 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=31109)[0m rmse: 0.1790461540222168
[2m[36m(func pid=31109)[0m mae:  0.13143666088581085
[2m[36m(func pid=31109)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.336, 0.107, 0.189, 0.293, 0.14, 0.143, 0.11]
== Status ==
Current time: 2024-01-07 17:30:36 (running for 00:14:52.87)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1599999964237213
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (16 PENDING, 3 RUNNING, 5 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00005 | RUNNING    | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.399 |  0.17  |                   74 |
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.34  |  0.143 |                   58 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.302 |  0.145 |                   57 |
| train_01e98_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14539042115211487
[2m[36m(func pid=36548)[0m mae:  0.09076078236103058
[2m[36m(func pid=36548)[0m rmse_per_class: [0.072, 0.209, 0.075, 0.279, 0.069, 0.158, 0.233, 0.111, 0.144, 0.103]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=31653)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4020 | Steps: 4 | Val loss: 0.3089 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=35640)[0m rmse: 0.14331074059009552
[2m[36m(func pid=35640)[0m mae:  0.1002318263053894
[2m[36m(func pid=35640)[0m rmse_per_class: [0.077, 0.219, 0.044, 0.285, 0.067, 0.156, 0.241, 0.113, 0.135, 0.097]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=31653)[0m rmse: 0.17018845677375793
[2m[36m(func pid=31653)[0m mae:  0.12437983602285385
[2m[36m(func pid=31653)[0m rmse_per_class: [0.113, 0.253, 0.078, 0.328, 0.08, 0.183, 0.278, 0.134, 0.143, 0.111]
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2917 | Steps: 4 | Val loss: 0.2724 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3270 | Steps: 4 | Val loss: 0.2658 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=36548)[0m rmse: 0.1497158706188202
[2m[36m(func pid=36548)[0m mae:  0.09365864843130112
[2m[36m(func pid=36548)[0m rmse_per_class: [0.062, 0.211, 0.067, 0.278, 0.07, 0.157, 0.23, 0.11, 0.146, 0.166]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.1429474651813507
[2m[36m(func pid=35640)[0m mae:  0.09989356994628906
[2m[36m(func pid=35640)[0m rmse_per_class: [0.077, 0.218, 0.042, 0.286, 0.068, 0.155, 0.24, 0.113, 0.135, 0.095]
[2m[36m(func pid=50163)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50163)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=50163)[0m Configuration completed!
[2m[36m(func pid=50163)[0m New optimizer parameters:
[2m[36m(func pid=50163)[0m SGD (
[2m[36m(func pid=50163)[0m Parameter Group 0
[2m[36m(func pid=50163)[0m     dampening: 0
[2m[36m(func pid=50163)[0m     differentiable: False
[2m[36m(func pid=50163)[0m     foreach: None
[2m[36m(func pid=50163)[0m     lr: 0.0001
[2m[36m(func pid=50163)[0m     maximize: False
[2m[36m(func pid=50163)[0m     momentum: 0.99
[2m[36m(func pid=50163)[0m     nesterov: False
[2m[36m(func pid=50163)[0m     weight_decay: 0.0001
[2m[36m(func pid=50163)[0m )
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2785 | Steps: 4 | Val loss: 0.2675 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=36548)[0m rmse: 0.14582914113998413
[2m[36m(func pid=36548)[0m mae:  0.09112821519374847
[2m[36m(func pid=36548)[0m rmse_per_class: [0.061, 0.21, 0.049, 0.262, 0.066, 0.157, 0.223, 0.118, 0.145, 0.168]
== Status ==
Current time: 2024-01-07 17:30:41 (running for 00:14:58.20)
Memory usage on this node: 19.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.334 |  0.143 |                   59 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.292 |  0.15  |                   58 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50292)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=50292)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=50292)[0m Configuration completed!
[2m[36m(func pid=50292)[0m New optimizer parameters:
[2m[36m(func pid=50292)[0m SGD (
[2m[36m(func pid=50292)[0m Parameter Group 0
[2m[36m(func pid=50292)[0m     dampening: 0
[2m[36m(func pid=50292)[0m     differentiable: False
[2m[36m(func pid=50292)[0m     foreach: None
[2m[36m(func pid=50292)[0m     lr: 0.001
[2m[36m(func pid=50292)[0m     maximize: False
[2m[36m(func pid=50292)[0m     momentum: 0.99
[2m[36m(func pid=50292)[0m     nesterov: False
[2m[36m(func pid=50292)[0m     weight_decay: 0.0001
[2m[36m(func pid=50292)[0m )
[2m[36m(func pid=50292)[0m 
== Status ==
Current time: 2024-01-07 17:30:47 (running for 00:15:03.92)
Memory usage on this node: 23.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.334 |  0.143 |                   59 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.278 |  0.146 |                   59 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8979 | Steps: 4 | Val loss: 0.7005 | Batch size: 32 | lr: 0.0001 | Duration: 4.59s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3381 | Steps: 4 | Val loss: 0.2668 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2941 | Steps: 4 | Val loss: 0.2667 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=50163)[0m rmse: 0.1824485957622528
[2m[36m(func pid=50163)[0m mae:  0.13434328138828278
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.266, 0.106, 0.339, 0.112, 0.19, 0.295, 0.143, 0.144, 0.111]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8945 | Steps: 4 | Val loss: 0.6971 | Batch size: 32 | lr: 0.001 | Duration: 4.45s
== Status ==
Current time: 2024-01-07 17:30:52 (running for 00:15:09.25)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.338 |  0.144 |                   61 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.278 |  0.146 |                   59 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.898 |  0.182 |                    1 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=35640)[0m rmse: 0.14355024695396423
[2m[36m(func pid=35640)[0m mae:  0.10036291182041168
[2m[36m(func pid=35640)[0m rmse_per_class: [0.077, 0.219, 0.044, 0.289, 0.069, 0.155, 0.24, 0.113, 0.136, 0.094]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.14583951234817505
[2m[36m(func pid=36548)[0m mae:  0.0908491238951683
[2m[36m(func pid=36548)[0m rmse_per_class: [0.074, 0.213, 0.048, 0.265, 0.067, 0.154, 0.225, 0.131, 0.148, 0.132]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.8927 | Steps: 4 | Val loss: 0.6928 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=50292)[0m rmse: 0.1825903058052063
[2m[36m(func pid=50292)[0m mae:  0.134392648935318
[2m[36m(func pid=50292)[0m rmse_per_class: [0.117, 0.267, 0.107, 0.339, 0.112, 0.19, 0.294, 0.144, 0.143, 0.112]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3171 | Steps: 4 | Val loss: 0.2663 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2869 | Steps: 4 | Val loss: 0.2703 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=50163)[0m rmse: 0.181478351354599
[2m[36m(func pid=50163)[0m mae:  0.1335882544517517
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.266, 0.104, 0.338, 0.112, 0.19, 0.294, 0.141, 0.143, 0.111]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.8753 | Steps: 4 | Val loss: 0.6678 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 17:30:58 (running for 00:15:14.50)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.338 |  0.144 |                   61 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.287 |  0.15  |                   61 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.893 |  0.181 |                    2 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.895 |  0.183 |                    1 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14956609904766083
[2m[36m(func pid=36548)[0m mae:  0.09324571490287781
[2m[36m(func pid=36548)[0m rmse_per_class: [0.09, 0.211, 0.055, 0.266, 0.066, 0.156, 0.235, 0.124, 0.164, 0.128]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.14307905733585358
[2m[36m(func pid=35640)[0m mae:  0.09972300380468369
[2m[36m(func pid=35640)[0m rmse_per_class: [0.077, 0.219, 0.044, 0.288, 0.067, 0.155, 0.237, 0.113, 0.136, 0.095]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.8900 | Steps: 4 | Val loss: 0.6866 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=50292)[0m rmse: 0.18187609314918518
[2m[36m(func pid=50292)[0m mae:  0.13386109471321106
[2m[36m(func pid=50292)[0m rmse_per_class: [0.117, 0.266, 0.104, 0.338, 0.113, 0.19, 0.294, 0.142, 0.143, 0.111]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2841 | Steps: 4 | Val loss: 0.2659 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3242 | Steps: 4 | Val loss: 0.2660 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=50163)[0m rmse: 0.18082121014595032
[2m[36m(func pid=50163)[0m mae:  0.13303381204605103
[2m[36m(func pid=50163)[0m rmse_per_class: [0.116, 0.265, 0.102, 0.338, 0.111, 0.19, 0.294, 0.14, 0.142, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.8372 | Steps: 4 | Val loss: 0.6292 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=36548)[0m rmse: 0.14553217589855194
[2m[36m(func pid=36548)[0m mae:  0.09064511954784393
[2m[36m(func pid=36548)[0m rmse_per_class: [0.076, 0.207, 0.055, 0.251, 0.066, 0.158, 0.248, 0.115, 0.159, 0.122]
[2m[36m(func pid=36548)[0m 
== Status ==
Current time: 2024-01-07 17:31:03 (running for 00:15:19.73)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.324 |  0.143 |                   63 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.284 |  0.146 |                   62 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.89  |  0.181 |                    3 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.875 |  0.182 |                    2 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=35640)[0m rmse: 0.14323925971984863
[2m[36m(func pid=35640)[0m mae:  0.09973714500665665
[2m[36m(func pid=35640)[0m rmse_per_class: [0.077, 0.22, 0.043, 0.284, 0.067, 0.155, 0.239, 0.112, 0.136, 0.1]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8847 | Steps: 4 | Val loss: 0.6827 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=50292)[0m rmse: 0.18111637234687805
[2m[36m(func pid=50292)[0m mae:  0.13328997790813446
[2m[36m(func pid=50292)[0m rmse_per_class: [0.116, 0.265, 0.102, 0.338, 0.111, 0.189, 0.295, 0.141, 0.143, 0.111]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2840 | Steps: 4 | Val loss: 0.2644 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3285 | Steps: 4 | Val loss: 0.2670 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=50163)[0m rmse: 0.1806914508342743
[2m[36m(func pid=50163)[0m mae:  0.1328771859407425
[2m[36m(func pid=50163)[0m rmse_per_class: [0.116, 0.264, 0.102, 0.338, 0.112, 0.189, 0.294, 0.14, 0.142, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.7833 | Steps: 4 | Val loss: 0.5840 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=36548)[0m rmse: 0.14425668120384216
[2m[36m(func pid=36548)[0m mae:  0.08953473716974258
[2m[36m(func pid=36548)[0m rmse_per_class: [0.068, 0.204, 0.073, 0.252, 0.064, 0.159, 0.245, 0.111, 0.155, 0.112]
[2m[36m(func pid=36548)[0m 
== Status ==
Current time: 2024-01-07 17:31:08 (running for 00:15:24.93)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.329 |  0.144 |                   64 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.284 |  0.144 |                   63 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.885 |  0.181 |                    4 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.837 |  0.181 |                    3 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=35640)[0m rmse: 0.14397494494915009
[2m[36m(func pid=35640)[0m mae:  0.10041794925928116
[2m[36m(func pid=35640)[0m rmse_per_class: [0.077, 0.22, 0.045, 0.288, 0.068, 0.155, 0.238, 0.111, 0.138, 0.1]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.18034282326698303
[2m[36m(func pid=50292)[0m mae:  0.13260431587696075
[2m[36m(func pid=50292)[0m rmse_per_class: [0.116, 0.264, 0.1, 0.337, 0.11, 0.189, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.8755 | Steps: 4 | Val loss: 0.6772 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2966 | Steps: 4 | Val loss: 0.2673 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3304 | Steps: 4 | Val loss: 0.2678 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=50163)[0m rmse: 0.1803833693265915
[2m[36m(func pid=50163)[0m mae:  0.13260617852210999
[2m[36m(func pid=50163)[0m rmse_per_class: [0.115, 0.263, 0.101, 0.338, 0.111, 0.189, 0.294, 0.14, 0.142, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7272 | Steps: 4 | Val loss: 0.5341 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=36548)[0m rmse: 0.14603129029273987
[2m[36m(func pid=36548)[0m mae:  0.09110280126333237
[2m[36m(func pid=36548)[0m rmse_per_class: [0.071, 0.203, 0.083, 0.273, 0.068, 0.157, 0.237, 0.112, 0.155, 0.101]
[2m[36m(func pid=36548)[0m 
== Status ==
Current time: 2024-01-07 17:31:13 (running for 00:15:30.13)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.33  |  0.144 |                   65 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.297 |  0.146 |                   64 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.876 |  0.18  |                    5 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.783 |  0.18  |                    4 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=35640)[0m rmse: 0.14439842104911804
[2m[36m(func pid=35640)[0m mae:  0.10067377239465714
[2m[36m(func pid=35640)[0m rmse_per_class: [0.076, 0.221, 0.044, 0.292, 0.067, 0.155, 0.236, 0.111, 0.14, 0.102]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.17995718121528625
[2m[36m(func pid=50292)[0m mae:  0.13231828808784485
[2m[36m(func pid=50292)[0m rmse_per_class: [0.117, 0.263, 0.098, 0.338, 0.108, 0.189, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.8675 | Steps: 4 | Val loss: 0.6710 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2658 | Steps: 4 | Val loss: 0.2728 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3413 | Steps: 4 | Val loss: 0.2655 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=50163)[0m rmse: 0.18026280403137207
[2m[36m(func pid=50163)[0m mae:  0.1324709951877594
[2m[36m(func pid=50163)[0m rmse_per_class: [0.116, 0.262, 0.1, 0.338, 0.111, 0.189, 0.294, 0.14, 0.142, 0.109]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.6634 | Steps: 4 | Val loss: 0.4855 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 17:31:18 (running for 00:15:35.30)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.341 |  0.143 |                   66 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.297 |  0.146 |                   64 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.867 |  0.18  |                    6 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.727 |  0.18  |                    5 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=35640)[0m rmse: 0.14274801313877106
[2m[36m(func pid=35640)[0m mae:  0.09925637394189835
[2m[36m(func pid=35640)[0m rmse_per_class: [0.077, 0.221, 0.042, 0.287, 0.066, 0.153, 0.234, 0.11, 0.139, 0.097]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m rmse: 0.14742161333560944
[2m[36m(func pid=36548)[0m mae:  0.0930248573422432
[2m[36m(func pid=36548)[0m rmse_per_class: [0.068, 0.204, 0.076, 0.297, 0.067, 0.163, 0.232, 0.112, 0.153, 0.101]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.17936451733112335
[2m[36m(func pid=50292)[0m mae:  0.13177920877933502
[2m[36m(func pid=50292)[0m rmse_per_class: [0.117, 0.261, 0.097, 0.337, 0.106, 0.189, 0.293, 0.141, 0.142, 0.11]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.8607 | Steps: 4 | Val loss: 0.6593 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2886 | Steps: 4 | Val loss: 0.2740 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3304 | Steps: 4 | Val loss: 0.2665 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=50163)[0m rmse: 0.1800992786884308
[2m[36m(func pid=50163)[0m mae:  0.13237716257572174
[2m[36m(func pid=50163)[0m rmse_per_class: [0.116, 0.262, 0.1, 0.337, 0.111, 0.189, 0.294, 0.141, 0.143, 0.108]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.6042 | Steps: 4 | Val loss: 0.4386 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 17:31:24 (running for 00:15:40.49)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.341 |  0.143 |                   66 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.289 |  0.147 |                   66 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.861 |  0.18  |                    7 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.663 |  0.179 |                    6 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14696092903614044
[2m[36m(func pid=36548)[0m mae:  0.09268135577440262
[2m[36m(func pid=36548)[0m rmse_per_class: [0.065, 0.208, 0.067, 0.304, 0.069, 0.157, 0.232, 0.115, 0.154, 0.1]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.14375607669353485
[2m[36m(func pid=35640)[0m mae:  0.09997852146625519
[2m[36m(func pid=35640)[0m rmse_per_class: [0.077, 0.219, 0.043, 0.287, 0.066, 0.154, 0.237, 0.11, 0.139, 0.104]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.1786072552204132
[2m[36m(func pid=50292)[0m mae:  0.13120296597480774
[2m[36m(func pid=50292)[0m rmse_per_class: [0.117, 0.26, 0.095, 0.337, 0.103, 0.189, 0.292, 0.14, 0.143, 0.11]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.8461 | Steps: 4 | Val loss: 0.6505 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3348 | Steps: 4 | Val loss: 0.2681 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2840 | Steps: 4 | Val loss: 0.2717 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=50163)[0m rmse: 0.18004384636878967
[2m[36m(func pid=50163)[0m mae:  0.13231459259986877
[2m[36m(func pid=50163)[0m rmse_per_class: [0.116, 0.262, 0.099, 0.338, 0.11, 0.189, 0.294, 0.141, 0.142, 0.109]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5513 | Steps: 4 | Val loss: 0.3988 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 17:31:29 (running for 00:15:45.71)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.33  |  0.144 |                   67 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.284 |  0.146 |                   67 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.846 |  0.18  |                    8 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.604 |  0.179 |                    7 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.1464899778366089
[2m[36m(func pid=36548)[0m mae:  0.09218056499958038
[2m[36m(func pid=36548)[0m rmse_per_class: [0.068, 0.209, 0.051, 0.29, 0.066, 0.155, 0.229, 0.116, 0.177, 0.104]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.14497707784175873
[2m[36m(func pid=35640)[0m mae:  0.10123556852340698
[2m[36m(func pid=35640)[0m rmse_per_class: [0.078, 0.22, 0.045, 0.292, 0.07, 0.155, 0.238, 0.11, 0.142, 0.1]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.1779802441596985
[2m[36m(func pid=50292)[0m mae:  0.13063807785511017
[2m[36m(func pid=50292)[0m rmse_per_class: [0.117, 0.259, 0.094, 0.336, 0.1, 0.19, 0.291, 0.14, 0.143, 0.11]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.8284 | Steps: 4 | Val loss: 0.6416 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2890 | Steps: 4 | Val loss: 0.2716 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3320 | Steps: 4 | Val loss: 0.2679 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=50163)[0m rmse: 0.18001198768615723
[2m[36m(func pid=50163)[0m mae:  0.13227921724319458
[2m[36m(func pid=50163)[0m rmse_per_class: [0.116, 0.262, 0.099, 0.337, 0.111, 0.189, 0.294, 0.141, 0.142, 0.108]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5050 | Steps: 4 | Val loss: 0.3689 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 17:31:34 (running for 00:15:50.98)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.335 |  0.145 |                   68 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.289 |  0.147 |                   68 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.828 |  0.18  |                    9 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.551 |  0.178 |                    8 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.1466580331325531
[2m[36m(func pid=36548)[0m mae:  0.09237247705459595
[2m[36m(func pid=36548)[0m rmse_per_class: [0.075, 0.208, 0.044, 0.272, 0.058, 0.156, 0.236, 0.116, 0.18, 0.12]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.14489975571632385
[2m[36m(func pid=35640)[0m mae:  0.10092960298061371
[2m[36m(func pid=35640)[0m rmse_per_class: [0.077, 0.22, 0.046, 0.29, 0.069, 0.155, 0.237, 0.11, 0.143, 0.102]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.17723113298416138
[2m[36m(func pid=50292)[0m mae:  0.13007093966007233
[2m[36m(func pid=50292)[0m rmse_per_class: [0.116, 0.258, 0.092, 0.336, 0.097, 0.189, 0.29, 0.14, 0.143, 0.111]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.8198 | Steps: 4 | Val loss: 0.6309 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2613 | Steps: 4 | Val loss: 0.2663 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3329 | Steps: 4 | Val loss: 0.2669 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=50163)[0m rmse: 0.17999668419361115
[2m[36m(func pid=50163)[0m mae:  0.13231173157691956
[2m[36m(func pid=50163)[0m rmse_per_class: [0.115, 0.262, 0.099, 0.337, 0.11, 0.189, 0.295, 0.14, 0.143, 0.109]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4656 | Steps: 4 | Val loss: 0.3449 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 17:31:39 (running for 00:15:56.16)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.332 |  0.145 |                   69 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.261 |  0.143 |                   69 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.82  |  0.18  |                   10 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.505 |  0.177 |                    9 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14288674294948578
[2m[36m(func pid=36548)[0m mae:  0.08997322618961334
[2m[36m(func pid=36548)[0m rmse_per_class: [0.071, 0.207, 0.043, 0.256, 0.059, 0.157, 0.239, 0.11, 0.166, 0.121]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.1440509706735611
[2m[36m(func pid=35640)[0m mae:  0.10011669248342514
[2m[36m(func pid=35640)[0m rmse_per_class: [0.081, 0.218, 0.045, 0.29, 0.068, 0.154, 0.235, 0.11, 0.142, 0.099]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.17642061412334442
[2m[36m(func pid=50292)[0m mae:  0.12936368584632874
[2m[36m(func pid=50292)[0m rmse_per_class: [0.117, 0.258, 0.091, 0.335, 0.092, 0.189, 0.289, 0.14, 0.143, 0.111]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.8058 | Steps: 4 | Val loss: 0.6193 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2935 | Steps: 4 | Val loss: 0.2623 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3249 | Steps: 4 | Val loss: 0.2694 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=50163)[0m rmse: 0.18008951842784882
[2m[36m(func pid=50163)[0m mae:  0.132363423705101
[2m[36m(func pid=50163)[0m rmse_per_class: [0.115, 0.262, 0.099, 0.338, 0.11, 0.19, 0.295, 0.14, 0.143, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4419 | Steps: 4 | Val loss: 0.3277 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 17:31:44 (running for 00:16:01.30)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.333 |  0.144 |                   70 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.294 |  0.141 |                   70 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.806 |  0.18  |                   11 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.466 |  0.176 |                   10 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14145907759666443
[2m[36m(func pid=36548)[0m mae:  0.0885111391544342
[2m[36m(func pid=36548)[0m rmse_per_class: [0.076, 0.209, 0.047, 0.262, 0.061, 0.155, 0.227, 0.11, 0.152, 0.115]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.14603978395462036
[2m[36m(func pid=35640)[0m mae:  0.10170439630746841
[2m[36m(func pid=35640)[0m rmse_per_class: [0.081, 0.221, 0.046, 0.294, 0.067, 0.154, 0.237, 0.11, 0.146, 0.103]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.17543469369411469
[2m[36m(func pid=50292)[0m mae:  0.12856541574001312
[2m[36m(func pid=50292)[0m rmse_per_class: [0.117, 0.257, 0.089, 0.333, 0.088, 0.189, 0.288, 0.14, 0.143, 0.111]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.7900 | Steps: 4 | Val loss: 0.6076 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2665 | Steps: 4 | Val loss: 0.2731 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3200 | Steps: 4 | Val loss: 0.2678 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=50163)[0m rmse: 0.1800871193408966
[2m[36m(func pid=50163)[0m mae:  0.1323537528514862
[2m[36m(func pid=50163)[0m rmse_per_class: [0.115, 0.262, 0.099, 0.337, 0.11, 0.19, 0.295, 0.14, 0.143, 0.11]
== Status ==
Current time: 2024-01-07 17:31:49 (running for 00:16:06.43)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.325 |  0.146 |                   71 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.294 |  0.141 |                   70 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.79  |  0.18  |                   12 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.442 |  0.175 |                   11 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.1485310047864914
[2m[36m(func pid=36548)[0m mae:  0.09291526675224304
[2m[36m(func pid=36548)[0m rmse_per_class: [0.07, 0.213, 0.049, 0.292, 0.065, 0.154, 0.225, 0.113, 0.159, 0.146]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4204 | Steps: 4 | Val loss: 0.3178 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=35640)[0m rmse: 0.14492641389369965
[2m[36m(func pid=35640)[0m mae:  0.10073915868997574
[2m[36m(func pid=35640)[0m rmse_per_class: [0.08, 0.22, 0.048, 0.287, 0.067, 0.154, 0.238, 0.11, 0.145, 0.099]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.17449131608009338
[2m[36m(func pid=50292)[0m mae:  0.1278158724308014
[2m[36m(func pid=50292)[0m rmse_per_class: [0.117, 0.256, 0.086, 0.332, 0.084, 0.188, 0.287, 0.14, 0.143, 0.112]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.7715 | Steps: 4 | Val loss: 0.5927 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2843 | Steps: 4 | Val loss: 0.2760 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3212 | Steps: 4 | Val loss: 0.2687 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 17:31:55 (running for 00:16:11.90)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.145 |                   72 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.284 |  0.15  |                   72 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.79  |  0.18  |                   12 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.42  |  0.174 |                   12 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.1498403251171112
[2m[36m(func pid=36548)[0m mae:  0.0934768095612526
[2m[36m(func pid=36548)[0m rmse_per_class: [0.065, 0.217, 0.051, 0.298, 0.07, 0.156, 0.225, 0.116, 0.157, 0.143]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50163)[0m rmse: 0.1799629032611847
[2m[36m(func pid=50163)[0m mae:  0.1322021186351776
[2m[36m(func pid=50163)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.109, 0.19, 0.295, 0.14, 0.143, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4131 | Steps: 4 | Val loss: 0.3140 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=35640)[0m rmse: 0.14556273818016052
[2m[36m(func pid=35640)[0m mae:  0.10108045488595963
[2m[36m(func pid=35640)[0m rmse_per_class: [0.078, 0.221, 0.048, 0.29, 0.068, 0.154, 0.238, 0.11, 0.145, 0.103]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.17365458607673645
[2m[36m(func pid=50292)[0m mae:  0.12708020210266113
[2m[36m(func pid=50292)[0m rmse_per_class: [0.116, 0.255, 0.085, 0.331, 0.082, 0.188, 0.285, 0.14, 0.143, 0.112]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2799 | Steps: 4 | Val loss: 0.2700 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7579 | Steps: 4 | Val loss: 0.5811 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3281 | Steps: 4 | Val loss: 0.2699 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 17:32:00 (running for 00:16:17.06)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.321 |  0.146 |                   73 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.28  |  0.147 |                   73 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.772 |  0.18  |                   13 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.413 |  0.174 |                   13 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14692234992980957
[2m[36m(func pid=36548)[0m mae:  0.09158363938331604
[2m[36m(func pid=36548)[0m rmse_per_class: [0.063, 0.211, 0.051, 0.283, 0.076, 0.157, 0.23, 0.119, 0.156, 0.123]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50163)[0m rmse: 0.18005558848381042
[2m[36m(func pid=50163)[0m mae:  0.13227607309818268
[2m[36m(func pid=50163)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.338, 0.11, 0.189, 0.295, 0.14, 0.143, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4074 | Steps: 4 | Val loss: 0.3139 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=35640)[0m rmse: 0.14684197306632996
[2m[36m(func pid=35640)[0m mae:  0.10197935253381729
[2m[36m(func pid=35640)[0m rmse_per_class: [0.081, 0.223, 0.054, 0.288, 0.069, 0.155, 0.238, 0.11, 0.145, 0.104]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.17287857830524445
[2m[36m(func pid=50292)[0m mae:  0.12646447122097015
[2m[36m(func pid=50292)[0m rmse_per_class: [0.116, 0.255, 0.084, 0.33, 0.079, 0.187, 0.284, 0.139, 0.142, 0.112]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2818 | Steps: 4 | Val loss: 0.2720 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.7407 | Steps: 4 | Val loss: 0.5669 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3262 | Steps: 4 | Val loss: 0.2684 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 17:32:05 (running for 00:16:22.32)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.328 |  0.147 |                   74 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.282 |  0.149 |                   74 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.758 |  0.18  |                   14 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.407 |  0.173 |                   14 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14880570769309998
[2m[36m(func pid=36548)[0m mae:  0.09295724332332611
[2m[36m(func pid=36548)[0m rmse_per_class: [0.067, 0.21, 0.048, 0.281, 0.09, 0.157, 0.241, 0.12, 0.159, 0.116]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50163)[0m rmse: 0.179809108376503
[2m[36m(func pid=50163)[0m mae:  0.13204611837863922
[2m[36m(func pid=50163)[0m rmse_per_class: [0.115, 0.26, 0.099, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4096 | Steps: 4 | Val loss: 0.3166 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=35640)[0m rmse: 0.14560188353061676
[2m[36m(func pid=35640)[0m mae:  0.10062851756811142
[2m[36m(func pid=35640)[0m rmse_per_class: [0.078, 0.222, 0.053, 0.288, 0.066, 0.155, 0.234, 0.111, 0.143, 0.107]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.17162835597991943
[2m[36m(func pid=50292)[0m mae:  0.12541794776916504
[2m[36m(func pid=50292)[0m rmse_per_class: [0.117, 0.254, 0.082, 0.328, 0.076, 0.186, 0.282, 0.138, 0.142, 0.11]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2855 | Steps: 4 | Val loss: 0.2733 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.7208 | Steps: 4 | Val loss: 0.5531 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.3308 | Steps: 4 | Val loss: 0.2667 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=36548)[0m rmse: 0.1489226371049881
[2m[36m(func pid=36548)[0m mae:  0.09350024163722992
[2m[36m(func pid=36548)[0m rmse_per_class: [0.084, 0.213, 0.051, 0.288, 0.086, 0.157, 0.239, 0.115, 0.151, 0.104]
== Status ==
Current time: 2024-01-07 17:32:10 (running for 00:16:27.43)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.326 |  0.146 |                   75 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.149 |                   75 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.741 |  0.18  |                   15 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.41  |  0.172 |                   15 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.4168 | Steps: 4 | Val loss: 0.3213 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=50163)[0m rmse: 0.1798020303249359
[2m[36m(func pid=50163)[0m mae:  0.1320735514163971
[2m[36m(func pid=50163)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.108, 0.189, 0.294, 0.141, 0.143, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.14462564885616302
[2m[36m(func pid=35640)[0m mae:  0.09983525425195694
[2m[36m(func pid=35640)[0m rmse_per_class: [0.078, 0.22, 0.051, 0.283, 0.065, 0.156, 0.235, 0.11, 0.14, 0.107]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.17071200907230377
[2m[36m(func pid=50292)[0m mae:  0.12463147938251495
[2m[36m(func pid=50292)[0m rmse_per_class: [0.116, 0.253, 0.08, 0.328, 0.074, 0.185, 0.28, 0.139, 0.142, 0.11]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2861 | Steps: 4 | Val loss: 0.2721 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.7050 | Steps: 4 | Val loss: 0.5393 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.3159 | Steps: 4 | Val loss: 0.2665 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 17:32:16 (running for 00:16:32.60)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.331 |  0.145 |                   76 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.149 |                   76 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.721 |  0.18  |                   16 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.417 |  0.171 |                   16 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.1490688920021057
[2m[36m(func pid=36548)[0m mae:  0.09325651824474335
[2m[36m(func pid=36548)[0m rmse_per_class: [0.096, 0.206, 0.059, 0.284, 0.071, 0.157, 0.233, 0.115, 0.162, 0.109]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4232 | Steps: 4 | Val loss: 0.3300 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=50163)[0m rmse: 0.17966005206108093
[2m[36m(func pid=50163)[0m mae:  0.13194000720977783
[2m[36m(func pid=50163)[0m rmse_per_class: [0.115, 0.261, 0.098, 0.337, 0.109, 0.189, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.14452247321605682
[2m[36m(func pid=35640)[0m mae:  0.09989231824874878
[2m[36m(func pid=35640)[0m rmse_per_class: [0.078, 0.219, 0.052, 0.282, 0.064, 0.156, 0.236, 0.11, 0.142, 0.105]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.16963092982769012
[2m[36m(func pid=50292)[0m mae:  0.12373880296945572
[2m[36m(func pid=50292)[0m rmse_per_class: [0.116, 0.253, 0.078, 0.327, 0.071, 0.185, 0.278, 0.138, 0.141, 0.11]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.3017 | Steps: 4 | Val loss: 0.2645 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.6882 | Steps: 4 | Val loss: 0.5257 | Batch size: 32 | lr: 0.0001 | Duration: 2.72s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.3315 | Steps: 4 | Val loss: 0.2678 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 17:32:21 (running for 00:16:37.89)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.316 |  0.145 |                   77 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.302 |  0.145 |                   77 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.705 |  0.18  |                   17 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.423 |  0.17  |                   17 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.1449151188135147
[2m[36m(func pid=36548)[0m mae:  0.09012008458375931
[2m[36m(func pid=36548)[0m rmse_per_class: [0.099, 0.207, 0.057, 0.255, 0.058, 0.156, 0.229, 0.114, 0.155, 0.119]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4287 | Steps: 4 | Val loss: 0.3371 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=50163)[0m rmse: 0.17957808077335358
[2m[36m(func pid=50163)[0m mae:  0.13186876475811005
[2m[36m(func pid=50163)[0m rmse_per_class: [0.116, 0.261, 0.098, 0.336, 0.108, 0.19, 0.294, 0.141, 0.143, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.14539562165737152
[2m[36m(func pid=35640)[0m mae:  0.10078148543834686
[2m[36m(func pid=35640)[0m rmse_per_class: [0.081, 0.218, 0.053, 0.284, 0.064, 0.157, 0.238, 0.11, 0.144, 0.106]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.16868045926094055
[2m[36m(func pid=50292)[0m mae:  0.1229264959692955
[2m[36m(func pid=50292)[0m rmse_per_class: [0.115, 0.252, 0.078, 0.325, 0.068, 0.184, 0.276, 0.137, 0.141, 0.11]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2797 | Steps: 4 | Val loss: 0.2633 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.6750 | Steps: 4 | Val loss: 0.5121 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.3257 | Steps: 4 | Val loss: 0.2661 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 17:32:26 (running for 00:16:43.17)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.331 |  0.145 |                   78 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.28  |  0.144 |                   78 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.688 |  0.18  |                   18 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.429 |  0.169 |                   18 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14357590675354004
[2m[36m(func pid=36548)[0m mae:  0.08832255750894547
[2m[36m(func pid=36548)[0m rmse_per_class: [0.071, 0.213, 0.079, 0.249, 0.052, 0.154, 0.226, 0.113, 0.149, 0.13]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.4346 | Steps: 4 | Val loss: 0.3455 | Batch size: 32 | lr: 0.001 | Duration: 2.69s
[2m[36m(func pid=50163)[0m rmse: 0.1793815791606903
[2m[36m(func pid=50163)[0m mae:  0.1317320466041565
[2m[36m(func pid=50163)[0m rmse_per_class: [0.116, 0.261, 0.097, 0.336, 0.107, 0.189, 0.294, 0.141, 0.143, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.14417867362499237
[2m[36m(func pid=35640)[0m mae:  0.09983360022306442
[2m[36m(func pid=35640)[0m rmse_per_class: [0.081, 0.217, 0.05, 0.281, 0.066, 0.156, 0.238, 0.11, 0.141, 0.102]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.16794265806674957
[2m[36m(func pid=50292)[0m mae:  0.12232919037342072
[2m[36m(func pid=50292)[0m rmse_per_class: [0.116, 0.252, 0.076, 0.324, 0.066, 0.183, 0.275, 0.137, 0.141, 0.109]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2791 | Steps: 4 | Val loss: 0.2622 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.6587 | Steps: 4 | Val loss: 0.4996 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.3076 | Steps: 4 | Val loss: 0.2641 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=36548)[0m rmse: 0.14188960194587708
[2m[36m(func pid=36548)[0m mae:  0.08719515800476074
[2m[36m(func pid=36548)[0m rmse_per_class: [0.062, 0.216, 0.084, 0.252, 0.053, 0.153, 0.225, 0.111, 0.143, 0.12]
== Status ==
Current time: 2024-01-07 17:32:31 (running for 00:16:48.36)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.326 |  0.144 |                   79 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.279 |  0.142 |                   79 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.675 |  0.179 |                   19 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.435 |  0.168 |                   19 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4373 | Steps: 4 | Val loss: 0.3497 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=35640)[0m rmse: 0.14237789809703827
[2m[36m(func pid=35640)[0m mae:  0.09824538230895996
[2m[36m(func pid=35640)[0m rmse_per_class: [0.078, 0.216, 0.047, 0.278, 0.064, 0.154, 0.235, 0.11, 0.143, 0.097]
[2m[36m(func pid=50163)[0m rmse: 0.1793355643749237
[2m[36m(func pid=50163)[0m mae:  0.13174128532409668
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.261, 0.096, 0.337, 0.107, 0.189, 0.294, 0.141, 0.143, 0.108]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2797 | Steps: 4 | Val loss: 0.2687 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=50292)[0m rmse: 0.16713052988052368
[2m[36m(func pid=50292)[0m mae:  0.12170817703008652
[2m[36m(func pid=50292)[0m rmse_per_class: [0.114, 0.251, 0.074, 0.323, 0.065, 0.183, 0.272, 0.136, 0.143, 0.11]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.3256 | Steps: 4 | Val loss: 0.2650 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.6393 | Steps: 4 | Val loss: 0.4873 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 17:32:37 (running for 00:16:53.47)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.308 |  0.142 |                   80 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.28  |  0.148 |                   80 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.659 |  0.179 |                   20 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.437 |  0.167 |                   20 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14760534465312958
[2m[36m(func pid=36548)[0m mae:  0.09115885943174362
[2m[36m(func pid=36548)[0m rmse_per_class: [0.063, 0.215, 0.093, 0.261, 0.056, 0.156, 0.228, 0.115, 0.16, 0.128]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4495 | Steps: 4 | Val loss: 0.3584 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=35640)[0m rmse: 0.14308759570121765
[2m[36m(func pid=35640)[0m mae:  0.09881842881441116
[2m[36m(func pid=35640)[0m rmse_per_class: [0.078, 0.217, 0.046, 0.282, 0.064, 0.156, 0.233, 0.11, 0.145, 0.1]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50163)[0m rmse: 0.17907771468162537
[2m[36m(func pid=50163)[0m mae:  0.13147172331809998
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.261, 0.095, 0.336, 0.108, 0.189, 0.294, 0.141, 0.143, 0.108]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2832 | Steps: 4 | Val loss: 0.2796 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=50292)[0m rmse: 0.16598935425281525
[2m[36m(func pid=50292)[0m mae:  0.12072595208883286
[2m[36m(func pid=50292)[0m rmse_per_class: [0.113, 0.248, 0.073, 0.323, 0.063, 0.182, 0.271, 0.135, 0.143, 0.109]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.3151 | Steps: 4 | Val loss: 0.2638 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.6264 | Steps: 4 | Val loss: 0.4740 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 17:32:42 (running for 00:16:58.65)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.326 |  0.143 |                   81 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.283 |  0.152 |                   81 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.639 |  0.179 |                   21 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.45  |  0.166 |                   21 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.1519594043493271
[2m[36m(func pid=36548)[0m mae:  0.09524174779653549
[2m[36m(func pid=36548)[0m rmse_per_class: [0.063, 0.212, 0.074, 0.302, 0.06, 0.159, 0.23, 0.128, 0.168, 0.124]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4516 | Steps: 4 | Val loss: 0.3640 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=50163)[0m rmse: 0.1789291352033615
[2m[36m(func pid=50163)[0m mae:  0.13139525055885315
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.26, 0.095, 0.336, 0.106, 0.189, 0.293, 0.14, 0.144, 0.109]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.1421554982662201
[2m[36m(func pid=35640)[0m mae:  0.09804384410381317
[2m[36m(func pid=35640)[0m rmse_per_class: [0.077, 0.218, 0.046, 0.28, 0.065, 0.154, 0.232, 0.11, 0.144, 0.096]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2916 | Steps: 4 | Val loss: 0.2871 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=50292)[0m rmse: 0.1652517467737198
[2m[36m(func pid=50292)[0m mae:  0.12005998939275742
[2m[36m(func pid=50292)[0m rmse_per_class: [0.112, 0.248, 0.071, 0.322, 0.062, 0.182, 0.269, 0.134, 0.143, 0.11]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.3244 | Steps: 4 | Val loss: 0.2650 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.6085 | Steps: 4 | Val loss: 0.4600 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 17:32:47 (running for 00:17:03.82)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.315 |  0.142 |                   82 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.292 |  0.155 |                   82 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.626 |  0.179 |                   22 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.452 |  0.165 |                   22 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.15541908144950867
[2m[36m(func pid=36548)[0m mae:  0.0976790338754654
[2m[36m(func pid=36548)[0m rmse_per_class: [0.061, 0.213, 0.069, 0.314, 0.06, 0.159, 0.231, 0.136, 0.193, 0.118]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4583 | Steps: 4 | Val loss: 0.3707 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=35640)[0m rmse: 0.14301949739456177
[2m[36m(func pid=35640)[0m mae:  0.09864626824855804
[2m[36m(func pid=35640)[0m rmse_per_class: [0.077, 0.218, 0.045, 0.282, 0.065, 0.153, 0.234, 0.109, 0.144, 0.101]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50163)[0m rmse: 0.17877845466136932
[2m[36m(func pid=50163)[0m mae:  0.1312330961227417
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.26, 0.095, 0.336, 0.106, 0.189, 0.293, 0.141, 0.143, 0.108]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2769 | Steps: 4 | Val loss: 0.2839 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=50292)[0m rmse: 0.16381940245628357
[2m[36m(func pid=50292)[0m mae:  0.11881394684314728
[2m[36m(func pid=50292)[0m rmse_per_class: [0.112, 0.245, 0.069, 0.319, 0.061, 0.181, 0.268, 0.133, 0.142, 0.109]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.3376 | Steps: 4 | Val loss: 0.2663 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.5930 | Steps: 4 | Val loss: 0.4498 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 17:32:52 (running for 00:17:08.97)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.324 |  0.143 |                   83 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.277 |  0.155 |                   83 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.609 |  0.179 |                   23 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.458 |  0.164 |                   23 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.1547613888978958
[2m[36m(func pid=36548)[0m mae:  0.09672104567289352
[2m[36m(func pid=36548)[0m rmse_per_class: [0.067, 0.212, 0.077, 0.311, 0.07, 0.159, 0.234, 0.126, 0.18, 0.113]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4777 | Steps: 4 | Val loss: 0.3731 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=35640)[0m rmse: 0.14418023824691772
[2m[36m(func pid=35640)[0m mae:  0.09941952675580978
[2m[36m(func pid=35640)[0m rmse_per_class: [0.077, 0.223, 0.043, 0.285, 0.065, 0.153, 0.234, 0.111, 0.145, 0.106]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50163)[0m rmse: 0.17889054119586945
[2m[36m(func pid=50163)[0m mae:  0.1313573122024536
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.26, 0.095, 0.337, 0.105, 0.189, 0.293, 0.141, 0.143, 0.109]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2679 | Steps: 4 | Val loss: 0.2780 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=50292)[0m rmse: 0.1627344936132431
[2m[36m(func pid=50292)[0m mae:  0.11784946918487549
[2m[36m(func pid=50292)[0m rmse_per_class: [0.11, 0.242, 0.067, 0.319, 0.06, 0.18, 0.266, 0.132, 0.142, 0.11]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.5805 | Steps: 4 | Val loss: 0.4389 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.3113 | Steps: 4 | Val loss: 0.2653 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=36548)[0m rmse: 0.15168166160583496
[2m[36m(func pid=36548)[0m mae:  0.09447994828224182
[2m[36m(func pid=36548)[0m rmse_per_class: [0.07, 0.215, 0.075, 0.295, 0.072, 0.16, 0.234, 0.116, 0.169, 0.112]
[2m[36m(func pid=36548)[0m 
== Status ==
Current time: 2024-01-07 17:32:57 (running for 00:17:14.15)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.338 |  0.144 |                   84 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.268 |  0.152 |                   84 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.593 |  0.179 |                   24 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.478 |  0.163 |                   24 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4867 | Steps: 4 | Val loss: 0.3797 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=50163)[0m rmse: 0.17869995534420013
[2m[36m(func pid=50163)[0m mae:  0.1312020868062973
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.26, 0.094, 0.336, 0.104, 0.189, 0.293, 0.141, 0.143, 0.109]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.1433211863040924
[2m[36m(func pid=35640)[0m mae:  0.09878348559141159
[2m[36m(func pid=35640)[0m rmse_per_class: [0.075, 0.221, 0.042, 0.283, 0.065, 0.153, 0.235, 0.11, 0.144, 0.105]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2793 | Steps: 4 | Val loss: 0.2711 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=50292)[0m rmse: 0.16110870242118835
[2m[36m(func pid=50292)[0m mae:  0.11640094220638275
[2m[36m(func pid=50292)[0m rmse_per_class: [0.109, 0.241, 0.064, 0.317, 0.058, 0.179, 0.263, 0.131, 0.141, 0.108]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.5684 | Steps: 4 | Val loss: 0.4289 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.3284 | Steps: 4 | Val loss: 0.2640 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 17:33:02 (running for 00:17:19.40)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.311 |  0.143 |                   85 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.279 |  0.149 |                   85 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.581 |  0.179 |                   25 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.487 |  0.161 |                   25 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.1488211750984192
[2m[36m(func pid=36548)[0m mae:  0.09205976873636246
[2m[36m(func pid=36548)[0m rmse_per_class: [0.076, 0.211, 0.066, 0.278, 0.078, 0.158, 0.224, 0.113, 0.166, 0.119]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4904 | Steps: 4 | Val loss: 0.3830 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=50163)[0m rmse: 0.17830070853233337
[2m[36m(func pid=50163)[0m mae:  0.13086022436618805
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.259, 0.094, 0.335, 0.103, 0.189, 0.292, 0.141, 0.143, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.1425013393163681
[2m[36m(func pid=35640)[0m mae:  0.09803377091884613
[2m[36m(func pid=35640)[0m rmse_per_class: [0.074, 0.218, 0.042, 0.28, 0.065, 0.153, 0.237, 0.109, 0.14, 0.106]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2756 | Steps: 4 | Val loss: 0.2698 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=50292)[0m rmse: 0.1602211743593216
[2m[36m(func pid=50292)[0m mae:  0.11558444797992706
[2m[36m(func pid=50292)[0m rmse_per_class: [0.109, 0.239, 0.062, 0.317, 0.057, 0.179, 0.26, 0.13, 0.141, 0.108]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.5540 | Steps: 4 | Val loss: 0.4206 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.3173 | Steps: 4 | Val loss: 0.2659 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=36548)[0m rmse: 0.1487664133310318
[2m[36m(func pid=36548)[0m mae:  0.0911003053188324
[2m[36m(func pid=36548)[0m rmse_per_class: [0.071, 0.217, 0.066, 0.269, 0.085, 0.157, 0.222, 0.112, 0.153, 0.135]
== Status ==
Current time: 2024-01-07 17:33:08 (running for 00:17:24.61)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.328 |  0.143 |                   86 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.276 |  0.149 |                   86 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.568 |  0.178 |                   26 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.49  |  0.16  |                   26 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4908 | Steps: 4 | Val loss: 0.3855 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=50163)[0m rmse: 0.17827321588993073
[2m[36m(func pid=50163)[0m mae:  0.13082896173000336
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.259, 0.094, 0.335, 0.102, 0.19, 0.292, 0.14, 0.143, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.14391657710075378
[2m[36m(func pid=35640)[0m mae:  0.0993705540895462
[2m[36m(func pid=35640)[0m rmse_per_class: [0.075, 0.219, 0.042, 0.285, 0.068, 0.154, 0.238, 0.11, 0.144, 0.105]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2646 | Steps: 4 | Val loss: 0.2667 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=50292)[0m rmse: 0.15890935063362122
[2m[36m(func pid=50292)[0m mae:  0.11442248523235321
[2m[36m(func pid=50292)[0m rmse_per_class: [0.107, 0.236, 0.06, 0.316, 0.057, 0.178, 0.259, 0.129, 0.14, 0.107]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.5353 | Steps: 4 | Val loss: 0.4108 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 17:33:13 (running for 00:17:29.77)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.317 |  0.144 |                   87 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.265 |  0.146 |                   87 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.554 |  0.178 |                   27 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.491 |  0.159 |                   27 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.3151 | Steps: 4 | Val loss: 0.2664 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=36548)[0m rmse: 0.14594510197639465
[2m[36m(func pid=36548)[0m mae:  0.09002262353897095
[2m[36m(func pid=36548)[0m rmse_per_class: [0.064, 0.217, 0.054, 0.26, 0.081, 0.157, 0.226, 0.115, 0.16, 0.126]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4938 | Steps: 4 | Val loss: 0.3855 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=50163)[0m rmse: 0.1779610961675644
[2m[36m(func pid=50163)[0m mae:  0.1305321604013443
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.258, 0.093, 0.335, 0.102, 0.19, 0.292, 0.14, 0.143, 0.109]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.14417091012001038
[2m[36m(func pid=35640)[0m mae:  0.09937512129545212
[2m[36m(func pid=35640)[0m rmse_per_class: [0.077, 0.22, 0.043, 0.288, 0.065, 0.153, 0.236, 0.109, 0.145, 0.106]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2583 | Steps: 4 | Val loss: 0.2720 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=50292)[0m rmse: 0.15796324610710144
[2m[36m(func pid=50292)[0m mae:  0.113444484770298
[2m[36m(func pid=50292)[0m rmse_per_class: [0.105, 0.236, 0.058, 0.316, 0.056, 0.176, 0.256, 0.128, 0.14, 0.107]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.3148 | Steps: 4 | Val loss: 0.2654 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.5321 | Steps: 4 | Val loss: 0.4030 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=36548)[0m rmse: 0.14921529591083527
[2m[36m(func pid=36548)[0m mae:  0.09280404448509216
[2m[36m(func pid=36548)[0m rmse_per_class: [0.062, 0.215, 0.055, 0.267, 0.072, 0.157, 0.23, 0.118, 0.194, 0.122]
== Status ==
Current time: 2024-01-07 17:33:18 (running for 00:17:35.09)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.315 |  0.144 |                   88 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.258 |  0.149 |                   88 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.535 |  0.178 |                   28 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.494 |  0.158 |                   28 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4983 | Steps: 4 | Val loss: 0.3843 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=35640)[0m rmse: 0.1433739960193634
[2m[36m(func pid=35640)[0m mae:  0.09868619590997696
[2m[36m(func pid=35640)[0m rmse_per_class: [0.075, 0.216, 0.044, 0.286, 0.064, 0.154, 0.236, 0.11, 0.143, 0.105]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50163)[0m rmse: 0.17780156433582306
[2m[36m(func pid=50163)[0m mae:  0.13043752312660217
[2m[36m(func pid=50163)[0m rmse_per_class: [0.116, 0.258, 0.093, 0.336, 0.101, 0.19, 0.292, 0.14, 0.144, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.3010 | Steps: 4 | Val loss: 0.2756 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=50292)[0m rmse: 0.15697821974754333
[2m[36m(func pid=50292)[0m mae:  0.11249730736017227
[2m[36m(func pid=50292)[0m rmse_per_class: [0.104, 0.234, 0.057, 0.315, 0.056, 0.175, 0.255, 0.127, 0.14, 0.107]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.3098 | Steps: 4 | Val loss: 0.2654 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.5168 | Steps: 4 | Val loss: 0.3933 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 17:33:23 (running for 00:17:40.43)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.315 |  0.143 |                   89 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.301 |  0.151 |                   89 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.532 |  0.178 |                   29 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.498 |  0.157 |                   29 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.1507042944431305
[2m[36m(func pid=36548)[0m mae:  0.09372805058956146
[2m[36m(func pid=36548)[0m rmse_per_class: [0.068, 0.212, 0.052, 0.282, 0.064, 0.157, 0.227, 0.124, 0.193, 0.126]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4983 | Steps: 4 | Val loss: 0.3836 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=35640)[0m rmse: 0.14334514737129211
[2m[36m(func pid=35640)[0m mae:  0.09850643575191498
[2m[36m(func pid=35640)[0m rmse_per_class: [0.077, 0.216, 0.044, 0.286, 0.065, 0.154, 0.235, 0.109, 0.142, 0.105]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50163)[0m rmse: 0.17746947705745697
[2m[36m(func pid=50163)[0m mae:  0.13018009066581726
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.258, 0.091, 0.335, 0.101, 0.189, 0.291, 0.14, 0.143, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2631 | Steps: 4 | Val loss: 0.2743 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=50292)[0m rmse: 0.15603139996528625
[2m[36m(func pid=50292)[0m mae:  0.11147032678127289
[2m[36m(func pid=50292)[0m rmse_per_class: [0.103, 0.233, 0.055, 0.315, 0.055, 0.175, 0.253, 0.127, 0.14, 0.104]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.3357 | Steps: 4 | Val loss: 0.2638 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 17:33:29 (running for 00:17:45.46)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.31  |  0.143 |                   90 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.263 |  0.148 |                   90 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.517 |  0.177 |                   30 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.498 |  0.156 |                   30 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14758668839931488
[2m[36m(func pid=36548)[0m mae:  0.09233713895082474
[2m[36m(func pid=36548)[0m rmse_per_class: [0.082, 0.219, 0.052, 0.289, 0.067, 0.156, 0.233, 0.121, 0.158, 0.1]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.5087 | Steps: 4 | Val loss: 0.3859 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4984 | Steps: 4 | Val loss: 0.3813 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=35640)[0m rmse: 0.14225532114505768
[2m[36m(func pid=35640)[0m mae:  0.09768171608448029
[2m[36m(func pid=35640)[0m rmse_per_class: [0.075, 0.214, 0.044, 0.28, 0.064, 0.155, 0.234, 0.109, 0.143, 0.105]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50163)[0m rmse: 0.17742577195167542
[2m[36m(func pid=50163)[0m mae:  0.13010989129543304
[2m[36m(func pid=50163)[0m rmse_per_class: [0.116, 0.257, 0.091, 0.336, 0.101, 0.189, 0.291, 0.14, 0.143, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2586 | Steps: 4 | Val loss: 0.2776 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=50292)[0m rmse: 0.15489749610424042
[2m[36m(func pid=50292)[0m mae:  0.11043170839548111
[2m[36m(func pid=50292)[0m rmse_per_class: [0.102, 0.232, 0.054, 0.314, 0.055, 0.174, 0.251, 0.126, 0.139, 0.103]
[2m[36m(func pid=50292)[0m 
== Status ==
Current time: 2024-01-07 17:33:34 (running for 00:17:50.58)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.336 |  0.142 |                   91 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.259 |  0.148 |                   91 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.509 |  0.177 |                   31 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.498 |  0.155 |                   31 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.148121640086174
[2m[36m(func pid=36548)[0m mae:  0.09273675829172134
[2m[36m(func pid=36548)[0m rmse_per_class: [0.072, 0.231, 0.063, 0.295, 0.073, 0.156, 0.235, 0.118, 0.15, 0.088]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.3285 | Steps: 4 | Val loss: 0.2635 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.5031 | Steps: 4 | Val loss: 0.3785 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.5052 | Steps: 4 | Val loss: 0.3792 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=35640)[0m rmse: 0.14181973040103912
[2m[36m(func pid=35640)[0m mae:  0.09756697714328766
[2m[36m(func pid=35640)[0m rmse_per_class: [0.073, 0.217, 0.043, 0.284, 0.065, 0.154, 0.232, 0.109, 0.142, 0.099]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50163)[0m rmse: 0.1773822009563446
[2m[36m(func pid=50163)[0m mae:  0.13008691370487213
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.256, 0.091, 0.336, 0.099, 0.189, 0.292, 0.14, 0.143, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2783 | Steps: 4 | Val loss: 0.2754 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=50292)[0m rmse: 0.153631329536438
[2m[36m(func pid=50292)[0m mae:  0.10923752933740616
[2m[36m(func pid=50292)[0m rmse_per_class: [0.101, 0.231, 0.052, 0.313, 0.055, 0.172, 0.248, 0.126, 0.139, 0.101]
[2m[36m(func pid=50292)[0m 
== Status ==
Current time: 2024-01-07 17:33:39 (running for 00:17:56.12)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.329 |  0.142 |                   92 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.278 |  0.149 |                   92 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.503 |  0.177 |                   32 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.505 |  0.154 |                   32 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.1493048369884491
[2m[36m(func pid=36548)[0m mae:  0.0923071950674057
[2m[36m(func pid=36548)[0m rmse_per_class: [0.075, 0.219, 0.079, 0.293, 0.075, 0.158, 0.233, 0.114, 0.143, 0.105]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.3149 | Steps: 4 | Val loss: 0.2633 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4932 | Steps: 4 | Val loss: 0.3727 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4847 | Steps: 4 | Val loss: 0.3794 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=35640)[0m rmse: 0.14163653552532196
[2m[36m(func pid=35640)[0m mae:  0.09710970520973206
[2m[36m(func pid=35640)[0m rmse_per_class: [0.073, 0.217, 0.044, 0.282, 0.061, 0.154, 0.23, 0.111, 0.144, 0.101]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50163)[0m rmse: 0.17773613333702087
[2m[36m(func pid=50163)[0m mae:  0.1303873211145401
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.258, 0.092, 0.336, 0.1, 0.189, 0.292, 0.14, 0.143, 0.111]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2834 | Steps: 4 | Val loss: 0.2783 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=50292)[0m rmse: 0.15269553661346436
[2m[36m(func pid=50292)[0m mae:  0.10830321162939072
[2m[36m(func pid=50292)[0m rmse_per_class: [0.099, 0.229, 0.05, 0.311, 0.055, 0.172, 0.246, 0.126, 0.139, 0.101]
[2m[36m(func pid=50292)[0m 
== Status ==
Current time: 2024-01-07 17:33:44 (running for 00:18:01.36)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.315 |  0.142 |                   93 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.283 |  0.154 |                   93 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.493 |  0.178 |                   33 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.485 |  0.153 |                   33 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.1544182449579239
[2m[36m(func pid=36548)[0m mae:  0.09480882436037064
[2m[36m(func pid=36548)[0m rmse_per_class: [0.072, 0.219, 0.081, 0.285, 0.078, 0.162, 0.23, 0.113, 0.147, 0.159]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.3293 | Steps: 4 | Val loss: 0.2631 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4809 | Steps: 4 | Val loss: 0.3663 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4929 | Steps: 4 | Val loss: 0.3765 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=35640)[0m rmse: 0.1417260468006134
[2m[36m(func pid=35640)[0m mae:  0.09703297913074493
[2m[36m(func pid=35640)[0m rmse_per_class: [0.074, 0.216, 0.047, 0.278, 0.062, 0.156, 0.231, 0.11, 0.143, 0.1]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50163)[0m rmse: 0.17711493372917175
[2m[36m(func pid=50163)[0m mae:  0.1298082172870636
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.258, 0.09, 0.334, 0.1, 0.189, 0.291, 0.14, 0.143, 0.109]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2845 | Steps: 4 | Val loss: 0.2766 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=50292)[0m rmse: 0.1514798104763031
[2m[36m(func pid=50292)[0m mae:  0.10705731064081192
[2m[36m(func pid=50292)[0m rmse_per_class: [0.098, 0.227, 0.048, 0.308, 0.055, 0.171, 0.245, 0.126, 0.137, 0.099]
[2m[36m(func pid=50292)[0m 
== Status ==
Current time: 2024-01-07 17:33:50 (running for 00:18:06.77)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.329 |  0.142 |                   94 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.284 |  0.153 |                   94 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.481 |  0.177 |                   34 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.493 |  0.151 |                   34 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.3382 | Steps: 4 | Val loss: 0.2649 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=36548)[0m rmse: 0.15336275100708008
[2m[36m(func pid=36548)[0m mae:  0.09430623799562454
[2m[36m(func pid=36548)[0m rmse_per_class: [0.065, 0.227, 0.072, 0.281, 0.089, 0.163, 0.228, 0.115, 0.146, 0.149]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4756 | Steps: 4 | Val loss: 0.3604 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4806 | Steps: 4 | Val loss: 0.3726 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=35640)[0m rmse: 0.14300066232681274
[2m[36m(func pid=35640)[0m mae:  0.09826917946338654
[2m[36m(func pid=35640)[0m rmse_per_class: [0.072, 0.219, 0.048, 0.286, 0.065, 0.155, 0.231, 0.111, 0.145, 0.098]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50163)[0m rmse: 0.17692165076732635
[2m[36m(func pid=50163)[0m mae:  0.12970806658267975
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.258, 0.09, 0.334, 0.098, 0.189, 0.291, 0.14, 0.143, 0.109]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2779 | Steps: 4 | Val loss: 0.2725 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=50292)[0m rmse: 0.1507236659526825
[2m[36m(func pid=50292)[0m mae:  0.10610433667898178
[2m[36m(func pid=50292)[0m rmse_per_class: [0.097, 0.226, 0.047, 0.308, 0.055, 0.17, 0.244, 0.125, 0.137, 0.099]
[2m[36m(func pid=50292)[0m 
== Status ==
Current time: 2024-01-07 17:33:55 (running for 00:18:11.82)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.338 |  0.143 |                   95 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.278 |  0.15  |                   95 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.476 |  0.177 |                   35 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.481 |  0.151 |                   35 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.15026721358299255
[2m[36m(func pid=36548)[0m mae:  0.09189911186695099
[2m[36m(func pid=36548)[0m rmse_per_class: [0.067, 0.225, 0.073, 0.272, 0.083, 0.158, 0.226, 0.119, 0.153, 0.126]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.3141 | Steps: 4 | Val loss: 0.2638 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4736 | Steps: 4 | Val loss: 0.3558 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4868 | Steps: 4 | Val loss: 0.3676 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=50163)[0m rmse: 0.17675915360450745
[2m[36m(func pid=50163)[0m mae:  0.12961344420909882
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.258, 0.089, 0.335, 0.097, 0.189, 0.29, 0.14, 0.143, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.14215943217277527
[2m[36m(func pid=35640)[0m mae:  0.09737774729728699
[2m[36m(func pid=35640)[0m rmse_per_class: [0.073, 0.217, 0.049, 0.284, 0.064, 0.154, 0.231, 0.111, 0.142, 0.097]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2757 | Steps: 4 | Val loss: 0.2711 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=50292)[0m rmse: 0.15000838041305542
[2m[36m(func pid=50292)[0m mae:  0.1052367314696312
[2m[36m(func pid=50292)[0m rmse_per_class: [0.095, 0.226, 0.046, 0.308, 0.055, 0.17, 0.24, 0.124, 0.137, 0.1]
[2m[36m(func pid=50292)[0m 
== Status ==
Current time: 2024-01-07 17:34:00 (running for 00:18:16.98)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.314 |  0.142 |                   96 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.278 |  0.15  |                   95 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.474 |  0.177 |                   36 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.487 |  0.15  |                   36 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14882513880729675
[2m[36m(func pid=36548)[0m mae:  0.09196944534778595
[2m[36m(func pid=36548)[0m rmse_per_class: [0.072, 0.215, 0.056, 0.263, 0.071, 0.158, 0.228, 0.122, 0.191, 0.112]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.3181 | Steps: 4 | Val loss: 0.2659 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4670 | Steps: 4 | Val loss: 0.3515 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=35640)[0m rmse: 0.14383871853351593
[2m[36m(func pid=35640)[0m mae:  0.09836812317371368
[2m[36m(func pid=35640)[0m rmse_per_class: [0.076, 0.219, 0.054, 0.289, 0.063, 0.154, 0.232, 0.11, 0.144, 0.098]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50163)[0m rmse: 0.17658290266990662
[2m[36m(func pid=50163)[0m mae:  0.12948165833950043
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.258, 0.089, 0.335, 0.096, 0.188, 0.29, 0.14, 0.143, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2662 | Steps: 4 | Val loss: 0.2790 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4760 | Steps: 4 | Val loss: 0.3629 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 17:34:05 (running for 00:18:22.37)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.318 |  0.144 |                   97 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.266 |  0.152 |                   97 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.467 |  0.177 |                   37 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.487 |  0.15  |                   36 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.15249894559383392
[2m[36m(func pid=36548)[0m mae:  0.09488071501255035
[2m[36m(func pid=36548)[0m rmse_per_class: [0.082, 0.21, 0.047, 0.282, 0.065, 0.162, 0.23, 0.118, 0.211, 0.117]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.14917859435081482
[2m[36m(func pid=50292)[0m mae:  0.1043192595243454
[2m[36m(func pid=50292)[0m rmse_per_class: [0.094, 0.224, 0.045, 0.307, 0.054, 0.169, 0.239, 0.124, 0.136, 0.099]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.3207 | Steps: 4 | Val loss: 0.2660 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4577 | Steps: 4 | Val loss: 0.3462 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2752 | Steps: 4 | Val loss: 0.2755 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=50163)[0m rmse: 0.17644408345222473
[2m[36m(func pid=50163)[0m mae:  0.12936589121818542
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.258, 0.088, 0.335, 0.095, 0.188, 0.289, 0.14, 0.143, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.14419926702976227
[2m[36m(func pid=35640)[0m mae:  0.09857211261987686
[2m[36m(func pid=35640)[0m rmse_per_class: [0.078, 0.218, 0.055, 0.287, 0.062, 0.154, 0.234, 0.11, 0.145, 0.099]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4669 | Steps: 4 | Val loss: 0.3558 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 17:34:11 (running for 00:18:27.68)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.321 |  0.144 |                   98 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.275 |  0.149 |                   98 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.458 |  0.176 |                   38 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.476 |  0.149 |                   37 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14889997243881226
[2m[36m(func pid=36548)[0m mae:  0.09244788438081741
[2m[36m(func pid=36548)[0m rmse_per_class: [0.073, 0.206, 0.042, 0.278, 0.064, 0.162, 0.225, 0.116, 0.206, 0.117]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.14838579297065735
[2m[36m(func pid=50292)[0m mae:  0.10324788093566895
[2m[36m(func pid=50292)[0m rmse_per_class: [0.093, 0.225, 0.044, 0.304, 0.054, 0.169, 0.238, 0.124, 0.136, 0.097]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4550 | Steps: 4 | Val loss: 0.3423 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.3181 | Steps: 4 | Val loss: 0.2643 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=50163)[0m rmse: 0.17637720704078674
[2m[36m(func pid=50163)[0m mae:  0.12933097779750824
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.258, 0.089, 0.335, 0.094, 0.188, 0.289, 0.141, 0.143, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2636 | Steps: 4 | Val loss: 0.2650 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=35640)[0m rmse: 0.1427461951971054
[2m[36m(func pid=35640)[0m mae:  0.09751079976558685
[2m[36m(func pid=35640)[0m rmse_per_class: [0.072, 0.216, 0.05, 0.284, 0.064, 0.153, 0.232, 0.109, 0.146, 0.1]
[2m[36m(func pid=35640)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4706 | Steps: 4 | Val loss: 0.3502 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 17:34:16 (running for 00:18:33.09)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00006 | RUNNING    | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.318 |  0.143 |                   99 |
| train_01e98_00007 | RUNNING    | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.264 |  0.141 |                   99 |
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.455 |  0.176 |                   39 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.467 |  0.148 |                   38 |
| train_01e98_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=36548)[0m rmse: 0.14148733019828796
[2m[36m(func pid=36548)[0m mae:  0.08734200894832611
[2m[36m(func pid=36548)[0m rmse_per_class: [0.065, 0.208, 0.038, 0.26, 0.062, 0.159, 0.224, 0.115, 0.162, 0.121]
[2m[36m(func pid=36548)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4466 | Steps: 4 | Val loss: 0.3395 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=50292)[0m rmse: 0.14847415685653687
[2m[36m(func pid=50292)[0m mae:  0.10305683314800262
[2m[36m(func pid=50292)[0m rmse_per_class: [0.091, 0.225, 0.044, 0.309, 0.054, 0.168, 0.237, 0.123, 0.136, 0.098]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=35640)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.3201 | Steps: 4 | Val loss: 0.2639 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=50163)[0m rmse: 0.17614540457725525
[2m[36m(func pid=50163)[0m mae:  0.12908273935317993
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.257, 0.089, 0.334, 0.094, 0.188, 0.289, 0.14, 0.143, 0.11]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=35640)[0m rmse: 0.1423420011997223
[2m[36m(func pid=35640)[0m mae:  0.09706992655992508
[2m[36m(func pid=35640)[0m rmse_per_class: [0.073, 0.217, 0.049, 0.284, 0.064, 0.152, 0.232, 0.109, 0.143, 0.101]
[2m[36m(func pid=36548)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2857 | Steps: 4 | Val loss: 0.2614 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4628 | Steps: 4 | Val loss: 0.3409 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=36548)[0m rmse: 0.13866664469242096
[2m[36m(func pid=36548)[0m mae:  0.08510612696409225
[2m[36m(func pid=36548)[0m rmse_per_class: [0.064, 0.211, 0.044, 0.255, 0.06, 0.156, 0.224, 0.112, 0.141, 0.119]
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4436 | Steps: 4 | Val loss: 0.3366 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=50292)[0m rmse: 0.14830011129379272
[2m[36m(func pid=50292)[0m mae:  0.10285305976867676
[2m[36m(func pid=50292)[0m rmse_per_class: [0.09, 0.225, 0.044, 0.309, 0.054, 0.168, 0.236, 0.123, 0.136, 0.098]
[2m[36m(func pid=50163)[0m rmse: 0.1761152744293213
[2m[36m(func pid=50163)[0m mae:  0.12906013429164886
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.257, 0.09, 0.334, 0.093, 0.189, 0.288, 0.14, 0.143, 0.111]
== Status ==
Current time: 2024-01-07 17:34:21 (running for 00:18:38.32)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (13 PENDING, 3 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.447 |  0.176 |                   40 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.471 |  0.148 |                   39 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


== Status ==
Current time: 2024-01-07 17:34:27 (running for 00:18:44.32)
Memory usage on this node: 20.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (13 PENDING, 3 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.444 |  0.176 |                   41 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.471 |  0.148 |                   39 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60251)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=60251)[0m Configuration completed!
[2m[36m(func pid=60251)[0m New optimizer parameters:
[2m[36m(func pid=60251)[0m SGD (
[2m[36m(func pid=60251)[0m Parameter Group 0
[2m[36m(func pid=60251)[0m     dampening: 0
[2m[36m(func pid=60251)[0m     differentiable: False
[2m[36m(func pid=60251)[0m     foreach: None
[2m[36m(func pid=60251)[0m     lr: 0.01
[2m[36m(func pid=60251)[0m     maximize: False
[2m[36m(func pid=60251)[0m     momentum: 0.99
[2m[36m(func pid=60251)[0m     nesterov: False
[2m[36m(func pid=60251)[0m     weight_decay: 0.0001
[2m[36m(func pid=60251)[0m )
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4400 | Steps: 4 | Val loss: 0.3335 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4582 | Steps: 4 | Val loss: 0.3345 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8657 | Steps: 4 | Val loss: 0.6234 | Batch size: 32 | lr: 0.01 | Duration: 4.37s
[2m[36m(func pid=50163)[0m rmse: 0.17594337463378906
[2m[36m(func pid=50163)[0m mae:  0.1289801299571991
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.257, 0.089, 0.334, 0.092, 0.188, 0.289, 0.139, 0.143, 0.111]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.14765621721744537
[2m[36m(func pid=50292)[0m mae:  0.10175672918558121
[2m[36m(func pid=50292)[0m rmse_per_class: [0.09, 0.224, 0.044, 0.308, 0.055, 0.167, 0.235, 0.122, 0.135, 0.098]
[2m[36m(func pid=60251)[0m rmse: 0.18233561515808105
[2m[36m(func pid=60251)[0m mae:  0.13419906795024872
[2m[36m(func pid=60251)[0m rmse_per_class: [0.117, 0.267, 0.107, 0.34, 0.111, 0.19, 0.293, 0.143, 0.143, 0.112]
== Status ==
Current time: 2024-01-07 17:34:33 (running for 00:18:49.91)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.44  |  0.176 |                   42 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.463 |  0.148 |                   40 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4336 | Steps: 4 | Val loss: 0.3303 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=60747)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=60747)[0m Configuration completed!
[2m[36m(func pid=60747)[0m New optimizer parameters:
[2m[36m(func pid=60747)[0m SGD (
[2m[36m(func pid=60747)[0m Parameter Group 0
[2m[36m(func pid=60747)[0m     dampening: 0
[2m[36m(func pid=60747)[0m     differentiable: False
[2m[36m(func pid=60747)[0m     foreach: None
[2m[36m(func pid=60747)[0m     lr: 0.1
[2m[36m(func pid=60747)[0m     maximize: False
[2m[36m(func pid=60747)[0m     momentum: 0.99
[2m[36m(func pid=60747)[0m     nesterov: False
[2m[36m(func pid=60747)[0m     weight_decay: 0.0001
[2m[36m(func pid=60747)[0m )
[2m[36m(func pid=60747)[0m 
== Status ==
Current time: 2024-01-07 17:34:38 (running for 00:18:55.26)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.434 |  0.176 |                   43 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.458 |  0.148 |                   41 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.866 |  0.182 |                    1 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.17571976780891418
[2m[36m(func pid=50163)[0m mae:  0.12880679965019226
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.257, 0.088, 0.334, 0.091, 0.188, 0.289, 0.14, 0.143, 0.111]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4609 | Steps: 4 | Val loss: 0.3307 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.7030 | Steps: 4 | Val loss: 0.4682 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.6885 | Steps: 4 | Val loss: 0.3430 | Batch size: 32 | lr: 0.1 | Duration: 4.41s
[2m[36m(func pid=50292)[0m rmse: 0.1471339762210846
[2m[36m(func pid=50292)[0m mae:  0.10108200460672379
[2m[36m(func pid=50292)[0m rmse_per_class: [0.088, 0.223, 0.044, 0.308, 0.055, 0.167, 0.234, 0.123, 0.134, 0.097]
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4310 | Steps: 4 | Val loss: 0.3292 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.18092766404151917
[2m[36m(func pid=60251)[0m mae:  0.1331510841846466
[2m[36m(func pid=60251)[0m rmse_per_class: [0.118, 0.266, 0.104, 0.338, 0.105, 0.189, 0.293, 0.142, 0.142, 0.112]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m rmse: 0.18067124485969543
[2m[36m(func pid=60747)[0m mae:  0.13269072771072388
[2m[36m(func pid=60747)[0m rmse_per_class: [0.122, 0.269, 0.102, 0.338, 0.093, 0.191, 0.284, 0.15, 0.143, 0.115]
[2m[36m(func pid=60747)[0m 
== Status ==
Current time: 2024-01-07 17:34:44 (running for 00:19:00.52)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.176 |                   44 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.461 |  0.147 |                   42 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.703 |  0.181 |                    2 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.688 |  0.181 |                    1 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.1759507954120636
[2m[36m(func pid=50163)[0m mae:  0.12897954881191254
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.258, 0.089, 0.333, 0.091, 0.188, 0.289, 0.14, 0.143, 0.112]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4397 | Steps: 4 | Val loss: 0.3255 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.5198 | Steps: 4 | Val loss: 0.3504 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.4437 | Steps: 4 | Val loss: 0.3899 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4304 | Steps: 4 | Val loss: 0.3269 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=50292)[0m rmse: 0.1469772607088089
[2m[36m(func pid=50292)[0m mae:  0.10080462694168091
[2m[36m(func pid=50292)[0m rmse_per_class: [0.087, 0.223, 0.043, 0.308, 0.055, 0.167, 0.234, 0.123, 0.134, 0.096]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.17816972732543945
[2m[36m(func pid=60251)[0m mae:  0.13096509873867035
[2m[36m(func pid=60251)[0m rmse_per_class: [0.118, 0.264, 0.098, 0.332, 0.093, 0.189, 0.29, 0.14, 0.142, 0.114]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m rmse: 0.16883207857608795
[2m[36m(func pid=60747)[0m mae:  0.1208859533071518
[2m[36m(func pid=60747)[0m rmse_per_class: [0.11, 0.268, 0.063, 0.336, 0.064, 0.19, 0.249, 0.167, 0.139, 0.103]
[2m[36m(func pid=60747)[0m 
== Status ==
Current time: 2024-01-07 17:34:49 (running for 00:19:05.92)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.43  |  0.176 |                   45 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.44  |  0.147 |                   43 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.52  |  0.178 |                    3 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.444 |  0.169 |                    2 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.175682932138443
[2m[36m(func pid=50163)[0m mae:  0.12877382338047028
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.257, 0.088, 0.334, 0.09, 0.187, 0.288, 0.14, 0.144, 0.112]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4216 | Steps: 4 | Val loss: 0.3163 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4304 | Steps: 4 | Val loss: 0.3184 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.6009 | Steps: 4 | Val loss: 0.4986 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=60251)[0m rmse: 0.1750645935535431
[2m[36m(func pid=60251)[0m mae:  0.12846516072750092
[2m[36m(func pid=60251)[0m rmse_per_class: [0.12, 0.261, 0.09, 0.326, 0.082, 0.188, 0.288, 0.138, 0.141, 0.116]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4247 | Steps: 4 | Val loss: 0.3245 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=50292)[0m rmse: 0.1463456153869629
[2m[36m(func pid=50292)[0m mae:  0.1000329852104187
[2m[36m(func pid=50292)[0m rmse_per_class: [0.086, 0.222, 0.043, 0.305, 0.055, 0.168, 0.233, 0.123, 0.134, 0.095]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m rmse: 0.16736461222171783
[2m[36m(func pid=60747)[0m mae:  0.11238352209329605
[2m[36m(func pid=60747)[0m rmse_per_class: [0.091, 0.267, 0.046, 0.342, 0.054, 0.189, 0.273, 0.185, 0.137, 0.089]
[2m[36m(func pid=60747)[0m 
== Status ==
Current time: 2024-01-07 17:34:54 (running for 00:19:11.09)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.425 |  0.175 |                   46 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.43  |  0.146 |                   44 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.422 |  0.175 |                    4 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.601 |  0.167 |                    3 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.1753782033920288
[2m[36m(func pid=50163)[0m mae:  0.12853766977787018
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.258, 0.087, 0.333, 0.089, 0.187, 0.288, 0.14, 0.143, 0.112]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4179 | Steps: 4 | Val loss: 0.3389 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4284 | Steps: 4 | Val loss: 0.3108 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.7172 | Steps: 4 | Val loss: 0.5003 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4231 | Steps: 4 | Val loss: 0.3237 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=60251)[0m rmse: 0.1722142994403839
[2m[36m(func pid=60251)[0m mae:  0.12611104547977448
[2m[36m(func pid=60251)[0m rmse_per_class: [0.123, 0.258, 0.081, 0.322, 0.072, 0.186, 0.285, 0.137, 0.14, 0.118]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.14561805129051208
[2m[36m(func pid=50292)[0m mae:  0.09899736940860748
[2m[36m(func pid=50292)[0m rmse_per_class: [0.083, 0.221, 0.043, 0.307, 0.055, 0.164, 0.234, 0.122, 0.133, 0.094]
[2m[36m(func pid=50292)[0m 
== Status ==
Current time: 2024-01-07 17:34:59 (running for 00:19:16.39)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.425 |  0.175 |                   46 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.428 |  0.146 |                   45 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.418 |  0.172 |                    5 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.717 |  0.174 |                    4 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60747)[0m rmse: 0.17426657676696777
[2m[36m(func pid=60747)[0m mae:  0.10990887880325317
[2m[36m(func pid=60747)[0m rmse_per_class: [0.078, 0.253, 0.047, 0.34, 0.056, 0.192, 0.418, 0.138, 0.132, 0.087]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m rmse: 0.17534729838371277
[2m[36m(func pid=50163)[0m mae:  0.12849482893943787
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.258, 0.087, 0.333, 0.089, 0.187, 0.288, 0.139, 0.144, 0.112]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4604 | Steps: 4 | Val loss: 0.3776 | Batch size: 32 | lr: 0.01 | Duration: 3.18s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4003 | Steps: 4 | Val loss: 0.3034 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4177 | Steps: 4 | Val loss: 0.3219 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=60251)[0m rmse: 0.16797330975532532
[2m[36m(func pid=60251)[0m mae:  0.12235919386148453
[2m[36m(func pid=60251)[0m rmse_per_class: [0.123, 0.252, 0.07, 0.314, 0.064, 0.184, 0.279, 0.134, 0.138, 0.121]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7298 | Steps: 4 | Val loss: 0.3991 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=50292)[0m rmse: 0.1446487307548523
[2m[36m(func pid=50292)[0m mae:  0.09794119745492935
[2m[36m(func pid=50292)[0m rmse_per_class: [0.083, 0.222, 0.042, 0.303, 0.055, 0.162, 0.232, 0.122, 0.133, 0.093]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=50163)[0m rmse: 0.17512182891368866
[2m[36m(func pid=50163)[0m mae:  0.12831458449363708
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.257, 0.087, 0.333, 0.087, 0.187, 0.288, 0.139, 0.143, 0.113]
== Status ==
Current time: 2024-01-07 17:35:05 (running for 00:19:21.64)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.418 |  0.175 |                   48 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.4   |  0.145 |                   46 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.46  |  0.168 |                    6 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.717 |  0.174 |                    4 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=60747)[0m rmse: 0.17655347287654877
[2m[36m(func pid=60747)[0m mae:  0.10910260677337646
[2m[36m(func pid=60747)[0m rmse_per_class: [0.078, 0.237, 0.049, 0.327, 0.056, 0.185, 0.494, 0.116, 0.132, 0.092]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.5220 | Steps: 4 | Val loss: 0.4218 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3950 | Steps: 4 | Val loss: 0.2987 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4192 | Steps: 4 | Val loss: 0.3203 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=60251)[0m rmse: 0.16427941620349884
[2m[36m(func pid=60251)[0m mae:  0.11870045959949493
[2m[36m(func pid=60251)[0m rmse_per_class: [0.123, 0.247, 0.06, 0.311, 0.058, 0.182, 0.269, 0.13, 0.137, 0.125]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.1446916162967682
[2m[36m(func pid=50292)[0m mae:  0.09801657497882843
[2m[36m(func pid=50292)[0m rmse_per_class: [0.082, 0.221, 0.042, 0.305, 0.055, 0.162, 0.232, 0.122, 0.133, 0.093]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.5973 | Steps: 4 | Val loss: 0.2957 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
== Status ==
Current time: 2024-01-07 17:35:10 (running for 00:19:27.08)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.419 |  0.175 |                   49 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.395 |  0.145 |                   47 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.522 |  0.164 |                    7 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.73  |  0.177 |                    5 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.17495843768119812
[2m[36m(func pid=50163)[0m mae:  0.12818023562431335
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.256, 0.086, 0.333, 0.086, 0.187, 0.287, 0.14, 0.143, 0.113]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=60747)[0m rmse: 0.14879047870635986
[2m[36m(func pid=60747)[0m mae:  0.0886564776301384
[2m[36m(func pid=60747)[0m rmse_per_class: [0.074, 0.213, 0.049, 0.28, 0.056, 0.153, 0.334, 0.113, 0.128, 0.089]
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5687 | Steps: 4 | Val loss: 0.4520 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3940 | Steps: 4 | Val loss: 0.2935 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4122 | Steps: 4 | Val loss: 0.3189 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=60251)[0m rmse: 0.16130053997039795
[2m[36m(func pid=60251)[0m mae:  0.1155080795288086
[2m[36m(func pid=60251)[0m rmse_per_class: [0.122, 0.24, 0.053, 0.311, 0.056, 0.182, 0.258, 0.128, 0.136, 0.127]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.14507587254047394
[2m[36m(func pid=50292)[0m mae:  0.0985201746225357
[2m[36m(func pid=50292)[0m rmse_per_class: [0.082, 0.222, 0.041, 0.306, 0.055, 0.161, 0.232, 0.122, 0.134, 0.095]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.5196 | Steps: 4 | Val loss: 0.3412 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=50163)[0m rmse: 0.17461499571800232
[2m[36m(func pid=50163)[0m mae:  0.12792149186134338
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.257, 0.086, 0.332, 0.086, 0.187, 0.287, 0.14, 0.142, 0.112]
[2m[36m(func pid=50163)[0m 
== Status ==
Current time: 2024-01-07 17:35:16 (running for 00:19:32.52)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.412 |  0.175 |                   50 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.394 |  0.145 |                   48 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.569 |  0.161 |                    8 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.597 |  0.149 |                    6 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.6045 | Steps: 4 | Val loss: 0.4743 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=60747)[0m rmse: 0.13774700462818146
[2m[36m(func pid=60747)[0m mae:  0.08736498653888702
[2m[36m(func pid=60747)[0m rmse_per_class: [0.066, 0.226, 0.048, 0.253, 0.056, 0.165, 0.233, 0.113, 0.138, 0.08]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4010 | Steps: 4 | Val loss: 0.2882 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4153 | Steps: 4 | Val loss: 0.3175 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=60251)[0m rmse: 0.15775564312934875
[2m[36m(func pid=60251)[0m mae:  0.11162356287240982
[2m[36m(func pid=60251)[0m rmse_per_class: [0.118, 0.233, 0.049, 0.311, 0.055, 0.179, 0.247, 0.126, 0.135, 0.125]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.1439618468284607
[2m[36m(func pid=50292)[0m mae:  0.09712006896734238
[2m[36m(func pid=50292)[0m rmse_per_class: [0.081, 0.221, 0.041, 0.304, 0.055, 0.159, 0.232, 0.121, 0.133, 0.093]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5148 | Steps: 4 | Val loss: 0.4509 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=50163)[0m rmse: 0.17434698343276978
[2m[36m(func pid=50163)[0m mae:  0.1277303695678711
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.256, 0.084, 0.332, 0.086, 0.187, 0.286, 0.14, 0.142, 0.112]
== Status ==
Current time: 2024-01-07 17:35:21 (running for 00:19:37.81)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.415 |  0.174 |                   51 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.401 |  0.144 |                   49 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.605 |  0.158 |                    9 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.52  |  0.138 |                    7 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.6231 | Steps: 4 | Val loss: 0.4869 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3910 | Steps: 4 | Val loss: 0.2825 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=60747)[0m rmse: 0.16167308390140533
[2m[36m(func pid=60747)[0m mae:  0.1073688268661499
[2m[36m(func pid=60747)[0m rmse_per_class: [0.099, 0.219, 0.042, 0.267, 0.056, 0.17, 0.309, 0.116, 0.221, 0.117]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4127 | Steps: 4 | Val loss: 0.3167 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=60251)[0m rmse: 0.15491202473640442
[2m[36m(func pid=60251)[0m mae:  0.10809396207332611
[2m[36m(func pid=60251)[0m rmse_per_class: [0.115, 0.227, 0.046, 0.312, 0.055, 0.176, 0.239, 0.126, 0.133, 0.119]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.1442234218120575
[2m[36m(func pid=50292)[0m mae:  0.09719677269458771
[2m[36m(func pid=50292)[0m rmse_per_class: [0.081, 0.223, 0.041, 0.305, 0.055, 0.158, 0.232, 0.119, 0.133, 0.096]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5219 | Steps: 4 | Val loss: 0.4181 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 17:35:26 (running for 00:19:43.24)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.413 |  0.174 |                   52 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.391 |  0.144 |                   50 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.623 |  0.155 |                   10 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.515 |  0.162 |                    8 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.17420844733715057
[2m[36m(func pid=50163)[0m mae:  0.12759742140769958
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.255, 0.084, 0.332, 0.086, 0.187, 0.286, 0.139, 0.143, 0.113]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.6201 | Steps: 4 | Val loss: 0.4885 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=60747)[0m rmse: 0.18084073066711426
[2m[36m(func pid=60747)[0m mae:  0.11719246208667755
[2m[36m(func pid=60747)[0m rmse_per_class: [0.175, 0.235, 0.028, 0.279, 0.056, 0.172, 0.321, 0.125, 0.172, 0.246]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4023 | Steps: 4 | Val loss: 0.2773 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4118 | Steps: 4 | Val loss: 0.3166 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=60251)[0m rmse: 0.15204137563705444
[2m[36m(func pid=60251)[0m mae:  0.1042766347527504
[2m[36m(func pid=60251)[0m rmse_per_class: [0.108, 0.223, 0.044, 0.314, 0.055, 0.171, 0.234, 0.127, 0.132, 0.111]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.1436423808336258
[2m[36m(func pid=50292)[0m mae:  0.0966566652059555
[2m[36m(func pid=50292)[0m rmse_per_class: [0.08, 0.223, 0.041, 0.301, 0.055, 0.158, 0.232, 0.118, 0.133, 0.095]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4748 | Steps: 4 | Val loss: 0.3820 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 17:35:32 (running for 00:19:48.64)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.412 |  0.174 |                   53 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.402 |  0.144 |                   51 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.62  |  0.152 |                   11 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.522 |  0.181 |                    9 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.17435841262340546
[2m[36m(func pid=50163)[0m mae:  0.12775763869285583
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.256, 0.084, 0.333, 0.085, 0.187, 0.286, 0.139, 0.143, 0.113]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.6386 | Steps: 4 | Val loss: 0.4766 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3953 | Steps: 4 | Val loss: 0.2727 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=60747)[0m rmse: 0.192649245262146
[2m[36m(func pid=60747)[0m mae:  0.11335156857967377
[2m[36m(func pid=60747)[0m rmse_per_class: [0.246, 0.266, 0.03, 0.299, 0.052, 0.17, 0.26, 0.156, 0.135, 0.313]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4076 | Steps: 4 | Val loss: 0.3153 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=60251)[0m rmse: 0.15137119591236115
[2m[36m(func pid=60251)[0m mae:  0.10162049531936646
[2m[36m(func pid=60251)[0m rmse_per_class: [0.101, 0.219, 0.044, 0.325, 0.055, 0.168, 0.24, 0.129, 0.131, 0.102]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.1427714228630066
[2m[36m(func pid=50292)[0m mae:  0.0960499718785286
[2m[36m(func pid=50292)[0m rmse_per_class: [0.079, 0.222, 0.04, 0.298, 0.055, 0.157, 0.229, 0.118, 0.133, 0.096]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4630 | Steps: 4 | Val loss: 0.4042 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 17:35:37 (running for 00:19:53.93)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.408 |  0.174 |                   54 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.395 |  0.143 |                   52 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.639 |  0.151 |                   12 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.475 |  0.193 |                   10 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.17396114766597748
[2m[36m(func pid=50163)[0m mae:  0.12741491198539734
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.256, 0.083, 0.332, 0.084, 0.187, 0.286, 0.139, 0.143, 0.112]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.6001 | Steps: 4 | Val loss: 0.4585 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3955 | Steps: 4 | Val loss: 0.2707 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=60747)[0m rmse: 0.18693992495536804
[2m[36m(func pid=60747)[0m mae:  0.09970788657665253
[2m[36m(func pid=60747)[0m rmse_per_class: [0.157, 0.257, 0.052, 0.317, 0.145, 0.176, 0.291, 0.123, 0.125, 0.225]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4076 | Steps: 4 | Val loss: 0.3150 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=60251)[0m rmse: 0.15250763297080994
[2m[36m(func pid=60251)[0m mae:  0.09990350902080536
[2m[36m(func pid=60251)[0m rmse_per_class: [0.094, 0.217, 0.043, 0.33, 0.056, 0.167, 0.261, 0.132, 0.13, 0.095]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.14352230727672577
[2m[36m(func pid=50292)[0m mae:  0.09682821482419968
[2m[36m(func pid=50292)[0m rmse_per_class: [0.08, 0.223, 0.04, 0.299, 0.055, 0.158, 0.228, 0.117, 0.134, 0.1]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4849 | Steps: 4 | Val loss: 0.4346 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 17:35:42 (running for 00:19:59.22)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.408 |  0.174 |                   55 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.396 |  0.144 |                   53 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.6   |  0.153 |                   13 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.463 |  0.187 |                   11 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.17401421070098877
[2m[36m(func pid=50163)[0m mae:  0.12743507325649261
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.255, 0.083, 0.332, 0.085, 0.187, 0.286, 0.14, 0.143, 0.112]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.6011 | Steps: 4 | Val loss: 0.4312 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3683 | Steps: 4 | Val loss: 0.2676 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=60747)[0m rmse: 0.199452742934227
[2m[36m(func pid=60747)[0m mae:  0.11325778812170029
[2m[36m(func pid=60747)[0m rmse_per_class: [0.083, 0.256, 0.051, 0.341, 0.219, 0.202, 0.46, 0.118, 0.132, 0.133]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4073 | Steps: 4 | Val loss: 0.3143 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=60251)[0m rmse: 0.15445676445960999
[2m[36m(func pid=60251)[0m mae:  0.09906960278749466
[2m[36m(func pid=60251)[0m rmse_per_class: [0.088, 0.214, 0.043, 0.335, 0.056, 0.167, 0.288, 0.135, 0.129, 0.089]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.14312510192394257
[2m[36m(func pid=50292)[0m mae:  0.09655044227838516
[2m[36m(func pid=50292)[0m rmse_per_class: [0.079, 0.223, 0.041, 0.297, 0.055, 0.157, 0.226, 0.117, 0.135, 0.101]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.5640 | Steps: 4 | Val loss: 0.4514 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 17:35:48 (running for 00:20:04.75)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.407 |  0.174 |                   56 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.368 |  0.143 |                   54 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.601 |  0.154 |                   14 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.485 |  0.199 |                   12 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)

[2m[36m(func pid=50163)[0m rmse: 0.17368832230567932

[2m[36m(func pid=50163)[0m mae:  0.1271626055240631
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.255, 0.082, 0.331, 0.085, 0.187, 0.286, 0.139, 0.143, 0.111]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.5681 | Steps: 4 | Val loss: 0.3980 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3844 | Steps: 4 | Val loss: 0.2666 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=60747)[0m rmse: 0.19913700222969055
[2m[36m(func pid=60747)[0m mae:  0.1154019832611084
[2m[36m(func pid=60747)[0m rmse_per_class: [0.083, 0.248, 0.061, 0.349, 0.266, 0.201, 0.438, 0.119, 0.133, 0.094]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4085 | Steps: 4 | Val loss: 0.3134 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=60251)[0m rmse: 0.15675386786460876
[2m[36m(func pid=60251)[0m mae:  0.0987529382109642
[2m[36m(func pid=60251)[0m rmse_per_class: [0.083, 0.216, 0.044, 0.341, 0.056, 0.164, 0.313, 0.137, 0.129, 0.085]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.1430193930864334
[2m[36m(func pid=50292)[0m mae:  0.0965852290391922
[2m[36m(func pid=50292)[0m rmse_per_class: [0.079, 0.223, 0.04, 0.298, 0.055, 0.156, 0.226, 0.116, 0.134, 0.102]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.5533 | Steps: 4 | Val loss: 0.4208 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 17:35:53 (running for 00:20:10.10)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.408 |  0.173 |                   57 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.384 |  0.143 |                   55 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.568 |  0.157 |                   15 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.564 |  0.199 |                   13 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.17331498861312866
[2m[36m(func pid=50163)[0m mae:  0.12683162093162537
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.255, 0.081, 0.331, 0.084, 0.187, 0.285, 0.139, 0.143, 0.111]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.5061 | Steps: 4 | Val loss: 0.3610 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3580 | Steps: 4 | Val loss: 0.2668 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=60747)[0m rmse: 0.18437287211418152
[2m[36m(func pid=60747)[0m mae:  0.10324577242136002
[2m[36m(func pid=60747)[0m rmse_per_class: [0.083, 0.268, 0.088, 0.326, 0.277, 0.176, 0.288, 0.121, 0.129, 0.088]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4066 | Steps: 4 | Val loss: 0.3128 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=60251)[0m rmse: 0.15774856507778168
[2m[36m(func pid=60251)[0m mae:  0.09857691079378128
[2m[36m(func pid=60251)[0m rmse_per_class: [0.083, 0.219, 0.044, 0.345, 0.056, 0.16, 0.319, 0.139, 0.129, 0.083]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.14395679533481598
[2m[36m(func pid=50292)[0m mae:  0.09775642305612564
[2m[36m(func pid=50292)[0m rmse_per_class: [0.08, 0.224, 0.04, 0.3, 0.055, 0.156, 0.227, 0.116, 0.136, 0.106]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4795 | Steps: 4 | Val loss: 0.4073 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 17:35:58 (running for 00:20:15.29)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.407 |  0.173 |                   58 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.358 |  0.144 |                   56 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.506 |  0.158 |                   16 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.553 |  0.184 |                   14 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.1730523407459259
[2m[36m(func pid=50163)[0m mae:  0.1265878975391388
[2m[36m(func pid=50163)[0m rmse_per_class: [0.116, 0.255, 0.082, 0.331, 0.083, 0.186, 0.285, 0.139, 0.142, 0.112]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4896 | Steps: 4 | Val loss: 0.3278 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3762 | Steps: 4 | Val loss: 0.2671 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=60747)[0m rmse: 0.18028438091278076
[2m[36m(func pid=60747)[0m mae:  0.10185849666595459
[2m[36m(func pid=60747)[0m rmse_per_class: [0.079, 0.28, 0.102, 0.305, 0.193, 0.195, 0.276, 0.15, 0.137, 0.085]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4082 | Steps: 4 | Val loss: 0.3130 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=50292)[0m rmse: 0.14446666836738586
[2m[36m(func pid=50292)[0m mae:  0.09844951331615448
[2m[36m(func pid=50292)[0m rmse_per_class: [0.081, 0.225, 0.039, 0.3, 0.055, 0.156, 0.227, 0.115, 0.138, 0.109]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.15682052075862885
[2m[36m(func pid=60251)[0m mae:  0.09750258922576904
[2m[36m(func pid=60251)[0m rmse_per_class: [0.088, 0.223, 0.044, 0.344, 0.056, 0.157, 0.305, 0.14, 0.129, 0.082]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.5065 | Steps: 4 | Val loss: 0.4216 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 17:36:04 (running for 00:20:20.55)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.408 |  0.173 |                   59 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.144 |                   57 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.49  |  0.157 |                   17 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.48  |  0.18  |                   15 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.1732117235660553
[2m[36m(func pid=50163)[0m mae:  0.12675829231739044
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.255, 0.082, 0.331, 0.082, 0.186, 0.284, 0.139, 0.142, 0.113]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3605 | Steps: 4 | Val loss: 0.2656 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4331 | Steps: 4 | Val loss: 0.3030 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=60747)[0m rmse: 0.17378857731819153
[2m[36m(func pid=60747)[0m mae:  0.1016608327627182
[2m[36m(func pid=60747)[0m rmse_per_class: [0.074, 0.24, 0.089, 0.306, 0.095, 0.212, 0.32, 0.147, 0.165, 0.09]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4084 | Steps: 4 | Val loss: 0.3134 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=50292)[0m rmse: 0.14355969429016113
[2m[36m(func pid=50292)[0m mae:  0.09790563583374023
[2m[36m(func pid=50292)[0m rmse_per_class: [0.081, 0.222, 0.038, 0.294, 0.055, 0.155, 0.226, 0.116, 0.137, 0.11]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.15534189343452454
[2m[36m(func pid=60251)[0m mae:  0.09671394526958466
[2m[36m(func pid=60251)[0m rmse_per_class: [0.094, 0.221, 0.043, 0.345, 0.056, 0.153, 0.29, 0.137, 0.129, 0.085]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4612 | Steps: 4 | Val loss: 0.4335 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 17:36:09 (running for 00:20:25.99)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.408 |  0.173 |                   60 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.36  |  0.144 |                   58 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.433 |  0.155 |                   18 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.507 |  0.174 |                   16 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.17329122126102448
[2m[36m(func pid=50163)[0m mae:  0.12687119841575623
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.255, 0.082, 0.332, 0.082, 0.186, 0.285, 0.139, 0.142, 0.112]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3549 | Steps: 4 | Val loss: 0.2651 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.4156 | Steps: 4 | Val loss: 0.2901 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=60747)[0m rmse: 0.17202474176883698
[2m[36m(func pid=60747)[0m mae:  0.10373325645923615
[2m[36m(func pid=60747)[0m rmse_per_class: [0.072, 0.227, 0.086, 0.29, 0.055, 0.213, 0.321, 0.14, 0.219, 0.098]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4036 | Steps: 4 | Val loss: 0.3131 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=50292)[0m rmse: 0.1428694725036621
[2m[36m(func pid=50292)[0m mae:  0.09752770513296127
[2m[36m(func pid=50292)[0m rmse_per_class: [0.081, 0.222, 0.038, 0.291, 0.055, 0.155, 0.227, 0.115, 0.137, 0.109]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.15159989893436432
[2m[36m(func pid=60251)[0m mae:  0.09506982564926147
[2m[36m(func pid=60251)[0m rmse_per_class: [0.102, 0.222, 0.043, 0.336, 0.056, 0.154, 0.257, 0.133, 0.128, 0.086]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4182 | Steps: 4 | Val loss: 0.4167 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=50163)[0m rmse: 0.17298273742198944
[2m[36m(func pid=50163)[0m mae:  0.12659767270088196
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.255, 0.081, 0.331, 0.082, 0.186, 0.286, 0.138, 0.143, 0.111]
== Status ==
Current time: 2024-01-07 17:36:14 (running for 00:20:31.19)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.173 |                   61 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.355 |  0.143 |                   59 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.416 |  0.152 |                   19 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.461 |  0.172 |                   17 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3630 | Steps: 4 | Val loss: 0.2670 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3851 | Steps: 4 | Val loss: 0.2923 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=60747)[0m rmse: 0.17763306200504303
[2m[36m(func pid=60747)[0m mae:  0.10558489710092545
[2m[36m(func pid=60747)[0m rmse_per_class: [0.103, 0.231, 0.082, 0.288, 0.052, 0.199, 0.286, 0.137, 0.279, 0.118]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4044 | Steps: 4 | Val loss: 0.3129 | Batch size: 32 | lr: 0.0001 | Duration: 2.73s
[2m[36m(func pid=50292)[0m rmse: 0.14373429119586945
[2m[36m(func pid=50292)[0m mae:  0.09821377694606781
[2m[36m(func pid=50292)[0m rmse_per_class: [0.082, 0.223, 0.038, 0.29, 0.055, 0.155, 0.23, 0.115, 0.137, 0.112]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.148280069231987
[2m[36m(func pid=60251)[0m mae:  0.09458854794502258
[2m[36m(func pid=60251)[0m rmse_per_class: [0.107, 0.221, 0.041, 0.325, 0.056, 0.157, 0.227, 0.127, 0.13, 0.092]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.4494 | Steps: 4 | Val loss: 0.4297 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 17:36:19 (running for 00:20:36.43)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.173 |                   62 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.363 |  0.144 |                   60 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.385 |  0.148 |                   20 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.418 |  0.178 |                   18 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.17283201217651367
[2m[36m(func pid=50163)[0m mae:  0.1264660507440567
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.255, 0.08, 0.331, 0.081, 0.186, 0.285, 0.139, 0.143, 0.111]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3464 | Steps: 4 | Val loss: 0.2667 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4437 | Steps: 4 | Val loss: 0.3068 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=60747)[0m rmse: 0.18296687304973602
[2m[36m(func pid=60747)[0m mae:  0.10632014274597168
[2m[36m(func pid=60747)[0m rmse_per_class: [0.17, 0.235, 0.068, 0.318, 0.056, 0.182, 0.265, 0.129, 0.251, 0.156]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4030 | Steps: 4 | Val loss: 0.3122 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=50292)[0m rmse: 0.1428854614496231
[2m[36m(func pid=50292)[0m mae:  0.09794939309358597
[2m[36m(func pid=50292)[0m rmse_per_class: [0.082, 0.222, 0.037, 0.285, 0.055, 0.154, 0.231, 0.115, 0.138, 0.11]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.14687278866767883
[2m[36m(func pid=60251)[0m mae:  0.09542204439640045
[2m[36m(func pid=60251)[0m rmse_per_class: [0.108, 0.218, 0.041, 0.312, 0.056, 0.161, 0.217, 0.118, 0.139, 0.098]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4323 | Steps: 4 | Val loss: 0.4599 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=50163)[0m rmse: 0.17254401743412018
[2m[36m(func pid=50163)[0m mae:  0.12620919942855835
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.253, 0.081, 0.331, 0.08, 0.186, 0.284, 0.139, 0.142, 0.111]
== Status ==
Current time: 2024-01-07 17:36:25 (running for 00:20:41.77)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.403 |  0.173 |                   63 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.346 |  0.143 |                   61 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.444 |  0.147 |                   21 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.449 |  0.183 |                   19 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3636 | Steps: 4 | Val loss: 0.2689 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4687 | Steps: 4 | Val loss: 0.3268 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=60747)[0m rmse: 0.1889314353466034
[2m[36m(func pid=60747)[0m mae:  0.10810951888561249
[2m[36m(func pid=60747)[0m rmse_per_class: [0.173, 0.23, 0.059, 0.349, 0.056, 0.187, 0.317, 0.133, 0.192, 0.192]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4033 | Steps: 4 | Val loss: 0.3120 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=50292)[0m rmse: 0.14376354217529297
[2m[36m(func pid=50292)[0m mae:  0.09906236827373505
[2m[36m(func pid=50292)[0m rmse_per_class: [0.083, 0.221, 0.036, 0.285, 0.055, 0.155, 0.234, 0.115, 0.141, 0.112]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.1483960747718811
[2m[36m(func pid=60251)[0m mae:  0.09822499006986618
[2m[36m(func pid=60251)[0m rmse_per_class: [0.115, 0.218, 0.037, 0.295, 0.056, 0.159, 0.229, 0.114, 0.154, 0.107]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4387 | Steps: 4 | Val loss: 0.4791 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 17:36:30 (running for 00:20:47.11)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.403 |  0.172 |                   64 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.364 |  0.144 |                   62 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.469 |  0.148 |                   22 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.432 |  0.189 |                   20 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.1723213940858841
[2m[36m(func pid=50163)[0m mae:  0.1260269582271576
[2m[36m(func pid=50163)[0m rmse_per_class: [0.116, 0.254, 0.08, 0.33, 0.08, 0.186, 0.284, 0.138, 0.142, 0.112]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3656 | Steps: 4 | Val loss: 0.2698 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4354 | Steps: 4 | Val loss: 0.3435 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=60747)[0m rmse: 0.19273537397384644
[2m[36m(func pid=60747)[0m mae:  0.10863103717565536
[2m[36m(func pid=60747)[0m rmse_per_class: [0.116, 0.263, 0.064, 0.355, 0.056, 0.193, 0.28, 0.161, 0.181, 0.257]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4030 | Steps: 4 | Val loss: 0.3123 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=50292)[0m rmse: 0.14362004399299622
[2m[36m(func pid=50292)[0m mae:  0.09909294545650482
[2m[36m(func pid=50292)[0m rmse_per_class: [0.083, 0.221, 0.036, 0.284, 0.055, 0.154, 0.238, 0.115, 0.141, 0.111]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.14989319443702698
[2m[36m(func pid=60251)[0m mae:  0.10033191740512848
[2m[36m(func pid=60251)[0m rmse_per_class: [0.11, 0.218, 0.033, 0.28, 0.056, 0.158, 0.25, 0.111, 0.169, 0.113]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.5203 | Steps: 4 | Val loss: 0.5090 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 17:36:35 (running for 00:20:52.32)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.403 |  0.172 |                   65 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.366 |  0.144 |                   63 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.435 |  0.15  |                   23 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.439 |  0.193 |                   21 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.17221590876579285
[2m[36m(func pid=50163)[0m mae:  0.12595507502555847
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.254, 0.08, 0.33, 0.08, 0.186, 0.284, 0.139, 0.142, 0.111]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3688 | Steps: 4 | Val loss: 0.2723 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4689 | Steps: 4 | Val loss: 0.3522 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=60747)[0m rmse: 0.20409008860588074
[2m[36m(func pid=60747)[0m mae:  0.11661636829376221
[2m[36m(func pid=60747)[0m rmse_per_class: [0.077, 0.327, 0.066, 0.356, 0.056, 0.198, 0.266, 0.239, 0.176, 0.28]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4066 | Steps: 4 | Val loss: 0.3131 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=50292)[0m rmse: 0.14445853233337402
[2m[36m(func pid=50292)[0m mae:  0.10002050548791885
[2m[36m(func pid=50292)[0m rmse_per_class: [0.086, 0.221, 0.035, 0.287, 0.055, 0.153, 0.239, 0.113, 0.143, 0.112]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.15196022391319275
[2m[36m(func pid=60251)[0m mae:  0.10235925763845444
[2m[36m(func pid=60251)[0m rmse_per_class: [0.098, 0.219, 0.029, 0.27, 0.056, 0.157, 0.272, 0.112, 0.18, 0.126]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.5521 | Steps: 4 | Val loss: 0.4785 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 17:36:41 (running for 00:20:57.59)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.407 |  0.173 |                   66 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.369 |  0.144 |                   64 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.469 |  0.152 |                   24 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.52  |  0.204 |                   22 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.17264387011528015
[2m[36m(func pid=50163)[0m mae:  0.12640605866909027
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.254, 0.08, 0.332, 0.08, 0.185, 0.284, 0.138, 0.143, 0.112]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3618 | Steps: 4 | Val loss: 0.2753 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4431 | Steps: 4 | Val loss: 0.3429 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=60747)[0m rmse: 0.1997399479150772
[2m[36m(func pid=60747)[0m mae:  0.11483286321163177
[2m[36m(func pid=60747)[0m rmse_per_class: [0.077, 0.358, 0.053, 0.342, 0.056, 0.206, 0.276, 0.261, 0.159, 0.209]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4060 | Steps: 4 | Val loss: 0.3124 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=50292)[0m rmse: 0.14574143290519714
[2m[36m(func pid=50292)[0m mae:  0.10113351047039032
[2m[36m(func pid=50292)[0m rmse_per_class: [0.085, 0.222, 0.034, 0.288, 0.055, 0.155, 0.243, 0.113, 0.146, 0.117]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.15266938507556915
[2m[36m(func pid=60251)[0m mae:  0.1028989776968956
[2m[36m(func pid=60251)[0m rmse_per_class: [0.084, 0.219, 0.027, 0.261, 0.056, 0.156, 0.288, 0.117, 0.185, 0.133]
[2m[36m(func pid=60251)[0m 
== Status ==
Current time: 2024-01-07 17:36:46 (running for 00:21:02.84)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.406 |  0.172 |                   67 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.362 |  0.146 |                   65 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.443 |  0.153 |                   25 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.552 |  0.2   |                   23 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.17210936546325684
[2m[36m(func pid=50163)[0m mae:  0.12592601776123047
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.254, 0.08, 0.331, 0.079, 0.185, 0.283, 0.138, 0.142, 0.111]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4609 | Steps: 4 | Val loss: 0.4240 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3682 | Steps: 4 | Val loss: 0.2756 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4606 | Steps: 4 | Val loss: 0.3315 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=60747)[0m rmse: 0.1851397007703781
[2m[36m(func pid=60747)[0m mae:  0.10704896599054337
[2m[36m(func pid=60747)[0m rmse_per_class: [0.081, 0.291, 0.045, 0.319, 0.056, 0.272, 0.274, 0.21, 0.145, 0.157]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4027 | Steps: 4 | Val loss: 0.3120 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=50292)[0m rmse: 0.14518369734287262
[2m[36m(func pid=50292)[0m mae:  0.10052166134119034
[2m[36m(func pid=50292)[0m rmse_per_class: [0.085, 0.223, 0.034, 0.286, 0.055, 0.154, 0.243, 0.112, 0.146, 0.114]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.1548372209072113
[2m[36m(func pid=60251)[0m mae:  0.10361181199550629
[2m[36m(func pid=60251)[0m rmse_per_class: [0.075, 0.22, 0.027, 0.255, 0.056, 0.155, 0.299, 0.128, 0.19, 0.144]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50163)[0m rmse: 0.17195428907871246
[2m[36m(func pid=50163)[0m mae:  0.12575964629650116
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.254, 0.08, 0.331, 0.079, 0.185, 0.282, 0.138, 0.142, 0.11]
[2m[36m(func pid=50163)[0m 
== Status ==
Current time: 2024-01-07 17:36:51 (running for 00:21:08.11)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.403 |  0.172 |                   68 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.368 |  0.145 |                   66 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.461 |  0.155 |                   26 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.461 |  0.185 |                   24 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4723 | Steps: 4 | Val loss: 0.4091 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3555 | Steps: 4 | Val loss: 0.2760 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3745 | Steps: 4 | Val loss: 0.3159 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=60747)[0m rmse: 0.16799414157867432
[2m[36m(func pid=60747)[0m mae:  0.10019700229167938
[2m[36m(func pid=60747)[0m rmse_per_class: [0.086, 0.235, 0.044, 0.29, 0.056, 0.309, 0.255, 0.144, 0.136, 0.124]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4020 | Steps: 4 | Val loss: 0.3122 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=50292)[0m rmse: 0.14498557150363922
[2m[36m(func pid=50292)[0m mae:  0.10035665333271027
[2m[36m(func pid=50292)[0m rmse_per_class: [0.086, 0.223, 0.034, 0.284, 0.055, 0.153, 0.246, 0.112, 0.146, 0.111]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.15810763835906982
[2m[36m(func pid=60251)[0m mae:  0.10400065034627914
[2m[36m(func pid=60251)[0m rmse_per_class: [0.073, 0.221, 0.036, 0.253, 0.056, 0.154, 0.304, 0.142, 0.185, 0.157]
[2m[36m(func pid=60251)[0m 
== Status ==
Current time: 2024-01-07 17:36:56 (running for 00:21:13.39)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.402 |  0.172 |                   69 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.355 |  0.145 |                   67 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.375 |  0.158 |                   27 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.472 |  0.168 |                   25 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.1719726026058197
[2m[36m(func pid=50163)[0m mae:  0.12579064071178436
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.254, 0.079, 0.331, 0.078, 0.184, 0.283, 0.138, 0.143, 0.111]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.5471 | Steps: 4 | Val loss: 0.4012 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3645 | Steps: 4 | Val loss: 0.2766 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3944 | Steps: 4 | Val loss: 0.3099 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=50292)[0m rmse: 0.14508572220802307
[2m[36m(func pid=50292)[0m mae:  0.10052748769521713
[2m[36m(func pid=50292)[0m rmse_per_class: [0.087, 0.222, 0.034, 0.281, 0.055, 0.154, 0.251, 0.112, 0.146, 0.108]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m rmse: 0.15614311397075653
[2m[36m(func pid=60747)[0m mae:  0.09236438572406769
[2m[36m(func pid=60747)[0m rmse_per_class: [0.084, 0.228, 0.043, 0.292, 0.056, 0.232, 0.234, 0.134, 0.141, 0.118]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4037 | Steps: 4 | Val loss: 0.3123 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=60251)[0m rmse: 0.16227766871452332
[2m[36m(func pid=60251)[0m mae:  0.1033414974808693
[2m[36m(func pid=60251)[0m rmse_per_class: [0.065, 0.224, 0.06, 0.254, 0.056, 0.154, 0.301, 0.176, 0.175, 0.158]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50163)[0m rmse: 0.17198562622070312
[2m[36m(func pid=50163)[0m mae:  0.12576408684253693
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.255, 0.08, 0.331, 0.078, 0.185, 0.281, 0.138, 0.142, 0.113]
== Status ==
Current time: 2024-01-07 17:37:02 (running for 00:21:18.80)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.172 |                   70 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.364 |  0.145 |                   68 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.394 |  0.162 |                   28 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.547 |  0.156 |                   26 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3658 | Steps: 4 | Val loss: 0.2783 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4663 | Steps: 4 | Val loss: 0.3731 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3747 | Steps: 4 | Val loss: 0.3097 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=50292)[0m rmse: 0.14616534113883972
[2m[36m(func pid=50292)[0m mae:  0.1014564037322998
[2m[36m(func pid=50292)[0m rmse_per_class: [0.089, 0.222, 0.035, 0.283, 0.055, 0.154, 0.252, 0.113, 0.15, 0.11]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4021 | Steps: 4 | Val loss: 0.3129 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=60747)[0m rmse: 0.15976890921592712
[2m[36m(func pid=60747)[0m mae:  0.09170971810817719
[2m[36m(func pid=60747)[0m rmse_per_class: [0.076, 0.229, 0.064, 0.305, 0.057, 0.183, 0.237, 0.138, 0.189, 0.12]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.1682213842868805
[2m[36m(func pid=60251)[0m mae:  0.10438092052936554
[2m[36m(func pid=60251)[0m rmse_per_class: [0.066, 0.229, 0.1, 0.257, 0.055, 0.154, 0.296, 0.195, 0.159, 0.171]
[2m[36m(func pid=60251)[0m 
== Status ==
Current time: 2024-01-07 17:37:07 (running for 00:21:24.27)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.402 |  0.172 |                   71 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.366 |  0.146 |                   69 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.375 |  0.168 |                   29 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.466 |  0.16  |                   27 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.17194852232933044
[2m[36m(func pid=50163)[0m mae:  0.1257070153951645
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.254, 0.081, 0.33, 0.077, 0.185, 0.281, 0.139, 0.142, 0.112]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3635 | Steps: 4 | Val loss: 0.2792 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3574 | Steps: 4 | Val loss: 0.3903 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3579 | Steps: 4 | Val loss: 0.3152 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=50292)[0m rmse: 0.14658108353614807
[2m[36m(func pid=50292)[0m mae:  0.10209944099187851
[2m[36m(func pid=50292)[0m rmse_per_class: [0.09, 0.222, 0.034, 0.283, 0.055, 0.154, 0.256, 0.112, 0.152, 0.109]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m rmse: 0.1774076670408249
[2m[36m(func pid=60747)[0m mae:  0.10022272169589996
[2m[36m(func pid=60747)[0m rmse_per_class: [0.083, 0.225, 0.083, 0.305, 0.085, 0.199, 0.25, 0.154, 0.285, 0.106]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4054 | Steps: 4 | Val loss: 0.3126 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=60251)[0m rmse: 0.17333784699440002
[2m[36m(func pid=60251)[0m mae:  0.10571583360433578
[2m[36m(func pid=60251)[0m rmse_per_class: [0.067, 0.227, 0.15, 0.262, 0.055, 0.157, 0.288, 0.199, 0.153, 0.176]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3600 | Steps: 4 | Val loss: 0.2784 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=50163)[0m rmse: 0.17152510583400726
[2m[36m(func pid=50163)[0m mae:  0.12537352740764618
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.253, 0.081, 0.33, 0.076, 0.186, 0.28, 0.138, 0.142, 0.112]
[2m[36m(func pid=50163)[0m 
== Status ==
Current time: 2024-01-07 17:37:13 (running for 00:21:29.78)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.405 |  0.172 |                   72 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.364 |  0.147 |                   70 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.358 |  0.173 |                   30 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.357 |  0.177 |                   28 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4131 | Steps: 4 | Val loss: 0.4795 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3575 | Steps: 4 | Val loss: 0.3211 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=50292)[0m rmse: 0.1462549865245819
[2m[36m(func pid=50292)[0m mae:  0.10187456756830215
[2m[36m(func pid=50292)[0m rmse_per_class: [0.089, 0.222, 0.034, 0.282, 0.055, 0.154, 0.256, 0.113, 0.153, 0.105]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m rmse: 0.2069855034351349
[2m[36m(func pid=60747)[0m mae:  0.11914956569671631
[2m[36m(func pid=60747)[0m rmse_per_class: [0.185, 0.226, 0.102, 0.326, 0.132, 0.211, 0.268, 0.161, 0.348, 0.11]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4049 | Steps: 4 | Val loss: 0.3123 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=60251)[0m rmse: 0.17575058341026306
[2m[36m(func pid=60251)[0m mae:  0.10598891973495483
[2m[36m(func pid=60251)[0m rmse_per_class: [0.066, 0.229, 0.192, 0.266, 0.054, 0.161, 0.271, 0.196, 0.15, 0.172]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3546 | Steps: 4 | Val loss: 0.2779 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 17:37:18 (running for 00:21:35.22)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.405 |  0.171 |                   73 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.36  |  0.146 |                   71 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.357 |  0.176 |                   31 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.413 |  0.207 |                   29 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.1711692065000534
[2m[36m(func pid=50163)[0m mae:  0.12511631846427917
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.252, 0.08, 0.33, 0.076, 0.185, 0.281, 0.137, 0.142, 0.111]
[2m[36m(func pid=50163)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4055 | Steps: 4 | Val loss: 0.5114 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3754 | Steps: 4 | Val loss: 0.3276 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=50292)[0m rmse: 0.1463698446750641
[2m[36m(func pid=50292)[0m mae:  0.10167883336544037
[2m[36m(func pid=50292)[0m rmse_per_class: [0.088, 0.222, 0.034, 0.28, 0.054, 0.154, 0.256, 0.114, 0.155, 0.106]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m rmse: 0.21587809920310974
[2m[36m(func pid=60747)[0m mae:  0.1249316930770874
[2m[36m(func pid=60747)[0m rmse_per_class: [0.24, 0.229, 0.117, 0.356, 0.16, 0.206, 0.267, 0.18, 0.288, 0.117]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4007 | Steps: 4 | Val loss: 0.3118 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=60251)[0m rmse: 0.17559468746185303
[2m[36m(func pid=60251)[0m mae:  0.10505075752735138
[2m[36m(func pid=60251)[0m rmse_per_class: [0.066, 0.225, 0.247, 0.272, 0.061, 0.164, 0.25, 0.169, 0.141, 0.16]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3514 | Steps: 4 | Val loss: 0.2775 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=50163)[0m rmse: 0.17104078829288483
[2m[36m(func pid=50163)[0m mae:  0.12497149407863617
[2m[36m(func pid=50163)[0m rmse_per_class: [0.118, 0.253, 0.079, 0.33, 0.076, 0.185, 0.28, 0.137, 0.142, 0.111]
[2m[36m(func pid=50163)[0m 
== Status ==
Current time: 2024-01-07 17:37:24 (running for 00:21:40.46)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00008 | RUNNING    | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.401 |  0.171 |                   74 |
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.355 |  0.146 |                   72 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.375 |  0.176 |                   32 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.405 |  0.216 |                   30 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4165 | Steps: 4 | Val loss: 0.4926 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3950 | Steps: 4 | Val loss: 0.3337 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=50292)[0m rmse: 0.1463821828365326
[2m[36m(func pid=50292)[0m mae:  0.10170946270227432
[2m[36m(func pid=50292)[0m rmse_per_class: [0.089, 0.222, 0.033, 0.277, 0.054, 0.154, 0.26, 0.114, 0.154, 0.106]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=50163)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4043 | Steps: 4 | Val loss: 0.3118 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=60747)[0m rmse: 0.20864923298358917
[2m[36m(func pid=60747)[0m mae:  0.11784972250461578
[2m[36m(func pid=60747)[0m rmse_per_class: [0.181, 0.241, 0.153, 0.361, 0.166, 0.197, 0.255, 0.174, 0.229, 0.129]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.17484785616397858
[2m[36m(func pid=60251)[0m mae:  0.10410432517528534
[2m[36m(func pid=60251)[0m rmse_per_class: [0.067, 0.224, 0.282, 0.278, 0.073, 0.167, 0.231, 0.139, 0.137, 0.151]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3501 | Steps: 4 | Val loss: 0.2773 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 17:37:29 (running for 00:21:45.67)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (12 PENDING, 3 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.351 |  0.146 |                   73 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.395 |  0.175 |                   33 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.417 |  0.209 |                   31 |
| train_01e98_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING)


[2m[36m(func pid=50163)[0m rmse: 0.17070573568344116
[2m[36m(func pid=50163)[0m mae:  0.12468405067920685
[2m[36m(func pid=50163)[0m rmse_per_class: [0.117, 0.252, 0.079, 0.329, 0.075, 0.185, 0.28, 0.137, 0.142, 0.112]
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4130 | Steps: 4 | Val loss: 0.4728 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3835 | Steps: 4 | Val loss: 0.3357 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=50292)[0m rmse: 0.1469445824623108
[2m[36m(func pid=50292)[0m mae:  0.10241714864969254
[2m[36m(func pid=50292)[0m rmse_per_class: [0.091, 0.221, 0.033, 0.278, 0.054, 0.154, 0.263, 0.113, 0.154, 0.107]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.17424502968788147
[2m[36m(func pid=60251)[0m mae:  0.10344308614730835
[2m[36m(func pid=60251)[0m rmse_per_class: [0.068, 0.225, 0.287, 0.287, 0.091, 0.169, 0.222, 0.115, 0.135, 0.143]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m rmse: 0.1942887306213379
[2m[36m(func pid=60747)[0m mae:  0.10894105583429337
[2m[36m(func pid=60747)[0m rmse_per_class: [0.085, 0.264, 0.156, 0.359, 0.165, 0.208, 0.25, 0.141, 0.161, 0.154]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3540 | Steps: 4 | Val loss: 0.2776 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3970 | Steps: 4 | Val loss: 0.3374 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3823 | Steps: 4 | Val loss: 0.4640 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=50292)[0m rmse: 0.14740851521492004
[2m[36m(func pid=50292)[0m mae:  0.10261956602334976
[2m[36m(func pid=50292)[0m rmse_per_class: [0.091, 0.222, 0.034, 0.278, 0.054, 0.154, 0.265, 0.115, 0.155, 0.107]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.17627111077308655
[2m[36m(func pid=60251)[0m mae:  0.1043032631278038
[2m[36m(func pid=60251)[0m rmse_per_class: [0.069, 0.222, 0.276, 0.302, 0.116, 0.174, 0.231, 0.11, 0.133, 0.13]
[2m[36m(func pid=60747)[0m rmse: 0.19309979677200317
[2m[36m(func pid=60747)[0m mae:  0.10908880084753036
[2m[36m(func pid=60747)[0m rmse_per_class: [0.082, 0.258, 0.143, 0.342, 0.142, 0.251, 0.256, 0.129, 0.143, 0.184]
== Status ==
Current time: 2024-01-07 17:37:36 (running for 00:21:52.67)
Memory usage on this node: 23.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.354 |  0.147 |                   75 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.384 |  0.174 |                   34 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.413 |  0.194 |                   32 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=68837)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=68837)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=68837)[0m Configuration completed!
[2m[36m(func pid=68837)[0m New optimizer parameters:
[2m[36m(func pid=68837)[0m SGD (
[2m[36m(func pid=68837)[0m Parameter Group 0
[2m[36m(func pid=68837)[0m     dampening: 0
[2m[36m(func pid=68837)[0m     differentiable: False
[2m[36m(func pid=68837)[0m     foreach: None
[2m[36m(func pid=68837)[0m     lr: 0.0001
[2m[36m(func pid=68837)[0m     maximize: False
[2m[36m(func pid=68837)[0m     momentum: 0.9
[2m[36m(func pid=68837)[0m     nesterov: False
[2m[36m(func pid=68837)[0m     weight_decay: 0.0001
[2m[36m(func pid=68837)[0m )
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.3538 | Steps: 4 | Val loss: 0.2776 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3819 | Steps: 4 | Val loss: 0.3324 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3660 | Steps: 4 | Val loss: 0.4229 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 17:37:41 (running for 00:21:57.91)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.354 |  0.148 |                   76 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.397 |  0.176 |                   35 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.382 |  0.193 |                   33 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.14813309907913208
[2m[36m(func pid=50292)[0m mae:  0.10323040187358856
[2m[36m(func pid=50292)[0m rmse_per_class: [0.093, 0.224, 0.035, 0.277, 0.053, 0.154, 0.265, 0.116, 0.159, 0.107]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8984 | Steps: 4 | Val loss: 0.7043 | Batch size: 32 | lr: 0.0001 | Duration: 4.52s
[2m[36m(func pid=60251)[0m rmse: 0.17587749660015106
[2m[36m(func pid=60251)[0m mae:  0.10353664308786392
[2m[36m(func pid=60251)[0m rmse_per_class: [0.07, 0.219, 0.237, 0.308, 0.134, 0.175, 0.256, 0.114, 0.131, 0.115]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m rmse: 0.19103798270225525
[2m[36m(func pid=60747)[0m mae:  0.10597054660320282
[2m[36m(func pid=60747)[0m rmse_per_class: [0.091, 0.26, 0.126, 0.309, 0.124, 0.261, 0.258, 0.125, 0.138, 0.218]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.3575 | Steps: 4 | Val loss: 0.2769 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=68837)[0m rmse: 0.1825648844242096
[2m[36m(func pid=68837)[0m mae:  0.13435354828834534
[2m[36m(func pid=68837)[0m rmse_per_class: [0.117, 0.267, 0.107, 0.339, 0.112, 0.19, 0.294, 0.144, 0.144, 0.113]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3800 | Steps: 4 | Val loss: 0.3228 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 17:37:46 (running for 00:22:03.13)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.357 |  0.148 |                   77 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.176 |                   36 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.366 |  0.191 |                   34 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.898 |  0.183 |                    1 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.14808830618858337
[2m[36m(func pid=50292)[0m mae:  0.10336766391992569
[2m[36m(func pid=50292)[0m rmse_per_class: [0.093, 0.222, 0.036, 0.274, 0.053, 0.155, 0.268, 0.114, 0.157, 0.109]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4254 | Steps: 4 | Val loss: 0.3960 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.8933 | Steps: 4 | Val loss: 0.6956 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=60251)[0m rmse: 0.17394396662712097
[2m[36m(func pid=60251)[0m mae:  0.10220116376876831
[2m[36m(func pid=60251)[0m rmse_per_class: [0.072, 0.221, 0.169, 0.314, 0.142, 0.171, 0.3, 0.116, 0.13, 0.104]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m rmse: 0.18673042953014374
[2m[36m(func pid=60747)[0m mae:  0.10122279822826385
[2m[36m(func pid=60747)[0m rmse_per_class: [0.095, 0.26, 0.103, 0.305, 0.105, 0.223, 0.269, 0.13, 0.14, 0.238]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.3523 | Steps: 4 | Val loss: 0.2755 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=68837)[0m rmse: 0.18192900717258453
[2m[36m(func pid=68837)[0m mae:  0.13389915227890015
[2m[36m(func pid=68837)[0m rmse_per_class: [0.117, 0.266, 0.104, 0.339, 0.114, 0.19, 0.294, 0.141, 0.143, 0.112]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3815 | Steps: 4 | Val loss: 0.3195 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 17:37:51 (running for 00:22:08.33)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.352 |  0.148 |                   78 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.38  |  0.174 |                   37 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.425 |  0.187 |                   35 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.893 |  0.182 |                    2 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.14841046929359436
[2m[36m(func pid=50292)[0m mae:  0.10312353074550629
[2m[36m(func pid=50292)[0m rmse_per_class: [0.093, 0.223, 0.038, 0.276, 0.053, 0.154, 0.263, 0.117, 0.159, 0.108]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4216 | Steps: 4 | Val loss: 0.3964 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.8929 | Steps: 4 | Val loss: 0.6933 | Batch size: 32 | lr: 0.0001 | Duration: 3.13s
[2m[36m(func pid=60251)[0m rmse: 0.17303790152072906
[2m[36m(func pid=60251)[0m mae:  0.10189564526081085
[2m[36m(func pid=60251)[0m rmse_per_class: [0.073, 0.219, 0.132, 0.317, 0.156, 0.171, 0.315, 0.122, 0.13, 0.095]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m rmse: 0.1850603073835373
[2m[36m(func pid=60747)[0m mae:  0.10041501373052597
[2m[36m(func pid=60747)[0m rmse_per_class: [0.087, 0.255, 0.079, 0.325, 0.084, 0.191, 0.273, 0.137, 0.17, 0.25]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.3471 | Steps: 4 | Val loss: 0.2746 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=68837)[0m rmse: 0.18144717812538147
[2m[36m(func pid=68837)[0m mae:  0.13349995017051697
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.265, 0.103, 0.338, 0.113, 0.189, 0.294, 0.141, 0.142, 0.111]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3774 | Steps: 4 | Val loss: 0.3123 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 17:37:57 (running for 00:22:13.59)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.347 |  0.148 |                   79 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.173 |                   38 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.422 |  0.185 |                   36 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.893 |  0.181 |                    3 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.14841243624687195
[2m[36m(func pid=50292)[0m mae:  0.10310850292444229
[2m[36m(func pid=50292)[0m rmse_per_class: [0.093, 0.221, 0.04, 0.274, 0.053, 0.157, 0.264, 0.116, 0.158, 0.108]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3832 | Steps: 4 | Val loss: 0.3957 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8854 | Steps: 4 | Val loss: 0.6870 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=60251)[0m rmse: 0.1685340851545334
[2m[36m(func pid=60251)[0m mae:  0.09906180202960968
[2m[36m(func pid=60251)[0m rmse_per_class: [0.073, 0.221, 0.095, 0.313, 0.163, 0.167, 0.308, 0.124, 0.13, 0.09]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.3367 | Steps: 4 | Val loss: 0.2757 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=60747)[0m rmse: 0.17897184193134308
[2m[36m(func pid=60747)[0m mae:  0.09816977381706238
[2m[36m(func pid=60747)[0m rmse_per_class: [0.079, 0.261, 0.065, 0.312, 0.065, 0.19, 0.266, 0.141, 0.216, 0.194]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.18081703782081604
[2m[36m(func pid=68837)[0m mae:  0.13298657536506653
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.264, 0.101, 0.338, 0.112, 0.189, 0.294, 0.14, 0.142, 0.111]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3687 | Steps: 4 | Val loss: 0.3066 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 17:38:02 (running for 00:22:18.89)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.337 |  0.15  |                   80 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.377 |  0.169 |                   39 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.383 |  0.179 |                   37 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.885 |  0.181 |                    4 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.14976079761981964
[2m[36m(func pid=50292)[0m mae:  0.10420973598957062
[2m[36m(func pid=50292)[0m rmse_per_class: [0.099, 0.222, 0.043, 0.275, 0.053, 0.157, 0.266, 0.116, 0.156, 0.111]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3600 | Steps: 4 | Val loss: 0.4035 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=60251)[0m rmse: 0.16462936997413635
[2m[36m(func pid=60251)[0m mae:  0.09692354500293732
[2m[36m(func pid=60251)[0m rmse_per_class: [0.07, 0.221, 0.071, 0.313, 0.174, 0.16, 0.287, 0.123, 0.133, 0.092]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.8803 | Steps: 4 | Val loss: 0.6833 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.3339 | Steps: 4 | Val loss: 0.2732 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=60747)[0m rmse: 0.17497612535953522
[2m[36m(func pid=60747)[0m mae:  0.09932325780391693
[2m[36m(func pid=60747)[0m rmse_per_class: [0.142, 0.245, 0.049, 0.296, 0.056, 0.195, 0.264, 0.134, 0.224, 0.144]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.18051886558532715
[2m[36m(func pid=68837)[0m mae:  0.13271799683570862
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.264, 0.1, 0.338, 0.112, 0.189, 0.294, 0.14, 0.142, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3578 | Steps: 4 | Val loss: 0.2993 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 17:38:07 (running for 00:22:24.23)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.334 |  0.149 |                   81 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.369 |  0.165 |                   40 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.36  |  0.175 |                   38 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.88  |  0.181 |                    5 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.14865384995937347
[2m[36m(func pid=50292)[0m mae:  0.10323182493448257
[2m[36m(func pid=50292)[0m rmse_per_class: [0.097, 0.222, 0.047, 0.274, 0.053, 0.156, 0.264, 0.115, 0.154, 0.106]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4293 | Steps: 4 | Val loss: 0.4435 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=60251)[0m rmse: 0.15950995683670044
[2m[36m(func pid=60251)[0m mae:  0.09418979287147522
[2m[36m(func pid=60251)[0m rmse_per_class: [0.068, 0.221, 0.057, 0.306, 0.165, 0.159, 0.266, 0.123, 0.137, 0.093]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.8824 | Steps: 4 | Val loss: 0.6802 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.3363 | Steps: 4 | Val loss: 0.2722 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=60747)[0m rmse: 0.1790267676115036
[2m[36m(func pid=60747)[0m mae:  0.1059916615486145
[2m[36m(func pid=60747)[0m rmse_per_class: [0.214, 0.231, 0.045, 0.325, 0.056, 0.181, 0.254, 0.13, 0.237, 0.117]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.18031004071235657
[2m[36m(func pid=68837)[0m mae:  0.13253465294837952
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.263, 0.1, 0.337, 0.112, 0.189, 0.294, 0.14, 0.142, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3399 | Steps: 4 | Val loss: 0.2962 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 17:38:13 (running for 00:22:29.61)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.336 |  0.148 |                   82 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.358 |  0.16  |                   41 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.429 |  0.179 |                   39 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.882 |  0.18  |                    6 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.14811186492443085
[2m[36m(func pid=50292)[0m mae:  0.10246382653713226
[2m[36m(func pid=50292)[0m rmse_per_class: [0.093, 0.223, 0.048, 0.271, 0.053, 0.155, 0.264, 0.117, 0.15, 0.108]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4673 | Steps: 4 | Val loss: 0.4450 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=60251)[0m rmse: 0.15698134899139404
[2m[36m(func pid=60251)[0m mae:  0.09329308569431305
[2m[36m(func pid=60251)[0m rmse_per_class: [0.068, 0.225, 0.052, 0.305, 0.16, 0.161, 0.244, 0.122, 0.142, 0.091]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.8763 | Steps: 4 | Val loss: 0.6778 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.3313 | Steps: 4 | Val loss: 0.2719 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=60747)[0m rmse: 0.18587085604667664
[2m[36m(func pid=60747)[0m mae:  0.10875729471445084
[2m[36m(func pid=60747)[0m rmse_per_class: [0.182, 0.246, 0.045, 0.344, 0.056, 0.19, 0.264, 0.138, 0.273, 0.12]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.1801910251379013
[2m[36m(func pid=68837)[0m mae:  0.1324663758277893
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.262, 0.1, 0.338, 0.111, 0.189, 0.295, 0.14, 0.143, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3561 | Steps: 4 | Val loss: 0.2911 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 17:38:18 (running for 00:22:35.01)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.331 |  0.148 |                   83 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.34  |  0.157 |                   42 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.467 |  0.186 |                   40 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.876 |  0.18  |                    7 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.14808513224124908
[2m[36m(func pid=50292)[0m mae:  0.10232923924922943
[2m[36m(func pid=50292)[0m rmse_per_class: [0.089, 0.221, 0.052, 0.271, 0.053, 0.156, 0.263, 0.116, 0.149, 0.11]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3726 | Steps: 4 | Val loss: 0.4601 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=60251)[0m rmse: 0.1532747894525528
[2m[36m(func pid=60251)[0m mae:  0.0912460908293724
[2m[36m(func pid=60251)[0m rmse_per_class: [0.069, 0.23, 0.045, 0.296, 0.139, 0.167, 0.227, 0.117, 0.15, 0.093]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.8706 | Steps: 4 | Val loss: 0.6750 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.3157 | Steps: 4 | Val loss: 0.2715 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=60747)[0m rmse: 0.19507820904254913
[2m[36m(func pid=60747)[0m mae:  0.11503437906503677
[2m[36m(func pid=60747)[0m rmse_per_class: [0.097, 0.264, 0.046, 0.348, 0.056, 0.303, 0.28, 0.14, 0.271, 0.146]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.1800367534160614
[2m[36m(func pid=68837)[0m mae:  0.1323360800743103
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.262, 0.099, 0.338, 0.111, 0.189, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3400 | Steps: 4 | Val loss: 0.2892 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 17:38:23 (running for 00:22:40.13)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.316 |  0.148 |                   84 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.356 |  0.153 |                   43 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.373 |  0.195 |                   41 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.871 |  0.18  |                    8 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.14797037839889526
[2m[36m(func pid=50292)[0m mae:  0.10215070098638535
[2m[36m(func pid=50292)[0m rmse_per_class: [0.087, 0.221, 0.057, 0.27, 0.055, 0.156, 0.262, 0.113, 0.149, 0.11]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3821 | Steps: 4 | Val loss: 0.4518 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=60251)[0m rmse: 0.15090243518352509
[2m[36m(func pid=60251)[0m mae:  0.09102508425712585
[2m[36m(func pid=60251)[0m rmse_per_class: [0.067, 0.229, 0.036, 0.283, 0.121, 0.176, 0.224, 0.115, 0.161, 0.096]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.8661 | Steps: 4 | Val loss: 0.6731 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.3310 | Steps: 4 | Val loss: 0.2717 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=60747)[0m rmse: 0.20020310580730438
[2m[36m(func pid=60747)[0m mae:  0.11679140478372574
[2m[36m(func pid=60747)[0m rmse_per_class: [0.087, 0.278, 0.056, 0.337, 0.056, 0.353, 0.29, 0.137, 0.225, 0.182]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.18015635013580322
[2m[36m(func pid=68837)[0m mae:  0.1324017196893692
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.262, 0.099, 0.338, 0.112, 0.19, 0.295, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3489 | Steps: 4 | Val loss: 0.2938 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 17:38:29 (running for 00:22:45.57)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.331 |  0.148 |                   85 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.34  |  0.151 |                   44 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.382 |  0.2   |                   42 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.866 |  0.18  |                    9 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.14827068150043488
[2m[36m(func pid=50292)[0m mae:  0.10213311016559601
[2m[36m(func pid=50292)[0m rmse_per_class: [0.088, 0.221, 0.061, 0.272, 0.056, 0.155, 0.261, 0.112, 0.148, 0.109]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3651 | Steps: 4 | Val loss: 0.4195 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=60251)[0m rmse: 0.1526845246553421
[2m[36m(func pid=60251)[0m mae:  0.09362993389368057
[2m[36m(func pid=60251)[0m rmse_per_class: [0.073, 0.217, 0.034, 0.274, 0.116, 0.183, 0.241, 0.115, 0.177, 0.098]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.8580 | Steps: 4 | Val loss: 0.6678 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.3133 | Steps: 4 | Val loss: 0.2718 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=60747)[0m rmse: 0.1929299384355545
[2m[36m(func pid=60747)[0m mae:  0.10785307735204697
[2m[36m(func pid=60747)[0m rmse_per_class: [0.089, 0.282, 0.095, 0.325, 0.057, 0.248, 0.281, 0.142, 0.194, 0.216]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.18008799850940704
[2m[36m(func pid=68837)[0m mae:  0.1323283314704895
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.262, 0.099, 0.337, 0.112, 0.19, 0.295, 0.14, 0.142, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3403 | Steps: 4 | Val loss: 0.2985 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 17:38:34 (running for 00:22:50.75)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.313 |  0.148 |                   86 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.349 |  0.153 |                   45 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.365 |  0.193 |                   43 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.858 |  0.18  |                   10 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.14821413159370422
[2m[36m(func pid=50292)[0m mae:  0.10219721496105194
[2m[36m(func pid=50292)[0m rmse_per_class: [0.087, 0.221, 0.061, 0.273, 0.058, 0.155, 0.26, 0.111, 0.147, 0.109]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3899 | Steps: 4 | Val loss: 0.3937 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=60251)[0m rmse: 0.1552879512310028
[2m[36m(func pid=60251)[0m mae:  0.09599509090185165
[2m[36m(func pid=60251)[0m rmse_per_class: [0.084, 0.209, 0.03, 0.274, 0.103, 0.185, 0.254, 0.113, 0.198, 0.102]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.8568 | Steps: 4 | Val loss: 0.6654 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.3208 | Steps: 4 | Val loss: 0.2715 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=60747)[0m rmse: 0.1821739375591278
[2m[36m(func pid=60747)[0m mae:  0.10097476094961166
[2m[36m(func pid=60747)[0m rmse_per_class: [0.084, 0.263, 0.12, 0.309, 0.056, 0.18, 0.284, 0.13, 0.173, 0.222]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.18012256920337677
[2m[36m(func pid=68837)[0m mae:  0.1323813647031784
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.262, 0.099, 0.337, 0.112, 0.19, 0.295, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3215 | Steps: 4 | Val loss: 0.3061 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 17:38:39 (running for 00:22:55.91)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.321 |  0.148 |                   87 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.34  |  0.155 |                   46 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.39  |  0.182 |                   44 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.857 |  0.18  |                   11 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.14797106385231018
[2m[36m(func pid=50292)[0m mae:  0.10173444449901581
[2m[36m(func pid=50292)[0m rmse_per_class: [0.085, 0.222, 0.064, 0.272, 0.061, 0.154, 0.258, 0.111, 0.144, 0.109]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3803 | Steps: 4 | Val loss: 0.3943 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=60251)[0m rmse: 0.1569589078426361
[2m[36m(func pid=60251)[0m mae:  0.0981520563364029
[2m[36m(func pid=60251)[0m rmse_per_class: [0.079, 0.21, 0.026, 0.268, 0.093, 0.19, 0.275, 0.114, 0.206, 0.109]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.8537 | Steps: 4 | Val loss: 0.6622 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.3377 | Steps: 4 | Val loss: 0.2713 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=60747)[0m rmse: 0.17683325707912445
[2m[36m(func pid=60747)[0m mae:  0.1006588563323021
[2m[36m(func pid=60747)[0m rmse_per_class: [0.079, 0.24, 0.124, 0.303, 0.056, 0.194, 0.285, 0.134, 0.153, 0.199]
[2m[36m(func pid=60747)[0m 
== Status ==
Current time: 2024-01-07 17:38:44 (running for 00:23:01.11)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.321 |  0.148 |                   87 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.322 |  0.157 |                   47 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.38  |  0.177 |                   45 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.854 |  0.18  |                   12 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=68837)[0m rmse: 0.18022581934928894
[2m[36m(func pid=68837)[0m mae:  0.13247106969356537
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.262, 0.1, 0.337, 0.11, 0.19, 0.295, 0.14, 0.144, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.14745858311653137
[2m[36m(func pid=50292)[0m mae:  0.10094108432531357
[2m[36m(func pid=50292)[0m rmse_per_class: [0.084, 0.221, 0.063, 0.268, 0.063, 0.155, 0.259, 0.11, 0.142, 0.11]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3249 | Steps: 4 | Val loss: 0.3082 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3626 | Steps: 4 | Val loss: 0.3879 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=60251)[0m rmse: 0.15589472651481628
[2m[36m(func pid=60251)[0m mae:  0.09781154245138168
[2m[36m(func pid=60251)[0m rmse_per_class: [0.077, 0.208, 0.025, 0.261, 0.076, 0.182, 0.284, 0.115, 0.216, 0.114]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.3336 | Steps: 4 | Val loss: 0.2734 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.8413 | Steps: 4 | Val loss: 0.6583 | Batch size: 32 | lr: 0.0001 | Duration: 3.15s
[2m[36m(func pid=60747)[0m rmse: 0.17493215203285217
[2m[36m(func pid=60747)[0m mae:  0.10037218034267426
[2m[36m(func pid=60747)[0m rmse_per_class: [0.087, 0.231, 0.127, 0.295, 0.062, 0.19, 0.248, 0.186, 0.155, 0.169]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=50292)[0m rmse: 0.14926905930042267
[2m[36m(func pid=50292)[0m mae:  0.10176284611225128
[2m[36m(func pid=50292)[0m rmse_per_class: [0.082, 0.224, 0.072, 0.277, 0.071, 0.154, 0.255, 0.11, 0.14, 0.108]
[2m[36m(func pid=50292)[0m 
== Status ==
Current time: 2024-01-07 17:38:50 (running for 00:23:06.64)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.334 |  0.149 |                   89 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.325 |  0.156 |                   48 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.363 |  0.175 |                   46 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.854 |  0.18  |                   12 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=68837)[0m rmse: 0.18023258447647095
[2m[36m(func pid=68837)[0m mae:  0.13246174156665802
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.262, 0.1, 0.337, 0.11, 0.19, 0.295, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3220 | Steps: 4 | Val loss: 0.3115 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3346 | Steps: 4 | Val loss: 0.4006 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=60251)[0m rmse: 0.15770323574543
[2m[36m(func pid=60251)[0m mae:  0.09864865243434906
[2m[36m(func pid=60251)[0m rmse_per_class: [0.086, 0.209, 0.025, 0.26, 0.066, 0.172, 0.289, 0.124, 0.221, 0.126]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.3237 | Steps: 4 | Val loss: 0.2747 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.8384 | Steps: 4 | Val loss: 0.6534 | Batch size: 32 | lr: 0.0001 | Duration: 3.11s
[2m[36m(func pid=60747)[0m rmse: 0.17966726422309875
[2m[36m(func pid=60747)[0m mae:  0.10542652755975723
[2m[36m(func pid=60747)[0m rmse_per_class: [0.125, 0.224, 0.114, 0.3, 0.067, 0.18, 0.284, 0.216, 0.164, 0.123]
[2m[36m(func pid=60747)[0m 
== Status ==
Current time: 2024-01-07 17:38:55 (running for 00:23:11.90)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.324 |  0.15  |                   90 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.322 |  0.158 |                   49 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.335 |  0.18  |                   47 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.841 |  0.18  |                   13 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.15009358525276184
[2m[36m(func pid=50292)[0m mae:  0.1022317185997963
[2m[36m(func pid=50292)[0m rmse_per_class: [0.085, 0.225, 0.077, 0.281, 0.072, 0.153, 0.25, 0.109, 0.141, 0.107]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3255 | Steps: 4 | Val loss: 0.3132 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=68837)[0m rmse: 0.17993482947349548
[2m[36m(func pid=68837)[0m mae:  0.13223427534103394
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.11, 0.19, 0.295, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3467 | Steps: 4 | Val loss: 0.4272 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=60251)[0m rmse: 0.1602988988161087
[2m[36m(func pid=60251)[0m mae:  0.09997538477182388
[2m[36m(func pid=60251)[0m rmse_per_class: [0.098, 0.212, 0.025, 0.26, 0.065, 0.166, 0.289, 0.13, 0.22, 0.136]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.3314 | Steps: 4 | Val loss: 0.2747 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.8384 | Steps: 4 | Val loss: 0.6501 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=60747)[0m rmse: 0.18669219315052032
[2m[36m(func pid=60747)[0m mae:  0.1112692579627037
[2m[36m(func pid=60747)[0m rmse_per_class: [0.141, 0.217, 0.121, 0.306, 0.081, 0.224, 0.315, 0.168, 0.198, 0.096]
[2m[36m(func pid=60747)[0m 
== Status ==
Current time: 2024-01-07 17:39:00 (running for 00:23:17.28)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.331 |  0.15  |                   91 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.325 |  0.16  |                   50 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.347 |  0.187 |                   48 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.838 |  0.18  |                   14 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.15018081665039062
[2m[36m(func pid=50292)[0m mae:  0.10207764804363251
[2m[36m(func pid=50292)[0m rmse_per_class: [0.084, 0.227, 0.078, 0.279, 0.074, 0.154, 0.247, 0.11, 0.141, 0.108]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3436 | Steps: 4 | Val loss: 0.3107 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=68837)[0m rmse: 0.18004219233989716
[2m[36m(func pid=68837)[0m mae:  0.1323423832654953
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.262, 0.098, 0.337, 0.111, 0.19, 0.295, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3525 | Steps: 4 | Val loss: 0.4564 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=60251)[0m rmse: 0.1625225991010666
[2m[36m(func pid=60251)[0m mae:  0.10078129917383194
[2m[36m(func pid=60251)[0m rmse_per_class: [0.108, 0.217, 0.025, 0.262, 0.066, 0.16, 0.286, 0.146, 0.213, 0.141]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.3237 | Steps: 4 | Val loss: 0.2742 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.8357 | Steps: 4 | Val loss: 0.6463 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=60747)[0m rmse: 0.19748160243034363
[2m[36m(func pid=60747)[0m mae:  0.11784001439809799
[2m[36m(func pid=60747)[0m rmse_per_class: [0.11, 0.221, 0.126, 0.316, 0.101, 0.267, 0.314, 0.143, 0.282, 0.095]
[2m[36m(func pid=60747)[0m 
== Status ==
Current time: 2024-01-07 17:39:05 (running for 00:23:22.32)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.324 |  0.15  |                   92 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.163 |                   51 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.352 |  0.197 |                   49 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.838 |  0.18  |                   15 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.14969682693481445
[2m[36m(func pid=50292)[0m mae:  0.10146667063236237
[2m[36m(func pid=50292)[0m rmse_per_class: [0.079, 0.225, 0.082, 0.277, 0.077, 0.156, 0.243, 0.11, 0.14, 0.108]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3141 | Steps: 4 | Val loss: 0.3053 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=68837)[0m rmse: 0.18000462651252747
[2m[36m(func pid=68837)[0m mae:  0.1322900652885437
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.111, 0.19, 0.295, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3951 | Steps: 4 | Val loss: 0.4581 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=60251)[0m rmse: 0.16335001587867737
[2m[36m(func pid=60251)[0m mae:  0.10063354671001434
[2m[36m(func pid=60251)[0m rmse_per_class: [0.118, 0.218, 0.026, 0.265, 0.063, 0.159, 0.278, 0.157, 0.205, 0.144]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.3279 | Steps: 4 | Val loss: 0.2734 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.8241 | Steps: 4 | Val loss: 0.6432 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=60747)[0m rmse: 0.20343251526355743
[2m[36m(func pid=60747)[0m mae:  0.11959972232580185
[2m[36m(func pid=60747)[0m rmse_per_class: [0.083, 0.237, 0.103, 0.323, 0.137, 0.276, 0.286, 0.137, 0.342, 0.111]
[2m[36m(func pid=60747)[0m 
== Status ==
Current time: 2024-01-07 17:39:11 (running for 00:23:27.74)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.328 |  0.149 |                   93 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.314 |  0.163 |                   52 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.395 |  0.203 |                   50 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.836 |  0.18  |                   16 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.14858274161815643
[2m[36m(func pid=50292)[0m mae:  0.10061205923557281
[2m[36m(func pid=50292)[0m rmse_per_class: [0.075, 0.226, 0.08, 0.278, 0.077, 0.157, 0.237, 0.11, 0.141, 0.106]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3458 | Steps: 4 | Val loss: 0.3035 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=68837)[0m rmse: 0.17996731400489807
[2m[36m(func pid=68837)[0m mae:  0.13226398825645447
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.11, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3636 | Steps: 4 | Val loss: 0.4265 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=60251)[0m rmse: 0.16474702954292297
[2m[36m(func pid=60251)[0m mae:  0.10091181844472885
[2m[36m(func pid=60251)[0m rmse_per_class: [0.109, 0.222, 0.027, 0.271, 0.064, 0.16, 0.267, 0.17, 0.201, 0.157]
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.3282 | Steps: 4 | Val loss: 0.2743 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.8247 | Steps: 4 | Val loss: 0.6402 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=60747)[0m rmse: 0.19703610241413116
[2m[36m(func pid=60747)[0m mae:  0.11195238679647446
[2m[36m(func pid=60747)[0m rmse_per_class: [0.081, 0.24, 0.099, 0.323, 0.173, 0.221, 0.257, 0.14, 0.314, 0.122]
[2m[36m(func pid=60747)[0m 
== Status ==
Current time: 2024-01-07 17:39:16 (running for 00:23:33.03)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.328 |  0.149 |                   94 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.346 |  0.165 |                   53 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.364 |  0.197 |                   51 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.824 |  0.18  |                   17 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.14929552376270294
[2m[36m(func pid=50292)[0m mae:  0.10078442096710205
[2m[36m(func pid=50292)[0m rmse_per_class: [0.075, 0.224, 0.082, 0.278, 0.084, 0.158, 0.236, 0.11, 0.14, 0.106]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3171 | Steps: 4 | Val loss: 0.3013 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=68837)[0m rmse: 0.17984287440776825
[2m[36m(func pid=68837)[0m mae:  0.1321604698896408
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.11, 0.189, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3613 | Steps: 4 | Val loss: 0.3988 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.3220 | Steps: 4 | Val loss: 0.2744 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=60251)[0m rmse: 0.16362954676151276
[2m[36m(func pid=60251)[0m mae:  0.09958672523498535
[2m[36m(func pid=60251)[0m rmse_per_class: [0.106, 0.22, 0.026, 0.276, 0.06, 0.162, 0.252, 0.172, 0.191, 0.172]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.8152 | Steps: 4 | Val loss: 0.6323 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=60747)[0m rmse: 0.18813739717006683
[2m[36m(func pid=60747)[0m mae:  0.10541621595621109
[2m[36m(func pid=60747)[0m rmse_per_class: [0.083, 0.239, 0.073, 0.322, 0.184, 0.201, 0.288, 0.142, 0.217, 0.132]
[2m[36m(func pid=60747)[0m 
== Status ==
Current time: 2024-01-07 17:39:21 (running for 00:23:38.46)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.322 |  0.15  |                   95 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.317 |  0.164 |                   54 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.361 |  0.188 |                   52 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.825 |  0.18  |                   18 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.1495077759027481
[2m[36m(func pid=50292)[0m mae:  0.10063543170690536
[2m[36m(func pid=50292)[0m rmse_per_class: [0.073, 0.223, 0.084, 0.278, 0.087, 0.16, 0.234, 0.11, 0.138, 0.108]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3186 | Steps: 4 | Val loss: 0.3025 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=68837)[0m rmse: 0.17984849214553833
[2m[36m(func pid=68837)[0m mae:  0.13218800723552704
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.109, 0.189, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3471 | Steps: 4 | Val loss: 0.3723 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.3277 | Steps: 4 | Val loss: 0.2738 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=60251)[0m rmse: 0.1624516248703003
[2m[36m(func pid=60251)[0m mae:  0.09825938194990158
[2m[36m(func pid=60251)[0m rmse_per_class: [0.092, 0.221, 0.026, 0.283, 0.057, 0.162, 0.237, 0.175, 0.182, 0.187]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.8143 | Steps: 4 | Val loss: 0.6298 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 17:39:27 (running for 00:23:43.52)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.322 |  0.15  |                   95 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.319 |  0.162 |                   55 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.347 |  0.178 |                   53 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.815 |  0.18  |                   19 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.1481899917125702
[2m[36m(func pid=50292)[0m mae:  0.09935855865478516
[2m[36m(func pid=50292)[0m rmse_per_class: [0.074, 0.225, 0.086, 0.28, 0.085, 0.158, 0.228, 0.11, 0.136, 0.1]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m rmse: 0.17841748893260956
[2m[36m(func pid=60747)[0m mae:  0.09975305199623108
[2m[36m(func pid=60747)[0m rmse_per_class: [0.083, 0.237, 0.054, 0.306, 0.168, 0.204, 0.264, 0.163, 0.165, 0.141]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3449 | Steps: 4 | Val loss: 0.3052 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=68837)[0m rmse: 0.17983761429786682
[2m[36m(func pid=68837)[0m mae:  0.13216006755828857
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.11, 0.189, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.3315 | Steps: 4 | Val loss: 0.2739 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3362 | Steps: 4 | Val loss: 0.3706 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=60251)[0m rmse: 0.1620948314666748
[2m[36m(func pid=60251)[0m mae:  0.09753315895795822
[2m[36m(func pid=60251)[0m rmse_per_class: [0.092, 0.225, 0.026, 0.292, 0.053, 0.163, 0.228, 0.175, 0.173, 0.194]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.8138 | Steps: 4 | Val loss: 0.6279 | Batch size: 32 | lr: 0.0001 | Duration: 3.10s
[2m[36m(func pid=50292)[0m rmse: 0.14820322394371033
[2m[36m(func pid=50292)[0m mae:  0.09901987016201019
[2m[36m(func pid=50292)[0m rmse_per_class: [0.071, 0.224, 0.09, 0.28, 0.09, 0.158, 0.226, 0.109, 0.135, 0.099]
[2m[36m(func pid=50292)[0m 
== Status ==
Current time: 2024-01-07 17:39:32 (running for 00:23:48.86)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.331 |  0.148 |                   97 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.345 |  0.162 |                   56 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.347 |  0.178 |                   53 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.814 |  0.18  |                   20 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=60747)[0m rmse: 0.1779010146856308
[2m[36m(func pid=60747)[0m mae:  0.10137411206960678
[2m[36m(func pid=60747)[0m rmse_per_class: [0.087, 0.238, 0.038, 0.308, 0.127, 0.206, 0.262, 0.222, 0.154, 0.138]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3236 | Steps: 4 | Val loss: 0.3073 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=68837)[0m rmse: 0.1799541860818863
[2m[36m(func pid=68837)[0m mae:  0.13221828639507294
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.111, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.3279 | Steps: 4 | Val loss: 0.2745 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=60251)[0m rmse: 0.16097377240657806
[2m[36m(func pid=60251)[0m mae:  0.09673340618610382
[2m[36m(func pid=60251)[0m rmse_per_class: [0.088, 0.225, 0.027, 0.299, 0.054, 0.168, 0.238, 0.151, 0.169, 0.191]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3458 | Steps: 4 | Val loss: 0.3905 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.8042 | Steps: 4 | Val loss: 0.6242 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 17:39:37 (running for 00:23:54.06)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.328 |  0.149 |                   98 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.324 |  0.161 |                   57 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.336 |  0.178 |                   54 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.814 |  0.18  |                   21 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.14901798963546753
[2m[36m(func pid=50292)[0m mae:  0.09939033538103104
[2m[36m(func pid=50292)[0m rmse_per_class: [0.07, 0.225, 0.087, 0.281, 0.094, 0.158, 0.225, 0.109, 0.135, 0.105]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60747)[0m rmse: 0.1831037849187851
[2m[36m(func pid=60747)[0m mae:  0.1068805679678917
[2m[36m(func pid=60747)[0m rmse_per_class: [0.117, 0.235, 0.037, 0.305, 0.09, 0.21, 0.301, 0.247, 0.146, 0.143]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3132 | Steps: 4 | Val loss: 0.3066 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=68837)[0m rmse: 0.1799170970916748
[2m[36m(func pid=68837)[0m mae:  0.13218484818935394
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.111, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.15910139679908752
[2m[36m(func pid=60251)[0m mae:  0.09569719433784485
[2m[36m(func pid=60251)[0m rmse_per_class: [0.084, 0.22, 0.027, 0.307, 0.054, 0.169, 0.251, 0.135, 0.165, 0.179]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.3374 | Steps: 4 | Val loss: 0.2748 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3456 | Steps: 4 | Val loss: 0.3974 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.8042 | Steps: 4 | Val loss: 0.6195 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 17:39:43 (running for 00:23:59.56)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00009 | RUNNING    | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.337 |  0.149 |                   99 |
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.313 |  0.159 |                   58 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.346 |  0.183 |                   55 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.804 |  0.18  |                   22 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.14904260635375977
[2m[36m(func pid=50292)[0m mae:  0.09947193413972855
[2m[36m(func pid=50292)[0m rmse_per_class: [0.067, 0.227, 0.081, 0.287, 0.106, 0.156, 0.224, 0.109, 0.134, 0.099]
[2m[36m(func pid=50292)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3712 | Steps: 4 | Val loss: 0.3085 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=60747)[0m rmse: 0.18332570791244507
[2m[36m(func pid=60747)[0m mae:  0.1085771769285202
[2m[36m(func pid=60747)[0m rmse_per_class: [0.155, 0.22, 0.037, 0.304, 0.063, 0.264, 0.307, 0.199, 0.141, 0.143]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.1798643171787262
[2m[36m(func pid=68837)[0m mae:  0.1321403682231903
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.338, 0.11, 0.189, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.15885809063911438
[2m[36m(func pid=60251)[0m mae:  0.09598962217569351
[2m[36m(func pid=60251)[0m rmse_per_class: [0.075, 0.219, 0.027, 0.315, 0.054, 0.168, 0.27, 0.134, 0.158, 0.169]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=50292)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.3187 | Steps: 4 | Val loss: 0.2759 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3558 | Steps: 4 | Val loss: 0.3960 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.7977 | Steps: 4 | Val loss: 0.6149 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 17:39:48 (running for 00:24:04.68)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (11 PENDING, 3 RUNNING, 10 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.371 |  0.159 |                   59 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.346 |  0.183 |                   56 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.804 |  0.18  |                   23 |
| train_01e98_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)


[2m[36m(func pid=50292)[0m rmse: 0.1501476913690567
[2m[36m(func pid=50292)[0m mae:  0.10006020963191986
[2m[36m(func pid=50292)[0m rmse_per_class: [0.068, 0.226, 0.082, 0.289, 0.111, 0.157, 0.225, 0.108, 0.134, 0.103]
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3089 | Steps: 4 | Val loss: 0.3093 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=60747)[0m rmse: 0.18356651067733765
[2m[36m(func pid=60747)[0m mae:  0.10919495671987534
[2m[36m(func pid=60747)[0m rmse_per_class: [0.157, 0.228, 0.035, 0.308, 0.054, 0.343, 0.281, 0.146, 0.137, 0.146]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17960616946220398
[2m[36m(func pid=68837)[0m mae:  0.1319158524274826
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.26, 0.098, 0.337, 0.111, 0.19, 0.294, 0.14, 0.143, 0.108]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.15832176804542542
[2m[36m(func pid=60251)[0m mae:  0.09594087302684784
[2m[36m(func pid=60251)[0m rmse_per_class: [0.072, 0.216, 0.027, 0.321, 0.053, 0.165, 0.276, 0.128, 0.161, 0.166]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3268 | Steps: 4 | Val loss: 0.3681 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.7949 | Steps: 4 | Val loss: 0.6132 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3207 | Steps: 4 | Val loss: 0.3046 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=60747)[0m rmse: 0.17238618433475494
[2m[36m(func pid=60747)[0m mae:  0.099108025431633
[2m[36m(func pid=60747)[0m rmse_per_class: [0.122, 0.236, 0.043, 0.303, 0.054, 0.276, 0.263, 0.13, 0.146, 0.15]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17962110042572021
[2m[36m(func pid=68837)[0m mae:  0.13194778561592102
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.26, 0.098, 0.337, 0.11, 0.19, 0.294, 0.14, 0.143, 0.108]
[2m[36m(func pid=60251)[0m rmse: 0.15573740005493164
[2m[36m(func pid=60251)[0m mae:  0.09454040229320526
[2m[36m(func pid=60251)[0m rmse_per_class: [0.069, 0.214, 0.027, 0.321, 0.054, 0.162, 0.272, 0.123, 0.16, 0.156]
== Status ==
Current time: 2024-01-07 17:39:54 (running for 00:24:10.98)
Memory usage on this node: 22.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.309 |  0.158 |                   60 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.327 |  0.172 |                   58 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.798 |  0.18  |                   24 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=74973)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=74973)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=74973)[0m Configuration completed!
[2m[36m(func pid=74973)[0m New optimizer parameters:
[2m[36m(func pid=74973)[0m SGD (
[2m[36m(func pid=74973)[0m Parameter Group 0
[2m[36m(func pid=74973)[0m     dampening: 0
[2m[36m(func pid=74973)[0m     differentiable: False
[2m[36m(func pid=74973)[0m     foreach: None
[2m[36m(func pid=74973)[0m     lr: 0.001
[2m[36m(func pid=74973)[0m     maximize: False
[2m[36m(func pid=74973)[0m     momentum: 0.9
[2m[36m(func pid=74973)[0m     nesterov: False
[2m[36m(func pid=74973)[0m     weight_decay: 0.0001
[2m[36m(func pid=74973)[0m )
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3351 | Steps: 4 | Val loss: 0.3696 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3396 | Steps: 4 | Val loss: 0.3010 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.7906 | Steps: 4 | Val loss: 0.6107 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
== Status ==
Current time: 2024-01-07 17:40:00 (running for 00:24:16.46)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.321 |  0.156 |                   61 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.335 |  0.174 |                   59 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.795 |  0.18  |                   25 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=60747)[0m rmse: 0.17422717809677124
[2m[36m(func pid=60747)[0m mae:  0.09876091778278351
[2m[36m(func pid=60747)[0m rmse_per_class: [0.09, 0.238, 0.06, 0.3, 0.054, 0.196, 0.341, 0.131, 0.171, 0.162]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8959 | Steps: 4 | Val loss: 0.6955 | Batch size: 32 | lr: 0.001 | Duration: 4.48s
[2m[36m(func pid=60251)[0m rmse: 0.1539936065673828
[2m[36m(func pid=60251)[0m mae:  0.09345591068267822
[2m[36m(func pid=60251)[0m rmse_per_class: [0.069, 0.216, 0.03, 0.321, 0.055, 0.16, 0.261, 0.126, 0.158, 0.144]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17972064018249512
[2m[36m(func pid=68837)[0m mae:  0.13204535841941833
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.261, 0.098, 0.337, 0.11, 0.189, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3094 | Steps: 4 | Val loss: 0.3669 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=74973)[0m rmse: 0.18257854878902435
[2m[36m(func pid=74973)[0m mae:  0.1343919336795807
[2m[36m(func pid=74973)[0m rmse_per_class: [0.117, 0.267, 0.107, 0.339, 0.113, 0.19, 0.294, 0.144, 0.144, 0.112]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3087 | Steps: 4 | Val loss: 0.2948 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.7853 | Steps: 4 | Val loss: 0.6073 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=60747)[0m rmse: 0.17503000795841217
[2m[36m(func pid=60747)[0m mae:  0.09800461679697037
[2m[36m(func pid=60747)[0m rmse_per_class: [0.081, 0.234, 0.081, 0.295, 0.055, 0.202, 0.305, 0.141, 0.211, 0.145]
== Status ==
Current time: 2024-01-07 17:40:05 (running for 00:24:21.76)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.34  |  0.154 |                   62 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.309 |  0.175 |                   60 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.791 |  0.18  |                   26 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.896 |  0.183 |                    1 |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.8770 | Steps: 4 | Val loss: 0.6720 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=60251)[0m rmse: 0.15149147808551788
[2m[36m(func pid=60251)[0m mae:  0.09199535101652145
[2m[36m(func pid=60251)[0m rmse_per_class: [0.07, 0.223, 0.032, 0.315, 0.053, 0.165, 0.236, 0.128, 0.163, 0.131]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17976535856723785
[2m[36m(func pid=68837)[0m mae:  0.13210377097129822
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.261, 0.098, 0.338, 0.11, 0.189, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3469 | Steps: 4 | Val loss: 0.3851 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=74973)[0m rmse: 0.1816037893295288
[2m[36m(func pid=74973)[0m mae:  0.1336517184972763
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.266, 0.104, 0.339, 0.112, 0.19, 0.293, 0.141, 0.143, 0.111]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3097 | Steps: 4 | Val loss: 0.2903 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.7833 | Steps: 4 | Val loss: 0.6045 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 17:40:10 (running for 00:24:27.32)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.309 |  0.151 |                   63 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.347 |  0.182 |                   61 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.785 |  0.18  |                   27 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.877 |  0.182 |                    2 |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=60747)[0m rmse: 0.18208090960979462
[2m[36m(func pid=60747)[0m mae:  0.10195986926555634
[2m[36m(func pid=60747)[0m rmse_per_class: [0.079, 0.254, 0.098, 0.285, 0.055, 0.209, 0.265, 0.173, 0.268, 0.135]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.8470 | Steps: 4 | Val loss: 0.6424 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=60251)[0m rmse: 0.14984570443630219
[2m[36m(func pid=60251)[0m mae:  0.09109561145305634
[2m[36m(func pid=60251)[0m rmse_per_class: [0.07, 0.227, 0.032, 0.308, 0.052, 0.177, 0.229, 0.128, 0.157, 0.118]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17969389259815216
[2m[36m(func pid=68837)[0m mae:  0.13204815983772278
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.261, 0.098, 0.338, 0.109, 0.189, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3673 | Steps: 4 | Val loss: 0.4061 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=74973)[0m rmse: 0.180660679936409
[2m[36m(func pid=74973)[0m mae:  0.1328851282596588
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.265, 0.102, 0.338, 0.111, 0.189, 0.294, 0.14, 0.142, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3047 | Steps: 4 | Val loss: 0.2885 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 17:40:16 (running for 00:24:32.61)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.31  |  0.15  |                   64 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.367 |  0.185 |                   62 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.783 |  0.18  |                   28 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.847 |  0.181 |                    3 |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=60747)[0m rmse: 0.1851116418838501
[2m[36m(func pid=60747)[0m mae:  0.10635137557983398
[2m[36m(func pid=60747)[0m rmse_per_class: [0.081, 0.243, 0.086, 0.276, 0.055, 0.207, 0.291, 0.204, 0.283, 0.125]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.7831 | Steps: 4 | Val loss: 0.6035 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8160 | Steps: 4 | Val loss: 0.6161 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=60251)[0m rmse: 0.15028412640094757
[2m[36m(func pid=60251)[0m mae:  0.0915624350309372
[2m[36m(func pid=60251)[0m rmse_per_class: [0.07, 0.228, 0.039, 0.302, 0.052, 0.183, 0.23, 0.13, 0.158, 0.11]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17985355854034424
[2m[36m(func pid=68837)[0m mae:  0.13215427100658417
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.261, 0.099, 0.337, 0.11, 0.189, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3179 | Steps: 4 | Val loss: 0.3961 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=74973)[0m rmse: 0.18044915795326233
[2m[36m(func pid=74973)[0m mae:  0.13270506262779236
[2m[36m(func pid=74973)[0m rmse_per_class: [0.115, 0.264, 0.102, 0.337, 0.109, 0.19, 0.294, 0.139, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2936 | Steps: 4 | Val loss: 0.2872 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.7734 | Steps: 4 | Val loss: 0.5994 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 17:40:21 (running for 00:24:38.01)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.305 |  0.15  |                   65 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.318 |  0.178 |                   63 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.783 |  0.18  |                   29 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.816 |  0.18  |                    4 |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=60747)[0m rmse: 0.1776895821094513
[2m[36m(func pid=60747)[0m mae:  0.1033833846449852
[2m[36m(func pid=60747)[0m rmse_per_class: [0.1, 0.23, 0.075, 0.281, 0.055, 0.194, 0.282, 0.186, 0.262, 0.113]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7810 | Steps: 4 | Val loss: 0.5897 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=60251)[0m rmse: 0.15137317776679993
[2m[36m(func pid=60251)[0m mae:  0.09271536767482758
[2m[36m(func pid=60251)[0m rmse_per_class: [0.071, 0.225, 0.043, 0.291, 0.052, 0.197, 0.238, 0.13, 0.162, 0.105]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17970745265483856
[2m[36m(func pid=68837)[0m mae:  0.13203196227550507
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.26, 0.098, 0.337, 0.11, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3276 | Steps: 4 | Val loss: 0.3871 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=74973)[0m rmse: 0.1801101714372635
[2m[36m(func pid=74973)[0m mae:  0.13241225481033325
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.263, 0.1, 0.337, 0.109, 0.189, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3048 | Steps: 4 | Val loss: 0.2877 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.7735 | Steps: 4 | Val loss: 0.5959 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
== Status ==
Current time: 2024-01-07 17:40:26 (running for 00:24:43.42)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.294 |  0.151 |                   66 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.328 |  0.173 |                   64 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.773 |  0.18  |                   30 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.781 |  0.18  |                    5 |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=60747)[0m rmse: 0.17261503636837006
[2m[36m(func pid=60747)[0m mae:  0.10029418766498566
[2m[36m(func pid=60747)[0m rmse_per_class: [0.128, 0.22, 0.078, 0.285, 0.054, 0.216, 0.259, 0.153, 0.22, 0.112]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.7472 | Steps: 4 | Val loss: 0.5647 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=60251)[0m rmse: 0.15191075205802917
[2m[36m(func pid=60251)[0m mae:  0.09393133968114853
[2m[36m(func pid=60251)[0m rmse_per_class: [0.072, 0.222, 0.048, 0.282, 0.052, 0.207, 0.254, 0.127, 0.158, 0.097]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17961135506629944
[2m[36m(func pid=68837)[0m mae:  0.13195976614952087
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.26, 0.098, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3201 | Steps: 4 | Val loss: 0.3925 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=74973)[0m rmse: 0.17994390428066254
[2m[36m(func pid=74973)[0m mae:  0.13224953413009644
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.263, 0.099, 0.337, 0.109, 0.189, 0.295, 0.14, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3350 | Steps: 4 | Val loss: 0.2914 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.7669 | Steps: 4 | Val loss: 0.5935 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 17:40:32 (running for 00:24:48.81)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.305 |  0.152 |                   67 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.32  |  0.174 |                   65 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.773 |  0.18  |                   31 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.747 |  0.18  |                    6 |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=60747)[0m rmse: 0.17448338866233826
[2m[36m(func pid=60747)[0m mae:  0.10111328214406967
[2m[36m(func pid=60747)[0m rmse_per_class: [0.137, 0.233, 0.08, 0.302, 0.056, 0.255, 0.247, 0.135, 0.183, 0.116]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.7136 | Steps: 4 | Val loss: 0.5374 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=60251)[0m rmse: 0.1537536084651947
[2m[36m(func pid=60251)[0m mae:  0.0957607850432396
[2m[36m(func pid=60251)[0m rmse_per_class: [0.075, 0.217, 0.045, 0.277, 0.05, 0.222, 0.264, 0.129, 0.164, 0.095]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17958873510360718
[2m[36m(func pid=68837)[0m mae:  0.13192670047283173
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.26, 0.098, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=74973)[0m rmse: 0.17959460616111755
[2m[36m(func pid=74973)[0m mae:  0.13195984065532684
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.262, 0.097, 0.337, 0.108, 0.189, 0.294, 0.141, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3331 | Steps: 4 | Val loss: 0.3803 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3161 | Steps: 4 | Val loss: 0.2908 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.7630 | Steps: 4 | Val loss: 0.5911 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 17:40:37 (running for 00:24:54.23)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.335 |  0.154 |                   68 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.333 |  0.177 |                   66 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.767 |  0.18  |                   32 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.714 |  0.18  |                    7 |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=60747)[0m rmse: 0.17714115977287292
[2m[36m(func pid=60747)[0m mae:  0.10050978511571884
[2m[36m(func pid=60747)[0m rmse_per_class: [0.112, 0.244, 0.079, 0.311, 0.078, 0.237, 0.264, 0.141, 0.176, 0.131]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.6854 | Steps: 4 | Val loss: 0.5155 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=60251)[0m rmse: 0.15400494635105133
[2m[36m(func pid=60251)[0m mae:  0.09581342339515686
[2m[36m(func pid=60251)[0m rmse_per_class: [0.073, 0.211, 0.053, 0.271, 0.05, 0.216, 0.269, 0.129, 0.173, 0.094]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17969326674938202
[2m[36m(func pid=68837)[0m mae:  0.13201844692230225
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.261, 0.098, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=74973)[0m rmse: 0.1793639361858368
[2m[36m(func pid=74973)[0m mae:  0.13174423575401306
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.261, 0.097, 0.337, 0.107, 0.189, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3467 | Steps: 4 | Val loss: 0.3752 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2974 | Steps: 4 | Val loss: 0.2894 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.7583 | Steps: 4 | Val loss: 0.5876 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.6591 | Steps: 4 | Val loss: 0.4958 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 17:40:43 (running for 00:24:59.58)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.316 |  0.154 |                   69 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.347 |  0.186 |                   67 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.763 |  0.18  |                   33 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.685 |  0.179 |                    8 |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=60747)[0m rmse: 0.18594418466091156
[2m[36m(func pid=60747)[0m mae:  0.10084053128957748
[2m[36m(func pid=60747)[0m rmse_per_class: [0.092, 0.246, 0.094, 0.311, 0.139, 0.197, 0.259, 0.167, 0.195, 0.16]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.1531887948513031
[2m[36m(func pid=60251)[0m mae:  0.09549366682767868
[2m[36m(func pid=60251)[0m rmse_per_class: [0.069, 0.203, 0.063, 0.27, 0.053, 0.199, 0.274, 0.127, 0.183, 0.091]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17966501414775848
[2m[36m(func pid=68837)[0m mae:  0.13195522129535675
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.26, 0.098, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=74973)[0m rmse: 0.17921850085258484
[2m[36m(func pid=74973)[0m mae:  0.13167552649974823
[2m[36m(func pid=74973)[0m rmse_per_class: [0.115, 0.261, 0.096, 0.336, 0.107, 0.189, 0.294, 0.14, 0.144, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3137 | Steps: 4 | Val loss: 0.3912 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3050 | Steps: 4 | Val loss: 0.2905 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.7545 | Steps: 4 | Val loss: 0.5857 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.6327 | Steps: 4 | Val loss: 0.4787 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 17:40:48 (running for 00:25:04.94)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.297 |  0.153 |                   70 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.314 |  0.194 |                   68 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.758 |  0.18  |                   34 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.659 |  0.179 |                    9 |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=60747)[0m rmse: 0.19433611631393433
[2m[36m(func pid=60747)[0m mae:  0.10500659048557281
[2m[36m(func pid=60747)[0m rmse_per_class: [0.081, 0.263, 0.09, 0.301, 0.173, 0.198, 0.255, 0.205, 0.195, 0.183]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.15380141139030457
[2m[36m(func pid=60251)[0m mae:  0.09566069394350052
[2m[36m(func pid=60251)[0m rmse_per_class: [0.067, 0.201, 0.072, 0.273, 0.06, 0.186, 0.276, 0.124, 0.188, 0.09]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=74973)[0m rmse: 0.17913852632045746
[2m[36m(func pid=74973)[0m mae:  0.13168156147003174
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.261, 0.094, 0.336, 0.107, 0.189, 0.294, 0.139, 0.144, 0.112]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17958475649356842
[2m[36m(func pid=68837)[0m mae:  0.13188055157661438
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.26, 0.098, 0.337, 0.109, 0.189, 0.294, 0.14, 0.142, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3173 | Steps: 4 | Val loss: 0.4034 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2923 | Steps: 4 | Val loss: 0.2897 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.6103 | Steps: 4 | Val loss: 0.4630 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.7503 | Steps: 4 | Val loss: 0.5830 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 17:40:53 (running for 00:25:10.26)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.305 |  0.154 |                   71 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.317 |  0.193 |                   69 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.754 |  0.18  |                   35 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.633 |  0.179 |                   10 |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=60747)[0m rmse: 0.1933574229478836
[2m[36m(func pid=60747)[0m mae:  0.10745520889759064
[2m[36m(func pid=60747)[0m rmse_per_class: [0.083, 0.282, 0.073, 0.293, 0.165, 0.214, 0.263, 0.21, 0.181, 0.171]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.15462706983089447
[2m[36m(func pid=60251)[0m mae:  0.09549123793840408
[2m[36m(func pid=60251)[0m rmse_per_class: [0.065, 0.199, 0.076, 0.27, 0.062, 0.174, 0.27, 0.128, 0.205, 0.098]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=74973)[0m rmse: 0.17893043160438538
[2m[36m(func pid=74973)[0m mae:  0.13142438232898712
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.26, 0.094, 0.336, 0.106, 0.189, 0.294, 0.14, 0.143, 0.111]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17951612174510956
[2m[36m(func pid=68837)[0m mae:  0.13182829320430756
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.261, 0.098, 0.337, 0.109, 0.19, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3735 | Steps: 4 | Val loss: 0.3926 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2965 | Steps: 4 | Val loss: 0.2877 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.5903 | Steps: 4 | Val loss: 0.4484 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 17:40:59 (running for 00:25:15.85)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.292 |  0.155 |                   72 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.374 |  0.185 |                   70 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.75  |  0.18  |                   36 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.61  |  0.179 |                   11 |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=60747)[0m rmse: 0.18465834856033325
[2m[36m(func pid=60747)[0m mae:  0.10432253777980804
[2m[36m(func pid=60747)[0m rmse_per_class: [0.095, 0.255, 0.061, 0.288, 0.147, 0.215, 0.256, 0.197, 0.176, 0.157]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.7470 | Steps: 4 | Val loss: 0.5802 | Batch size: 32 | lr: 0.0001 | Duration: 3.20s
[2m[36m(func pid=60251)[0m rmse: 0.15545248985290527
[2m[36m(func pid=60251)[0m mae:  0.09513159096240997
[2m[36m(func pid=60251)[0m rmse_per_class: [0.065, 0.2, 0.088, 0.27, 0.073, 0.17, 0.259, 0.128, 0.2, 0.101]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=74973)[0m rmse: 0.17860308289527893
[2m[36m(func pid=74973)[0m mae:  0.13114067912101746
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.26, 0.093, 0.336, 0.106, 0.189, 0.293, 0.14, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17959748208522797
[2m[36m(func pid=68837)[0m mae:  0.13189680874347687
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.261, 0.099, 0.337, 0.108, 0.19, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3841 | Steps: 4 | Val loss: 0.3706 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2935 | Steps: 4 | Val loss: 0.2897 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.5729 | Steps: 4 | Val loss: 0.4329 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.7503 | Steps: 4 | Val loss: 0.5771 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 17:41:04 (running for 00:25:21.32)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.296 |  0.155 |                   73 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.384 |  0.17  |                   71 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.747 |  0.18  |                   37 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.59  |  0.179 |                   12 |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=60747)[0m rmse: 0.1698240339756012
[2m[36m(func pid=60747)[0m mae:  0.09742383658885956
[2m[36m(func pid=60747)[0m rmse_per_class: [0.106, 0.228, 0.057, 0.275, 0.107, 0.206, 0.24, 0.163, 0.181, 0.136]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=60251)[0m rmse: 0.1567489057779312
[2m[36m(func pid=60251)[0m mae:  0.09536776691675186
[2m[36m(func pid=60251)[0m rmse_per_class: [0.065, 0.206, 0.082, 0.267, 0.077, 0.167, 0.248, 0.13, 0.216, 0.108]
[2m[36m(func pid=60251)[0m 
[2m[36m(func pid=74973)[0m rmse: 0.17834535241127014
[2m[36m(func pid=74973)[0m mae:  0.13093718886375427
[2m[36m(func pid=74973)[0m rmse_per_class: [0.117, 0.259, 0.093, 0.335, 0.105, 0.189, 0.293, 0.14, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.1796518862247467
[2m[36m(func pid=68837)[0m mae:  0.13194122910499573
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.1, 0.337, 0.107, 0.19, 0.294, 0.139, 0.144, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3172 | Steps: 4 | Val loss: 0.3493 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=60251)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2969 | Steps: 4 | Val loss: 0.2871 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.5563 | Steps: 4 | Val loss: 0.4224 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 17:41:10 (running for 00:25:26.73)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.1482500024139881
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00010 | RUNNING    | 192.168.7.53:60251 | 0.01   |       0.99 |         0.0001 |  0.294 |  0.157 |                   74 |
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.317 |  0.165 |                   72 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.75  |  0.18  |                   38 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.573 |  0.178 |                   13 |
| train_01e98_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=60747)[0m rmse: 0.16475942730903625
[2m[36m(func pid=60747)[0m mae:  0.09456701576709747
[2m[36m(func pid=60747)[0m rmse_per_class: [0.113, 0.223, 0.067, 0.273, 0.085, 0.179, 0.236, 0.159, 0.197, 0.116]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.7431 | Steps: 4 | Val loss: 0.5726 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=60251)[0m rmse: 0.1555759757757187
[2m[36m(func pid=60251)[0m mae:  0.09378759562969208
[2m[36m(func pid=60251)[0m rmse_per_class: [0.066, 0.208, 0.077, 0.265, 0.084, 0.169, 0.237, 0.129, 0.209, 0.113]
[2m[36m(func pid=74973)[0m rmse: 0.17816656827926636
[2m[36m(func pid=74973)[0m mae:  0.13075444102287292
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.259, 0.093, 0.335, 0.105, 0.189, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17947976291179657
[2m[36m(func pid=68837)[0m mae:  0.13185261189937592
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.098, 0.337, 0.107, 0.19, 0.294, 0.14, 0.144, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2965 | Steps: 4 | Val loss: 0.3690 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.5448 | Steps: 4 | Val loss: 0.4115 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=60747)[0m rmse: 0.1753237545490265
[2m[36m(func pid=60747)[0m mae:  0.10217875242233276
[2m[36m(func pid=60747)[0m rmse_per_class: [0.101, 0.239, 0.08, 0.291, 0.062, 0.213, 0.247, 0.156, 0.239, 0.126]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.7390 | Steps: 4 | Val loss: 0.5706 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=74973)[0m rmse: 0.17798219621181488
[2m[36m(func pid=74973)[0m mae:  0.13054724037647247
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.259, 0.093, 0.335, 0.104, 0.189, 0.292, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m rmse: 0.17955289781093597
[2m[36m(func pid=68837)[0m mae:  0.131905198097229
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.261, 0.098, 0.337, 0.108, 0.19, 0.294, 0.14, 0.144, 0.109]
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3147 | Steps: 4 | Val loss: 0.4244 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 17:41:15 (running for 00:25:32.13)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.1485000029206276
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.296 |  0.175 |                   73 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.743 |  0.179 |                   39 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.556 |  0.178 |                   14 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=78743)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=78743)[0m Configuration completed!
[2m[36m(func pid=78743)[0m New optimizer parameters:
[2m[36m(func pid=78743)[0m SGD (
[2m[36m(func pid=78743)[0m Parameter Group 0
[2m[36m(func pid=78743)[0m     dampening: 0
[2m[36m(func pid=78743)[0m     differentiable: False
[2m[36m(func pid=78743)[0m     foreach: None
[2m[36m(func pid=78743)[0m     lr: 0.01
[2m[36m(func pid=78743)[0m     maximize: False
[2m[36m(func pid=78743)[0m     momentum: 0.9
[2m[36m(func pid=78743)[0m     nesterov: False
[2m[36m(func pid=78743)[0m     weight_decay: 0.0001
[2m[36m(func pid=78743)[0m )
[2m[36m(func pid=78743)[0m 
== Status ==
Current time: 2024-01-07 17:41:21 (running for 00:25:37.90)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.1485000029206276
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00011 | RUNNING    | 192.168.7.53:60747 | 0.1    |       0.99 |         0.0001 |  0.315 |  0.196 |                   74 |
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.739 |  0.18  |                   40 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.545 |  0.178 |                   15 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=60747)[0m rmse: 0.1964939534664154
[2m[36m(func pid=60747)[0m mae:  0.11779437959194183
[2m[36m(func pid=60747)[0m rmse_per_class: [0.086, 0.248, 0.086, 0.321, 0.053, 0.32, 0.282, 0.169, 0.249, 0.152]
[2m[36m(func pid=60747)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.7336 | Steps: 4 | Val loss: 0.5674 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.5363 | Steps: 4 | Val loss: 0.4042 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8674 | Steps: 4 | Val loss: 0.6337 | Batch size: 32 | lr: 0.01 | Duration: 4.62s
[2m[36m(func pid=60747)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3523 | Steps: 4 | Val loss: 0.4325 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=68837)[0m rmse: 0.17956389486789703
[2m[36m(func pid=68837)[0m mae:  0.13189125061035156
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.261, 0.098, 0.337, 0.108, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=74973)[0m rmse: 0.1781797558069229
[2m[36m(func pid=74973)[0m mae:  0.13069236278533936
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.259, 0.094, 0.335, 0.103, 0.189, 0.292, 0.14, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.18267276883125305
[2m[36m(func pid=78743)[0m mae:  0.1344851851463318
[2m[36m(func pid=78743)[0m rmse_per_class: [0.117, 0.267, 0.107, 0.339, 0.111, 0.191, 0.294, 0.144, 0.144, 0.113]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=60747)[0m rmse: 0.20574304461479187
[2m[36m(func pid=60747)[0m mae:  0.12161286920309067
[2m[36m(func pid=60747)[0m rmse_per_class: [0.088, 0.234, 0.108, 0.329, 0.053, 0.324, 0.311, 0.184, 0.238, 0.188]
== Status ==
Current time: 2024-01-07 17:41:27 (running for 00:25:43.46)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (9 PENDING, 3 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.734 |  0.18  |                   41 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.536 |  0.178 |                   16 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.867 |  0.183 |                    1 |
| train_01e98_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)


[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.5226 | Steps: 4 | Val loss: 0.3959 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.7333 | Steps: 4 | Val loss: 0.5678 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.7270 | Steps: 4 | Val loss: 0.5031 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=68837)[0m rmse: 0.17964261770248413
[2m[36m(func pid=68837)[0m mae:  0.13197603821754456
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.098, 0.337, 0.107, 0.19, 0.294, 0.14, 0.144, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=74973)[0m rmse: 0.1777655929327011
[2m[36m(func pid=74973)[0m mae:  0.13034367561340332
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.258, 0.093, 0.335, 0.103, 0.189, 0.292, 0.14, 0.142, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.18139639496803284
[2m[36m(func pid=78743)[0m mae:  0.1335202157497406
[2m[36m(func pid=78743)[0m rmse_per_class: [0.118, 0.267, 0.103, 0.338, 0.108, 0.19, 0.293, 0.143, 0.143, 0.112]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.5116 | Steps: 4 | Val loss: 0.3881 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.7315 | Steps: 4 | Val loss: 0.5650 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.5717 | Steps: 4 | Val loss: 0.4027 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=74973)[0m rmse: 0.1777590960264206
[2m[36m(func pid=74973)[0m mae:  0.1303323209285736
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.258, 0.094, 0.335, 0.102, 0.188, 0.292, 0.141, 0.142, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17962944507598877
[2m[36m(func pid=68837)[0m mae:  0.1319524347782135
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.26, 0.099, 0.337, 0.107, 0.19, 0.294, 0.139, 0.144, 0.109]
== Status ==
Current time: 2024-01-07 17:41:35 (running for 00:25:51.78)
Memory usage on this node: 23.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.733 |  0.18  |                   42 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.512 |  0.178 |                   18 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.727 |  0.181 |                    2 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=79710)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=79710)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=79710)[0m Configuration completed!
[2m[36m(func pid=79710)[0m New optimizer parameters:
[2m[36m(func pid=79710)[0m SGD (
[2m[36m(func pid=79710)[0m Parameter Group 0
[2m[36m(func pid=79710)[0m     dampening: 0
[2m[36m(func pid=79710)[0m     differentiable: False
[2m[36m(func pid=79710)[0m     foreach: None
[2m[36m(func pid=79710)[0m     lr: 0.1
[2m[36m(func pid=79710)[0m     maximize: False
[2m[36m(func pid=79710)[0m     momentum: 0.9
[2m[36m(func pid=79710)[0m     nesterov: False
[2m[36m(func pid=79710)[0m     weight_decay: 0.0001
[2m[36m(func pid=79710)[0m )
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.17991475760936737
[2m[36m(func pid=78743)[0m mae:  0.13241642713546753
[2m[36m(func pid=78743)[0m rmse_per_class: [0.119, 0.265, 0.097, 0.337, 0.102, 0.189, 0.291, 0.141, 0.144, 0.113]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.5010 | Steps: 4 | Val loss: 0.3809 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.7270 | Steps: 4 | Val loss: 0.5623 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.6927 | Steps: 4 | Val loss: 0.3538 | Batch size: 32 | lr: 0.1 | Duration: 4.50s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4726 | Steps: 4 | Val loss: 0.3457 | Batch size: 32 | lr: 0.01 | Duration: 3.22s
[2m[36m(func pid=74973)[0m rmse: 0.17733851075172424
[2m[36m(func pid=74973)[0m mae:  0.1299845576286316
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.258, 0.094, 0.334, 0.1, 0.188, 0.291, 0.141, 0.142, 0.109]
== Status ==
Current time: 2024-01-07 17:41:40 (running for 00:25:57.23)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.732 |  0.18  |                   43 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.501 |  0.177 |                   19 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.572 |  0.18  |                    3 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.1796819567680359
[2m[36m(func pid=68837)[0m mae:  0.13197463750839233
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.26, 0.099, 0.337, 0.108, 0.19, 0.294, 0.14, 0.144, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.18068274855613708
[2m[36m(func pid=79710)[0m mae:  0.13283514976501465
[2m[36m(func pid=79710)[0m rmse_per_class: [0.128, 0.267, 0.099, 0.338, 0.098, 0.191, 0.286, 0.143, 0.143, 0.114]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.1780615895986557
[2m[36m(func pid=78743)[0m mae:  0.13086767494678497
[2m[36m(func pid=78743)[0m rmse_per_class: [0.119, 0.264, 0.095, 0.335, 0.094, 0.188, 0.289, 0.141, 0.145, 0.112]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4966 | Steps: 4 | Val loss: 0.3759 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.7220 | Steps: 4 | Val loss: 0.5580 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.4222 | Steps: 4 | Val loss: 0.3433 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 17:41:46 (running for 00:26:02.53)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.727 |  0.18  |                   44 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.497 |  0.177 |                   20 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.473 |  0.178 |                    4 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.693 |  0.181 |                    1 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17711196839809418
[2m[36m(func pid=74973)[0m mae:  0.12981107831001282
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.258, 0.094, 0.334, 0.099, 0.188, 0.291, 0.14, 0.142, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17957556247711182
[2m[36m(func pid=68837)[0m mae:  0.13190487027168274
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.26, 0.098, 0.337, 0.108, 0.19, 0.294, 0.14, 0.144, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4269 | Steps: 4 | Val loss: 0.3213 | Batch size: 32 | lr: 0.01 | Duration: 3.20s
[2m[36m(func pid=79710)[0m rmse: 0.17359068989753723
[2m[36m(func pid=79710)[0m mae:  0.12588408589363098
[2m[36m(func pid=79710)[0m rmse_per_class: [0.162, 0.264, 0.074, 0.336, 0.074, 0.19, 0.257, 0.135, 0.138, 0.105]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.17569410800933838
[2m[36m(func pid=78743)[0m mae:  0.12892228364944458
[2m[36m(func pid=78743)[0m rmse_per_class: [0.118, 0.261, 0.092, 0.332, 0.085, 0.186, 0.287, 0.14, 0.145, 0.111]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4867 | Steps: 4 | Val loss: 0.3701 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.7207 | Steps: 4 | Val loss: 0.5569 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.4837 | Steps: 4 | Val loss: 0.3672 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 17:41:51 (running for 00:26:07.79)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.722 |  0.18  |                   45 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.487 |  0.177 |                   21 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.427 |  0.176 |                    5 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.422 |  0.174 |                    2 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17684532701969147
[2m[36m(func pid=74973)[0m mae:  0.1296585500240326
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.258, 0.092, 0.334, 0.097, 0.188, 0.291, 0.14, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17962002754211426
[2m[36m(func pid=68837)[0m mae:  0.1319223791360855
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.26, 0.099, 0.337, 0.108, 0.19, 0.295, 0.139, 0.143, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4095 | Steps: 4 | Val loss: 0.3140 | Batch size: 32 | lr: 0.01 | Duration: 3.18s
[2m[36m(func pid=79710)[0m rmse: 0.16556653380393982
[2m[36m(func pid=79710)[0m mae:  0.1158379316329956
[2m[36m(func pid=79710)[0m rmse_per_class: [0.173, 0.255, 0.058, 0.332, 0.056, 0.189, 0.24, 0.127, 0.134, 0.092]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4824 | Steps: 4 | Val loss: 0.3660 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.7146 | Steps: 4 | Val loss: 0.5536 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=78743)[0m rmse: 0.17373062670230865
[2m[36m(func pid=78743)[0m mae:  0.12728475034236908
[2m[36m(func pid=78743)[0m rmse_per_class: [0.117, 0.259, 0.087, 0.33, 0.081, 0.185, 0.285, 0.139, 0.144, 0.11]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4819 | Steps: 4 | Val loss: 0.3323 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 17:41:56 (running for 00:26:13.35)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.721 |  0.18  |                   46 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.482 |  0.177 |                   22 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.41  |  0.174 |                    6 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.484 |  0.166 |                    3 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.1767069399356842
[2m[36m(func pid=74973)[0m mae:  0.1295352429151535
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.257, 0.092, 0.333, 0.097, 0.188, 0.291, 0.14, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17944100499153137
[2m[36m(func pid=68837)[0m mae:  0.1317368894815445
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.098, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4020 | Steps: 4 | Val loss: 0.3123 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=79710)[0m rmse: 0.15938948094844818
[2m[36m(func pid=79710)[0m mae:  0.10781694948673248
[2m[36m(func pid=79710)[0m rmse_per_class: [0.156, 0.236, 0.044, 0.33, 0.054, 0.185, 0.248, 0.123, 0.131, 0.087]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4749 | Steps: 4 | Val loss: 0.3627 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.7134 | Steps: 4 | Val loss: 0.5516 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=78743)[0m rmse: 0.17201122641563416
[2m[36m(func pid=78743)[0m mae:  0.1259049028158188
[2m[36m(func pid=78743)[0m rmse_per_class: [0.118, 0.256, 0.083, 0.328, 0.077, 0.184, 0.283, 0.138, 0.144, 0.109]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4178 | Steps: 4 | Val loss: 0.2824 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 17:42:02 (running for 00:26:18.57)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.715 |  0.179 |                   47 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.475 |  0.177 |                   23 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.402 |  0.172 |                    7 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.482 |  0.159 |                    4 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.1766713261604309
[2m[36m(func pid=74973)[0m mae:  0.12944196164608002
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.258, 0.093, 0.333, 0.095, 0.188, 0.291, 0.139, 0.144, 0.109]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17939414083957672
[2m[36m(func pid=68837)[0m mae:  0.13174374401569366
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.097, 0.336, 0.108, 0.19, 0.293, 0.14, 0.143, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.3997 | Steps: 4 | Val loss: 0.3109 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=79710)[0m rmse: 0.1483650654554367
[2m[36m(func pid=79710)[0m mae:  0.10073491185903549
[2m[36m(func pid=79710)[0m rmse_per_class: [0.115, 0.219, 0.038, 0.325, 0.055, 0.17, 0.232, 0.116, 0.131, 0.083]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4705 | Steps: 4 | Val loss: 0.3584 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.7094 | Steps: 4 | Val loss: 0.5491 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=78743)[0m rmse: 0.1698622703552246
[2m[36m(func pid=78743)[0m mae:  0.12424837052822113
[2m[36m(func pid=78743)[0m rmse_per_class: [0.119, 0.252, 0.078, 0.326, 0.073, 0.183, 0.281, 0.136, 0.144, 0.106]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.3738 | Steps: 4 | Val loss: 0.2707 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 17:42:07 (running for 00:26:23.79)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.713 |  0.179 |                   48 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.47  |  0.176 |                   24 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.4   |  0.17  |                    8 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.418 |  0.148 |                    5 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17637498676776886
[2m[36m(func pid=74973)[0m mae:  0.12928035855293274
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.257, 0.091, 0.333, 0.096, 0.188, 0.29, 0.139, 0.143, 0.109]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.179271399974823
[2m[36m(func pid=68837)[0m mae:  0.13158726692199707
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.097, 0.336, 0.108, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.4057 | Steps: 4 | Val loss: 0.3087 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
[2m[36m(func pid=79710)[0m rmse: 0.14270973205566406
[2m[36m(func pid=79710)[0m mae:  0.09915457665920258
[2m[36m(func pid=79710)[0m rmse_per_class: [0.082, 0.219, 0.038, 0.302, 0.055, 0.157, 0.232, 0.115, 0.142, 0.085]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4672 | Steps: 4 | Val loss: 0.3540 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.7041 | Steps: 4 | Val loss: 0.5462 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=78743)[0m rmse: 0.1675073355436325
[2m[36m(func pid=78743)[0m mae:  0.12228993326425552
[2m[36m(func pid=78743)[0m rmse_per_class: [0.12, 0.25, 0.072, 0.322, 0.069, 0.182, 0.278, 0.135, 0.143, 0.105]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.3634 | Steps: 4 | Val loss: 0.2789 | Batch size: 32 | lr: 0.1 | Duration: 2.65s
== Status ==
Current time: 2024-01-07 17:42:12 (running for 00:26:29.14)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.709 |  0.179 |                   49 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.467 |  0.176 |                   25 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.406 |  0.168 |                    9 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.374 |  0.143 |                    6 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17611822485923767
[2m[36m(func pid=74973)[0m mae:  0.12902730703353882
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.257, 0.091, 0.332, 0.095, 0.188, 0.29, 0.139, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.1792554259300232
[2m[36m(func pid=68837)[0m mae:  0.1315818727016449
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.097, 0.335, 0.107, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.1455681174993515
[2m[36m(func pid=79710)[0m mae:  0.10143224895000458
[2m[36m(func pid=79710)[0m rmse_per_class: [0.074, 0.223, 0.045, 0.28, 0.054, 0.158, 0.256, 0.113, 0.15, 0.102]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3986 | Steps: 4 | Val loss: 0.3065 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4637 | Steps: 4 | Val loss: 0.3502 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.7045 | Steps: 4 | Val loss: 0.5457 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.3582 | Steps: 4 | Val loss: 0.2727 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=78743)[0m rmse: 0.16595566272735596
[2m[36m(func pid=78743)[0m mae:  0.12103073298931122
[2m[36m(func pid=78743)[0m rmse_per_class: [0.118, 0.247, 0.069, 0.32, 0.067, 0.18, 0.277, 0.134, 0.143, 0.105]
[2m[36m(func pid=78743)[0m 
== Status ==
Current time: 2024-01-07 17:42:17 (running for 00:26:34.38)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.704 |  0.179 |                   50 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.464 |  0.176 |                   26 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.399 |  0.166 |                   10 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.363 |  0.146 |                    7 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17583607137203217
[2m[36m(func pid=74973)[0m mae:  0.12882868945598602
[2m[36m(func pid=74973)[0m rmse_per_class: [0.117, 0.257, 0.09, 0.332, 0.095, 0.188, 0.289, 0.139, 0.143, 0.109]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17943421006202698
[2m[36m(func pid=68837)[0m mae:  0.1317436397075653
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.262, 0.098, 0.335, 0.107, 0.19, 0.294, 0.14, 0.144, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.1488044559955597
[2m[36m(func pid=79710)[0m mae:  0.10238603502511978
[2m[36m(func pid=79710)[0m rmse_per_class: [0.072, 0.23, 0.07, 0.272, 0.053, 0.156, 0.259, 0.11, 0.146, 0.119]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4018 | Steps: 4 | Val loss: 0.3023 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4599 | Steps: 4 | Val loss: 0.3482 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.7017 | Steps: 4 | Val loss: 0.5428 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.3330 | Steps: 4 | Val loss: 0.2703 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 17:42:22 (running for 00:26:39.39)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.705 |  0.179 |                   51 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.464 |  0.176 |                   26 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.402 |  0.164 |                   11 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.358 |  0.149 |                    8 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=78743)[0m rmse: 0.1641404628753662
[2m[36m(func pid=78743)[0m mae:  0.11954094469547272
[2m[36m(func pid=78743)[0m rmse_per_class: [0.115, 0.246, 0.066, 0.319, 0.065, 0.178, 0.274, 0.132, 0.141, 0.105]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=74973)[0m rmse: 0.17575916647911072
[2m[36m(func pid=74973)[0m mae:  0.1287638545036316
[2m[36m(func pid=74973)[0m rmse_per_class: [0.117, 0.256, 0.09, 0.332, 0.094, 0.188, 0.289, 0.139, 0.143, 0.109]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17938676476478577
[2m[36m(func pid=68837)[0m mae:  0.13171860575675964
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.336, 0.107, 0.19, 0.294, 0.139, 0.144, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14613156020641327
[2m[36m(func pid=79710)[0m mae:  0.09844918549060822
[2m[36m(func pid=79710)[0m rmse_per_class: [0.072, 0.225, 0.074, 0.285, 0.073, 0.155, 0.234, 0.109, 0.133, 0.1]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4545 | Steps: 4 | Val loss: 0.3442 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.3893 | Steps: 4 | Val loss: 0.2997 | Batch size: 32 | lr: 0.01 | Duration: 3.14s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.6982 | Steps: 4 | Val loss: 0.5402 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3254 | Steps: 4 | Val loss: 0.2728 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 17:42:28 (running for 00:26:44.91)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.702 |  0.179 |                   52 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.455 |  0.176 |                   28 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.402 |  0.164 |                   11 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.333 |  0.146 |                    9 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17553767561912537
[2m[36m(func pid=74973)[0m mae:  0.12857897579669952
[2m[36m(func pid=74973)[0m rmse_per_class: [0.117, 0.256, 0.089, 0.332, 0.094, 0.188, 0.288, 0.139, 0.142, 0.109]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.163174569606781
[2m[36m(func pid=78743)[0m mae:  0.1188260167837143
[2m[36m(func pid=78743)[0m rmse_per_class: [0.113, 0.244, 0.065, 0.319, 0.065, 0.176, 0.273, 0.131, 0.141, 0.104]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17932334542274475
[2m[36m(func pid=68837)[0m mae:  0.13170883059501648
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.098, 0.336, 0.107, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14648887515068054
[2m[36m(func pid=79710)[0m mae:  0.09680740535259247
[2m[36m(func pid=79710)[0m rmse_per_class: [0.066, 0.22, 0.051, 0.308, 0.117, 0.155, 0.227, 0.109, 0.128, 0.084]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4518 | Steps: 4 | Val loss: 0.3427 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.3923 | Steps: 4 | Val loss: 0.2966 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.6980 | Steps: 4 | Val loss: 0.5368 | Batch size: 32 | lr: 0.0001 | Duration: 3.14s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3219 | Steps: 4 | Val loss: 0.2748 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=74973)[0m rmse: 0.1754067838191986
[2m[36m(func pid=74973)[0m mae:  0.1284564882516861
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.256, 0.089, 0.332, 0.093, 0.188, 0.288, 0.139, 0.142, 0.11]
== Status ==
Current time: 2024-01-07 17:42:33 (running for 00:26:50.23)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.698 |  0.179 |                   53 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.452 |  0.175 |                   29 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.389 |  0.163 |                   12 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.325 |  0.146 |                   10 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.16148258745670319
[2m[36m(func pid=78743)[0m mae:  0.11736297607421875
[2m[36m(func pid=78743)[0m rmse_per_class: [0.11, 0.24, 0.064, 0.318, 0.064, 0.175, 0.271, 0.13, 0.139, 0.103]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17921876907348633
[2m[36m(func pid=68837)[0m mae:  0.13159391283988953
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.26, 0.097, 0.336, 0.108, 0.19, 0.293, 0.14, 0.143, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14801163971424103
[2m[36m(func pid=79710)[0m mae:  0.09788168966770172
[2m[36m(func pid=79710)[0m rmse_per_class: [0.071, 0.23, 0.033, 0.314, 0.127, 0.157, 0.228, 0.11, 0.131, 0.081]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4502 | Steps: 4 | Val loss: 0.3414 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.3888 | Steps: 4 | Val loss: 0.2945 | Batch size: 32 | lr: 0.01 | Duration: 3.14s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.6975 | Steps: 4 | Val loss: 0.5355 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.3201 | Steps: 4 | Val loss: 0.2685 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 17:42:39 (running for 00:26:55.69)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.698 |  0.179 |                   54 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.45  |  0.176 |                   30 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.392 |  0.161 |                   13 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.322 |  0.148 |                   11 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.1756570041179657
[2m[36m(func pid=74973)[0m mae:  0.12865307927131653
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.256, 0.09, 0.332, 0.093, 0.188, 0.289, 0.139, 0.143, 0.111]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17958636581897736
[2m[36m(func pid=68837)[0m mae:  0.13185220956802368
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.336, 0.107, 0.19, 0.294, 0.141, 0.143, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.1606546938419342
[2m[36m(func pid=78743)[0m mae:  0.11669101566076279
[2m[36m(func pid=78743)[0m rmse_per_class: [0.109, 0.238, 0.064, 0.317, 0.064, 0.174, 0.271, 0.13, 0.139, 0.101]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14435739815235138
[2m[36m(func pid=79710)[0m mae:  0.09589160233736038
[2m[36m(func pid=79710)[0m rmse_per_class: [0.075, 0.222, 0.031, 0.299, 0.097, 0.157, 0.23, 0.107, 0.139, 0.088]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4423 | Steps: 4 | Val loss: 0.3381 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.6889 | Steps: 4 | Val loss: 0.5316 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.3865 | Steps: 4 | Val loss: 0.2923 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.3041 | Steps: 4 | Val loss: 0.2613 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=74973)[0m rmse: 0.175362691283226
[2m[36m(func pid=74973)[0m mae:  0.12847377359867096
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.256, 0.089, 0.332, 0.092, 0.187, 0.288, 0.139, 0.143, 0.111]
== Status ==
Current time: 2024-01-07 17:42:44 (running for 00:27:01.14)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.697 |  0.18  |                   55 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.442 |  0.175 |                   31 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.389 |  0.161 |                   14 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.32  |  0.144 |                   12 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17960523068904877
[2m[36m(func pid=68837)[0m mae:  0.1319020539522171
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.107, 0.19, 0.294, 0.14, 0.143, 0.111]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.15972767770290375
[2m[36m(func pid=78743)[0m mae:  0.11583127081394196
[2m[36m(func pid=78743)[0m rmse_per_class: [0.106, 0.238, 0.064, 0.316, 0.063, 0.173, 0.269, 0.128, 0.139, 0.101]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.13991697132587433
[2m[36m(func pid=79710)[0m mae:  0.09318339824676514
[2m[36m(func pid=79710)[0m rmse_per_class: [0.069, 0.213, 0.03, 0.276, 0.067, 0.155, 0.229, 0.108, 0.153, 0.099]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4394 | Steps: 4 | Val loss: 0.3358 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.6890 | Steps: 4 | Val loss: 0.5311 | Batch size: 32 | lr: 0.0001 | Duration: 3.08s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.3198 | Steps: 4 | Val loss: 0.2630 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3865 | Steps: 4 | Val loss: 0.2898 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 17:42:49 (running for 00:27:06.45)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.689 |  0.18  |                   56 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.439 |  0.175 |                   32 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.387 |  0.16  |                   15 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.304 |  0.14  |                   13 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17495155334472656
[2m[36m(func pid=74973)[0m mae:  0.1281719207763672
[2m[36m(func pid=74973)[0m rmse_per_class: [0.115, 0.256, 0.088, 0.332, 0.091, 0.187, 0.287, 0.139, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.1795513927936554
[2m[36m(func pid=68837)[0m mae:  0.1318679004907608
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.107, 0.19, 0.293, 0.14, 0.143, 0.111]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.1408068984746933
[2m[36m(func pid=79710)[0m mae:  0.09323077648878098
[2m[36m(func pid=79710)[0m rmse_per_class: [0.065, 0.216, 0.032, 0.275, 0.055, 0.154, 0.223, 0.108, 0.169, 0.11]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.1586863249540329
[2m[36m(func pid=78743)[0m mae:  0.11483790725469589
[2m[36m(func pid=78743)[0m rmse_per_class: [0.106, 0.237, 0.062, 0.314, 0.063, 0.173, 0.267, 0.127, 0.137, 0.101]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4372 | Steps: 4 | Val loss: 0.3345 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.6846 | Steps: 4 | Val loss: 0.5292 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.3094 | Steps: 4 | Val loss: 0.2635 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3841 | Steps: 4 | Val loss: 0.2875 | Batch size: 32 | lr: 0.01 | Duration: 3.20s
== Status ==
Current time: 2024-01-07 17:42:55 (running for 00:27:11.70)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.689 |  0.18  |                   57 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.437 |  0.175 |                   33 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.386 |  0.159 |                   16 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.32  |  0.141 |                   14 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17483434081077576
[2m[36m(func pid=74973)[0m mae:  0.1280815452337265
[2m[36m(func pid=74973)[0m rmse_per_class: [0.115, 0.256, 0.088, 0.332, 0.09, 0.187, 0.287, 0.138, 0.143, 0.111]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17923901975154877
[2m[36m(func pid=68837)[0m mae:  0.13161394000053406
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.26, 0.098, 0.337, 0.106, 0.19, 0.293, 0.14, 0.143, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14071902632713318
[2m[36m(func pid=79710)[0m mae:  0.09285793453454971
[2m[36m(func pid=79710)[0m rmse_per_class: [0.066, 0.214, 0.035, 0.279, 0.053, 0.155, 0.229, 0.107, 0.149, 0.12]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.1575237214565277
[2m[36m(func pid=78743)[0m mae:  0.11370903253555298
[2m[36m(func pid=78743)[0m rmse_per_class: [0.106, 0.237, 0.061, 0.312, 0.062, 0.171, 0.264, 0.126, 0.136, 0.1]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4381 | Steps: 4 | Val loss: 0.3339 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3038 | Steps: 4 | Val loss: 0.2705 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.6810 | Steps: 4 | Val loss: 0.5251 | Batch size: 32 | lr: 0.0001 | Duration: 3.10s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3761 | Steps: 4 | Val loss: 0.2874 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
== Status ==
Current time: 2024-01-07 17:43:00 (running for 00:27:17.04)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.685 |  0.179 |                   58 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.438 |  0.175 |                   34 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.384 |  0.158 |                   17 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.309 |  0.141 |                   15 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.1750219464302063
[2m[36m(func pid=74973)[0m mae:  0.1283845603466034
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.257, 0.087, 0.333, 0.09, 0.186, 0.288, 0.139, 0.144, 0.111]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14522825181484222
[2m[36m(func pid=79710)[0m mae:  0.0956120416522026
[2m[36m(func pid=79710)[0m rmse_per_class: [0.068, 0.221, 0.048, 0.288, 0.054, 0.155, 0.235, 0.106, 0.133, 0.145]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17913992702960968
[2m[36m(func pid=68837)[0m mae:  0.1315217912197113
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.26, 0.097, 0.336, 0.107, 0.19, 0.293, 0.14, 0.143, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.15774813294410706
[2m[36m(func pid=78743)[0m mae:  0.11382440477609634
[2m[36m(func pid=78743)[0m rmse_per_class: [0.104, 0.237, 0.061, 0.314, 0.062, 0.172, 0.261, 0.126, 0.136, 0.105]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4349 | Steps: 4 | Val loss: 0.3337 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3022 | Steps: 4 | Val loss: 0.2695 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.6805 | Steps: 4 | Val loss: 0.5250 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3676 | Steps: 4 | Val loss: 0.2862 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 17:43:05 (running for 00:27:22.33)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.681 |  0.179 |                   59 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.435 |  0.175 |                   35 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.376 |  0.158 |                   18 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.304 |  0.145 |                   16 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17520751059055328
[2m[36m(func pid=74973)[0m mae:  0.12848372757434845
[2m[36m(func pid=74973)[0m rmse_per_class: [0.115, 0.257, 0.089, 0.333, 0.09, 0.187, 0.287, 0.139, 0.144, 0.112]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.1456623077392578
[2m[36m(func pid=79710)[0m mae:  0.09502570331096649
[2m[36m(func pid=79710)[0m rmse_per_class: [0.07, 0.219, 0.051, 0.29, 0.055, 0.154, 0.233, 0.104, 0.127, 0.154]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17927506566047668
[2m[36m(func pid=68837)[0m mae:  0.1316428929567337
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.097, 0.336, 0.107, 0.19, 0.293, 0.14, 0.143, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.15732771158218384
[2m[36m(func pid=78743)[0m mae:  0.11343306303024292
[2m[36m(func pid=78743)[0m rmse_per_class: [0.103, 0.238, 0.061, 0.31, 0.062, 0.171, 0.26, 0.125, 0.136, 0.107]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4325 | Steps: 4 | Val loss: 0.3313 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3033 | Steps: 4 | Val loss: 0.2624 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.6780 | Steps: 4 | Val loss: 0.5229 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 17:43:11 (running for 00:27:27.60)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.68  |  0.179 |                   60 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.433 |  0.175 |                   36 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.368 |  0.157 |                   19 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.302 |  0.146 |                   17 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17481745779514313
[2m[36m(func pid=74973)[0m mae:  0.12814317643642426
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.257, 0.088, 0.332, 0.089, 0.186, 0.287, 0.139, 0.143, 0.111]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3755 | Steps: 4 | Val loss: 0.2850 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=79710)[0m rmse: 0.1412230283021927
[2m[36m(func pid=79710)[0m mae:  0.09116281569004059
[2m[36m(func pid=79710)[0m rmse_per_class: [0.07, 0.213, 0.047, 0.284, 0.058, 0.156, 0.227, 0.105, 0.127, 0.124]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.1791573464870453
[2m[36m(func pid=68837)[0m mae:  0.1315329372882843
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.261, 0.097, 0.337, 0.107, 0.19, 0.292, 0.14, 0.143, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.15684901177883148
[2m[36m(func pid=78743)[0m mae:  0.11301670223474503
[2m[36m(func pid=78743)[0m rmse_per_class: [0.102, 0.238, 0.06, 0.309, 0.062, 0.17, 0.258, 0.124, 0.136, 0.109]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4316 | Steps: 4 | Val loss: 0.3291 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3005 | Steps: 4 | Val loss: 0.2635 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.6755 | Steps: 4 | Val loss: 0.5196 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 17:43:16 (running for 00:27:32.70)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.678 |  0.179 |                   61 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.432 |  0.174 |                   37 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.375 |  0.157 |                   20 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.303 |  0.141 |                   18 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17433616518974304
[2m[36m(func pid=74973)[0m mae:  0.12772956490516663
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.255, 0.087, 0.332, 0.088, 0.187, 0.286, 0.139, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3728 | Steps: 4 | Val loss: 0.2836 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=79710)[0m rmse: 0.1418187916278839
[2m[36m(func pid=79710)[0m mae:  0.09216252714395523
[2m[36m(func pid=79710)[0m rmse_per_class: [0.07, 0.214, 0.052, 0.284, 0.06, 0.163, 0.228, 0.106, 0.141, 0.102]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17909960448741913
[2m[36m(func pid=68837)[0m mae:  0.13150706887245178
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.26, 0.096, 0.337, 0.107, 0.19, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4317 | Steps: 4 | Val loss: 0.3268 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=78743)[0m rmse: 0.15601764619350433
[2m[36m(func pid=78743)[0m mae:  0.1122996062040329
[2m[36m(func pid=78743)[0m rmse_per_class: [0.1, 0.236, 0.059, 0.308, 0.062, 0.17, 0.257, 0.123, 0.136, 0.11]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3044 | Steps: 4 | Val loss: 0.2634 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.6744 | Steps: 4 | Val loss: 0.5166 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 17:43:21 (running for 00:27:38.11)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.676 |  0.179 |                   62 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.432 |  0.174 |                   38 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.373 |  0.156 |                   21 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.301 |  0.142 |                   19 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17411813139915466
[2m[36m(func pid=74973)[0m mae:  0.1275002807378769
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.255, 0.087, 0.33, 0.088, 0.187, 0.286, 0.139, 0.142, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3715 | Steps: 4 | Val loss: 0.2842 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=79710)[0m rmse: 0.14095067977905273
[2m[36m(func pid=79710)[0m mae:  0.09244540333747864
[2m[36m(func pid=79710)[0m rmse_per_class: [0.066, 0.214, 0.047, 0.276, 0.058, 0.156, 0.227, 0.109, 0.169, 0.088]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17925487458705902
[2m[36m(func pid=68837)[0m mae:  0.1316085159778595
[2m[36m(func pid=68837)[0m rmse_per_class: [0.115, 0.26, 0.097, 0.336, 0.108, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4262 | Steps: 4 | Val loss: 0.3269 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=78743)[0m rmse: 0.156472310423851
[2m[36m(func pid=78743)[0m mae:  0.11280052363872528
[2m[36m(func pid=78743)[0m rmse_per_class: [0.1, 0.235, 0.06, 0.307, 0.062, 0.171, 0.259, 0.123, 0.136, 0.111]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3007 | Steps: 4 | Val loss: 0.2597 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.6668 | Steps: 4 | Val loss: 0.5139 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 17:43:26 (running for 00:27:43.27)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.674 |  0.179 |                   63 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.426 |  0.174 |                   39 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.371 |  0.156 |                   22 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.304 |  0.141 |                   20 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17411933839321136
[2m[36m(func pid=74973)[0m mae:  0.12756042182445526
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.255, 0.087, 0.331, 0.088, 0.187, 0.286, 0.138, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3658 | Steps: 4 | Val loss: 0.2838 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=79710)[0m rmse: 0.13828885555267334
[2m[36m(func pid=79710)[0m mae:  0.09046227484941483
[2m[36m(func pid=79710)[0m rmse_per_class: [0.067, 0.206, 0.041, 0.273, 0.061, 0.153, 0.223, 0.109, 0.167, 0.083]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17925621569156647
[2m[36m(func pid=68837)[0m mae:  0.1316147744655609
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.261, 0.096, 0.336, 0.107, 0.19, 0.293, 0.141, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4230 | Steps: 4 | Val loss: 0.3247 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=78743)[0m rmse: 0.156071737408638
[2m[36m(func pid=78743)[0m mae:  0.11251840740442276
[2m[36m(func pid=78743)[0m rmse_per_class: [0.098, 0.233, 0.06, 0.307, 0.063, 0.171, 0.26, 0.123, 0.136, 0.11]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.2913 | Steps: 4 | Val loss: 0.2615 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.6674 | Steps: 4 | Val loss: 0.5136 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 17:43:32 (running for 00:27:48.65)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.667 |  0.179 |                   64 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.423 |  0.174 |                   40 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.366 |  0.156 |                   23 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.301 |  0.138 |                   21 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17387324571609497
[2m[36m(func pid=74973)[0m mae:  0.12732207775115967
[2m[36m(func pid=74973)[0m rmse_per_class: [0.115, 0.255, 0.088, 0.33, 0.088, 0.186, 0.286, 0.138, 0.142, 0.109]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3669 | Steps: 4 | Val loss: 0.2824 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=79710)[0m rmse: 0.13955658674240112
[2m[36m(func pid=79710)[0m mae:  0.09036929905414581
[2m[36m(func pid=79710)[0m rmse_per_class: [0.067, 0.211, 0.037, 0.28, 0.063, 0.157, 0.217, 0.109, 0.149, 0.105]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17924638092517853
[2m[36m(func pid=68837)[0m mae:  0.1315910667181015
[2m[36m(func pid=68837)[0m rmse_per_class: [0.117, 0.261, 0.097, 0.336, 0.107, 0.19, 0.293, 0.141, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4233 | Steps: 4 | Val loss: 0.3235 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=78743)[0m rmse: 0.15508760511875153
[2m[36m(func pid=78743)[0m mae:  0.111781045794487
[2m[36m(func pid=78743)[0m rmse_per_class: [0.097, 0.232, 0.059, 0.305, 0.063, 0.17, 0.26, 0.123, 0.136, 0.108]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3034 | Steps: 4 | Val loss: 0.2663 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.6628 | Steps: 4 | Val loss: 0.5124 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 17:43:37 (running for 00:27:53.85)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.667 |  0.179 |                   65 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.423 |  0.174 |                   41 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.367 |  0.155 |                   24 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.291 |  0.14  |                   22 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.1736001968383789
[2m[36m(func pid=74973)[0m mae:  0.12710657715797424
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.255, 0.087, 0.33, 0.088, 0.186, 0.286, 0.138, 0.142, 0.109]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3695 | Steps: 4 | Val loss: 0.2816 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=79710)[0m rmse: 0.14350812137126923
[2m[36m(func pid=79710)[0m mae:  0.0920955240726471
[2m[36m(func pid=79710)[0m rmse_per_class: [0.072, 0.218, 0.034, 0.283, 0.066, 0.157, 0.221, 0.111, 0.138, 0.135]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17907798290252686
[2m[36m(func pid=68837)[0m mae:  0.13146692514419556
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.336, 0.107, 0.19, 0.293, 0.141, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4246 | Steps: 4 | Val loss: 0.3223 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=78743)[0m rmse: 0.15449640154838562
[2m[36m(func pid=78743)[0m mae:  0.11118794977664948
[2m[36m(func pid=78743)[0m rmse_per_class: [0.097, 0.23, 0.059, 0.302, 0.063, 0.17, 0.261, 0.123, 0.135, 0.106]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.2966 | Steps: 4 | Val loss: 0.2703 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.6641 | Steps: 4 | Val loss: 0.5117 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 17:43:42 (running for 00:27:59.25)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.663 |  0.179 |                   66 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.425 |  0.173 |                   42 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.37  |  0.154 |                   25 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.303 |  0.144 |                   23 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17347782850265503
[2m[36m(func pid=74973)[0m mae:  0.12696102261543274
[2m[36m(func pid=74973)[0m rmse_per_class: [0.115, 0.255, 0.087, 0.33, 0.087, 0.186, 0.286, 0.138, 0.142, 0.109]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14787445962429047
[2m[36m(func pid=79710)[0m mae:  0.09475546330213547
[2m[36m(func pid=79710)[0m rmse_per_class: [0.073, 0.218, 0.04, 0.283, 0.072, 0.155, 0.227, 0.115, 0.153, 0.143]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17927399277687073
[2m[36m(func pid=68837)[0m mae:  0.1316571831703186
[2m[36m(func pid=68837)[0m rmse_per_class: [0.117, 0.261, 0.096, 0.337, 0.107, 0.189, 0.292, 0.142, 0.142, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3652 | Steps: 4 | Val loss: 0.2830 | Batch size: 32 | lr: 0.01 | Duration: 3.26s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4225 | Steps: 4 | Val loss: 0.3232 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=78743)[0m rmse: 0.15518637001514435
[2m[36m(func pid=78743)[0m mae:  0.11172304302453995
[2m[36m(func pid=78743)[0m rmse_per_class: [0.096, 0.231, 0.062, 0.306, 0.063, 0.17, 0.261, 0.122, 0.136, 0.104]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3030 | Steps: 4 | Val loss: 0.2711 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.6563 | Steps: 4 | Val loss: 0.5082 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 17:43:48 (running for 00:28:04.65)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.664 |  0.179 |                   67 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.422 |  0.174 |                   43 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.365 |  0.155 |                   26 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.297 |  0.148 |                   24 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17378169298171997
[2m[36m(func pid=74973)[0m mae:  0.12719431519508362
[2m[36m(func pid=74973)[0m rmse_per_class: [0.115, 0.255, 0.088, 0.33, 0.087, 0.186, 0.286, 0.138, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14827093482017517
[2m[36m(func pid=79710)[0m mae:  0.09509199857711792
[2m[36m(func pid=79710)[0m rmse_per_class: [0.066, 0.219, 0.039, 0.286, 0.073, 0.153, 0.233, 0.115, 0.162, 0.136]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17903093993663788
[2m[36m(func pid=68837)[0m mae:  0.13147298991680145
[2m[36m(func pid=68837)[0m rmse_per_class: [0.117, 0.261, 0.096, 0.337, 0.106, 0.189, 0.292, 0.142, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3608 | Steps: 4 | Val loss: 0.2823 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4180 | Steps: 4 | Val loss: 0.3210 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3145 | Steps: 4 | Val loss: 0.2700 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=78743)[0m rmse: 0.15458720922470093
[2m[36m(func pid=78743)[0m mae:  0.11125664412975311
[2m[36m(func pid=78743)[0m rmse_per_class: [0.096, 0.229, 0.063, 0.306, 0.063, 0.168, 0.261, 0.122, 0.136, 0.102]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.6551 | Steps: 4 | Val loss: 0.5031 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=74973)[0m rmse: 0.17328867316246033
[2m[36m(func pid=74973)[0m mae:  0.12680378556251526
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.254, 0.087, 0.33, 0.086, 0.185, 0.285, 0.138, 0.142, 0.109]
== Status ==
Current time: 2024-01-07 17:43:53 (running for 00:28:09.89)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.656 |  0.179 |                   68 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.418 |  0.173 |                   44 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.361 |  0.155 |                   27 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.303 |  0.148 |                   25 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14712195098400116
[2m[36m(func pid=79710)[0m mae:  0.0951155424118042
[2m[36m(func pid=79710)[0m rmse_per_class: [0.07, 0.216, 0.039, 0.286, 0.074, 0.155, 0.237, 0.11, 0.172, 0.113]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.17895393073558807
[2m[36m(func pid=68837)[0m mae:  0.13147366046905518
[2m[36m(func pid=68837)[0m rmse_per_class: [0.117, 0.261, 0.096, 0.337, 0.105, 0.189, 0.292, 0.142, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3587 | Steps: 4 | Val loss: 0.2819 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4197 | Steps: 4 | Val loss: 0.3213 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3017 | Steps: 4 | Val loss: 0.2640 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 17:43:58 (running for 00:28:15.07)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.655 |  0.179 |                   69 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.418 |  0.173 |                   44 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.359 |  0.154 |                   28 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.314 |  0.147 |                   26 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=78743)[0m rmse: 0.15429440140724182
[2m[36m(func pid=78743)[0m mae:  0.11105413734912872
[2m[36m(func pid=78743)[0m rmse_per_class: [0.095, 0.23, 0.065, 0.304, 0.062, 0.168, 0.26, 0.122, 0.137, 0.1]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=74973)[0m rmse: 0.1735157072544098
[2m[36m(func pid=74973)[0m mae:  0.126915842294693
[2m[36m(func pid=74973)[0m rmse_per_class: [0.114, 0.253, 0.089, 0.331, 0.086, 0.186, 0.286, 0.137, 0.143, 0.109]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.6589 | Steps: 4 | Val loss: 0.5046 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=79710)[0m rmse: 0.14234185218811035
[2m[36m(func pid=79710)[0m mae:  0.09141665697097778
[2m[36m(func pid=79710)[0m rmse_per_class: [0.065, 0.214, 0.046, 0.283, 0.066, 0.151, 0.224, 0.12, 0.153, 0.102]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=68837)[0m rmse: 0.1791514903306961
[2m[36m(func pid=68837)[0m mae:  0.1315837800502777
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.261, 0.096, 0.337, 0.106, 0.189, 0.293, 0.141, 0.143, 0.11]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4194 | Steps: 4 | Val loss: 0.3202 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3642 | Steps: 4 | Val loss: 0.2798 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.2869 | Steps: 4 | Val loss: 0.2632 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 17:44:03 (running for 00:28:20.40)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.659 |  0.179 |                   70 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.419 |  0.173 |                   46 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.359 |  0.154 |                   28 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.302 |  0.142 |                   27 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17345257103443146
[2m[36m(func pid=74973)[0m mae:  0.1269456148147583
[2m[36m(func pid=74973)[0m rmse_per_class: [0.115, 0.253, 0.088, 0.331, 0.085, 0.185, 0.286, 0.137, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.6524 | Steps: 4 | Val loss: 0.5018 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=78743)[0m rmse: 0.15286685526371002
[2m[36m(func pid=78743)[0m mae:  0.10978589951992035
[2m[36m(func pid=78743)[0m rmse_per_class: [0.093, 0.229, 0.063, 0.302, 0.062, 0.167, 0.258, 0.121, 0.136, 0.097]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14284703135490417
[2m[36m(func pid=79710)[0m mae:  0.09087491035461426
[2m[36m(func pid=79710)[0m rmse_per_class: [0.067, 0.215, 0.061, 0.283, 0.067, 0.15, 0.218, 0.119, 0.142, 0.106]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4158 | Steps: 4 | Val loss: 0.3200 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=68837)[0m rmse: 0.17909955978393555
[2m[36m(func pid=68837)[0m mae:  0.1315450221300125
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.261, 0.096, 0.337, 0.107, 0.189, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3659 | Steps: 4 | Val loss: 0.2780 | Batch size: 32 | lr: 0.01 | Duration: 3.18s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.2923 | Steps: 4 | Val loss: 0.2627 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 17:44:09 (running for 00:28:25.68)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.652 |  0.179 |                   71 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.416 |  0.173 |                   47 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.364 |  0.153 |                   29 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.287 |  0.143 |                   28 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17334921658039093
[2m[36m(func pid=74973)[0m mae:  0.1268528401851654
[2m[36m(func pid=74973)[0m rmse_per_class: [0.114, 0.254, 0.087, 0.33, 0.085, 0.185, 0.286, 0.137, 0.143, 0.111]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.6539 | Steps: 4 | Val loss: 0.5003 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=78743)[0m rmse: 0.15160086750984192
[2m[36m(func pid=78743)[0m mae:  0.10850763320922852
[2m[36m(func pid=78743)[0m rmse_per_class: [0.091, 0.228, 0.062, 0.299, 0.061, 0.164, 0.257, 0.121, 0.136, 0.096]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14258207380771637
[2m[36m(func pid=79710)[0m mae:  0.09036123007535934
[2m[36m(func pid=79710)[0m rmse_per_class: [0.067, 0.215, 0.066, 0.281, 0.068, 0.15, 0.219, 0.114, 0.137, 0.108]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4187 | Steps: 4 | Val loss: 0.3194 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=68837)[0m rmse: 0.17921732366085052
[2m[36m(func pid=68837)[0m mae:  0.1316150277853012
[2m[36m(func pid=68837)[0m rmse_per_class: [0.117, 0.261, 0.096, 0.337, 0.107, 0.189, 0.293, 0.141, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3646 | Steps: 4 | Val loss: 0.2770 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.2970 | Steps: 4 | Val loss: 0.2641 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 17:44:14 (running for 00:28:31.02)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.654 |  0.179 |                   72 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.419 |  0.173 |                   48 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.366 |  0.152 |                   30 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.292 |  0.143 |                   29 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17348870635032654
[2m[36m(func pid=74973)[0m mae:  0.12700878083705902
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.255, 0.087, 0.331, 0.084, 0.185, 0.284, 0.138, 0.143, 0.111]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.6487 | Steps: 4 | Val loss: 0.4986 | Batch size: 32 | lr: 0.0001 | Duration: 3.12s
[2m[36m(func pid=78743)[0m rmse: 0.15092916786670685
[2m[36m(func pid=78743)[0m mae:  0.10796143114566803
[2m[36m(func pid=78743)[0m rmse_per_class: [0.09, 0.228, 0.061, 0.296, 0.061, 0.165, 0.255, 0.12, 0.136, 0.096]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14337709546089172
[2m[36m(func pid=79710)[0m mae:  0.09057404100894928
[2m[36m(func pid=79710)[0m rmse_per_class: [0.069, 0.214, 0.068, 0.281, 0.068, 0.151, 0.221, 0.112, 0.142, 0.109]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4143 | Steps: 4 | Val loss: 0.3178 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=68837)[0m rmse: 0.17902064323425293
[2m[36m(func pid=68837)[0m mae:  0.13144220411777496
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.336, 0.107, 0.19, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3590 | Steps: 4 | Val loss: 0.2767 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.2929 | Steps: 4 | Val loss: 0.2650 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 17:44:19 (running for 00:28:36.25)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.649 |  0.179 |                   73 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.414 |  0.173 |                   49 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.365 |  0.151 |                   31 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.297 |  0.143 |                   30 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17306610941886902
[2m[36m(func pid=74973)[0m mae:  0.12667153775691986
[2m[36m(func pid=74973)[0m rmse_per_class: [0.115, 0.255, 0.086, 0.33, 0.084, 0.185, 0.284, 0.137, 0.143, 0.111]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.6475 | Steps: 4 | Val loss: 0.4973 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=78743)[0m rmse: 0.15088514983654022
[2m[36m(func pid=78743)[0m mae:  0.10773538053035736
[2m[36m(func pid=78743)[0m rmse_per_class: [0.09, 0.229, 0.058, 0.296, 0.063, 0.165, 0.254, 0.121, 0.137, 0.097]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14574244618415833
[2m[36m(func pid=79710)[0m mae:  0.09203408658504486
[2m[36m(func pid=79710)[0m rmse_per_class: [0.066, 0.211, 0.068, 0.273, 0.082, 0.153, 0.228, 0.109, 0.145, 0.123]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4157 | Steps: 4 | Val loss: 0.3175 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=68837)[0m rmse: 0.17896445095539093
[2m[36m(func pid=68837)[0m mae:  0.13135017454624176
[2m[36m(func pid=68837)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.336, 0.107, 0.189, 0.293, 0.14, 0.142, 0.109]
[2m[36m(func pid=68837)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3522 | Steps: 4 | Val loss: 0.2754 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.2929 | Steps: 4 | Val loss: 0.2612 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 17:44:25 (running for 00:28:41.61)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00012 | RUNNING    | 192.168.7.53:68837 | 0.0001 |       0.9  |         0.0001 |  0.647 |  0.179 |                   74 |
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.416 |  0.173 |                   50 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.359 |  0.151 |                   32 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.293 |  0.146 |                   31 |
| train_01e98_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17292943596839905
[2m[36m(func pid=74973)[0m mae:  0.12653926014900208
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.254, 0.085, 0.33, 0.084, 0.185, 0.284, 0.138, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=68837)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.6410 | Steps: 4 | Val loss: 0.4931 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=78743)[0m rmse: 0.1500231772661209
[2m[36m(func pid=78743)[0m mae:  0.10701411962509155
[2m[36m(func pid=78743)[0m rmse_per_class: [0.09, 0.228, 0.056, 0.293, 0.064, 0.164, 0.253, 0.12, 0.136, 0.096]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14264534413814545
[2m[36m(func pid=79710)[0m mae:  0.09030147641897202
[2m[36m(func pid=79710)[0m rmse_per_class: [0.062, 0.212, 0.053, 0.271, 0.08, 0.155, 0.223, 0.109, 0.143, 0.119]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4103 | Steps: 4 | Val loss: 0.3172 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=68837)[0m rmse: 0.17900636792182922
[2m[36m(func pid=68837)[0m mae:  0.1313542276620865
[2m[36m(func pid=68837)[0m rmse_per_class: [0.117, 0.26, 0.097, 0.336, 0.107, 0.189, 0.293, 0.14, 0.142, 0.109]
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.2728 | Steps: 4 | Val loss: 0.2608 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3597 | Steps: 4 | Val loss: 0.2753 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=74973)[0m rmse: 0.17249421775341034
[2m[36m(func pid=74973)[0m mae:  0.12615735828876495
[2m[36m(func pid=74973)[0m rmse_per_class: [0.115, 0.254, 0.084, 0.33, 0.084, 0.186, 0.284, 0.137, 0.144, 0.109]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14165456593036652
[2m[36m(func pid=79710)[0m mae:  0.08955077826976776
[2m[36m(func pid=79710)[0m rmse_per_class: [0.062, 0.211, 0.058, 0.273, 0.068, 0.152, 0.22, 0.111, 0.148, 0.115]
[2m[36m(func pid=78743)[0m rmse: 0.15004728734493256
[2m[36m(func pid=78743)[0m mae:  0.10694696009159088
[2m[36m(func pid=78743)[0m rmse_per_class: [0.091, 0.228, 0.055, 0.292, 0.066, 0.164, 0.254, 0.119, 0.136, 0.096]
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4125 | Steps: 4 | Val loss: 0.3164 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=74973)[0m rmse: 0.1723669022321701
[2m[36m(func pid=74973)[0m mae:  0.12606748938560486
[2m[36m(func pid=74973)[0m rmse_per_class: [0.114, 0.255, 0.084, 0.329, 0.083, 0.185, 0.284, 0.136, 0.144, 0.109]
== Status ==
Current time: 2024-01-07 17:44:30 (running for 00:28:46.96)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.41  |  0.172 |                   51 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.352 |  0.15  |                   33 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.293 |  0.143 |                   32 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


== Status ==
Current time: 2024-01-07 17:44:38 (running for 00:28:54.46)
Memory usage on this node: 23.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.41  |  0.172 |                   51 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.352 |  0.15  |                   33 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.273 |  0.142 |                   33 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)

[2m[36m(func pid=79710)[0m 

[2m[36m(func pid=87539)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=87539)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=87539)[0m Configuration completed!
[2m[36m(func pid=87539)[0m New optimizer parameters:
[2m[36m(func pid=87539)[0m SGD (
[2m[36m(func pid=87539)[0m Parameter Group 0
[2m[36m(func pid=87539)[0m     dampening: 0
[2m[36m(func pid=87539)[0m     differentiable: False
[2m[36m(func pid=87539)[0m     foreach: None
[2m[36m(func pid=87539)[0m     lr: 0.0001
[2m[36m(func pid=87539)[0m     maximize: False
[2m[36m(func pid=87539)[0m     momentum: 0.99
[2m[36m(func pid=87539)[0m     nesterov: False
[2m[36m(func pid=87539)[0m     weight_decay: 1e-05
[2m[36m(func pid=87539)[0m )
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4109 | Steps: 4 | Val loss: 0.3153 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2961 | Steps: 4 | Val loss: 0.2574 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3460 | Steps: 4 | Val loss: 0.2739 | Batch size: 32 | lr: 0.01 | Duration: 3.20s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8938 | Steps: 4 | Val loss: 0.7025 | Batch size: 32 | lr: 0.0001 | Duration: 4.69s
== Status ==
Current time: 2024-01-07 17:44:43 (running for 00:28:59.48)
Memory usage on this node: 25.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.412 |  0.172 |                   52 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.36  |  0.15  |                   34 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.273 |  0.142 |                   33 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=79710)[0m rmse: 0.1386910229921341
[2m[36m(func pid=79710)[0m mae:  0.0877605527639389
[2m[36m(func pid=79710)[0m rmse_per_class: [0.063, 0.21, 0.054, 0.259, 0.06, 0.15, 0.219, 0.121, 0.142, 0.108]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m rmse: 0.17219163477420807
[2m[36m(func pid=74973)[0m mae:  0.12592120468616486
[2m[36m(func pid=74973)[0m rmse_per_class: [0.115, 0.254, 0.084, 0.329, 0.083, 0.185, 0.284, 0.136, 0.144, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14923031628131866
[2m[36m(func pid=78743)[0m mae:  0.10635838657617569
[2m[36m(func pid=78743)[0m rmse_per_class: [0.093, 0.228, 0.052, 0.288, 0.067, 0.162, 0.254, 0.118, 0.135, 0.094]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.18237021565437317
[2m[36m(func pid=87539)[0m mae:  0.13422270119190216
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.266, 0.107, 0.339, 0.112, 0.191, 0.294, 0.143, 0.143, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2922 | Steps: 4 | Val loss: 0.2592 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4084 | Steps: 4 | Val loss: 0.3149 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3375 | Steps: 4 | Val loss: 0.2749 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.8912 | Steps: 4 | Val loss: 0.6954 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=79710)[0m rmse: 0.13982930779457092
[2m[36m(func pid=79710)[0m mae:  0.08823167532682419
[2m[36m(func pid=79710)[0m rmse_per_class: [0.063, 0.212, 0.058, 0.268, 0.057, 0.15, 0.217, 0.119, 0.141, 0.114]
[2m[36m(func pid=79710)[0m 
== Status ==
Current time: 2024-01-07 17:44:48 (running for 00:29:05.07)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.411 |  0.172 |                   53 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.346 |  0.149 |                   35 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.292 |  0.14  |                   35 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.894 |  0.182 |                    1 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.1720312535762787
[2m[36m(func pid=74973)[0m mae:  0.12583336234092712
[2m[36m(func pid=74973)[0m rmse_per_class: [0.114, 0.253, 0.083, 0.329, 0.083, 0.185, 0.283, 0.136, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14998860657215118
[2m[36m(func pid=78743)[0m mae:  0.10693702846765518
[2m[36m(func pid=78743)[0m rmse_per_class: [0.095, 0.228, 0.053, 0.288, 0.068, 0.163, 0.256, 0.118, 0.135, 0.097]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.18162691593170166
[2m[36m(func pid=87539)[0m mae:  0.1336560845375061
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.266, 0.105, 0.338, 0.111, 0.19, 0.294, 0.142, 0.143, 0.111]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2844 | Steps: 4 | Val loss: 0.2567 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4092 | Steps: 4 | Val loss: 0.3128 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3344 | Steps: 4 | Val loss: 0.2749 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.8886 | Steps: 4 | Val loss: 0.6887 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 17:44:54 (running for 00:29:10.60)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.408 |  0.172 |                   54 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.338 |  0.15  |                   36 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.284 |  0.138 |                   36 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.891 |  0.182 |                    2 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17145279049873352
[2m[36m(func pid=74973)[0m mae:  0.12538738548755646
[2m[36m(func pid=74973)[0m rmse_per_class: [0.114, 0.254, 0.082, 0.328, 0.082, 0.184, 0.282, 0.136, 0.143, 0.109]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.13842879235744476
[2m[36m(func pid=79710)[0m mae:  0.08759941160678864
[2m[36m(func pid=79710)[0m rmse_per_class: [0.065, 0.21, 0.052, 0.254, 0.055, 0.153, 0.222, 0.111, 0.144, 0.118]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14998775720596313
[2m[36m(func pid=78743)[0m mae:  0.1068725734949112
[2m[36m(func pid=78743)[0m rmse_per_class: [0.097, 0.228, 0.053, 0.288, 0.067, 0.162, 0.255, 0.117, 0.135, 0.098]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.18087629973888397
[2m[36m(func pid=87539)[0m mae:  0.13304314017295837
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.265, 0.103, 0.338, 0.112, 0.19, 0.294, 0.141, 0.142, 0.11]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3087 | Steps: 4 | Val loss: 0.2601 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4078 | Steps: 4 | Val loss: 0.3128 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3474 | Steps: 4 | Val loss: 0.2754 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8843 | Steps: 4 | Val loss: 0.6826 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 17:44:59 (running for 00:29:16.13)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.409 |  0.171 |                   55 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.334 |  0.15  |                   37 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.309 |  0.141 |                   37 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.889 |  0.181 |                    3 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=79710)[0m rmse: 0.14120283722877502
[2m[36m(func pid=79710)[0m mae:  0.08933548629283905
[2m[36m(func pid=79710)[0m rmse_per_class: [0.064, 0.213, 0.046, 0.258, 0.054, 0.152, 0.226, 0.115, 0.162, 0.12]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m rmse: 0.1713150292634964
[2m[36m(func pid=74973)[0m mae:  0.12523069977760315
[2m[36m(func pid=74973)[0m rmse_per_class: [0.113, 0.254, 0.082, 0.328, 0.082, 0.184, 0.281, 0.136, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.1505778729915619
[2m[36m(func pid=78743)[0m mae:  0.10730509459972382
[2m[36m(func pid=78743)[0m rmse_per_class: [0.097, 0.228, 0.052, 0.288, 0.068, 0.162, 0.256, 0.117, 0.135, 0.102]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.18064440786838531
[2m[36m(func pid=87539)[0m mae:  0.13285551965236664
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.264, 0.102, 0.337, 0.111, 0.189, 0.295, 0.141, 0.142, 0.109]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2921 | Steps: 4 | Val loss: 0.2663 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4096 | Steps: 4 | Val loss: 0.3118 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3543 | Steps: 4 | Val loss: 0.2747 | Batch size: 32 | lr: 0.01 | Duration: 3.17s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.8763 | Steps: 4 | Val loss: 0.6776 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 17:45:04 (running for 00:29:21.30)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.408 |  0.171 |                   56 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.347 |  0.151 |                   38 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.292 |  0.146 |                   38 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.884 |  0.181 |                    4 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=79710)[0m rmse: 0.14591899514198303
[2m[36m(func pid=79710)[0m mae:  0.09234647452831268
[2m[36m(func pid=79710)[0m rmse_per_class: [0.068, 0.214, 0.059, 0.277, 0.063, 0.154, 0.231, 0.112, 0.168, 0.114]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m rmse: 0.17107674479484558
[2m[36m(func pid=74973)[0m mae:  0.12505193054676056
[2m[36m(func pid=74973)[0m rmse_per_class: [0.114, 0.253, 0.081, 0.327, 0.081, 0.184, 0.282, 0.137, 0.143, 0.108]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14994463324546814
[2m[36m(func pid=78743)[0m mae:  0.10652332007884979
[2m[36m(func pid=78743)[0m rmse_per_class: [0.095, 0.23, 0.051, 0.29, 0.066, 0.161, 0.253, 0.116, 0.135, 0.104]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.1804593801498413
[2m[36m(func pid=87539)[0m mae:  0.13267460465431213
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.263, 0.101, 0.337, 0.111, 0.189, 0.295, 0.14, 0.142, 0.11]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2787 | Steps: 4 | Val loss: 0.2677 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4088 | Steps: 4 | Val loss: 0.3119 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.8678 | Steps: 4 | Val loss: 0.6701 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3396 | Steps: 4 | Val loss: 0.2736 | Batch size: 32 | lr: 0.01 | Duration: 3.13s
== Status ==
Current time: 2024-01-07 17:45:10 (running for 00:29:26.60)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.41  |  0.171 |                   57 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.354 |  0.15  |                   39 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.279 |  0.146 |                   39 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.876 |  0.18  |                    5 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=79710)[0m rmse: 0.14641782641410828
[2m[36m(func pid=79710)[0m mae:  0.09240557253360748
[2m[36m(func pid=79710)[0m rmse_per_class: [0.069, 0.218, 0.062, 0.293, 0.073, 0.157, 0.227, 0.11, 0.151, 0.105]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m rmse: 0.1711646020412445
[2m[36m(func pid=74973)[0m mae:  0.12513503432273865
[2m[36m(func pid=74973)[0m rmse_per_class: [0.114, 0.252, 0.081, 0.328, 0.082, 0.184, 0.282, 0.137, 0.143, 0.109]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.18040134012699127
[2m[36m(func pid=87539)[0m mae:  0.1326313018798828
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.263, 0.1, 0.338, 0.111, 0.189, 0.294, 0.141, 0.143, 0.109]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.149386927485466
[2m[36m(func pid=78743)[0m mae:  0.10584847629070282
[2m[36m(func pid=78743)[0m rmse_per_class: [0.093, 0.231, 0.05, 0.286, 0.065, 0.161, 0.251, 0.117, 0.134, 0.105]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2820 | Steps: 4 | Val loss: 0.2712 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4079 | Steps: 4 | Val loss: 0.3119 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.8559 | Steps: 4 | Val loss: 0.6603 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 17:45:15 (running for 00:29:32.02)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.409 |  0.171 |                   58 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.34  |  0.149 |                   40 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.282 |  0.148 |                   40 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.868 |  0.18  |                    6 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3426 | Steps: 4 | Val loss: 0.2742 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=79710)[0m rmse: 0.14798058569431305
[2m[36m(func pid=79710)[0m mae:  0.0939866453409195
[2m[36m(func pid=79710)[0m rmse_per_class: [0.071, 0.222, 0.058, 0.298, 0.079, 0.157, 0.233, 0.11, 0.159, 0.095]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m rmse: 0.171281099319458
[2m[36m(func pid=74973)[0m mae:  0.12523339688777924
[2m[36m(func pid=74973)[0m rmse_per_class: [0.115, 0.252, 0.081, 0.328, 0.081, 0.184, 0.282, 0.137, 0.143, 0.109]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.18002036213874817
[2m[36m(func pid=87539)[0m mae:  0.13228651881217957
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.262, 0.099, 0.337, 0.111, 0.19, 0.294, 0.141, 0.142, 0.108]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14972151815891266
[2m[36m(func pid=78743)[0m mae:  0.10609173774719238
[2m[36m(func pid=78743)[0m rmse_per_class: [0.092, 0.23, 0.051, 0.29, 0.067, 0.161, 0.252, 0.116, 0.134, 0.106]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2723 | Steps: 4 | Val loss: 0.2666 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4091 | Steps: 4 | Val loss: 0.3124 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.8426 | Steps: 4 | Val loss: 0.6507 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=79710)[0m rmse: 0.14566579461097717
[2m[36m(func pid=79710)[0m mae:  0.09213551878929138
[2m[36m(func pid=79710)[0m rmse_per_class: [0.075, 0.216, 0.058, 0.286, 0.076, 0.155, 0.228, 0.114, 0.154, 0.094]
[2m[36m(func pid=79710)[0m 
== Status ==
Current time: 2024-01-07 17:45:20 (running for 00:29:37.38)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.408 |  0.171 |                   59 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.343 |  0.15  |                   41 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.272 |  0.146 |                   41 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.856 |  0.18  |                    7 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.1717665195465088
[2m[36m(func pid=74973)[0m mae:  0.12571093440055847
[2m[36m(func pid=74973)[0m rmse_per_class: [0.116, 0.253, 0.082, 0.329, 0.081, 0.183, 0.282, 0.138, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3446 | Steps: 4 | Val loss: 0.2728 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=87539)[0m rmse: 0.17977723479270935
[2m[36m(func pid=87539)[0m mae:  0.13205690681934357
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.262, 0.099, 0.337, 0.11, 0.19, 0.294, 0.14, 0.142, 0.108]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2816 | Steps: 4 | Val loss: 0.2624 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=78743)[0m rmse: 0.1486247330904007
[2m[36m(func pid=78743)[0m mae:  0.10515516996383667
[2m[36m(func pid=78743)[0m rmse_per_class: [0.089, 0.228, 0.051, 0.291, 0.067, 0.16, 0.248, 0.115, 0.134, 0.103]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4064 | Steps: 4 | Val loss: 0.3116 | Batch size: 32 | lr: 0.001 | Duration: 3.15s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.8322 | Steps: 4 | Val loss: 0.6413 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 17:45:26 (running for 00:29:42.77)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.409 |  0.172 |                   60 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.345 |  0.149 |                   42 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.282 |  0.144 |                   42 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.843 |  0.18  |                    8 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=79710)[0m rmse: 0.1442548930644989
[2m[36m(func pid=79710)[0m mae:  0.09027014672756195
[2m[36m(func pid=79710)[0m rmse_per_class: [0.07, 0.214, 0.066, 0.27, 0.082, 0.156, 0.223, 0.114, 0.144, 0.104]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m rmse: 0.17145490646362305
[2m[36m(func pid=74973)[0m mae:  0.12548664212226868
[2m[36m(func pid=74973)[0m rmse_per_class: [0.115, 0.252, 0.082, 0.329, 0.08, 0.183, 0.282, 0.137, 0.143, 0.111]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3471 | Steps: 4 | Val loss: 0.2713 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
[2m[36m(func pid=87539)[0m rmse: 0.1798805296421051
[2m[36m(func pid=87539)[0m mae:  0.13212084770202637
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.111, 0.19, 0.295, 0.14, 0.142, 0.109]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3011 | Steps: 4 | Val loss: 0.2615 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=78743)[0m rmse: 0.14740128815174103
[2m[36m(func pid=78743)[0m mae:  0.10427363216876984
[2m[36m(func pid=78743)[0m rmse_per_class: [0.086, 0.224, 0.052, 0.29, 0.067, 0.159, 0.247, 0.114, 0.134, 0.099]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4067 | Steps: 4 | Val loss: 0.3105 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.8152 | Steps: 4 | Val loss: 0.6295 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 17:45:31 (running for 00:29:48.01)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.406 |  0.171 |                   61 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.347 |  0.147 |                   43 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.301 |  0.144 |                   43 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.832 |  0.18  |                    9 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=79710)[0m rmse: 0.14404010772705078
[2m[36m(func pid=79710)[0m mae:  0.0899597778916359
[2m[36m(func pid=79710)[0m rmse_per_class: [0.066, 0.217, 0.063, 0.26, 0.072, 0.155, 0.222, 0.12, 0.137, 0.128]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=74973)[0m rmse: 0.17092281579971313
[2m[36m(func pid=74973)[0m mae:  0.1250816434621811
[2m[36m(func pid=74973)[0m rmse_per_class: [0.113, 0.252, 0.08, 0.329, 0.079, 0.183, 0.281, 0.137, 0.143, 0.111]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3499 | Steps: 4 | Val loss: 0.2724 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=87539)[0m rmse: 0.17973092198371887
[2m[36m(func pid=87539)[0m mae:  0.13200610876083374
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.11, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2809 | Steps: 4 | Val loss: 0.2632 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4036 | Steps: 4 | Val loss: 0.3106 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=78743)[0m rmse: 0.14792004227638245
[2m[36m(func pid=78743)[0m mae:  0.10487332195043564
[2m[36m(func pid=78743)[0m rmse_per_class: [0.085, 0.224, 0.052, 0.296, 0.068, 0.16, 0.245, 0.115, 0.137, 0.097]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.8002 | Steps: 4 | Val loss: 0.6167 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=79710)[0m rmse: 0.14345207810401917
[2m[36m(func pid=79710)[0m mae:  0.09027668088674545
[2m[36m(func pid=79710)[0m rmse_per_class: [0.063, 0.216, 0.058, 0.272, 0.065, 0.151, 0.227, 0.13, 0.132, 0.121]
[2m[36m(func pid=79710)[0m 
== Status ==
Current time: 2024-01-07 17:45:37 (running for 00:29:53.81)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.404 |  0.171 |                   63 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.35  |  0.148 |                   44 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.281 |  0.143 |                   44 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.815 |  0.18  |                   10 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.1710086315870285
[2m[36m(func pid=74973)[0m mae:  0.12521886825561523
[2m[36m(func pid=74973)[0m rmse_per_class: [0.114, 0.252, 0.08, 0.328, 0.079, 0.183, 0.281, 0.137, 0.144, 0.111]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3437 | Steps: 4 | Val loss: 0.2713 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=87539)[0m rmse: 0.1797308325767517
[2m[36m(func pid=87539)[0m mae:  0.13199597597122192
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.26, 0.099, 0.337, 0.11, 0.19, 0.294, 0.14, 0.142, 0.109]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2842 | Steps: 4 | Val loss: 0.2676 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4031 | Steps: 4 | Val loss: 0.3098 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=78743)[0m rmse: 0.1471147984266281
[2m[36m(func pid=78743)[0m mae:  0.10416726022958755
[2m[36m(func pid=78743)[0m rmse_per_class: [0.084, 0.222, 0.053, 0.294, 0.067, 0.16, 0.244, 0.114, 0.137, 0.095]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.7889 | Steps: 4 | Val loss: 0.6054 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=79710)[0m rmse: 0.14461417496204376
[2m[36m(func pid=79710)[0m mae:  0.09199308604001999
[2m[36m(func pid=79710)[0m rmse_per_class: [0.067, 0.213, 0.049, 0.292, 0.06, 0.156, 0.23, 0.12, 0.148, 0.111]
[2m[36m(func pid=79710)[0m 
== Status ==
Current time: 2024-01-07 17:45:42 (running for 00:29:59.16)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.403 |  0.171 |                   64 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.344 |  0.147 |                   45 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.284 |  0.145 |                   45 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.8   |  0.18  |                   11 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17059704661369324
[2m[36m(func pid=74973)[0m mae:  0.12481938302516937
[2m[36m(func pid=74973)[0m rmse_per_class: [0.113, 0.252, 0.08, 0.328, 0.079, 0.183, 0.281, 0.136, 0.144, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.1799335777759552
[2m[36m(func pid=87539)[0m mae:  0.13214926421642303
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.261, 0.1, 0.337, 0.11, 0.19, 0.295, 0.14, 0.143, 0.11]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3407 | Steps: 4 | Val loss: 0.2719 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2754 | Steps: 4 | Val loss: 0.2751 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4097 | Steps: 4 | Val loss: 0.3091 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.7754 | Steps: 4 | Val loss: 0.5937 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=78743)[0m rmse: 0.1474553644657135
[2m[36m(func pid=78743)[0m mae:  0.10441495478153229
[2m[36m(func pid=78743)[0m rmse_per_class: [0.085, 0.221, 0.056, 0.295, 0.066, 0.16, 0.244, 0.114, 0.138, 0.095]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.1484922617673874
[2m[36m(func pid=79710)[0m mae:  0.09483136236667633
[2m[36m(func pid=79710)[0m rmse_per_class: [0.07, 0.216, 0.047, 0.308, 0.063, 0.162, 0.233, 0.112, 0.174, 0.1]
[2m[36m(func pid=79710)[0m 
== Status ==
Current time: 2024-01-07 17:45:48 (running for 00:30:04.56)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.41  |  0.17  |                   65 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.341 |  0.147 |                   46 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.275 |  0.148 |                   46 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.789 |  0.18  |                   12 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.17015375196933746
[2m[36m(func pid=74973)[0m mae:  0.12439699470996857
[2m[36m(func pid=74973)[0m rmse_per_class: [0.113, 0.252, 0.079, 0.327, 0.079, 0.183, 0.281, 0.135, 0.143, 0.11]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.18004895746707916
[2m[36m(func pid=87539)[0m mae:  0.1322164237499237
[2m[36m(func pid=87539)[0m rmse_per_class: [0.114, 0.261, 0.1, 0.338, 0.11, 0.19, 0.295, 0.14, 0.143, 0.11]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3406 | Steps: 4 | Val loss: 0.2727 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2881 | Steps: 4 | Val loss: 0.2791 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4084 | Steps: 4 | Val loss: 0.3083 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7566 | Steps: 4 | Val loss: 0.5812 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=78743)[0m rmse: 0.14805980026721954
[2m[36m(func pid=78743)[0m mae:  0.10469400882720947
[2m[36m(func pid=78743)[0m rmse_per_class: [0.084, 0.224, 0.055, 0.298, 0.066, 0.159, 0.244, 0.114, 0.139, 0.099]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.15204362571239471
[2m[36m(func pid=79710)[0m mae:  0.09710988402366638
[2m[36m(func pid=79710)[0m rmse_per_class: [0.07, 0.221, 0.047, 0.311, 0.072, 0.173, 0.243, 0.112, 0.182, 0.09]
[2m[36m(func pid=79710)[0m 
== Status ==
Current time: 2024-01-07 17:45:53 (running for 00:30:09.76)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.408 |  0.17  |                   66 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.341 |  0.148 |                   47 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.288 |  0.152 |                   47 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.775 |  0.18  |                   13 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.16977199912071228
[2m[36m(func pid=74973)[0m mae:  0.12401839345693588
[2m[36m(func pid=74973)[0m rmse_per_class: [0.113, 0.251, 0.079, 0.327, 0.079, 0.183, 0.281, 0.135, 0.143, 0.109]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17995937168598175
[2m[36m(func pid=87539)[0m mae:  0.13214702904224396
[2m[36m(func pid=87539)[0m rmse_per_class: [0.114, 0.261, 0.1, 0.338, 0.109, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2803 | Steps: 4 | Val loss: 0.2780 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3490 | Steps: 4 | Val loss: 0.2730 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4011 | Steps: 4 | Val loss: 0.3078 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.7393 | Steps: 4 | Val loss: 0.5672 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=79710)[0m rmse: 0.15353178977966309
[2m[36m(func pid=79710)[0m mae:  0.0972333699464798
[2m[36m(func pid=79710)[0m rmse_per_class: [0.066, 0.214, 0.048, 0.294, 0.077, 0.163, 0.241, 0.113, 0.211, 0.108]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.1481354683637619
[2m[36m(func pid=78743)[0m mae:  0.10503631830215454
[2m[36m(func pid=78743)[0m rmse_per_class: [0.083, 0.225, 0.055, 0.299, 0.066, 0.159, 0.244, 0.114, 0.14, 0.096]
[2m[36m(func pid=78743)[0m 
== Status ==
Current time: 2024-01-07 17:45:58 (running for 00:30:15.17)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.401 |  0.169 |                   67 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.349 |  0.148 |                   48 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.28  |  0.154 |                   48 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.757 |  0.18  |                   14 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.16949355602264404
[2m[36m(func pid=74973)[0m mae:  0.12374387681484222
[2m[36m(func pid=74973)[0m rmse_per_class: [0.113, 0.251, 0.079, 0.326, 0.079, 0.183, 0.281, 0.134, 0.143, 0.108]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17969365417957306
[2m[36m(func pid=87539)[0m mae:  0.1319512277841568
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.261, 0.098, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2885 | Steps: 4 | Val loss: 0.2746 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3425 | Steps: 4 | Val loss: 0.2729 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4034 | Steps: 4 | Val loss: 0.3077 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.7206 | Steps: 4 | Val loss: 0.5504 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=79710)[0m rmse: 0.15188446640968323
[2m[36m(func pid=79710)[0m mae:  0.09599654376506805
[2m[36m(func pid=79710)[0m rmse_per_class: [0.065, 0.211, 0.053, 0.276, 0.072, 0.161, 0.235, 0.112, 0.208, 0.126]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14809158444404602
[2m[36m(func pid=78743)[0m mae:  0.10467851161956787
[2m[36m(func pid=78743)[0m rmse_per_class: [0.082, 0.225, 0.058, 0.298, 0.066, 0.158, 0.244, 0.113, 0.14, 0.097]
[2m[36m(func pid=78743)[0m 
== Status ==
Current time: 2024-01-07 17:46:03 (running for 00:30:20.34)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.403 |  0.169 |                   68 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.342 |  0.148 |                   49 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.289 |  0.152 |                   49 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.739 |  0.18  |                   15 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.16936971247196198
[2m[36m(func pid=74973)[0m mae:  0.1236390694975853
[2m[36m(func pid=74973)[0m rmse_per_class: [0.112, 0.25, 0.079, 0.326, 0.079, 0.183, 0.28, 0.134, 0.143, 0.108]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.1793840229511261
[2m[36m(func pid=87539)[0m mae:  0.13169027864933014
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.26, 0.098, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2868 | Steps: 4 | Val loss: 0.2748 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3444 | Steps: 4 | Val loss: 0.2717 | Batch size: 32 | lr: 0.01 | Duration: 3.19s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3997 | Steps: 4 | Val loss: 0.3072 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.6989 | Steps: 4 | Val loss: 0.5364 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=79710)[0m rmse: 0.15200412273406982
[2m[36m(func pid=79710)[0m mae:  0.09584735333919525
[2m[36m(func pid=79710)[0m rmse_per_class: [0.068, 0.212, 0.063, 0.277, 0.065, 0.16, 0.229, 0.113, 0.202, 0.131]
[2m[36m(func pid=79710)[0m 
== Status ==
Current time: 2024-01-07 17:46:09 (running for 00:30:25.70)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.403 |  0.169 |                   68 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.344 |  0.147 |                   50 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.287 |  0.152 |                   50 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.721 |  0.179 |                   16 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.16924193501472473
[2m[36m(func pid=74973)[0m mae:  0.1235659271478653
[2m[36m(func pid=74973)[0m rmse_per_class: [0.112, 0.25, 0.078, 0.326, 0.078, 0.183, 0.28, 0.134, 0.143, 0.108]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.1473981887102127
[2m[36m(func pid=78743)[0m mae:  0.1039092093706131
[2m[36m(func pid=78743)[0m rmse_per_class: [0.081, 0.223, 0.059, 0.294, 0.066, 0.158, 0.244, 0.113, 0.138, 0.098]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.1793368011713028
[2m[36m(func pid=87539)[0m mae:  0.13166961073875427
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.26, 0.097, 0.337, 0.108, 0.19, 0.293, 0.14, 0.143, 0.11]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2831 | Steps: 4 | Val loss: 0.2669 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3975 | Steps: 4 | Val loss: 0.3065 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3389 | Steps: 4 | Val loss: 0.2723 | Batch size: 32 | lr: 0.01 | Duration: 3.18s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.6891 | Steps: 4 | Val loss: 0.5235 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=79710)[0m rmse: 0.14637026190757751
[2m[36m(func pid=79710)[0m mae:  0.09193815290927887
[2m[36m(func pid=79710)[0m rmse_per_class: [0.08, 0.21, 0.059, 0.271, 0.059, 0.158, 0.225, 0.111, 0.173, 0.117]
[2m[36m(func pid=79710)[0m 
== Status ==
Current time: 2024-01-07 17:46:14 (running for 00:30:30.95)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   70 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.344 |  0.147 |                   50 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.283 |  0.146 |                   51 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.699 |  0.179 |                   17 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.16924700140953064
[2m[36m(func pid=74973)[0m mae:  0.12359760701656342
[2m[36m(func pid=74973)[0m rmse_per_class: [0.113, 0.25, 0.078, 0.326, 0.078, 0.183, 0.279, 0.135, 0.143, 0.108]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14790868759155273
[2m[36m(func pid=78743)[0m mae:  0.10432787984609604
[2m[36m(func pid=78743)[0m rmse_per_class: [0.083, 0.223, 0.057, 0.296, 0.067, 0.158, 0.245, 0.113, 0.139, 0.098]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17929241061210632
[2m[36m(func pid=87539)[0m mae:  0.13163410127162933
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.26, 0.097, 0.337, 0.108, 0.19, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2766 | Steps: 4 | Val loss: 0.2642 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4012 | Steps: 4 | Val loss: 0.3063 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3418 | Steps: 4 | Val loss: 0.2707 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.6740 | Steps: 4 | Val loss: 0.5115 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=79710)[0m rmse: 0.14305201172828674
[2m[36m(func pid=79710)[0m mae:  0.08976145833730698
[2m[36m(func pid=79710)[0m rmse_per_class: [0.074, 0.214, 0.053, 0.282, 0.062, 0.156, 0.22, 0.111, 0.149, 0.11]
[2m[36m(func pid=79710)[0m 
== Status ==
Current time: 2024-01-07 17:46:19 (running for 00:30:36.20)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.401 |  0.169 |                   71 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.339 |  0.148 |                   51 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.277 |  0.143 |                   52 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.689 |  0.179 |                   18 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.16913890838623047
[2m[36m(func pid=74973)[0m mae:  0.12348820269107819
[2m[36m(func pid=74973)[0m rmse_per_class: [0.114, 0.249, 0.078, 0.326, 0.079, 0.182, 0.279, 0.135, 0.142, 0.107]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14693915843963623
[2m[36m(func pid=78743)[0m mae:  0.1034226045012474
[2m[36m(func pid=78743)[0m rmse_per_class: [0.085, 0.222, 0.056, 0.291, 0.065, 0.158, 0.244, 0.113, 0.138, 0.096]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17925743758678436
[2m[36m(func pid=87539)[0m mae:  0.13158836960792542
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.26, 0.097, 0.337, 0.108, 0.19, 0.293, 0.14, 0.143, 0.11]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2864 | Steps: 4 | Val loss: 0.2667 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3986 | Steps: 4 | Val loss: 0.3060 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.6561 | Steps: 4 | Val loss: 0.4998 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3425 | Steps: 4 | Val loss: 0.2704 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
[2m[36m(func pid=79710)[0m rmse: 0.14609214663505554
[2m[36m(func pid=79710)[0m mae:  0.09153664857149124
[2m[36m(func pid=79710)[0m rmse_per_class: [0.069, 0.216, 0.06, 0.282, 0.075, 0.167, 0.231, 0.111, 0.143, 0.107]
[2m[36m(func pid=79710)[0m 
== Status ==
Current time: 2024-01-07 17:46:25 (running for 00:30:41.56)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.399 |  0.169 |                   72 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.342 |  0.147 |                   52 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.286 |  0.146 |                   53 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.674 |  0.179 |                   19 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.16904325783252716
[2m[36m(func pid=74973)[0m mae:  0.12343436479568481
[2m[36m(func pid=74973)[0m rmse_per_class: [0.114, 0.25, 0.078, 0.325, 0.078, 0.182, 0.279, 0.135, 0.143, 0.107]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17918309569358826
[2m[36m(func pid=87539)[0m mae:  0.1314893662929535
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.26, 0.097, 0.337, 0.106, 0.19, 0.293, 0.14, 0.144, 0.109]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.1467316597700119
[2m[36m(func pid=78743)[0m mae:  0.10321862995624542
[2m[36m(func pid=78743)[0m rmse_per_class: [0.087, 0.222, 0.055, 0.29, 0.066, 0.156, 0.245, 0.112, 0.138, 0.096]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2817 | Steps: 4 | Val loss: 0.2741 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4003 | Steps: 4 | Val loss: 0.3066 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.6399 | Steps: 4 | Val loss: 0.4856 | Batch size: 32 | lr: 0.0001 | Duration: 3.12s
[2m[36m(func pid=79710)[0m rmse: 0.15109972655773163
[2m[36m(func pid=79710)[0m mae:  0.09511971473693848
[2m[36m(func pid=79710)[0m rmse_per_class: [0.063, 0.217, 0.058, 0.286, 0.073, 0.165, 0.241, 0.115, 0.186, 0.105]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3319 | Steps: 4 | Val loss: 0.2711 | Batch size: 32 | lr: 0.01 | Duration: 3.22s
== Status ==
Current time: 2024-01-07 17:46:30 (running for 00:30:46.77)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.4   |  0.169 |                   73 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.342 |  0.147 |                   53 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.282 |  0.151 |                   54 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.656 |  0.179 |                   20 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.16942879557609558
[2m[36m(func pid=74973)[0m mae:  0.1237853541970253
[2m[36m(func pid=74973)[0m rmse_per_class: [0.113, 0.25, 0.08, 0.325, 0.078, 0.183, 0.28, 0.135, 0.143, 0.108]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.1790025383234024
[2m[36m(func pid=87539)[0m mae:  0.13141445815563202
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.337, 0.104, 0.19, 0.293, 0.14, 0.144, 0.11]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14722426235675812
[2m[36m(func pid=78743)[0m mae:  0.10360368341207504
[2m[36m(func pid=78743)[0m rmse_per_class: [0.087, 0.221, 0.054, 0.292, 0.066, 0.157, 0.246, 0.113, 0.141, 0.097]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2744 | Steps: 4 | Val loss: 0.2783 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3999 | Steps: 4 | Val loss: 0.3067 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.6261 | Steps: 4 | Val loss: 0.4752 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=79710)[0m rmse: 0.15239600837230682
[2m[36m(func pid=79710)[0m mae:  0.09621677547693253
[2m[36m(func pid=79710)[0m rmse_per_class: [0.063, 0.22, 0.05, 0.292, 0.074, 0.162, 0.243, 0.116, 0.201, 0.102]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3401 | Steps: 4 | Val loss: 0.2709 | Batch size: 32 | lr: 0.01 | Duration: 3.15s
== Status ==
Current time: 2024-01-07 17:46:35 (running for 00:30:52.05)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00013 | RUNNING    | 192.168.7.53:74973 | 0.001  |       0.9  |         0.0001 |  0.4   |  0.169 |                   74 |
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.332 |  0.147 |                   54 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.274 |  0.152 |                   55 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.64  |  0.179 |                   21 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.16928723454475403
[2m[36m(func pid=74973)[0m mae:  0.12365126609802246
[2m[36m(func pid=74973)[0m rmse_per_class: [0.112, 0.251, 0.079, 0.326, 0.078, 0.182, 0.279, 0.135, 0.143, 0.109]
[2m[36m(func pid=74973)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.1788683980703354
[2m[36m(func pid=87539)[0m mae:  0.13128478825092316
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.26, 0.097, 0.336, 0.104, 0.19, 0.293, 0.139, 0.144, 0.111]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2979 | Steps: 4 | Val loss: 0.2740 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=78743)[0m rmse: 0.1470838487148285
[2m[36m(func pid=78743)[0m mae:  0.10343720018863678
[2m[36m(func pid=78743)[0m rmse_per_class: [0.085, 0.221, 0.053, 0.291, 0.065, 0.157, 0.244, 0.113, 0.143, 0.098]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=74973)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3967 | Steps: 4 | Val loss: 0.3057 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.6084 | Steps: 4 | Val loss: 0.4645 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=79710)[0m rmse: 0.14905397593975067
[2m[36m(func pid=79710)[0m mae:  0.09334295988082886
[2m[36m(func pid=79710)[0m rmse_per_class: [0.064, 0.227, 0.045, 0.292, 0.073, 0.16, 0.231, 0.116, 0.17, 0.111]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3296 | Steps: 4 | Val loss: 0.2723 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
== Status ==
Current time: 2024-01-07 17:46:41 (running for 00:30:57.50)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (7 PENDING, 3 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.34  |  0.147 |                   55 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.298 |  0.149 |                   56 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.626 |  0.179 |                   22 |
| train_01e98_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=74973)[0m rmse: 0.16901032626628876
[2m[36m(func pid=74973)[0m mae:  0.12340062856674194
[2m[36m(func pid=74973)[0m rmse_per_class: [0.114, 0.25, 0.078, 0.326, 0.078, 0.182, 0.278, 0.135, 0.142, 0.108]
[2m[36m(func pid=87539)[0m rmse: 0.178592711687088
[2m[36m(func pid=87539)[0m mae:  0.1310795247554779
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.26, 0.095, 0.336, 0.104, 0.19, 0.292, 0.14, 0.144, 0.11]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2693 | Steps: 4 | Val loss: 0.2677 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=78743)[0m rmse: 0.14817294478416443
[2m[36m(func pid=78743)[0m mae:  0.10428090393543243
[2m[36m(func pid=78743)[0m rmse_per_class: [0.088, 0.224, 0.054, 0.295, 0.066, 0.157, 0.243, 0.112, 0.146, 0.097]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.5975 | Steps: 4 | Val loss: 0.4506 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=79710)[0m rmse: 0.14439207315444946
[2m[36m(func pid=79710)[0m mae:  0.09046050906181335
[2m[36m(func pid=79710)[0m rmse_per_class: [0.067, 0.218, 0.043, 0.291, 0.07, 0.157, 0.22, 0.115, 0.151, 0.112]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3392 | Steps: 4 | Val loss: 0.2740 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=87539)[0m rmse: 0.17849574983119965
[2m[36m(func pid=87539)[0m mae:  0.13103114068508148
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.261, 0.095, 0.336, 0.102, 0.189, 0.292, 0.14, 0.144, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2851 | Steps: 4 | Val loss: 0.2669 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=78743)[0m rmse: 0.14921800792217255
[2m[36m(func pid=78743)[0m mae:  0.10494216531515121
[2m[36m(func pid=78743)[0m rmse_per_class: [0.086, 0.224, 0.057, 0.302, 0.07, 0.157, 0.243, 0.113, 0.146, 0.095]
== Status ==
Current time: 2024-01-07 17:46:47 (running for 00:31:03.87)
Memory usage on this node: 22.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.33  |  0.148 |                   56 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.269 |  0.144 |                   57 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.598 |  0.178 |                   24 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=93214)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=93214)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=93214)[0m Configuration completed!
[2m[36m(func pid=93214)[0m New optimizer parameters:
[2m[36m(func pid=93214)[0m SGD (
[2m[36m(func pid=93214)[0m Parameter Group 0
[2m[36m(func pid=93214)[0m     dampening: 0
[2m[36m(func pid=93214)[0m     differentiable: False
[2m[36m(func pid=93214)[0m     foreach: None
[2m[36m(func pid=93214)[0m     lr: 0.001
[2m[36m(func pid=93214)[0m     maximize: False
[2m[36m(func pid=93214)[0m     momentum: 0.99
[2m[36m(func pid=93214)[0m     nesterov: False
[2m[36m(func pid=93214)[0m     weight_decay: 1e-05
[2m[36m(func pid=93214)[0m )
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.5776 | Steps: 4 | Val loss: 0.4395 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=79710)[0m rmse: 0.14440102875232697
[2m[36m(func pid=79710)[0m mae:  0.09073712676763535
[2m[36m(func pid=79710)[0m rmse_per_class: [0.069, 0.216, 0.042, 0.285, 0.069, 0.156, 0.223, 0.122, 0.152, 0.109]
[2m[36m(func pid=79710)[0m 
== Status ==
Current time: 2024-01-07 17:46:52 (running for 00:31:09.28)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.339 |  0.149 |                   57 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.285 |  0.144 |                   58 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.578 |  0.178 |                   25 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.17830237746238708
[2m[36m(func pid=87539)[0m mae:  0.13090884685516357
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.26, 0.094, 0.336, 0.102, 0.189, 0.292, 0.14, 0.144, 0.111]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3289 | Steps: 4 | Val loss: 0.2739 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2783 | Steps: 4 | Val loss: 0.2725 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8921 | Steps: 4 | Val loss: 0.6979 | Batch size: 32 | lr: 0.001 | Duration: 4.63s
[2m[36m(func pid=78743)[0m rmse: 0.14908170700073242
[2m[36m(func pid=78743)[0m mae:  0.10477453470230103
[2m[36m(func pid=78743)[0m rmse_per_class: [0.085, 0.225, 0.056, 0.301, 0.071, 0.156, 0.243, 0.113, 0.146, 0.096]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.5676 | Steps: 4 | Val loss: 0.4293 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=79710)[0m rmse: 0.1503940373659134
[2m[36m(func pid=79710)[0m mae:  0.09441006183624268
[2m[36m(func pid=79710)[0m rmse_per_class: [0.07, 0.22, 0.048, 0.281, 0.073, 0.166, 0.238, 0.119, 0.166, 0.123]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.1826443374156952
[2m[36m(func pid=93214)[0m mae:  0.13441899418830872
[2m[36m(func pid=93214)[0m rmse_per_class: [0.116, 0.267, 0.108, 0.339, 0.112, 0.19, 0.294, 0.144, 0.144, 0.112]
[2m[36m(func pid=93214)[0m 
== Status ==
Current time: 2024-01-07 17:46:58 (running for 00:31:14.58)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.329 |  0.149 |                   58 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.278 |  0.15  |                   59 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.568 |  0.179 |                   26 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.892 |  0.183 |                    1 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.17858529090881348
[2m[36m(func pid=87539)[0m mae:  0.13112397491931915
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.261, 0.096, 0.336, 0.101, 0.189, 0.292, 0.14, 0.144, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3446 | Steps: 4 | Val loss: 0.2721 | Batch size: 32 | lr: 0.01 | Duration: 3.13s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2801 | Steps: 4 | Val loss: 0.2780 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.8722 | Steps: 4 | Val loss: 0.6671 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.5565 | Steps: 4 | Val loss: 0.4216 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=78743)[0m rmse: 0.14794103801250458
[2m[36m(func pid=78743)[0m mae:  0.10375213623046875
[2m[36m(func pid=78743)[0m rmse_per_class: [0.085, 0.224, 0.055, 0.296, 0.069, 0.156, 0.242, 0.112, 0.144, 0.097]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.15418951213359833
[2m[36m(func pid=79710)[0m mae:  0.09673470258712769
[2m[36m(func pid=79710)[0m rmse_per_class: [0.084, 0.22, 0.053, 0.288, 0.07, 0.164, 0.239, 0.113, 0.181, 0.13]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.18180222809314728
[2m[36m(func pid=93214)[0m mae:  0.1338060200214386
[2m[36m(func pid=93214)[0m rmse_per_class: [0.117, 0.266, 0.104, 0.339, 0.112, 0.19, 0.294, 0.142, 0.143, 0.112]
[2m[36m(func pid=93214)[0m 
== Status ==
Current time: 2024-01-07 17:47:03 (running for 00:31:19.90)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.345 |  0.148 |                   59 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.28  |  0.154 |                   60 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.556 |  0.178 |                   27 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.872 |  0.182 |                    2 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.17834077775478363
[2m[36m(func pid=87539)[0m mae:  0.13090911507606506
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.26, 0.096, 0.336, 0.1, 0.189, 0.292, 0.139, 0.145, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2880 | Steps: 4 | Val loss: 0.2760 | Batch size: 32 | lr: 0.1 | Duration: 2.67s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3339 | Steps: 4 | Val loss: 0.2712 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.8349 | Steps: 4 | Val loss: 0.6284 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.5451 | Steps: 4 | Val loss: 0.4155 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=79710)[0m rmse: 0.15119829773902893
[2m[36m(func pid=79710)[0m mae:  0.09421473741531372
[2m[36m(func pid=79710)[0m rmse_per_class: [0.075, 0.227, 0.052, 0.292, 0.072, 0.162, 0.231, 0.11, 0.166, 0.125]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14746953547000885
[2m[36m(func pid=78743)[0m mae:  0.10337535291910172
[2m[36m(func pid=78743)[0m rmse_per_class: [0.084, 0.222, 0.056, 0.292, 0.068, 0.156, 0.243, 0.112, 0.143, 0.098]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.1810946762561798
[2m[36m(func pid=93214)[0m mae:  0.13322383165359497
[2m[36m(func pid=93214)[0m rmse_per_class: [0.116, 0.265, 0.102, 0.338, 0.112, 0.189, 0.294, 0.141, 0.142, 0.111]
[2m[36m(func pid=93214)[0m 
== Status ==
Current time: 2024-01-07 17:47:08 (running for 00:31:25.09)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.334 |  0.147 |                   60 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.288 |  0.151 |                   61 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.545 |  0.178 |                   28 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.835 |  0.181 |                    3 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.17843832075595856
[2m[36m(func pid=87539)[0m mae:  0.13109518587589264
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.261, 0.094, 0.336, 0.1, 0.188, 0.293, 0.139, 0.145, 0.113]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2853 | Steps: 4 | Val loss: 0.2751 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3303 | Steps: 4 | Val loss: 0.2710 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.7838 | Steps: 4 | Val loss: 0.5831 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.5304 | Steps: 4 | Val loss: 0.4060 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=79710)[0m rmse: 0.1485469490289688
[2m[36m(func pid=79710)[0m mae:  0.0920109823346138
[2m[36m(func pid=79710)[0m rmse_per_class: [0.065, 0.231, 0.05, 0.286, 0.063, 0.16, 0.226, 0.11, 0.155, 0.141]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.1474059820175171
[2m[36m(func pid=78743)[0m mae:  0.10325859487056732
[2m[36m(func pid=78743)[0m rmse_per_class: [0.084, 0.222, 0.059, 0.292, 0.067, 0.155, 0.242, 0.112, 0.142, 0.099]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.18026591837406158
[2m[36m(func pid=93214)[0m mae:  0.1325293332338333
[2m[36m(func pid=93214)[0m rmse_per_class: [0.116, 0.264, 0.1, 0.337, 0.11, 0.189, 0.294, 0.14, 0.142, 0.11]
[2m[36m(func pid=93214)[0m 
== Status ==
Current time: 2024-01-07 17:47:13 (running for 00:31:30.35)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.33  |  0.147 |                   61 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.285 |  0.149 |                   62 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.53  |  0.178 |                   29 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.784 |  0.18  |                    4 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.17836537957191467
[2m[36m(func pid=87539)[0m mae:  0.1310032308101654
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.26, 0.094, 0.336, 0.1, 0.189, 0.292, 0.14, 0.144, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2990 | Steps: 4 | Val loss: 0.2731 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3351 | Steps: 4 | Val loss: 0.2727 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7280 | Steps: 4 | Val loss: 0.5332 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.5188 | Steps: 4 | Val loss: 0.3985 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=79710)[0m rmse: 0.14877161383628845
[2m[36m(func pid=79710)[0m mae:  0.09247393906116486
[2m[36m(func pid=79710)[0m rmse_per_class: [0.064, 0.224, 0.049, 0.277, 0.063, 0.159, 0.229, 0.112, 0.182, 0.129]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14858858287334442
[2m[36m(func pid=78743)[0m mae:  0.10396013408899307
[2m[36m(func pid=78743)[0m rmse_per_class: [0.083, 0.224, 0.063, 0.298, 0.069, 0.156, 0.242, 0.111, 0.141, 0.098]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.1798228770494461
[2m[36m(func pid=93214)[0m mae:  0.13211950659751892
[2m[36m(func pid=93214)[0m rmse_per_class: [0.116, 0.263, 0.099, 0.336, 0.109, 0.189, 0.294, 0.141, 0.142, 0.11]
[2m[36m(func pid=93214)[0m 
== Status ==
Current time: 2024-01-07 17:47:19 (running for 00:31:35.61)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.335 |  0.149 |                   62 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.299 |  0.149 |                   63 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.519 |  0.178 |                   30 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.728 |  0.18  |                    5 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.178114116191864
[2m[36m(func pid=87539)[0m mae:  0.13076114654541016
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.26, 0.093, 0.336, 0.1, 0.188, 0.292, 0.139, 0.144, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2831 | Steps: 4 | Val loss: 0.2691 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3295 | Steps: 4 | Val loss: 0.2724 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.6639 | Steps: 4 | Val loss: 0.4843 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.5111 | Steps: 4 | Val loss: 0.3911 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=79710)[0m rmse: 0.1479608118534088
[2m[36m(func pid=79710)[0m mae:  0.09188838303089142
[2m[36m(func pid=79710)[0m rmse_per_class: [0.063, 0.216, 0.07, 0.264, 0.062, 0.158, 0.229, 0.112, 0.19, 0.114]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.1791922152042389
[2m[36m(func pid=93214)[0m mae:  0.13159754872322083
[2m[36m(func pid=93214)[0m rmse_per_class: [0.116, 0.261, 0.097, 0.336, 0.106, 0.189, 0.293, 0.141, 0.142, 0.11]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14825162291526794
[2m[36m(func pid=78743)[0m mae:  0.10368071496486664
[2m[36m(func pid=78743)[0m rmse_per_class: [0.084, 0.224, 0.061, 0.3, 0.07, 0.154, 0.241, 0.111, 0.141, 0.098]
[2m[36m(func pid=78743)[0m 
== Status ==
Current time: 2024-01-07 17:47:24 (running for 00:31:40.75)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.33  |  0.148 |                   63 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.283 |  0.148 |                   64 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.511 |  0.178 |                   31 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.664 |  0.179 |                    6 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.17813369631767273
[2m[36m(func pid=87539)[0m mae:  0.1308210790157318
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.26, 0.093, 0.336, 0.1, 0.189, 0.292, 0.14, 0.144, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2863 | Steps: 4 | Val loss: 0.2629 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.6073 | Steps: 4 | Val loss: 0.4407 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3223 | Steps: 4 | Val loss: 0.2702 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.5025 | Steps: 4 | Val loss: 0.3826 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=79710)[0m rmse: 0.14263126254081726
[2m[36m(func pid=79710)[0m mae:  0.08844251930713654
[2m[36m(func pid=79710)[0m rmse_per_class: [0.064, 0.215, 0.074, 0.261, 0.06, 0.159, 0.224, 0.111, 0.156, 0.102]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.17870911955833435
[2m[36m(func pid=93214)[0m mae:  0.13115952908992767
[2m[36m(func pid=93214)[0m rmse_per_class: [0.117, 0.26, 0.096, 0.336, 0.105, 0.189, 0.293, 0.14, 0.142, 0.11]
[2m[36m(func pid=93214)[0m 
== Status ==
Current time: 2024-01-07 17:47:29 (running for 00:31:45.84)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.322 |  0.146 |                   64 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.286 |  0.143 |                   65 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.511 |  0.178 |                   31 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.607 |  0.179 |                    7 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=78743)[0m rmse: 0.14637012779712677
[2m[36m(func pid=78743)[0m mae:  0.1022576093673706
[2m[36m(func pid=78743)[0m rmse_per_class: [0.079, 0.221, 0.057, 0.295, 0.068, 0.153, 0.242, 0.11, 0.139, 0.099]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17796151340007782
[2m[36m(func pid=87539)[0m mae:  0.1306804120540619
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.259, 0.093, 0.336, 0.099, 0.188, 0.292, 0.14, 0.144, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3021 | Steps: 4 | Val loss: 0.2675 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5524 | Steps: 4 | Val loss: 0.4009 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4936 | Steps: 4 | Val loss: 0.3741 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3400 | Steps: 4 | Val loss: 0.2706 | Batch size: 32 | lr: 0.01 | Duration: 3.19s
[2m[36m(func pid=79710)[0m rmse: 0.14508429169654846
[2m[36m(func pid=79710)[0m mae:  0.08994028717279434
[2m[36m(func pid=79710)[0m rmse_per_class: [0.066, 0.218, 0.065, 0.279, 0.06, 0.166, 0.226, 0.118, 0.139, 0.115]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.17790846526622772
[2m[36m(func pid=93214)[0m mae:  0.13052822649478912
[2m[36m(func pid=93214)[0m rmse_per_class: [0.117, 0.259, 0.093, 0.334, 0.102, 0.189, 0.292, 0.14, 0.142, 0.11]
[2m[36m(func pid=93214)[0m 
== Status ==
Current time: 2024-01-07 17:47:34 (running for 00:31:51.18)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.322 |  0.146 |                   64 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.302 |  0.145 |                   66 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.494 |  0.177 |                   33 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.552 |  0.178 |                    8 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.17733430862426758
[2m[36m(func pid=87539)[0m mae:  0.13016338646411896
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.258, 0.091, 0.335, 0.098, 0.188, 0.292, 0.14, 0.144, 0.111]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14674869179725647
[2m[36m(func pid=78743)[0m mae:  0.10250405967235565
[2m[36m(func pid=78743)[0m rmse_per_class: [0.08, 0.223, 0.054, 0.294, 0.063, 0.154, 0.24, 0.111, 0.143, 0.106]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2865 | Steps: 4 | Val loss: 0.2696 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5084 | Steps: 4 | Val loss: 0.3690 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4872 | Steps: 4 | Val loss: 0.3669 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=79710)[0m rmse: 0.1460115760564804
[2m[36m(func pid=79710)[0m mae:  0.0908808559179306
[2m[36m(func pid=79710)[0m rmse_per_class: [0.073, 0.219, 0.059, 0.29, 0.062, 0.158, 0.226, 0.119, 0.143, 0.112]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3300 | Steps: 4 | Val loss: 0.2685 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=93214)[0m rmse: 0.17721423506736755
[2m[36m(func pid=93214)[0m mae:  0.12999986112117767
[2m[36m(func pid=93214)[0m rmse_per_class: [0.118, 0.259, 0.09, 0.334, 0.1, 0.189, 0.292, 0.14, 0.142, 0.109]
[2m[36m(func pid=93214)[0m 
== Status ==
Current time: 2024-01-07 17:47:40 (running for 00:31:56.46)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.34  |  0.147 |                   65 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.287 |  0.146 |                   67 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.487 |  0.177 |                   34 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.508 |  0.177 |                    9 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.17729392647743225
[2m[36m(func pid=87539)[0m mae:  0.13010045886039734
[2m[36m(func pid=87539)[0m rmse_per_class: [0.118, 0.258, 0.091, 0.336, 0.096, 0.188, 0.291, 0.14, 0.144, 0.11]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14524438977241516
[2m[36m(func pid=78743)[0m mae:  0.10111842304468155
[2m[36m(func pid=78743)[0m rmse_per_class: [0.077, 0.222, 0.051, 0.289, 0.061, 0.153, 0.239, 0.111, 0.143, 0.106]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2688 | Steps: 4 | Val loss: 0.2702 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4651 | Steps: 4 | Val loss: 0.3456 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4772 | Steps: 4 | Val loss: 0.3604 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=79710)[0m rmse: 0.1466067135334015
[2m[36m(func pid=79710)[0m mae:  0.0915512666106224
[2m[36m(func pid=79710)[0m rmse_per_class: [0.074, 0.218, 0.052, 0.289, 0.061, 0.156, 0.227, 0.126, 0.147, 0.116]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3327 | Steps: 4 | Val loss: 0.2672 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 17:47:45 (running for 00:32:01.54)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.33  |  0.145 |                   66 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.269 |  0.147 |                   68 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.487 |  0.177 |                   34 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.465 |  0.177 |                   10 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.17655347287654877
[2m[36m(func pid=93214)[0m mae:  0.12947823107242584
[2m[36m(func pid=93214)[0m rmse_per_class: [0.118, 0.258, 0.088, 0.333, 0.097, 0.188, 0.291, 0.141, 0.142, 0.11]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17713940143585205
[2m[36m(func pid=87539)[0m mae:  0.12999016046524048
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.258, 0.091, 0.335, 0.095, 0.188, 0.291, 0.14, 0.144, 0.111]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2730 | Steps: 4 | Val loss: 0.2709 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=78743)[0m rmse: 0.14456722140312195
[2m[36m(func pid=78743)[0m mae:  0.1004544273018837
[2m[36m(func pid=78743)[0m rmse_per_class: [0.076, 0.221, 0.048, 0.285, 0.063, 0.153, 0.239, 0.111, 0.14, 0.109]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4437 | Steps: 4 | Val loss: 0.3290 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4728 | Steps: 4 | Val loss: 0.3563 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=79710)[0m rmse: 0.14767196774482727
[2m[36m(func pid=79710)[0m mae:  0.09225328266620636
[2m[36m(func pid=79710)[0m rmse_per_class: [0.068, 0.217, 0.047, 0.286, 0.07, 0.159, 0.23, 0.121, 0.154, 0.125]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3283 | Steps: 4 | Val loss: 0.2665 | Batch size: 32 | lr: 0.01 | Duration: 3.21s
== Status ==
Current time: 2024-01-07 17:47:50 (running for 00:32:06.86)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.333 |  0.145 |                   67 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.273 |  0.148 |                   69 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.477 |  0.177 |                   35 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.444 |  0.176 |                   11 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.1756196916103363
[2m[36m(func pid=93214)[0m mae:  0.12872552871704102
[2m[36m(func pid=93214)[0m rmse_per_class: [0.118, 0.257, 0.086, 0.332, 0.093, 0.188, 0.291, 0.14, 0.142, 0.11]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17740240693092346
[2m[36m(func pid=87539)[0m mae:  0.13021191954612732
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.258, 0.092, 0.336, 0.095, 0.188, 0.291, 0.14, 0.144, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2709 | Steps: 4 | Val loss: 0.2722 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=78743)[0m rmse: 0.1442757546901703
[2m[36m(func pid=78743)[0m mae:  0.10026775300502777
[2m[36m(func pid=78743)[0m rmse_per_class: [0.074, 0.221, 0.044, 0.284, 0.064, 0.154, 0.239, 0.111, 0.139, 0.112]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4237 | Steps: 4 | Val loss: 0.3186 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4660 | Steps: 4 | Val loss: 0.3516 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=79710)[0m rmse: 0.14915278553962708
[2m[36m(func pid=79710)[0m mae:  0.09302928298711777
[2m[36m(func pid=79710)[0m rmse_per_class: [0.067, 0.215, 0.048, 0.284, 0.072, 0.16, 0.232, 0.119, 0.171, 0.123]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3297 | Steps: 4 | Val loss: 0.2673 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 17:47:55 (running for 00:32:12.29)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.328 |  0.144 |                   68 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.271 |  0.149 |                   70 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.473 |  0.177 |                   36 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.424 |  0.175 |                   12 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.17465636134147644
[2m[36m(func pid=93214)[0m mae:  0.12800154089927673
[2m[36m(func pid=93214)[0m rmse_per_class: [0.118, 0.256, 0.085, 0.33, 0.088, 0.187, 0.289, 0.14, 0.143, 0.11]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17678943276405334
[2m[36m(func pid=87539)[0m mae:  0.1297101229429245
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.258, 0.091, 0.336, 0.094, 0.188, 0.29, 0.14, 0.143, 0.111]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2573 | Steps: 4 | Val loss: 0.2681 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=78743)[0m rmse: 0.14487844705581665
[2m[36m(func pid=78743)[0m mae:  0.1005617007613182
[2m[36m(func pid=78743)[0m rmse_per_class: [0.077, 0.22, 0.044, 0.284, 0.064, 0.156, 0.238, 0.111, 0.139, 0.115]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4130 | Steps: 4 | Val loss: 0.3143 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4559 | Steps: 4 | Val loss: 0.3487 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=79710)[0m rmse: 0.14655143022537231
[2m[36m(func pid=79710)[0m mae:  0.09146599471569061
[2m[36m(func pid=79710)[0m rmse_per_class: [0.069, 0.21, 0.053, 0.267, 0.071, 0.16, 0.235, 0.113, 0.178, 0.11]
[2m[36m(func pid=79710)[0m 
== Status ==
Current time: 2024-01-07 17:48:01 (running for 00:32:17.63)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.33  |  0.145 |                   69 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.257 |  0.147 |                   71 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.466 |  0.177 |                   37 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.413 |  0.174 |                   13 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3254 | Steps: 4 | Val loss: 0.2652 | Batch size: 32 | lr: 0.01 | Duration: 3.19s
[2m[36m(func pid=93214)[0m rmse: 0.1739199310541153
[2m[36m(func pid=93214)[0m mae:  0.12742191553115845
[2m[36m(func pid=93214)[0m rmse_per_class: [0.118, 0.255, 0.084, 0.33, 0.085, 0.187, 0.288, 0.139, 0.144, 0.111]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.1765519678592682
[2m[36m(func pid=87539)[0m mae:  0.12949764728546143
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.258, 0.091, 0.335, 0.093, 0.188, 0.289, 0.14, 0.144, 0.111]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2768 | Steps: 4 | Val loss: 0.2704 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=78743)[0m rmse: 0.14348001778125763
[2m[36m(func pid=78743)[0m mae:  0.09921303391456604
[2m[36m(func pid=78743)[0m rmse_per_class: [0.075, 0.22, 0.044, 0.281, 0.065, 0.155, 0.236, 0.11, 0.137, 0.112]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4040 | Steps: 4 | Val loss: 0.3138 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4523 | Steps: 4 | Val loss: 0.3448 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=79710)[0m rmse: 0.14832347631454468
[2m[36m(func pid=79710)[0m mae:  0.09251861274242401
[2m[36m(func pid=79710)[0m rmse_per_class: [0.068, 0.211, 0.06, 0.263, 0.069, 0.159, 0.234, 0.112, 0.185, 0.123]
[2m[36m(func pid=79710)[0m 
== Status ==
Current time: 2024-01-07 17:48:06 (running for 00:32:22.91)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.325 |  0.143 |                   70 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.277 |  0.148 |                   72 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.456 |  0.177 |                   38 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.404 |  0.173 |                   14 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.17293313145637512
[2m[36m(func pid=93214)[0m mae:  0.12663158774375916
[2m[36m(func pid=93214)[0m rmse_per_class: [0.118, 0.254, 0.082, 0.327, 0.082, 0.187, 0.288, 0.139, 0.143, 0.11]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.1764138787984848
[2m[36m(func pid=87539)[0m mae:  0.1293422132730484
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.257, 0.09, 0.335, 0.093, 0.189, 0.289, 0.14, 0.144, 0.11]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3326 | Steps: 4 | Val loss: 0.2630 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2888 | Steps: 4 | Val loss: 0.2685 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4086 | Steps: 4 | Val loss: 0.3164 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=78743)[0m rmse: 0.1418265402317047
[2m[36m(func pid=78743)[0m mae:  0.09767629206180573
[2m[36m(func pid=78743)[0m rmse_per_class: [0.075, 0.22, 0.042, 0.278, 0.064, 0.155, 0.233, 0.111, 0.136, 0.106]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4481 | Steps: 4 | Val loss: 0.3411 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=79710)[0m rmse: 0.1469256728887558
[2m[36m(func pid=79710)[0m mae:  0.09127415716648102
[2m[36m(func pid=79710)[0m rmse_per_class: [0.075, 0.213, 0.053, 0.268, 0.065, 0.158, 0.224, 0.115, 0.174, 0.124]
[2m[36m(func pid=79710)[0m 
== Status ==
Current time: 2024-01-07 17:48:11 (running for 00:32:28.10)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.333 |  0.142 |                   71 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.289 |  0.147 |                   73 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.452 |  0.176 |                   39 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.409 |  0.172 |                   15 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.17214779555797577
[2m[36m(func pid=93214)[0m mae:  0.12601108849048615
[2m[36m(func pid=93214)[0m rmse_per_class: [0.118, 0.253, 0.08, 0.326, 0.079, 0.185, 0.286, 0.139, 0.143, 0.112]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.1764458864927292
[2m[36m(func pid=87539)[0m mae:  0.1293274462223053
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.257, 0.09, 0.334, 0.093, 0.189, 0.289, 0.141, 0.143, 0.11]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3248 | Steps: 4 | Val loss: 0.2640 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2823 | Steps: 4 | Val loss: 0.2724 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.4125 | Steps: 4 | Val loss: 0.3218 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4441 | Steps: 4 | Val loss: 0.3392 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=79710)[0m rmse: 0.14789387583732605
[2m[36m(func pid=79710)[0m mae:  0.09248916059732437
[2m[36m(func pid=79710)[0m rmse_per_class: [0.068, 0.213, 0.056, 0.283, 0.064, 0.158, 0.225, 0.116, 0.184, 0.113]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14256124198436737
[2m[36m(func pid=78743)[0m mae:  0.09835172444581985
[2m[36m(func pid=78743)[0m rmse_per_class: [0.076, 0.22, 0.042, 0.279, 0.064, 0.155, 0.233, 0.11, 0.138, 0.107]
[2m[36m(func pid=78743)[0m 
== Status ==
Current time: 2024-01-07 17:48:16 (running for 00:32:33.44)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15075000375509262
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.325 |  0.143 |                   72 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.282 |  0.148 |                   74 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.448 |  0.176 |                   40 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.413 |  0.172 |                   16 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.1716555655002594
[2m[36m(func pid=93214)[0m mae:  0.12561620771884918
[2m[36m(func pid=93214)[0m rmse_per_class: [0.119, 0.252, 0.08, 0.325, 0.076, 0.186, 0.285, 0.138, 0.144, 0.113]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.1767406314611435
[2m[36m(func pid=87539)[0m mae:  0.12960709631443024
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.259, 0.091, 0.334, 0.092, 0.189, 0.289, 0.141, 0.144, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2735 | Steps: 4 | Val loss: 0.2752 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3299 | Steps: 4 | Val loss: 0.2639 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4277 | Steps: 4 | Val loss: 0.3269 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4373 | Steps: 4 | Val loss: 0.3347 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=79710)[0m rmse: 0.14984576404094696
[2m[36m(func pid=79710)[0m mae:  0.0936855897307396
[2m[36m(func pid=79710)[0m rmse_per_class: [0.065, 0.215, 0.074, 0.297, 0.069, 0.163, 0.228, 0.116, 0.167, 0.104]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.1424110382795334
[2m[36m(func pid=78743)[0m mae:  0.09843117743730545
[2m[36m(func pid=78743)[0m rmse_per_class: [0.076, 0.218, 0.043, 0.279, 0.067, 0.156, 0.234, 0.111, 0.138, 0.102]
[2m[36m(func pid=78743)[0m 
== Status ==
Current time: 2024-01-07 17:48:22 (running for 00:32:38.80)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14950000494718552
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.33  |  0.142 |                   73 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.273 |  0.15  |                   75 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.444 |  0.177 |                   41 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.428 |  0.171 |                   17 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.17063990235328674
[2m[36m(func pid=93214)[0m mae:  0.12483718246221542
[2m[36m(func pid=93214)[0m rmse_per_class: [0.118, 0.252, 0.078, 0.323, 0.073, 0.185, 0.283, 0.137, 0.144, 0.113]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.1764320433139801
[2m[36m(func pid=87539)[0m mae:  0.12939681112766266
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.259, 0.091, 0.334, 0.09, 0.189, 0.289, 0.141, 0.143, 0.113]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2952 | Steps: 4 | Val loss: 0.2725 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3229 | Steps: 4 | Val loss: 0.2628 | Batch size: 32 | lr: 0.01 | Duration: 3.17s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4250 | Steps: 4 | Val loss: 0.3332 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=79710)[0m rmse: 0.14796285331249237
[2m[36m(func pid=79710)[0m mae:  0.09139557927846909
[2m[36m(func pid=79710)[0m rmse_per_class: [0.063, 0.213, 0.084, 0.295, 0.068, 0.162, 0.221, 0.119, 0.149, 0.106]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4336 | Steps: 4 | Val loss: 0.3322 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=78743)[0m rmse: 0.14132586121559143
[2m[36m(func pid=78743)[0m mae:  0.09763732552528381
[2m[36m(func pid=78743)[0m rmse_per_class: [0.076, 0.218, 0.042, 0.282, 0.068, 0.153, 0.233, 0.11, 0.137, 0.095]
[2m[36m(func pid=78743)[0m 
== Status ==
Current time: 2024-01-07 17:48:27 (running for 00:32:44.37)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14950000494718552
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.323 |  0.141 |                   74 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.295 |  0.148 |                   76 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.437 |  0.176 |                   42 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.425 |  0.17  |                   18 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.16972637176513672
[2m[36m(func pid=93214)[0m mae:  0.1240590363740921
[2m[36m(func pid=93214)[0m rmse_per_class: [0.118, 0.251, 0.076, 0.322, 0.071, 0.185, 0.282, 0.136, 0.144, 0.113]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17654737830162048
[2m[36m(func pid=87539)[0m mae:  0.12949594855308533
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.258, 0.091, 0.334, 0.09, 0.189, 0.289, 0.141, 0.144, 0.113]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2780 | Steps: 4 | Val loss: 0.2717 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3213 | Steps: 4 | Val loss: 0.2633 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.4359 | Steps: 4 | Val loss: 0.3406 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4298 | Steps: 4 | Val loss: 0.3286 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=79710)[0m rmse: 0.1489681750535965
[2m[36m(func pid=79710)[0m mae:  0.09165000170469284
[2m[36m(func pid=79710)[0m rmse_per_class: [0.062, 0.213, 0.084, 0.288, 0.087, 0.162, 0.223, 0.122, 0.142, 0.106]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.1418079137802124
[2m[36m(func pid=78743)[0m mae:  0.09800704568624496
[2m[36m(func pid=78743)[0m rmse_per_class: [0.075, 0.217, 0.043, 0.281, 0.068, 0.154, 0.235, 0.11, 0.138, 0.098]
[2m[36m(func pid=78743)[0m 
== Status ==
Current time: 2024-01-07 17:48:33 (running for 00:32:49.63)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.321 |  0.142 |                   75 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.278 |  0.149 |                   77 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.434 |  0.177 |                   43 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.436 |  0.169 |                   19 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.16899177432060242
[2m[36m(func pid=93214)[0m mae:  0.12339697033166885
[2m[36m(func pid=93214)[0m rmse_per_class: [0.118, 0.25, 0.075, 0.321, 0.068, 0.186, 0.28, 0.135, 0.144, 0.114]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17614680528640747
[2m[36m(func pid=87539)[0m mae:  0.12915462255477905
[2m[36m(func pid=87539)[0m rmse_per_class: [0.118, 0.257, 0.09, 0.334, 0.089, 0.188, 0.289, 0.141, 0.143, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2791 | Steps: 4 | Val loss: 0.2727 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.3213 | Steps: 4 | Val loss: 0.2641 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4447 | Steps: 4 | Val loss: 0.3490 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=79710)[0m rmse: 0.1499570906162262
[2m[36m(func pid=79710)[0m mae:  0.09276356548070908
[2m[36m(func pid=79710)[0m rmse_per_class: [0.063, 0.215, 0.072, 0.287, 0.086, 0.163, 0.232, 0.129, 0.15, 0.104]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4321 | Steps: 4 | Val loss: 0.3265 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=78743)[0m rmse: 0.1422579288482666
[2m[36m(func pid=78743)[0m mae:  0.0981236919760704
[2m[36m(func pid=78743)[0m rmse_per_class: [0.076, 0.216, 0.043, 0.281, 0.065, 0.155, 0.235, 0.11, 0.138, 0.103]
[2m[36m(func pid=78743)[0m 
== Status ==
Current time: 2024-01-07 17:48:38 (running for 00:32:55.02)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.321 |  0.142 |                   76 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.279 |  0.15  |                   78 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.43  |  0.176 |                   44 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.445 |  0.168 |                   20 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.16781477630138397
[2m[36m(func pid=93214)[0m mae:  0.12240038812160492
[2m[36m(func pid=93214)[0m rmse_per_class: [0.117, 0.248, 0.074, 0.318, 0.066, 0.185, 0.278, 0.134, 0.144, 0.113]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17594125866889954
[2m[36m(func pid=87539)[0m mae:  0.12904766201972961
[2m[36m(func pid=87539)[0m rmse_per_class: [0.118, 0.257, 0.09, 0.333, 0.089, 0.188, 0.289, 0.14, 0.144, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2786 | Steps: 4 | Val loss: 0.2759 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.3265 | Steps: 4 | Val loss: 0.2644 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=79710)[0m rmse: 0.1515328586101532
[2m[36m(func pid=79710)[0m mae:  0.09419990330934525
[2m[36m(func pid=79710)[0m rmse_per_class: [0.066, 0.216, 0.057, 0.292, 0.097, 0.164, 0.236, 0.126, 0.158, 0.104]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4467 | Steps: 4 | Val loss: 0.3571 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4244 | Steps: 4 | Val loss: 0.3245 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=78743)[0m rmse: 0.14273463189601898
[2m[36m(func pid=78743)[0m mae:  0.09837765991687775
[2m[36m(func pid=78743)[0m rmse_per_class: [0.076, 0.216, 0.045, 0.281, 0.065, 0.156, 0.235, 0.111, 0.137, 0.105]
[2m[36m(func pid=78743)[0m 
== Status ==
Current time: 2024-01-07 17:48:43 (running for 00:33:00.38)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.326 |  0.143 |                   77 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.279 |  0.152 |                   79 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.432 |  0.176 |                   45 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.447 |  0.167 |                   21 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.1671523153781891
[2m[36m(func pid=93214)[0m mae:  0.12184065580368042
[2m[36m(func pid=93214)[0m rmse_per_class: [0.118, 0.248, 0.072, 0.317, 0.064, 0.185, 0.277, 0.133, 0.145, 0.113]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17568528652191162
[2m[36m(func pid=87539)[0m mae:  0.12885847687721252
[2m[36m(func pid=87539)[0m rmse_per_class: [0.118, 0.256, 0.089, 0.333, 0.088, 0.188, 0.289, 0.14, 0.144, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2797 | Steps: 4 | Val loss: 0.2742 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.3295 | Steps: 4 | Val loss: 0.2644 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=79710)[0m rmse: 0.15031872689723969
[2m[36m(func pid=79710)[0m mae:  0.09328822791576385
[2m[36m(func pid=79710)[0m rmse_per_class: [0.068, 0.215, 0.044, 0.284, 0.092, 0.163, 0.236, 0.118, 0.165, 0.118]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4237 | Steps: 4 | Val loss: 0.3229 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4581 | Steps: 4 | Val loss: 0.3635 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 17:48:49 (running for 00:33:05.64)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.33  |  0.143 |                   78 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.28  |  0.15  |                   80 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.424 |  0.176 |                   46 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.447 |  0.167 |                   21 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=78743)[0m rmse: 0.14266489446163177
[2m[36m(func pid=78743)[0m mae:  0.09841436892747879
[2m[36m(func pid=78743)[0m rmse_per_class: [0.077, 0.216, 0.044, 0.281, 0.065, 0.156, 0.236, 0.111, 0.137, 0.104]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17532147467136383
[2m[36m(func pid=87539)[0m mae:  0.12853789329528809
[2m[36m(func pid=87539)[0m rmse_per_class: [0.118, 0.255, 0.088, 0.333, 0.087, 0.189, 0.287, 0.14, 0.144, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.16641759872436523
[2m[36m(func pid=93214)[0m mae:  0.12117086350917816
[2m[36m(func pid=93214)[0m rmse_per_class: [0.118, 0.246, 0.071, 0.316, 0.063, 0.185, 0.275, 0.133, 0.144, 0.113]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2651 | Steps: 4 | Val loss: 0.2711 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=79710)[0m rmse: 0.1483020782470703
[2m[36m(func pid=79710)[0m mae:  0.09223510324954987
[2m[36m(func pid=79710)[0m rmse_per_class: [0.076, 0.216, 0.04, 0.279, 0.084, 0.16, 0.228, 0.112, 0.164, 0.123]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4192 | Steps: 4 | Val loss: 0.3204 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4682 | Steps: 4 | Val loss: 0.3681 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.3225 | Steps: 4 | Val loss: 0.2621 | Batch size: 32 | lr: 0.01 | Duration: 3.25s
== Status ==
Current time: 2024-01-07 17:48:54 (running for 00:33:11.24)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.33  |  0.143 |                   78 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.265 |  0.148 |                   81 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.419 |  0.175 |                   48 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.458 |  0.166 |                   22 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.17504480481147766
[2m[36m(func pid=87539)[0m mae:  0.12831611931324005
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.256, 0.088, 0.333, 0.086, 0.188, 0.287, 0.14, 0.143, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.16582649946212769
[2m[36m(func pid=93214)[0m mae:  0.12053307145833969
[2m[36m(func pid=93214)[0m rmse_per_class: [0.117, 0.247, 0.071, 0.315, 0.061, 0.185, 0.272, 0.132, 0.145, 0.115]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14085862040519714
[2m[36m(func pid=78743)[0m mae:  0.09688737988471985
[2m[36m(func pid=78743)[0m rmse_per_class: [0.074, 0.218, 0.042, 0.278, 0.066, 0.154, 0.234, 0.11, 0.134, 0.1]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2651 | Steps: 4 | Val loss: 0.2686 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=79710)[0m rmse: 0.14626559615135193
[2m[36m(func pid=79710)[0m mae:  0.09085008502006531
[2m[36m(func pid=79710)[0m rmse_per_class: [0.082, 0.216, 0.038, 0.271, 0.067, 0.16, 0.225, 0.111, 0.161, 0.132]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4740 | Steps: 4 | Val loss: 0.3732 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4141 | Steps: 4 | Val loss: 0.3195 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.3439 | Steps: 4 | Val loss: 0.2626 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
== Status ==
Current time: 2024-01-07 17:49:00 (running for 00:33:16.66)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.322 |  0.141 |                   79 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.265 |  0.146 |                   82 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.419 |  0.175 |                   48 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.474 |  0.165 |                   24 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.16468064486980438
[2m[36m(func pid=93214)[0m mae:  0.11959169805049896
[2m[36m(func pid=93214)[0m rmse_per_class: [0.116, 0.246, 0.069, 0.313, 0.06, 0.184, 0.27, 0.131, 0.144, 0.114]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17495319247245789
[2m[36m(func pid=87539)[0m mae:  0.1281750649213791
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.257, 0.087, 0.331, 0.087, 0.187, 0.288, 0.14, 0.142, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2803 | Steps: 4 | Val loss: 0.2687 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=78743)[0m rmse: 0.141131192445755
[2m[36m(func pid=78743)[0m mae:  0.09703033417463303
[2m[36m(func pid=78743)[0m rmse_per_class: [0.074, 0.217, 0.042, 0.282, 0.064, 0.154, 0.231, 0.111, 0.135, 0.101]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.145936980843544
[2m[36m(func pid=79710)[0m mae:  0.08997881412506104
[2m[36m(func pid=79710)[0m rmse_per_class: [0.074, 0.216, 0.043, 0.273, 0.059, 0.16, 0.222, 0.112, 0.169, 0.13]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4806 | Steps: 4 | Val loss: 0.3779 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4144 | Steps: 4 | Val loss: 0.3189 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.3229 | Steps: 4 | Val loss: 0.2612 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 17:49:05 (running for 00:33:22.07)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.344 |  0.141 |                   80 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.28  |  0.146 |                   83 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.414 |  0.175 |                   50 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.474 |  0.165 |                   24 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.17491522431373596
[2m[36m(func pid=87539)[0m mae:  0.12815937399864197
[2m[36m(func pid=87539)[0m rmse_per_class: [0.118, 0.256, 0.087, 0.332, 0.086, 0.188, 0.287, 0.141, 0.143, 0.111]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.16356027126312256
[2m[36m(func pid=93214)[0m mae:  0.11860127747058868
[2m[36m(func pid=93214)[0m rmse_per_class: [0.115, 0.245, 0.067, 0.311, 0.059, 0.184, 0.268, 0.13, 0.144, 0.112]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2784 | Steps: 4 | Val loss: 0.2654 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=78743)[0m rmse: 0.14017066359519958
[2m[36m(func pid=78743)[0m mae:  0.09606092423200607
[2m[36m(func pid=78743)[0m rmse_per_class: [0.072, 0.22, 0.04, 0.278, 0.064, 0.153, 0.23, 0.112, 0.134, 0.101]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14333318173885345
[2m[36m(func pid=79710)[0m mae:  0.08859211206436157
[2m[36m(func pid=79710)[0m rmse_per_class: [0.073, 0.217, 0.05, 0.271, 0.054, 0.158, 0.222, 0.113, 0.161, 0.113]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4156 | Steps: 4 | Val loss: 0.3183 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4801 | Steps: 4 | Val loss: 0.3816 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.3243 | Steps: 4 | Val loss: 0.2635 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 17:49:10 (running for 00:33:27.39)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.323 |  0.14  |                   81 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.278 |  0.143 |                   84 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.416 |  0.175 |                   51 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.481 |  0.164 |                   25 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.1747823804616928
[2m[36m(func pid=87539)[0m mae:  0.12807825207710266
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.257, 0.087, 0.331, 0.086, 0.188, 0.287, 0.14, 0.144, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2934 | Steps: 4 | Val loss: 0.2628 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=93214)[0m rmse: 0.1623605340719223
[2m[36m(func pid=93214)[0m mae:  0.11754205077886581
[2m[36m(func pid=93214)[0m rmse_per_class: [0.115, 0.243, 0.066, 0.308, 0.058, 0.184, 0.266, 0.129, 0.144, 0.112]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14184315502643585
[2m[36m(func pid=78743)[0m mae:  0.09715606272220612
[2m[36m(func pid=78743)[0m rmse_per_class: [0.072, 0.22, 0.044, 0.288, 0.067, 0.152, 0.229, 0.111, 0.134, 0.1]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14045943319797516
[2m[36m(func pid=79710)[0m mae:  0.08677764981985092
[2m[36m(func pid=79710)[0m rmse_per_class: [0.066, 0.21, 0.049, 0.257, 0.051, 0.156, 0.228, 0.119, 0.166, 0.101]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4145 | Steps: 4 | Val loss: 0.3183 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.5013 | Steps: 4 | Val loss: 0.3845 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.3317 | Steps: 4 | Val loss: 0.2642 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 17:49:16 (running for 00:33:32.67)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.324 |  0.142 |                   82 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.293 |  0.14  |                   85 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.416 |  0.175 |                   51 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.501 |  0.161 |                   27 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.16052944958209991
[2m[36m(func pid=93214)[0m mae:  0.11583848297595978
[2m[36m(func pid=93214)[0m rmse_per_class: [0.114, 0.24, 0.064, 0.305, 0.057, 0.183, 0.263, 0.128, 0.142, 0.109]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2842 | Steps: 4 | Val loss: 0.2678 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=87539)[0m rmse: 0.17508149147033691
[2m[36m(func pid=87539)[0m mae:  0.12834806740283966
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.257, 0.087, 0.332, 0.085, 0.188, 0.287, 0.14, 0.144, 0.113]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14231303334236145
[2m[36m(func pid=78743)[0m mae:  0.09757249057292938
[2m[36m(func pid=78743)[0m rmse_per_class: [0.071, 0.219, 0.046, 0.288, 0.066, 0.153, 0.229, 0.11, 0.137, 0.105]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.1430623084306717
[2m[36m(func pid=79710)[0m mae:  0.08853821456432343
[2m[36m(func pid=79710)[0m rmse_per_class: [0.066, 0.216, 0.047, 0.261, 0.053, 0.158, 0.238, 0.124, 0.161, 0.107]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4907 | Steps: 4 | Val loss: 0.3877 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4144 | Steps: 4 | Val loss: 0.3178 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.3368 | Steps: 4 | Val loss: 0.2652 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2732 | Steps: 4 | Val loss: 0.2694 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 17:49:21 (running for 00:33:38.12)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.332 |  0.142 |                   83 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.284 |  0.143 |                   86 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.415 |  0.175 |                   52 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.491 |  0.16  |                   28 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.1597619354724884
[2m[36m(func pid=93214)[0m mae:  0.11518038809299469
[2m[36m(func pid=93214)[0m rmse_per_class: [0.114, 0.237, 0.062, 0.305, 0.056, 0.183, 0.262, 0.127, 0.142, 0.108]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17506752908229828
[2m[36m(func pid=87539)[0m mae:  0.12835893034934998
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.257, 0.087, 0.333, 0.084, 0.188, 0.287, 0.139, 0.146, 0.113]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.143071711063385
[2m[36m(func pid=78743)[0m mae:  0.09819754958152771
[2m[36m(func pid=78743)[0m rmse_per_class: [0.07, 0.22, 0.046, 0.291, 0.066, 0.153, 0.228, 0.11, 0.139, 0.106]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14494045078754425
[2m[36m(func pid=79710)[0m mae:  0.08989015221595764
[2m[36m(func pid=79710)[0m rmse_per_class: [0.067, 0.215, 0.049, 0.267, 0.063, 0.16, 0.239, 0.12, 0.161, 0.108]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4950 | Steps: 4 | Val loss: 0.3891 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4134 | Steps: 4 | Val loss: 0.3167 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.3229 | Steps: 4 | Val loss: 0.2641 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2672 | Steps: 4 | Val loss: 0.2709 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 17:49:26 (running for 00:33:43.37)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.337 |  0.143 |                   84 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.273 |  0.145 |                   87 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.414 |  0.175 |                   53 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.495 |  0.159 |                   29 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.158604234457016
[2m[36m(func pid=93214)[0m mae:  0.11404888331890106
[2m[36m(func pid=93214)[0m rmse_per_class: [0.114, 0.238, 0.059, 0.302, 0.056, 0.183, 0.258, 0.127, 0.142, 0.107]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17472752928733826
[2m[36m(func pid=87539)[0m mae:  0.1281258761882782
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.255, 0.087, 0.333, 0.083, 0.188, 0.287, 0.139, 0.146, 0.113]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14238505065441132
[2m[36m(func pid=78743)[0m mae:  0.09771404415369034
[2m[36m(func pid=78743)[0m rmse_per_class: [0.07, 0.218, 0.045, 0.288, 0.07, 0.153, 0.231, 0.109, 0.138, 0.102]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14742566645145416
[2m[36m(func pid=79710)[0m mae:  0.09164222329854965
[2m[36m(func pid=79710)[0m rmse_per_class: [0.076, 0.211, 0.051, 0.277, 0.071, 0.161, 0.234, 0.115, 0.172, 0.107]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.5041 | Steps: 4 | Val loss: 0.3902 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4092 | Steps: 4 | Val loss: 0.3166 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.3215 | Steps: 4 | Val loss: 0.2652 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2666 | Steps: 4 | Val loss: 0.2736 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 17:49:32 (running for 00:33:48.89)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.323 |  0.142 |                   85 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.267 |  0.147 |                   88 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.413 |  0.175 |                   54 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.504 |  0.157 |                   30 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.1747046858072281
[2m[36m(func pid=87539)[0m mae:  0.12803009152412415
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.257, 0.087, 0.331, 0.084, 0.188, 0.287, 0.138, 0.146, 0.113]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.15733745694160461
[2m[36m(func pid=93214)[0m mae:  0.11289308965206146
[2m[36m(func pid=93214)[0m rmse_per_class: [0.113, 0.236, 0.058, 0.3, 0.055, 0.183, 0.256, 0.126, 0.14, 0.106]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.143103688955307
[2m[36m(func pid=78743)[0m mae:  0.09807059168815613
[2m[36m(func pid=78743)[0m rmse_per_class: [0.07, 0.217, 0.047, 0.29, 0.072, 0.154, 0.233, 0.109, 0.137, 0.102]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.1492476612329483
[2m[36m(func pid=79710)[0m mae:  0.09288842976093292
[2m[36m(func pid=79710)[0m rmse_per_class: [0.074, 0.21, 0.057, 0.282, 0.065, 0.17, 0.234, 0.116, 0.181, 0.104]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4986 | Steps: 4 | Val loss: 0.3886 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4089 | Steps: 4 | Val loss: 0.3152 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2698 | Steps: 4 | Val loss: 0.2742 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.3158 | Steps: 4 | Val loss: 0.2668 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 17:49:37 (running for 00:33:54.14)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.322 |  0.143 |                   86 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.267 |  0.149 |                   89 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.409 |  0.175 |                   55 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.499 |  0.156 |                   31 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.1561383605003357
[2m[36m(func pid=93214)[0m mae:  0.111699678003788
[2m[36m(func pid=93214)[0m rmse_per_class: [0.111, 0.234, 0.056, 0.3, 0.055, 0.181, 0.253, 0.125, 0.14, 0.106]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17421187460422516
[2m[36m(func pid=87539)[0m mae:  0.1276615858078003
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.257, 0.085, 0.33, 0.083, 0.187, 0.287, 0.139, 0.146, 0.113]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.15071266889572144
[2m[36m(func pid=79710)[0m mae:  0.09323947876691818
[2m[36m(func pid=79710)[0m rmse_per_class: [0.071, 0.215, 0.065, 0.282, 0.073, 0.165, 0.231, 0.117, 0.167, 0.121]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14432567358016968
[2m[36m(func pid=78743)[0m mae:  0.09924599528312683
[2m[36m(func pid=78743)[0m rmse_per_class: [0.071, 0.217, 0.047, 0.294, 0.077, 0.153, 0.234, 0.109, 0.139, 0.101]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4096 | Steps: 4 | Val loss: 0.3147 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.5053 | Steps: 4 | Val loss: 0.3828 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2750 | Steps: 4 | Val loss: 0.2676 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 17:49:43 (running for 00:33:59.57)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.316 |  0.144 |                   87 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.27  |  0.151 |                   90 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.409 |  0.174 |                   56 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.505 |  0.155 |                   32 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.17401716113090515
[2m[36m(func pid=87539)[0m mae:  0.12751106917858124
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.256, 0.086, 0.33, 0.082, 0.187, 0.287, 0.14, 0.144, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.1547270268201828
[2m[36m(func pid=93214)[0m mae:  0.11019805818796158
[2m[36m(func pid=93214)[0m rmse_per_class: [0.11, 0.234, 0.054, 0.297, 0.055, 0.181, 0.249, 0.124, 0.138, 0.105]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.3230 | Steps: 4 | Val loss: 0.2663 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=79710)[0m rmse: 0.14621707797050476
[2m[36m(func pid=79710)[0m mae:  0.09042613953351974
[2m[36m(func pid=79710)[0m rmse_per_class: [0.076, 0.209, 0.06, 0.272, 0.071, 0.16, 0.229, 0.115, 0.149, 0.121]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.1441107839345932
[2m[36m(func pid=78743)[0m mae:  0.09901700913906097
[2m[36m(func pid=78743)[0m rmse_per_class: [0.07, 0.216, 0.05, 0.292, 0.078, 0.153, 0.234, 0.108, 0.139, 0.1]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4069 | Steps: 4 | Val loss: 0.3138 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4912 | Steps: 4 | Val loss: 0.3825 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2805 | Steps: 4 | Val loss: 0.2632 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 17:49:48 (running for 00:34:04.87)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.323 |  0.144 |                   88 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.275 |  0.146 |                   91 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.41  |  0.174 |                   57 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.491 |  0.154 |                   33 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.1538444459438324
[2m[36m(func pid=93214)[0m mae:  0.10939012467861176
[2m[36m(func pid=93214)[0m rmse_per_class: [0.109, 0.231, 0.052, 0.297, 0.055, 0.18, 0.248, 0.125, 0.138, 0.103]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.1736924797296524
[2m[36m(func pid=87539)[0m mae:  0.12724801898002625
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.256, 0.085, 0.331, 0.081, 0.186, 0.286, 0.139, 0.145, 0.113]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.3166 | Steps: 4 | Val loss: 0.2680 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=79710)[0m rmse: 0.14184615015983582
[2m[36m(func pid=79710)[0m mae:  0.08789132535457611
[2m[36m(func pid=79710)[0m rmse_per_class: [0.069, 0.208, 0.052, 0.261, 0.064, 0.159, 0.228, 0.117, 0.15, 0.11]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.145039364695549
[2m[36m(func pid=78743)[0m mae:  0.09975295513868332
[2m[36m(func pid=78743)[0m rmse_per_class: [0.072, 0.222, 0.052, 0.296, 0.072, 0.153, 0.229, 0.108, 0.145, 0.102]
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4077 | Steps: 4 | Val loss: 0.3138 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4936 | Steps: 4 | Val loss: 0.3797 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2760 | Steps: 4 | Val loss: 0.2632 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 17:49:53 (running for 00:34:10.25)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.317 |  0.145 |                   89 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.28  |  0.142 |                   92 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.408 |  0.174 |                   59 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.491 |  0.154 |                   33 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.17364910244941711
[2m[36m(func pid=87539)[0m mae:  0.12720663845539093
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.255, 0.085, 0.331, 0.081, 0.186, 0.285, 0.139, 0.145, 0.113]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.15212340652942657
[2m[36m(func pid=93214)[0m mae:  0.10763474553823471
[2m[36m(func pid=93214)[0m rmse_per_class: [0.108, 0.229, 0.05, 0.293, 0.055, 0.179, 0.246, 0.124, 0.137, 0.101]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.3327 | Steps: 4 | Val loss: 0.2671 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=79710)[0m rmse: 0.14216205477714539
[2m[36m(func pid=79710)[0m mae:  0.08819736540317535
[2m[36m(func pid=79710)[0m rmse_per_class: [0.069, 0.208, 0.058, 0.258, 0.075, 0.161, 0.232, 0.115, 0.147, 0.099]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4082 | Steps: 4 | Val loss: 0.3140 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4956 | Steps: 4 | Val loss: 0.3763 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=78743)[0m rmse: 0.14471006393432617
[2m[36m(func pid=78743)[0m mae:  0.09933049231767654
[2m[36m(func pid=78743)[0m rmse_per_class: [0.072, 0.22, 0.054, 0.292, 0.07, 0.154, 0.23, 0.109, 0.143, 0.104]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2766 | Steps: 4 | Val loss: 0.2652 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 17:49:59 (running for 00:34:15.65)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.333 |  0.145 |                   90 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.276 |  0.142 |                   93 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.408 |  0.174 |                   59 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.496 |  0.151 |                   35 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.17357000708580017
[2m[36m(func pid=87539)[0m mae:  0.12714828550815582
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.256, 0.084, 0.331, 0.08, 0.187, 0.285, 0.138, 0.145, 0.113]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.15132847428321838
[2m[36m(func pid=93214)[0m mae:  0.10677236318588257
[2m[36m(func pid=93214)[0m rmse_per_class: [0.107, 0.227, 0.049, 0.296, 0.055, 0.178, 0.243, 0.123, 0.137, 0.1]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.3304 | Steps: 4 | Val loss: 0.2661 | Batch size: 32 | lr: 0.01 | Duration: 3.17s
[2m[36m(func pid=79710)[0m rmse: 0.14376802742481232
[2m[36m(func pid=79710)[0m mae:  0.08926903456449509
[2m[36m(func pid=79710)[0m rmse_per_class: [0.068, 0.209, 0.057, 0.269, 0.087, 0.159, 0.229, 0.12, 0.144, 0.096]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4079 | Steps: 4 | Val loss: 0.3140 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4744 | Steps: 4 | Val loss: 0.3699 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=78743)[0m rmse: 0.14372944831848145
[2m[36m(func pid=78743)[0m mae:  0.09849011898040771
[2m[36m(func pid=78743)[0m rmse_per_class: [0.07, 0.221, 0.05, 0.292, 0.068, 0.153, 0.228, 0.11, 0.143, 0.101]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2911 | Steps: 4 | Val loss: 0.2704 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 17:50:04 (running for 00:34:20.91)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.33  |  0.144 |                   91 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.277 |  0.144 |                   94 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.408 |  0.174 |                   60 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.474 |  0.151 |                   36 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.17371663451194763
[2m[36m(func pid=87539)[0m mae:  0.12727226316928864
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.256, 0.084, 0.331, 0.081, 0.187, 0.284, 0.138, 0.145, 0.114]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.15067324042320251
[2m[36m(func pid=93214)[0m mae:  0.10606776177883148
[2m[36m(func pid=93214)[0m rmse_per_class: [0.107, 0.227, 0.048, 0.294, 0.054, 0.177, 0.241, 0.123, 0.136, 0.099]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.3144 | Steps: 4 | Val loss: 0.2658 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=79710)[0m rmse: 0.14722779393196106
[2m[36m(func pid=79710)[0m mae:  0.0916287750005722
[2m[36m(func pid=79710)[0m rmse_per_class: [0.082, 0.212, 0.052, 0.283, 0.078, 0.159, 0.227, 0.124, 0.159, 0.097]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4092 | Steps: 4 | Val loss: 0.3138 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4815 | Steps: 4 | Val loss: 0.3664 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=78743)[0m rmse: 0.14356623589992523
[2m[36m(func pid=78743)[0m mae:  0.09839679300785065
[2m[36m(func pid=78743)[0m rmse_per_class: [0.07, 0.22, 0.052, 0.289, 0.071, 0.152, 0.23, 0.109, 0.142, 0.099]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2589 | Steps: 4 | Val loss: 0.2770 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 17:50:09 (running for 00:34:26.26)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.314 |  0.144 |                   92 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.291 |  0.147 |                   95 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.409 |  0.173 |                   62 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.474 |  0.151 |                   36 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.17342853546142578
[2m[36m(func pid=87539)[0m mae:  0.127031147480011
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.256, 0.084, 0.331, 0.08, 0.186, 0.284, 0.138, 0.145, 0.114]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.14983367919921875
[2m[36m(func pid=93214)[0m mae:  0.1051083579659462
[2m[36m(func pid=93214)[0m rmse_per_class: [0.106, 0.227, 0.047, 0.293, 0.055, 0.177, 0.238, 0.124, 0.135, 0.097]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.3218 | Steps: 4 | Val loss: 0.2651 | Batch size: 32 | lr: 0.01 | Duration: 3.20s
[2m[36m(func pid=79710)[0m rmse: 0.1510985791683197
[2m[36m(func pid=79710)[0m mae:  0.0943431705236435
[2m[36m(func pid=79710)[0m rmse_per_class: [0.087, 0.211, 0.06, 0.294, 0.071, 0.161, 0.235, 0.122, 0.172, 0.098]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4044 | Steps: 4 | Val loss: 0.3139 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4937 | Steps: 4 | Val loss: 0.3578 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=78743)[0m rmse: 0.14305128157138824
[2m[36m(func pid=78743)[0m mae:  0.09797389805316925
[2m[36m(func pid=78743)[0m rmse_per_class: [0.069, 0.219, 0.047, 0.29, 0.068, 0.152, 0.231, 0.11, 0.141, 0.103]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2725 | Steps: 4 | Val loss: 0.2771 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 17:50:15 (running for 00:34:31.55)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.322 |  0.143 |                   93 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.259 |  0.151 |                   96 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.404 |  0.173 |                   63 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.482 |  0.15  |                   37 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.17334306240081787
[2m[36m(func pid=87539)[0m mae:  0.12697003781795502
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.255, 0.084, 0.331, 0.079, 0.187, 0.284, 0.138, 0.145, 0.114]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.148796945810318
[2m[36m(func pid=93214)[0m mae:  0.10393135249614716
[2m[36m(func pid=93214)[0m rmse_per_class: [0.105, 0.225, 0.046, 0.293, 0.055, 0.175, 0.236, 0.123, 0.135, 0.096]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.15113712847232819
[2m[36m(func pid=79710)[0m mae:  0.09447924047708511
[2m[36m(func pid=79710)[0m rmse_per_class: [0.079, 0.212, 0.064, 0.292, 0.067, 0.163, 0.24, 0.121, 0.176, 0.098]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.3123 | Steps: 4 | Val loss: 0.2630 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4035 | Steps: 4 | Val loss: 0.3135 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4606 | Steps: 4 | Val loss: 0.3522 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2756 | Steps: 4 | Val loss: 0.2732 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=78743)[0m rmse: 0.14154306054115295
[2m[36m(func pid=78743)[0m mae:  0.09681268036365509
[2m[36m(func pid=78743)[0m rmse_per_class: [0.071, 0.218, 0.049, 0.287, 0.067, 0.151, 0.229, 0.11, 0.138, 0.097]
[2m[36m(func pid=78743)[0m 
== Status ==
Current time: 2024-01-07 17:50:20 (running for 00:34:37.00)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.312 |  0.142 |                   94 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.272 |  0.151 |                   97 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.173 |                   64 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.494 |  0.149 |                   38 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.1731344759464264
[2m[36m(func pid=87539)[0m mae:  0.12678326666355133
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.255, 0.084, 0.331, 0.078, 0.187, 0.283, 0.138, 0.145, 0.114]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.1488986760377884
[2m[36m(func pid=93214)[0m mae:  0.10400853306055069
[2m[36m(func pid=93214)[0m rmse_per_class: [0.103, 0.224, 0.046, 0.298, 0.055, 0.175, 0.234, 0.123, 0.135, 0.096]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.15021094679832458
[2m[36m(func pid=79710)[0m mae:  0.0927777960896492
[2m[36m(func pid=79710)[0m rmse_per_class: [0.073, 0.211, 0.076, 0.277, 0.061, 0.161, 0.232, 0.119, 0.174, 0.119]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.3103 | Steps: 4 | Val loss: 0.2625 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4021 | Steps: 4 | Val loss: 0.3133 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4699 | Steps: 4 | Val loss: 0.3471 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2590 | Steps: 4 | Val loss: 0.2687 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
== Status ==
Current time: 2024-01-07 17:50:25 (running for 00:34:42.14)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.31  |  0.141 |                   95 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.276 |  0.15  |                   98 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.173 |                   64 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.461 |  0.149 |                   39 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=78743)[0m rmse: 0.14146669209003448
[2m[36m(func pid=78743)[0m mae:  0.09670588374137878
[2m[36m(func pid=78743)[0m rmse_per_class: [0.069, 0.216, 0.047, 0.284, 0.07, 0.152, 0.23, 0.109, 0.137, 0.1]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.173027902841568
[2m[36m(func pid=87539)[0m mae:  0.12668588757514954
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.255, 0.084, 0.331, 0.079, 0.187, 0.283, 0.138, 0.145, 0.114]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.1476113349199295
[2m[36m(func pid=93214)[0m mae:  0.10255904495716095
[2m[36m(func pid=93214)[0m rmse_per_class: [0.101, 0.224, 0.045, 0.296, 0.055, 0.172, 0.233, 0.123, 0.134, 0.094]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.1472819596529007
[2m[36m(func pid=79710)[0m mae:  0.09033136069774628
[2m[36m(func pid=79710)[0m rmse_per_class: [0.067, 0.212, 0.072, 0.265, 0.061, 0.158, 0.223, 0.117, 0.166, 0.129]
[2m[36m(func pid=79710)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4062 | Steps: 4 | Val loss: 0.3134 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.3231 | Steps: 4 | Val loss: 0.2618 | Batch size: 32 | lr: 0.01 | Duration: 3.23s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4480 | Steps: 4 | Val loss: 0.3419 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=79710)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2529 | Steps: 4 | Val loss: 0.2691 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
== Status ==
Current time: 2024-01-07 17:50:30 (running for 00:34:47.38)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743 | 0.01   |       0.9  |         0.0001 |  0.31  |  0.141 |                   95 |
| train_01e98_00015 | RUNNING    | 192.168.7.53:79710 | 0.1    |       0.9  |         0.0001 |  0.259 |  0.147 |                   99 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539 | 0.0001 |       0.99 |         1e-05  |  0.406 |  0.173 |                   66 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214 | 0.001  |       0.99 |         1e-05  |  0.47  |  0.148 |                   40 |
| train_01e98_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                    | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                    | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                    | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                    | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611 | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990 | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418 | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847 | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109 | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640 | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548 | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292 | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.1728459894657135
[2m[36m(func pid=87539)[0m mae:  0.1265428364276886
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.254, 0.083, 0.331, 0.079, 0.187, 0.283, 0.137, 0.145, 0.113]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.1478550136089325
[2m[36m(func pid=93214)[0m mae:  0.10281552374362946
[2m[36m(func pid=93214)[0m rmse_per_class: [0.101, 0.224, 0.044, 0.297, 0.055, 0.172, 0.233, 0.123, 0.134, 0.095]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.1411723792552948
[2m[36m(func pid=78743)[0m mae:  0.0963759571313858
[2m[36m(func pid=78743)[0m rmse_per_class: [0.069, 0.216, 0.048, 0.28, 0.07, 0.153, 0.23, 0.109, 0.135, 0.102]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=79710)[0m rmse: 0.14714494347572327
[2m[36m(func pid=79710)[0m mae:  0.0908629521727562
[2m[36m(func pid=79710)[0m rmse_per_class: [0.073, 0.213, 0.063, 0.268, 0.064, 0.158, 0.224, 0.116, 0.163, 0.129]
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4042 | Steps: 4 | Val loss: 0.3139 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4498 | Steps: 4 | Val loss: 0.3331 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.3311 | Steps: 4 | Val loss: 0.2610 | Batch size: 32 | lr: 0.01 | Duration: 3.16s
[2m[36m(func pid=87539)[0m rmse: 0.1729796677827835
[2m[36m(func pid=87539)[0m mae:  0.12672410905361176
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.254, 0.083, 0.331, 0.079, 0.187, 0.283, 0.137, 0.146, 0.113]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.14706185460090637
[2m[36m(func pid=93214)[0m mae:  0.1018037423491478
[2m[36m(func pid=93214)[0m rmse_per_class: [0.098, 0.222, 0.044, 0.298, 0.055, 0.171, 0.232, 0.123, 0.134, 0.094]
[2m[36m(func pid=78743)[0m rmse: 0.14064180850982666
[2m[36m(func pid=78743)[0m mae:  0.09580822288990021
[2m[36m(func pid=78743)[0m rmse_per_class: [0.069, 0.217, 0.045, 0.279, 0.067, 0.152, 0.228, 0.11, 0.136, 0.102]
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4081 | Steps: 4 | Val loss: 0.3133 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=87539)[0m rmse: 0.1723974198102951
[2m[36m(func pid=87539)[0m mae:  0.12625446915626526
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.253, 0.081, 0.331, 0.078, 0.187, 0.283, 0.137, 0.145, 0.113]
== Status ==
Current time: 2024-01-07 17:50:36 (running for 00:34:52.73)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.323 |  0.141 |                   96 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.404 |  0.173 |                   67 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.448 |  0.148 |                   41 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=103512)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=103512)[0m Configuration completed!
[2m[36m(func pid=103512)[0m New optimizer parameters:
[2m[36m(func pid=103512)[0m SGD (
[2m[36m(func pid=103512)[0m Parameter Group 0
[2m[36m(func pid=103512)[0m     dampening: 0
[2m[36m(func pid=103512)[0m     differentiable: False
[2m[36m(func pid=103512)[0m     foreach: None
[2m[36m(func pid=103512)[0m     lr: 0.01
[2m[36m(func pid=103512)[0m     maximize: False
[2m[36m(func pid=103512)[0m     momentum: 0.99
[2m[36m(func pid=103512)[0m     nesterov: False
[2m[36m(func pid=103512)[0m     weight_decay: 1e-05
[2m[36m(func pid=103512)[0m )
[2m[36m(func pid=103512)[0m 
== Status ==
Current time: 2024-01-07 17:50:41 (running for 00:34:58.39)
Memory usage on this node: 23.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.323 |  0.141 |                   96 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.404 |  0.173 |                   67 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.45  |  0.147 |                   42 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4425 | Steps: 4 | Val loss: 0.3253 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4056 | Steps: 4 | Val loss: 0.3136 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.3191 | Steps: 4 | Val loss: 0.2633 | Batch size: 32 | lr: 0.01 | Duration: 3.31s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8665 | Steps: 4 | Val loss: 0.6245 | Batch size: 32 | lr: 0.01 | Duration: 4.36s
== Status ==
Current time: 2024-01-07 17:50:46 (running for 00:35:03.41)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.331 |  0.141 |                   97 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.408 |  0.172 |                   68 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.45  |  0.147 |                   42 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.146352618932724
[2m[36m(func pid=93214)[0m mae:  0.10074751079082489
[2m[36m(func pid=93214)[0m rmse_per_class: [0.095, 0.221, 0.043, 0.298, 0.055, 0.171, 0.231, 0.122, 0.133, 0.093]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17247633635997772
[2m[36m(func pid=87539)[0m mae:  0.12632934749126434
[2m[36m(func pid=87539)[0m rmse_per_class: [0.119, 0.253, 0.08, 0.331, 0.078, 0.187, 0.283, 0.137, 0.144, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14239346981048584
[2m[36m(func pid=78743)[0m mae:  0.09728404879570007
[2m[36m(func pid=78743)[0m rmse_per_class: [0.07, 0.219, 0.046, 0.283, 0.069, 0.153, 0.229, 0.109, 0.141, 0.106]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.1824323982000351
[2m[36m(func pid=103512)[0m mae:  0.1343294382095337
[2m[36m(func pid=103512)[0m rmse_per_class: [0.118, 0.266, 0.106, 0.339, 0.11, 0.19, 0.294, 0.144, 0.143, 0.113]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4449 | Steps: 4 | Val loss: 0.3188 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4059 | Steps: 4 | Val loss: 0.3127 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.3252 | Steps: 4 | Val loss: 0.2626 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.7018 | Steps: 4 | Val loss: 0.4702 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 17:50:52 (running for 00:35:09.00)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.319 |  0.142 |                   98 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.406 |  0.172 |                   69 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.445 |  0.146 |                   44 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.866 |  0.182 |                    1 |
| train_01e98_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14578863978385925
[2m[36m(func pid=93214)[0m mae:  0.09988720715045929
[2m[36m(func pid=93214)[0m rmse_per_class: [0.096, 0.22, 0.043, 0.298, 0.055, 0.172, 0.23, 0.122, 0.132, 0.092]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17189793288707733
[2m[36m(func pid=87539)[0m mae:  0.12586095929145813
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.252, 0.08, 0.331, 0.077, 0.186, 0.282, 0.137, 0.145, 0.111]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14173313975334167
[2m[36m(func pid=78743)[0m mae:  0.09670566022396088
[2m[36m(func pid=78743)[0m rmse_per_class: [0.07, 0.218, 0.046, 0.282, 0.068, 0.152, 0.229, 0.109, 0.141, 0.101]
[2m[36m(func pid=78743)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.18117770552635193
[2m[36m(func pid=103512)[0m mae:  0.13337068259716034
[2m[36m(func pid=103512)[0m rmse_per_class: [0.119, 0.266, 0.101, 0.338, 0.107, 0.189, 0.292, 0.142, 0.142, 0.114]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4228 | Steps: 4 | Val loss: 0.3112 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4034 | Steps: 4 | Val loss: 0.3128 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=78743)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.3170 | Steps: 4 | Val loss: 0.2639 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.5204 | Steps: 4 | Val loss: 0.3524 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 17:50:57 (running for 00:35:14.10)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00014 | RUNNING    | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.325 |  0.142 |                   99 |
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.406 |  0.172 |                   70 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.423 |  0.145 |                   45 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.702 |  0.181 |                    2 |
| train_01e98_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14520038664340973
[2m[36m(func pid=93214)[0m mae:  0.09930098801851273
[2m[36m(func pid=93214)[0m rmse_per_class: [0.096, 0.221, 0.042, 0.295, 0.055, 0.17, 0.228, 0.122, 0.132, 0.092]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.1716936230659485
[2m[36m(func pid=87539)[0m mae:  0.12569501996040344
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.253, 0.079, 0.33, 0.077, 0.186, 0.282, 0.137, 0.145, 0.112]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=78743)[0m rmse: 0.14253905415534973
[2m[36m(func pid=78743)[0m mae:  0.0970497578382492
[2m[36m(func pid=78743)[0m rmse_per_class: [0.072, 0.218, 0.049, 0.286, 0.065, 0.152, 0.228, 0.109, 0.142, 0.104]
[2m[36m(func pid=103512)[0m rmse: 0.17866499722003937
[2m[36m(func pid=103512)[0m mae:  0.13138258457183838
[2m[36m(func pid=103512)[0m rmse_per_class: [0.121, 0.264, 0.094, 0.336, 0.096, 0.188, 0.289, 0.141, 0.141, 0.116]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4313 | Steps: 4 | Val loss: 0.3060 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4044 | Steps: 4 | Val loss: 0.3124 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4213 | Steps: 4 | Val loss: 0.3173 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=93214)[0m rmse: 0.1450236290693283
[2m[36m(func pid=93214)[0m mae:  0.09883050620555878
[2m[36m(func pid=93214)[0m rmse_per_class: [0.094, 0.221, 0.042, 0.297, 0.055, 0.17, 0.227, 0.122, 0.132, 0.091]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17178286612033844
[2m[36m(func pid=87539)[0m mae:  0.12578126788139343
[2m[36m(func pid=87539)[0m rmse_per_class: [0.115, 0.254, 0.079, 0.33, 0.077, 0.185, 0.281, 0.136, 0.146, 0.114]
[2m[36m(func pid=103512)[0m rmse: 0.17559604346752167
[2m[36m(func pid=103512)[0m mae:  0.12883910536766052
[2m[36m(func pid=103512)[0m rmse_per_class: [0.123, 0.261, 0.087, 0.331, 0.083, 0.188, 0.286, 0.14, 0.14, 0.118]
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4190 | Steps: 4 | Val loss: 0.3003 | Batch size: 32 | lr: 0.001 | Duration: 2.71s
== Status ==
Current time: 2024-01-07 17:51:03 (running for 00:35:19.48)
Memory usage on this node: 22.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.172 |                   71 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.431 |  0.145 |                   46 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.52  |  0.179 |                    3 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=104772)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=104772)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=104772)[0m Configuration completed!
[2m[36m(func pid=104772)[0m New optimizer parameters:
[2m[36m(func pid=104772)[0m SGD (
== Status ==
Current time: 2024-01-07 17:51:08 (running for 00:35:24.49)
Memory usage on this node: 23.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.404 |  0.172 |                   72 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.431 |  0.145 |                   46 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.52  |  0.179 |                    3 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=104772)[0m Parameter Group 0
[2m[36m(func pid=104772)[0m     dampening: 0
[2m[36m(func pid=104772)[0m     differentiable: False
[2m[36m(func pid=104772)[0m     foreach: None
[2m[36m(func pid=104772)[0m     lr: 0.1
[2m[36m(func pid=104772)[0m     maximize: False
[2m[36m(func pid=104772)[0m     momentum: 0.99
[2m[36m(func pid=104772)[0m     nesterov: False
[2m[36m(func pid=104772)[0m     weight_decay: 1e-05
[2m[36m(func pid=104772)[0m )
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.14496228098869324
[2m[36m(func pid=93214)[0m mae:  0.09852005541324615
[2m[36m(func pid=93214)[0m rmse_per_class: [0.094, 0.22, 0.041, 0.3, 0.055, 0.169, 0.227, 0.121, 0.131, 0.09]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4023 | Steps: 4 | Val loss: 0.3124 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4147 | Steps: 4 | Val loss: 0.3355 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3981 | Steps: 4 | Val loss: 0.2941 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.6888 | Steps: 4 | Val loss: 0.3415 | Batch size: 32 | lr: 0.1 | Duration: 4.65s
== Status ==
Current time: 2024-01-07 17:51:13 (running for 00:35:29.61)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.404 |  0.172 |                   72 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.419 |  0.145 |                   47 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.421 |  0.176 |                    4 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_01e98_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.17139017581939697
[2m[36m(func pid=87539)[0m mae:  0.125443696975708
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.253, 0.079, 0.329, 0.076, 0.185, 0.281, 0.136, 0.145, 0.114]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.1445072442293167
[2m[36m(func pid=93214)[0m mae:  0.09790607541799545
[2m[36m(func pid=93214)[0m rmse_per_class: [0.093, 0.22, 0.041, 0.299, 0.055, 0.167, 0.227, 0.122, 0.131, 0.09]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.1714051514863968
[2m[36m(func pid=103512)[0m mae:  0.1253400295972824
[2m[36m(func pid=103512)[0m rmse_per_class: [0.123, 0.256, 0.077, 0.324, 0.073, 0.186, 0.281, 0.137, 0.139, 0.118]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.1801036298274994
[2m[36m(func pid=104772)[0m mae:  0.13275465369224548
[2m[36m(func pid=104772)[0m rmse_per_class: [0.126, 0.265, 0.097, 0.338, 0.091, 0.191, 0.287, 0.144, 0.147, 0.114]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3993 | Steps: 4 | Val loss: 0.3132 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3880 | Steps: 4 | Val loss: 0.2895 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4570 | Steps: 4 | Val loss: 0.3739 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.4569 | Steps: 4 | Val loss: 0.3928 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 17:51:18 (running for 00:35:35.43)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.402 |  0.171 |                   73 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.388 |  0.145 |                   49 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.415 |  0.171 |                    5 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.689 |  0.18  |                    1 |
| train_01e98_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=87539)[0m rmse: 0.17132315039634705
[2m[36m(func pid=87539)[0m mae:  0.1253863126039505
[2m[36m(func pid=87539)[0m rmse_per_class: [0.116, 0.253, 0.079, 0.329, 0.076, 0.185, 0.281, 0.136, 0.144, 0.114]
[2m[36m(func pid=87539)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.1445406973361969
[2m[36m(func pid=93214)[0m mae:  0.09769509732723236
[2m[36m(func pid=93214)[0m rmse_per_class: [0.092, 0.221, 0.04, 0.301, 0.055, 0.166, 0.227, 0.122, 0.131, 0.09]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.16721835732460022
[2m[36m(func pid=103512)[0m mae:  0.12159164994955063
[2m[36m(func pid=103512)[0m rmse_per_class: [0.122, 0.251, 0.069, 0.318, 0.064, 0.185, 0.272, 0.135, 0.137, 0.119]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.17018389701843262
[2m[36m(func pid=104772)[0m mae:  0.124770388007164
[2m[36m(func pid=104772)[0m rmse_per_class: [0.133, 0.256, 0.064, 0.335, 0.06, 0.192, 0.262, 0.134, 0.155, 0.111]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3903 | Steps: 4 | Val loss: 0.2841 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4984 | Steps: 4 | Val loss: 0.4145 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=87539)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4029 | Steps: 4 | Val loss: 0.3138 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.6103 | Steps: 4 | Val loss: 0.5044 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 17:51:24 (running for 00:35:40.67)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00016 | RUNNING    | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.399 |  0.171 |                   74 |
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.39  |  0.145 |                   50 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.457 |  0.167 |                    6 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.457 |  0.17  |                    2 |
| train_01e98_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14480282366275787
[2m[36m(func pid=93214)[0m mae:  0.09820673614740372
[2m[36m(func pid=93214)[0m rmse_per_class: [0.096, 0.221, 0.041, 0.302, 0.055, 0.166, 0.225, 0.121, 0.131, 0.09]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.16301992535591125
[2m[36m(func pid=103512)[0m mae:  0.11745993793010712
[2m[36m(func pid=103512)[0m rmse_per_class: [0.121, 0.247, 0.059, 0.314, 0.059, 0.183, 0.262, 0.131, 0.135, 0.119]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=87539)[0m rmse: 0.17131036520004272
[2m[36m(func pid=87539)[0m mae:  0.12537959218025208
[2m[36m(func pid=87539)[0m rmse_per_class: [0.117, 0.252, 0.079, 0.329, 0.075, 0.185, 0.282, 0.137, 0.145, 0.114]
[2m[36m(func pid=104772)[0m rmse: 0.1626136153936386
[2m[36m(func pid=104772)[0m mae:  0.11558184772729874
[2m[36m(func pid=104772)[0m rmse_per_class: [0.114, 0.24, 0.046, 0.337, 0.054, 0.192, 0.231, 0.126, 0.18, 0.106]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3846 | Steps: 4 | Val loss: 0.2789 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5452 | Steps: 4 | Val loss: 0.4462 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.7249 | Steps: 4 | Val loss: 0.5179 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=93214)[0m rmse: 0.14458875358104706
[2m[36m(func pid=93214)[0m mae:  0.09799760580062866
[2m[36m(func pid=93214)[0m rmse_per_class: [0.095, 0.221, 0.041, 0.303, 0.055, 0.163, 0.226, 0.12, 0.131, 0.09]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.15897180140018463
[2m[36m(func pid=103512)[0m mae:  0.11313313245773315
[2m[36m(func pid=103512)[0m rmse_per_class: [0.119, 0.242, 0.052, 0.311, 0.056, 0.181, 0.251, 0.128, 0.134, 0.116]
[2m[36m(func pid=104772)[0m rmse: 0.1582757979631424
[2m[36m(func pid=104772)[0m mae:  0.10558193922042847
[2m[36m(func pid=104772)[0m rmse_per_class: [0.078, 0.231, 0.046, 0.343, 0.056, 0.188, 0.231, 0.132, 0.189, 0.089]
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3802 | Steps: 4 | Val loss: 0.2747 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 17:51:29 (running for 00:35:46.06)
Memory usage on this node: 22.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.385 |  0.145 |                   51 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.498 |  0.163 |                    7 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.61  |  0.163 |                    3 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=106005)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=106005)[0m Configuration completed!
[2m[36m(func pid=106005)[0m New optimizer parameters:
[2m[36m(func pid=106005)[0m SGD (
[2m[36m(func pid=106005)[0m Parameter Group 0
[2m[36m(func pid=106005)[0m     dampening: 0
[2m[36m(func pid=106005)[0m     differentiable: False
[2m[36m(func pid=106005)[0m     foreach: None
[2m[36m(func pid=106005)[0m     lr: 0.0001
[2m[36m(func pid=106005)[0m     maximize: False
[2m[36m(func pid=106005)[0m     momentum: 0.9
[2m[36m(func pid=106005)[0m     nesterov: False
[2m[36m(func pid=106005)[0m     weight_decay: 1e-05
[2m[36m(func pid=106005)[0m )
[2m[36m(func pid=106005)[0m 
== Status ==
Current time: 2024-01-07 17:51:35 (running for 00:35:51.53)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.38  |  0.144 |                   52 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.545 |  0.159 |                    8 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.725 |  0.158 |                    4 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.1439957171678543
[2m[36m(func pid=93214)[0m mae:  0.09719664603471756
[2m[36m(func pid=93214)[0m rmse_per_class: [0.094, 0.222, 0.04, 0.302, 0.056, 0.162, 0.225, 0.12, 0.131, 0.089]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5875 | Steps: 4 | Val loss: 0.4720 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.6863 | Steps: 4 | Val loss: 0.4225 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8969 | Steps: 4 | Val loss: 0.7025 | Batch size: 32 | lr: 0.0001 | Duration: 4.77s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3609 | Steps: 4 | Val loss: 0.2720 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=104772)[0m rmse: 0.1650191843509674
[2m[36m(func pid=104772)[0m mae:  0.10306328535079956
[2m[36m(func pid=104772)[0m rmse_per_class: [0.064, 0.3, 0.048, 0.348, 0.056, 0.185, 0.276, 0.144, 0.15, 0.079]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.15579953789710999
[2m[36m(func pid=103512)[0m mae:  0.10907582193613052
[2m[36m(func pid=103512)[0m rmse_per_class: [0.119, 0.238, 0.048, 0.308, 0.055, 0.179, 0.243, 0.125, 0.132, 0.113]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.18253979086875916
[2m[36m(func pid=106005)[0m mae:  0.13438625633716583
[2m[36m(func pid=106005)[0m rmse_per_class: [0.117, 0.266, 0.107, 0.339, 0.112, 0.191, 0.294, 0.143, 0.144, 0.113]
[2m[36m(func pid=106005)[0m 
== Status ==
Current time: 2024-01-07 17:51:40 (running for 00:35:56.92)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.361 |  0.144 |                   53 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.588 |  0.156 |                    9 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.686 |  0.165 |                    5 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.897 |  0.183 |                    1 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14380422234535217
[2m[36m(func pid=93214)[0m mae:  0.09711446613073349
[2m[36m(func pid=93214)[0m rmse_per_class: [0.093, 0.222, 0.039, 0.303, 0.056, 0.16, 0.225, 0.119, 0.131, 0.091]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.6200 | Steps: 4 | Val loss: 0.4800 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.5301 | Steps: 4 | Val loss: 0.3245 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.8951 | Steps: 4 | Val loss: 0.6959 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=103512)[0m rmse: 0.15251989662647247
[2m[36m(func pid=103512)[0m mae:  0.10432849079370499
[2m[36m(func pid=103512)[0m rmse_per_class: [0.115, 0.235, 0.045, 0.303, 0.054, 0.176, 0.239, 0.122, 0.131, 0.105]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3624 | Steps: 4 | Val loss: 0.2687 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=104772)[0m rmse: 0.16150064766407013
[2m[36m(func pid=104772)[0m mae:  0.10009424388408661
[2m[36m(func pid=104772)[0m rmse_per_class: [0.067, 0.31, 0.049, 0.334, 0.056, 0.165, 0.261, 0.146, 0.143, 0.084]
[2m[36m(func pid=104772)[0m 
== Status ==
Current time: 2024-01-07 17:51:45 (running for 00:36:01.93)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.361 |  0.144 |                   53 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.62  |  0.153 |                   10 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.53  |  0.162 |                    6 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.895 |  0.182 |                    2 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=106005)[0m rmse: 0.18185046315193176
[2m[36m(func pid=106005)[0m mae:  0.13388045132160187
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.266, 0.104, 0.339, 0.113, 0.19, 0.294, 0.142, 0.143, 0.111]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.14343777298927307
[2m[36m(func pid=93214)[0m mae:  0.0968383178114891
[2m[36m(func pid=93214)[0m rmse_per_class: [0.094, 0.224, 0.039, 0.298, 0.056, 0.16, 0.223, 0.12, 0.131, 0.09]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.6414 | Steps: 4 | Val loss: 0.4801 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4764 | Steps: 4 | Val loss: 0.3781 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.8931 | Steps: 4 | Val loss: 0.6931 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=103512)[0m rmse: 0.1506149023771286
[2m[36m(func pid=103512)[0m mae:  0.10065990686416626
[2m[36m(func pid=103512)[0m rmse_per_class: [0.115, 0.228, 0.044, 0.3, 0.055, 0.175, 0.241, 0.121, 0.131, 0.097]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3637 | Steps: 4 | Val loss: 0.2666 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=104772)[0m rmse: 0.14820899069309235
[2m[36m(func pid=104772)[0m mae:  0.0953437089920044
[2m[36m(func pid=104772)[0m rmse_per_class: [0.066, 0.226, 0.049, 0.291, 0.056, 0.166, 0.212, 0.132, 0.165, 0.118]
[2m[36m(func pid=104772)[0m 
== Status ==
Current time: 2024-01-07 17:51:50 (running for 00:36:07.43)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.362 |  0.143 |                   54 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.641 |  0.151 |                   11 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.476 |  0.148 |                    7 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.893 |  0.181 |                    3 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=106005)[0m rmse: 0.18135413527488708
[2m[36m(func pid=106005)[0m mae:  0.13345271348953247
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.265, 0.103, 0.339, 0.113, 0.189, 0.295, 0.141, 0.142, 0.111]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.14299839735031128
[2m[36m(func pid=93214)[0m mae:  0.0964600220322609
[2m[36m(func pid=93214)[0m rmse_per_class: [0.096, 0.224, 0.039, 0.298, 0.056, 0.156, 0.222, 0.119, 0.13, 0.089]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.6067 | Steps: 4 | Val loss: 0.4684 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5543 | Steps: 4 | Val loss: 0.4100 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=103512)[0m rmse: 0.15028831362724304
[2m[36m(func pid=103512)[0m mae:  0.09834884107112885
[2m[36m(func pid=103512)[0m rmse_per_class: [0.119, 0.224, 0.043, 0.297, 0.055, 0.175, 0.244, 0.122, 0.131, 0.093]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8865 | Steps: 4 | Val loss: 0.6914 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=104772)[0m rmse: 0.15821683406829834
[2m[36m(func pid=104772)[0m mae:  0.10302992165088654
[2m[36m(func pid=104772)[0m rmse_per_class: [0.105, 0.23, 0.044, 0.261, 0.056, 0.172, 0.265, 0.117, 0.183, 0.149]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3656 | Steps: 4 | Val loss: 0.2657 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 17:51:56 (running for 00:36:12.73)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.364 |  0.143 |                   55 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.607 |  0.15  |                   12 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.554 |  0.158 |                    8 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.887 |  0.181 |                    4 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=106005)[0m rmse: 0.18087813258171082
[2m[36m(func pid=106005)[0m mae:  0.13300664722919464
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.264, 0.103, 0.338, 0.112, 0.19, 0.294, 0.141, 0.142, 0.11]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.14303913712501526
[2m[36m(func pid=93214)[0m mae:  0.09654119610786438
[2m[36m(func pid=93214)[0m rmse_per_class: [0.095, 0.223, 0.039, 0.299, 0.056, 0.157, 0.222, 0.116, 0.131, 0.093]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.5895 | Steps: 4 | Val loss: 0.4466 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5536 | Steps: 4 | Val loss: 0.3814 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=103512)[0m rmse: 0.15079088509082794
[2m[36m(func pid=103512)[0m mae:  0.0963786318898201
[2m[36m(func pid=103512)[0m rmse_per_class: [0.124, 0.225, 0.043, 0.293, 0.056, 0.171, 0.253, 0.123, 0.132, 0.089]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.8824 | Steps: 4 | Val loss: 0.6874 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=104772)[0m rmse: 0.17930898070335388
[2m[36m(func pid=104772)[0m mae:  0.11036400496959686
[2m[36m(func pid=104772)[0m rmse_per_class: [0.194, 0.25, 0.026, 0.258, 0.056, 0.166, 0.325, 0.179, 0.143, 0.197]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3570 | Steps: 4 | Val loss: 0.2672 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 17:52:01 (running for 00:36:18.06)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.366 |  0.143 |                   56 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.589 |  0.151 |                   13 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.554 |  0.179 |                    9 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.882 |  0.181 |                    5 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=106005)[0m rmse: 0.1805386245250702
[2m[36m(func pid=106005)[0m mae:  0.13273771107196808
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.263, 0.102, 0.338, 0.111, 0.19, 0.294, 0.141, 0.142, 0.11]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.14434880018234253
[2m[36m(func pid=93214)[0m mae:  0.09801850467920303
[2m[36m(func pid=93214)[0m rmse_per_class: [0.096, 0.223, 0.038, 0.302, 0.055, 0.157, 0.224, 0.116, 0.132, 0.099]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.5807 | Steps: 4 | Val loss: 0.4158 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4835 | Steps: 4 | Val loss: 0.4161 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=103512)[0m rmse: 0.15206924080848694
[2m[36m(func pid=103512)[0m mae:  0.09533564746379852
[2m[36m(func pid=103512)[0m rmse_per_class: [0.129, 0.222, 0.044, 0.291, 0.056, 0.17, 0.265, 0.125, 0.134, 0.085]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.8810 | Steps: 4 | Val loss: 0.6840 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=104772)[0m rmse: 0.20449626445770264
[2m[36m(func pid=104772)[0m mae:  0.11835403740406036
[2m[36m(func pid=104772)[0m rmse_per_class: [0.22, 0.253, 0.04, 0.277, 0.061, 0.169, 0.328, 0.339, 0.144, 0.214]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3641 | Steps: 4 | Val loss: 0.2681 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 17:52:06 (running for 00:36:23.45)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.357 |  0.144 |                   57 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.581 |  0.152 |                   14 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.484 |  0.204 |                   10 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.881 |  0.18  |                    6 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=106005)[0m rmse: 0.18030282855033875
[2m[36m(func pid=106005)[0m mae:  0.13254067301750183
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.262, 0.101, 0.338, 0.111, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.14472822844982147
[2m[36m(func pid=93214)[0m mae:  0.09843634814023972
[2m[36m(func pid=93214)[0m rmse_per_class: [0.098, 0.223, 0.038, 0.304, 0.055, 0.156, 0.224, 0.115, 0.132, 0.102]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.5465 | Steps: 4 | Val loss: 0.3788 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4751 | Steps: 4 | Val loss: 0.4642 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=103512)[0m rmse: 0.15195122361183167
[2m[36m(func pid=103512)[0m mae:  0.09364510327577591
[2m[36m(func pid=103512)[0m rmse_per_class: [0.134, 0.219, 0.044, 0.284, 0.056, 0.169, 0.269, 0.126, 0.135, 0.083]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.8755 | Steps: 4 | Val loss: 0.6794 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=104772)[0m rmse: 0.22233101725578308
[2m[36m(func pid=104772)[0m mae:  0.12284944206476212
[2m[36m(func pid=104772)[0m rmse_per_class: [0.169, 0.241, 0.1, 0.29, 0.171, 0.2, 0.309, 0.371, 0.186, 0.187]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3738 | Steps: 4 | Val loss: 0.2687 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 17:52:12 (running for 00:36:28.74)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.364 |  0.145 |                   58 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.547 |  0.152 |                   15 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.475 |  0.222 |                   11 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.875 |  0.18  |                    7 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=106005)[0m rmse: 0.18003885447978973
[2m[36m(func pid=106005)[0m mae:  0.1323036104440689
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.262, 0.1, 0.337, 0.11, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.5227 | Steps: 4 | Val loss: 0.3425 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=93214)[0m rmse: 0.14474788308143616
[2m[36m(func pid=93214)[0m mae:  0.098883718252182
[2m[36m(func pid=93214)[0m rmse_per_class: [0.098, 0.222, 0.037, 0.303, 0.055, 0.157, 0.225, 0.115, 0.132, 0.104]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4880 | Steps: 4 | Val loss: 0.4698 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=103512)[0m rmse: 0.1541024148464203
[2m[36m(func pid=103512)[0m mae:  0.0939856469631195
[2m[36m(func pid=103512)[0m rmse_per_class: [0.149, 0.218, 0.045, 0.285, 0.056, 0.168, 0.275, 0.129, 0.136, 0.081]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.8716 | Steps: 4 | Val loss: 0.6745 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=104772)[0m rmse: 0.22405974566936493
[2m[36m(func pid=104772)[0m mae:  0.12410938739776611
[2m[36m(func pid=104772)[0m rmse_per_class: [0.087, 0.286, 0.133, 0.343, 0.341, 0.207, 0.27, 0.227, 0.2, 0.147]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3567 | Steps: 4 | Val loss: 0.2684 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 17:52:17 (running for 00:36:33.93)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.374 |  0.145 |                   59 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.523 |  0.154 |                   16 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.488 |  0.224 |                   12 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.872 |  0.18  |                    8 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=106005)[0m rmse: 0.18003031611442566
[2m[36m(func pid=106005)[0m mae:  0.1322958767414093
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.1, 0.337, 0.11, 0.19, 0.295, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4876 | Steps: 4 | Val loss: 0.3064 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=93214)[0m rmse: 0.14418922364711761
[2m[36m(func pid=93214)[0m mae:  0.09861475974321365
[2m[36m(func pid=93214)[0m rmse_per_class: [0.099, 0.221, 0.036, 0.298, 0.055, 0.156, 0.226, 0.114, 0.132, 0.103]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.5035 | Steps: 4 | Val loss: 0.4648 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=103512)[0m rmse: 0.15286755561828613
[2m[36m(func pid=103512)[0m mae:  0.09273877739906311
[2m[36m(func pid=103512)[0m rmse_per_class: [0.156, 0.216, 0.045, 0.28, 0.056, 0.165, 0.264, 0.13, 0.136, 0.08]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.8645 | Steps: 4 | Val loss: 0.6713 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=104772)[0m rmse: 0.20856210589408875
[2m[36m(func pid=104772)[0m mae:  0.12030705064535141
[2m[36m(func pid=104772)[0m rmse_per_class: [0.081, 0.284, 0.095, 0.374, 0.319, 0.213, 0.276, 0.125, 0.213, 0.108]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3538 | Steps: 4 | Val loss: 0.2703 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 17:52:22 (running for 00:36:39.38)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.357 |  0.144 |                   60 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.488 |  0.153 |                   17 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.504 |  0.209 |                   13 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.864 |  0.18  |                    9 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=106005)[0m rmse: 0.18006905913352966
[2m[36m(func pid=106005)[0m mae:  0.13231661915779114
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.1, 0.338, 0.111, 0.19, 0.295, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4477 | Steps: 4 | Val loss: 0.2864 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=93214)[0m rmse: 0.1447777897119522
[2m[36m(func pid=93214)[0m mae:  0.0992683619260788
[2m[36m(func pid=93214)[0m rmse_per_class: [0.099, 0.221, 0.036, 0.298, 0.055, 0.156, 0.227, 0.115, 0.133, 0.107]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.5190 | Steps: 4 | Val loss: 0.5074 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=103512)[0m rmse: 0.15274155139923096
[2m[36m(func pid=103512)[0m mae:  0.09255541861057281
[2m[36m(func pid=103512)[0m rmse_per_class: [0.163, 0.217, 0.044, 0.285, 0.056, 0.157, 0.256, 0.128, 0.136, 0.085]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.8625 | Steps: 4 | Val loss: 0.6691 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3675 | Steps: 4 | Val loss: 0.2722 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=104772)[0m rmse: 0.1940086930990219
[2m[36m(func pid=104772)[0m mae:  0.11667971312999725
[2m[36m(func pid=104772)[0m rmse_per_class: [0.08, 0.248, 0.093, 0.372, 0.215, 0.202, 0.287, 0.134, 0.217, 0.093]
[2m[36m(func pid=104772)[0m 
== Status ==
Current time: 2024-01-07 17:52:28 (running for 00:36:44.79)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.354 |  0.145 |                   61 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.448 |  0.153 |                   18 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.519 |  0.194 |                   14 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.863 |  0.18  |                   10 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=106005)[0m rmse: 0.17997722327709198
[2m[36m(func pid=106005)[0m mae:  0.13222214579582214
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.1, 0.337, 0.111, 0.19, 0.295, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.4139 | Steps: 4 | Val loss: 0.2799 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=93214)[0m rmse: 0.14535176753997803
[2m[36m(func pid=93214)[0m mae:  0.09963544458150864
[2m[36m(func pid=93214)[0m rmse_per_class: [0.101, 0.222, 0.035, 0.298, 0.055, 0.156, 0.229, 0.114, 0.133, 0.11]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.5358 | Steps: 4 | Val loss: 0.4366 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=103512)[0m rmse: 0.1496421992778778
[2m[36m(func pid=103512)[0m mae:  0.09155594557523727
[2m[36m(func pid=103512)[0m rmse_per_class: [0.156, 0.217, 0.044, 0.285, 0.056, 0.152, 0.232, 0.124, 0.136, 0.095]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.8576 | Steps: 4 | Val loss: 0.6627 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=104772)[0m rmse: 0.1781415343284607
[2m[36m(func pid=104772)[0m mae:  0.10522260516881943
[2m[36m(func pid=104772)[0m rmse_per_class: [0.074, 0.237, 0.102, 0.324, 0.157, 0.174, 0.237, 0.129, 0.25, 0.097]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3697 | Steps: 4 | Val loss: 0.2735 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 17:52:33 (running for 00:36:50.25)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.368 |  0.145 |                   62 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.414 |  0.15  |                   19 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.536 |  0.178 |                   15 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.858 |  0.18  |                   11 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=106005)[0m rmse: 0.1797848343849182
[2m[36m(func pid=106005)[0m mae:  0.1320391744375229
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.112, 0.19, 0.294, 0.14, 0.143, 0.108]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4170 | Steps: 4 | Val loss: 0.2872 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=93214)[0m rmse: 0.14537791907787323
[2m[36m(func pid=93214)[0m mae:  0.09990527480840683
[2m[36m(func pid=93214)[0m rmse_per_class: [0.1, 0.222, 0.035, 0.296, 0.055, 0.156, 0.232, 0.114, 0.134, 0.111]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.5008 | Steps: 4 | Val loss: 0.3773 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=103512)[0m rmse: 0.1445210874080658
[2m[36m(func pid=103512)[0m mae:  0.08956705778837204
[2m[36m(func pid=103512)[0m rmse_per_class: [0.139, 0.217, 0.042, 0.274, 0.056, 0.152, 0.215, 0.118, 0.135, 0.095]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.17069078981876373
[2m[36m(func pid=104772)[0m mae:  0.09891895949840546
[2m[36m(func pid=104772)[0m rmse_per_class: [0.071, 0.218, 0.12, 0.265, 0.092, 0.219, 0.266, 0.123, 0.214, 0.118]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.8536 | Steps: 4 | Val loss: 0.6588 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3556 | Steps: 4 | Val loss: 0.2740 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 17:52:39 (running for 00:36:55.56)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.37  |  0.145 |                   63 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.417 |  0.145 |                   20 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.501 |  0.171 |                   16 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.854 |  0.18  |                   12 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4349 | Steps: 4 | Val loss: 0.3033 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=106005)[0m rmse: 0.17980846762657166
[2m[36m(func pid=106005)[0m mae:  0.1320808231830597
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.111, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.14504078030586243
[2m[36m(func pid=93214)[0m mae:  0.09975634515285492
[2m[36m(func pid=93214)[0m rmse_per_class: [0.099, 0.223, 0.034, 0.293, 0.055, 0.156, 0.234, 0.113, 0.134, 0.109]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4374 | Steps: 4 | Val loss: 0.4186 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=103512)[0m rmse: 0.14395496249198914
[2m[36m(func pid=103512)[0m mae:  0.09084589034318924
[2m[36m(func pid=103512)[0m rmse_per_class: [0.13, 0.219, 0.038, 0.272, 0.056, 0.153, 0.212, 0.116, 0.133, 0.111]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.18356555700302124
[2m[36m(func pid=104772)[0m mae:  0.10659686475992203
[2m[36m(func pid=104772)[0m rmse_per_class: [0.079, 0.234, 0.136, 0.279, 0.06, 0.261, 0.326, 0.13, 0.16, 0.171]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.8479 | Steps: 4 | Val loss: 0.6522 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3787 | Steps: 4 | Val loss: 0.2749 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4750 | Steps: 4 | Val loss: 0.3205 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 17:52:44 (running for 00:37:00.96)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.379 |  0.145 |                   65 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.435 |  0.144 |                   21 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.437 |  0.184 |                   17 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.854 |  0.18  |                   12 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14491045475006104
[2m[36m(func pid=93214)[0m mae:  0.09979856014251709
[2m[36m(func pid=93214)[0m rmse_per_class: [0.1, 0.221, 0.035, 0.291, 0.055, 0.156, 0.236, 0.112, 0.134, 0.109]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17974507808685303
[2m[36m(func pid=106005)[0m mae:  0.13208334147930145
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.11, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4726 | Steps: 4 | Val loss: 0.4569 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=103512)[0m rmse: 0.1449715793132782
[2m[36m(func pid=103512)[0m mae:  0.09265387058258057
[2m[36m(func pid=103512)[0m rmse_per_class: [0.123, 0.221, 0.031, 0.276, 0.056, 0.159, 0.221, 0.112, 0.129, 0.121]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.20103318989276886
[2m[36m(func pid=104772)[0m mae:  0.1142694354057312
[2m[36m(func pid=104772)[0m rmse_per_class: [0.141, 0.261, 0.114, 0.269, 0.055, 0.228, 0.332, 0.201, 0.14, 0.269]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.8404 | Steps: 4 | Val loss: 0.6508 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3656 | Steps: 4 | Val loss: 0.2778 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 17:52:49 (running for 00:37:06.30)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.379 |  0.145 |                   65 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.475 |  0.145 |                   22 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.473 |  0.201 |                   18 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.84  |  0.18  |                   14 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=106005)[0m rmse: 0.17965199053287506
[2m[36m(func pid=106005)[0m mae:  0.13199502229690552
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.11, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4729 | Steps: 4 | Val loss: 0.3325 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=93214)[0m rmse: 0.14589951932430267
[2m[36m(func pid=93214)[0m mae:  0.10061551630496979
[2m[36m(func pid=93214)[0m rmse_per_class: [0.098, 0.221, 0.034, 0.296, 0.055, 0.156, 0.239, 0.112, 0.135, 0.112]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.5088 | Steps: 4 | Val loss: 0.4747 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=103512)[0m rmse: 0.14497683942317963
[2m[36m(func pid=103512)[0m mae:  0.09405005723237991
[2m[36m(func pid=103512)[0m rmse_per_class: [0.101, 0.222, 0.03, 0.271, 0.056, 0.16, 0.237, 0.112, 0.127, 0.133]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.21430787444114685
[2m[36m(func pid=104772)[0m mae:  0.12256630510091782
[2m[36m(func pid=104772)[0m rmse_per_class: [0.217, 0.262, 0.092, 0.291, 0.056, 0.187, 0.315, 0.269, 0.139, 0.316]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.8401 | Steps: 4 | Val loss: 0.6464 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3702 | Steps: 4 | Val loss: 0.2791 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 17:52:55 (running for 00:37:11.54)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.366 |  0.146 |                   66 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.473 |  0.145 |                   23 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.509 |  0.214 |                   19 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.84  |  0.18  |                   15 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=106005)[0m rmse: 0.17994046211242676
[2m[36m(func pid=106005)[0m mae:  0.13220486044883728
[2m[36m(func pid=106005)[0m rmse_per_class: [0.114, 0.262, 0.1, 0.337, 0.109, 0.19, 0.294, 0.139, 0.144, 0.11]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.1465441882610321
[2m[36m(func pid=93214)[0m mae:  0.10114500671625137
[2m[36m(func pid=93214)[0m rmse_per_class: [0.097, 0.221, 0.034, 0.293, 0.055, 0.156, 0.244, 0.112, 0.137, 0.116]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4261 | Steps: 4 | Val loss: 0.3355 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.5637 | Steps: 4 | Val loss: 0.4545 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=103512)[0m rmse: 0.14829906821250916
[2m[36m(func pid=103512)[0m mae:  0.09810232371091843
[2m[36m(func pid=103512)[0m rmse_per_class: [0.087, 0.221, 0.026, 0.275, 0.056, 0.16, 0.256, 0.114, 0.14, 0.147]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.2016088217496872
[2m[36m(func pid=104772)[0m mae:  0.11459989845752716
[2m[36m(func pid=104772)[0m rmse_per_class: [0.174, 0.255, 0.06, 0.32, 0.056, 0.181, 0.258, 0.275, 0.143, 0.294]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.8382 | Steps: 4 | Val loss: 0.6453 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3739 | Steps: 4 | Val loss: 0.2796 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=106005)[0m rmse: 0.17990681529045105
[2m[36m(func pid=106005)[0m mae:  0.1321554034948349
[2m[36m(func pid=106005)[0m rmse_per_class: [0.114, 0.261, 0.1, 0.337, 0.11, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=106005)[0m 
== Status ==
Current time: 2024-01-07 17:53:00 (running for 00:37:17.11)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.37  |  0.147 |                   67 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.426 |  0.148 |                   24 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.564 |  0.202 |                   20 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.838 |  0.18  |                   16 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.1465459018945694
[2m[36m(func pid=93214)[0m mae:  0.10124455392360687
[2m[36m(func pid=93214)[0m rmse_per_class: [0.096, 0.222, 0.034, 0.288, 0.055, 0.156, 0.248, 0.113, 0.137, 0.117]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4899 | Steps: 4 | Val loss: 0.3347 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.5203 | Steps: 4 | Val loss: 0.4715 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=103512)[0m rmse: 0.15265321731567383
[2m[36m(func pid=103512)[0m mae:  0.10181023180484772
[2m[36m(func pid=103512)[0m rmse_per_class: [0.077, 0.22, 0.025, 0.275, 0.056, 0.155, 0.273, 0.119, 0.174, 0.153]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.19225621223449707
[2m[36m(func pid=104772)[0m mae:  0.1106376200914383
[2m[36m(func pid=104772)[0m rmse_per_class: [0.124, 0.252, 0.036, 0.353, 0.056, 0.197, 0.388, 0.183, 0.145, 0.187]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3560 | Steps: 4 | Val loss: 0.2807 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.8267 | Steps: 4 | Val loss: 0.6443 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4289 | Steps: 4 | Val loss: 0.3374 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=106005)[0m rmse: 0.1798563301563263
[2m[36m(func pid=106005)[0m mae:  0.13212336599826813
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.11, 0.19, 0.294, 0.14, 0.143, 0.109]
== Status ==
Current time: 2024-01-07 17:53:06 (running for 00:37:22.63)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.374 |  0.147 |                   68 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.49  |  0.153 |                   25 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.52  |  0.192 |                   21 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.827 |  0.18  |                   17 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14709286391735077
[2m[36m(func pid=93214)[0m mae:  0.10179611295461655
[2m[36m(func pid=93214)[0m rmse_per_class: [0.097, 0.222, 0.034, 0.287, 0.055, 0.156, 0.25, 0.113, 0.139, 0.119]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4968 | Steps: 4 | Val loss: 0.4489 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.15935365855693817
[2m[36m(func pid=103512)[0m mae:  0.10620789229869843
[2m[36m(func pid=103512)[0m rmse_per_class: [0.069, 0.22, 0.025, 0.278, 0.056, 0.154, 0.288, 0.126, 0.223, 0.155]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.18298664689064026
[2m[36m(func pid=104772)[0m mae:  0.10695769637823105
[2m[36m(func pid=104772)[0m rmse_per_class: [0.082, 0.272, 0.029, 0.358, 0.056, 0.196, 0.4, 0.145, 0.162, 0.129]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.8207 | Steps: 4 | Val loss: 0.6398 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3548 | Steps: 4 | Val loss: 0.2806 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3923 | Steps: 4 | Val loss: 0.3394 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=106005)[0m rmse: 0.17990995943546295
[2m[36m(func pid=106005)[0m mae:  0.1322028934955597
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.11, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
== Status ==
Current time: 2024-01-07 17:53:11 (running for 00:37:27.94)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.356 |  0.147 |                   69 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.429 |  0.159 |                   26 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.497 |  0.183 |                   22 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.821 |  0.18  |                   18 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14734195172786713
[2m[36m(func pid=93214)[0m mae:  0.10216154903173447
[2m[36m(func pid=93214)[0m rmse_per_class: [0.093, 0.221, 0.033, 0.287, 0.055, 0.156, 0.252, 0.113, 0.141, 0.124]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4509 | Steps: 4 | Val loss: 0.4249 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=103512)[0m rmse: 0.16780269145965576
[2m[36m(func pid=103512)[0m mae:  0.11101403087377548
[2m[36m(func pid=103512)[0m rmse_per_class: [0.066, 0.225, 0.025, 0.286, 0.056, 0.154, 0.296, 0.139, 0.273, 0.158]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.1802685409784317
[2m[36m(func pid=104772)[0m mae:  0.10395624488592148
[2m[36m(func pid=104772)[0m rmse_per_class: [0.075, 0.34, 0.032, 0.346, 0.056, 0.184, 0.274, 0.145, 0.244, 0.106]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.8175 | Steps: 4 | Val loss: 0.6364 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3670 | Steps: 4 | Val loss: 0.2794 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4107 | Steps: 4 | Val loss: 0.3365 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 17:53:16 (running for 00:37:33.36)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.355 |  0.147 |                   70 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.392 |  0.168 |                   27 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.451 |  0.18  |                   23 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.818 |  0.18  |                   19 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.1477624475955963
[2m[36m(func pid=93214)[0m mae:  0.10268701612949371
[2m[36m(func pid=93214)[0m rmse_per_class: [0.095, 0.222, 0.034, 0.286, 0.055, 0.155, 0.253, 0.113, 0.142, 0.124]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.5258 | Steps: 4 | Val loss: 0.4365 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=106005)[0m rmse: 0.1799469292163849
[2m[36m(func pid=106005)[0m mae:  0.13224360346794128
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.338, 0.109, 0.19, 0.294, 0.14, 0.144, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.17388899624347687
[2m[36m(func pid=103512)[0m mae:  0.11362941563129425
[2m[36m(func pid=103512)[0m rmse_per_class: [0.065, 0.228, 0.031, 0.289, 0.056, 0.155, 0.298, 0.149, 0.311, 0.156]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.1851198524236679
[2m[36m(func pid=104772)[0m mae:  0.10980025678873062
[2m[36m(func pid=104772)[0m rmse_per_class: [0.079, 0.297, 0.03, 0.316, 0.056, 0.229, 0.283, 0.15, 0.317, 0.092]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.8152 | Steps: 4 | Val loss: 0.6292 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3528 | Steps: 4 | Val loss: 0.2797 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3697 | Steps: 4 | Val loss: 0.3278 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=106005)[0m rmse: 0.17999549210071564
[2m[36m(func pid=106005)[0m mae:  0.13228407502174377
[2m[36m(func pid=106005)[0m rmse_per_class: [0.114, 0.261, 0.1, 0.337, 0.109, 0.19, 0.295, 0.139, 0.144, 0.111]
[2m[36m(func pid=106005)[0m 
== Status ==
Current time: 2024-01-07 17:53:22 (running for 00:37:38.67)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.367 |  0.148 |                   71 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.411 |  0.174 |                   28 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.526 |  0.185 |                   24 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.815 |  0.18  |                   20 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14821745455265045
[2m[36m(func pid=93214)[0m mae:  0.10307755321264267
[2m[36m(func pid=93214)[0m rmse_per_class: [0.094, 0.222, 0.034, 0.287, 0.054, 0.154, 0.255, 0.113, 0.144, 0.124]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4462 | Steps: 4 | Val loss: 0.4525 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=103512)[0m rmse: 0.17686593532562256
[2m[36m(func pid=103512)[0m mae:  0.11398236453533173
[2m[36m(func pid=103512)[0m rmse_per_class: [0.065, 0.231, 0.047, 0.285, 0.056, 0.158, 0.295, 0.149, 0.332, 0.149]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.18722420930862427
[2m[36m(func pid=104772)[0m mae:  0.11371481418609619
[2m[36m(func pid=104772)[0m rmse_per_class: [0.08, 0.222, 0.029, 0.301, 0.056, 0.298, 0.327, 0.142, 0.32, 0.096]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.8114 | Steps: 4 | Val loss: 0.6266 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3645 | Steps: 4 | Val loss: 0.2789 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3673 | Steps: 4 | Val loss: 0.3259 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 17:53:27 (running for 00:37:43.90)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.353 |  0.148 |                   72 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.37  |  0.177 |                   29 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.446 |  0.187 |                   25 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.811 |  0.18  |                   21 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=106005)[0m rmse: 0.1799376904964447
[2m[36m(func pid=106005)[0m mae:  0.13226279616355896
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.262, 0.099, 0.337, 0.11, 0.189, 0.295, 0.14, 0.143, 0.11]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4868 | Steps: 4 | Val loss: 0.4461 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=93214)[0m rmse: 0.14883403480052948
[2m[36m(func pid=93214)[0m mae:  0.10371671617031097
[2m[36m(func pid=93214)[0m rmse_per_class: [0.096, 0.221, 0.036, 0.284, 0.054, 0.155, 0.259, 0.113, 0.146, 0.125]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.17791005969047546
[2m[36m(func pid=103512)[0m mae:  0.11242695897817612
[2m[36m(func pid=103512)[0m rmse_per_class: [0.066, 0.234, 0.068, 0.285, 0.055, 0.16, 0.286, 0.152, 0.32, 0.152]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.18563643097877502
[2m[36m(func pid=104772)[0m mae:  0.11303676664829254
[2m[36m(func pid=104772)[0m rmse_per_class: [0.079, 0.223, 0.033, 0.314, 0.055, 0.314, 0.33, 0.141, 0.263, 0.104]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.8075 | Steps: 4 | Val loss: 0.6267 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3461 | Steps: 4 | Val loss: 0.2788 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3981 | Steps: 4 | Val loss: 0.3272 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 17:53:32 (running for 00:37:49.10)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.364 |  0.149 |                   73 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.367 |  0.178 |                   30 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.487 |  0.186 |                   26 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.807 |  0.18  |                   22 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=106005)[0m rmse: 0.18013069033622742
[2m[36m(func pid=106005)[0m mae:  0.13238711655139923
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.262, 0.1, 0.337, 0.11, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4255 | Steps: 4 | Val loss: 0.3983 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=93214)[0m rmse: 0.14898255467414856
[2m[36m(func pid=93214)[0m mae:  0.10387493669986725
[2m[36m(func pid=93214)[0m rmse_per_class: [0.094, 0.22, 0.037, 0.284, 0.054, 0.154, 0.261, 0.113, 0.147, 0.126]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.1759437471628189
[2m[36m(func pid=103512)[0m mae:  0.1085696816444397
[2m[36m(func pid=103512)[0m rmse_per_class: [0.067, 0.235, 0.103, 0.283, 0.055, 0.161, 0.267, 0.166, 0.268, 0.154]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.18510675430297852
[2m[36m(func pid=104772)[0m mae:  0.10749795287847519
[2m[36m(func pid=104772)[0m rmse_per_class: [0.08, 0.241, 0.041, 0.319, 0.057, 0.268, 0.299, 0.2, 0.222, 0.125]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.8041 | Steps: 4 | Val loss: 0.6237 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3581 | Steps: 4 | Val loss: 0.2785 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3433 | Steps: 4 | Val loss: 0.3293 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 17:53:38 (running for 00:37:54.48)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.149 |                   74 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.398 |  0.176 |                   31 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.426 |  0.185 |                   27 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.804 |  0.18  |                   23 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=106005)[0m rmse: 0.18004710972309113
[2m[36m(func pid=106005)[0m mae:  0.13231074810028076
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.262, 0.1, 0.337, 0.11, 0.189, 0.295, 0.14, 0.143, 0.11]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.14893664419651031
[2m[36m(func pid=93214)[0m mae:  0.10355156660079956
[2m[36m(func pid=93214)[0m rmse_per_class: [0.091, 0.221, 0.037, 0.284, 0.054, 0.154, 0.26, 0.116, 0.149, 0.123]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4226 | Steps: 4 | Val loss: 0.4073 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=103512)[0m rmse: 0.17206428945064545
[2m[36m(func pid=103512)[0m mae:  0.1038641482591629
[2m[36m(func pid=103512)[0m rmse_per_class: [0.068, 0.234, 0.143, 0.281, 0.061, 0.162, 0.245, 0.157, 0.218, 0.154]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.18640294671058655
[2m[36m(func pid=104772)[0m mae:  0.1041981428861618
[2m[36m(func pid=104772)[0m rmse_per_class: [0.096, 0.265, 0.061, 0.293, 0.091, 0.189, 0.26, 0.277, 0.176, 0.157]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.3572 | Steps: 4 | Val loss: 0.2772 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.7952 | Steps: 4 | Val loss: 0.6197 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3677 | Steps: 4 | Val loss: 0.3319 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 17:53:43 (running for 00:37:59.98)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.358 |  0.149 |                   75 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.343 |  0.172 |                   32 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.423 |  0.186 |                   28 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.795 |  0.18  |                   24 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4168 | Steps: 4 | Val loss: 0.4568 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=106005)[0m rmse: 0.1799415647983551
[2m[36m(func pid=106005)[0m mae:  0.13226105272769928
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.262, 0.098, 0.337, 0.11, 0.189, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.148674875497818
[2m[36m(func pid=93214)[0m mae:  0.10322214663028717
[2m[36m(func pid=93214)[0m rmse_per_class: [0.088, 0.222, 0.039, 0.282, 0.054, 0.155, 0.26, 0.118, 0.149, 0.12]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.1693047732114792
[2m[36m(func pid=103512)[0m mae:  0.10068397223949432
[2m[36m(func pid=103512)[0m rmse_per_class: [0.07, 0.234, 0.18, 0.281, 0.081, 0.164, 0.226, 0.135, 0.174, 0.148]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.1949436366558075
[2m[36m(func pid=104772)[0m mae:  0.11107778549194336
[2m[36m(func pid=104772)[0m rmse_per_class: [0.136, 0.27, 0.072, 0.313, 0.105, 0.187, 0.303, 0.253, 0.144, 0.168]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.7960 | Steps: 4 | Val loss: 0.6164 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.3352 | Steps: 4 | Val loss: 0.2758 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3893 | Steps: 4 | Val loss: 0.3315 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 17:53:48 (running for 00:38:05.39)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.335 |  0.148 |                   77 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.368 |  0.169 |                   33 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.417 |  0.195 |                   29 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.795 |  0.18  |                   24 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14849694073200226
[2m[36m(func pid=93214)[0m mae:  0.10299301147460938
[2m[36m(func pid=93214)[0m rmse_per_class: [0.085, 0.221, 0.042, 0.281, 0.054, 0.154, 0.26, 0.119, 0.15, 0.118]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4435 | Steps: 4 | Val loss: 0.4639 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=106005)[0m rmse: 0.17990580201148987
[2m[36m(func pid=106005)[0m mae:  0.1322072446346283
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.262, 0.099, 0.337, 0.109, 0.19, 0.295, 0.14, 0.144, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.16651983559131622
[2m[36m(func pid=103512)[0m mae:  0.09758105129003525
[2m[36m(func pid=103512)[0m rmse_per_class: [0.071, 0.235, 0.186, 0.284, 0.096, 0.166, 0.219, 0.123, 0.148, 0.139]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.19930937886238098
[2m[36m(func pid=104772)[0m mae:  0.11403165012598038
[2m[36m(func pid=104772)[0m rmse_per_class: [0.207, 0.258, 0.079, 0.326, 0.114, 0.191, 0.262, 0.222, 0.14, 0.194]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.3572 | Steps: 4 | Val loss: 0.2744 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.7889 | Steps: 4 | Val loss: 0.6125 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4015 | Steps: 4 | Val loss: 0.3251 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 17:53:54 (running for 00:38:10.73)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.357 |  0.148 |                   78 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.389 |  0.167 |                   34 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.444 |  0.199 |                   30 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.796 |  0.18  |                   25 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.1479855179786682
[2m[36m(func pid=93214)[0m mae:  0.10251567512750626
[2m[36m(func pid=93214)[0m rmse_per_class: [0.086, 0.223, 0.043, 0.278, 0.053, 0.153, 0.262, 0.12, 0.149, 0.113]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17969904839992523
[2m[36m(func pid=106005)[0m mae:  0.1320565640926361
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.337, 0.108, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3869 | Steps: 4 | Val loss: 0.4340 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=103512)[0m rmse: 0.1653473973274231
[2m[36m(func pid=103512)[0m mae:  0.09562395513057709
[2m[36m(func pid=103512)[0m rmse_per_class: [0.07, 0.235, 0.174, 0.282, 0.121, 0.166, 0.229, 0.114, 0.131, 0.132]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.20153804123401642
[2m[36m(func pid=104772)[0m mae:  0.1131080836057663
[2m[36m(func pid=104772)[0m rmse_per_class: [0.18, 0.237, 0.104, 0.322, 0.136, 0.188, 0.264, 0.203, 0.149, 0.232]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.3427 | Steps: 4 | Val loss: 0.2761 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.7863 | Steps: 4 | Val loss: 0.6097 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3775 | Steps: 4 | Val loss: 0.3228 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=93214)[0m rmse: 0.14957819879055023== Status ==
Current time: 2024-01-07 17:53:59 (running for 00:38:16.13)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.343 |  0.15  |                   79 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.402 |  0.165 |                   35 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.387 |  0.202 |                   31 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.789 |  0.18  |                   26 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)



[2m[36m(func pid=93214)[0m mae:  0.10349154472351074
[2m[36m(func pid=93214)[0m rmse_per_class: [0.085, 0.225, 0.046, 0.282, 0.053, 0.154, 0.262, 0.123, 0.152, 0.115]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3998 | Steps: 4 | Val loss: 0.4557 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=106005)[0m rmse: 0.17955580353736877
[2m[36m(func pid=106005)[0m mae:  0.13187755644321442
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.336, 0.108, 0.19, 0.295, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.16784711182117462
[2m[36m(func pid=103512)[0m mae:  0.0965171605348587
[2m[36m(func pid=103512)[0m rmse_per_class: [0.07, 0.234, 0.164, 0.285, 0.15, 0.17, 0.25, 0.111, 0.127, 0.118]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.1988985538482666
[2m[36m(func pid=104772)[0m mae:  0.11288018524646759
[2m[36m(func pid=104772)[0m rmse_per_class: [0.091, 0.268, 0.114, 0.308, 0.136, 0.211, 0.312, 0.167, 0.157, 0.225]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.3379 | Steps: 4 | Val loss: 0.2742 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.7818 | Steps: 4 | Val loss: 0.6071 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3821 | Steps: 4 | Val loss: 0.3181 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 17:54:05 (running for 00:38:21.57)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.338 |  0.149 |                   80 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.377 |  0.168 |                   36 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.4   |  0.199 |                   32 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.786 |  0.18  |                   27 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14882048964500427
[2m[36m(func pid=93214)[0m mae:  0.1029861569404602
[2m[36m(func pid=93214)[0m rmse_per_class: [0.082, 0.223, 0.05, 0.278, 0.053, 0.153, 0.262, 0.121, 0.153, 0.111]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4411 | Steps: 4 | Val loss: 0.4871 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=106005)[0m rmse: 0.17960278689861298
[2m[36m(func pid=106005)[0m mae:  0.13192255795001984
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.336, 0.109, 0.19, 0.295, 0.139, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.17013540863990784
[2m[36m(func pid=103512)[0m mae:  0.09777979552745819
[2m[36m(func pid=103512)[0m rmse_per_class: [0.069, 0.231, 0.144, 0.288, 0.169, 0.173, 0.273, 0.115, 0.126, 0.113]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.2020622193813324
[2m[36m(func pid=104772)[0m mae:  0.1161864846944809
[2m[36m(func pid=104772)[0m rmse_per_class: [0.093, 0.276, 0.13, 0.308, 0.13, 0.281, 0.326, 0.136, 0.17, 0.171]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.3381 | Steps: 4 | Val loss: 0.2727 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.7754 | Steps: 4 | Val loss: 0.6036 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3827 | Steps: 4 | Val loss: 0.3157 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 17:54:10 (running for 00:38:26.73)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.338 |  0.148 |                   81 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.382 |  0.17  |                   37 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.441 |  0.202 |                   33 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.782 |  0.18  |                   28 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14754188060760498
[2m[36m(func pid=93214)[0m mae:  0.10192115604877472
[2m[36m(func pid=93214)[0m rmse_per_class: [0.08, 0.222, 0.051, 0.274, 0.053, 0.152, 0.264, 0.121, 0.151, 0.109]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3969 | Steps: 4 | Val loss: 0.4851 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=106005)[0m rmse: 0.1797347366809845
[2m[36m(func pid=106005)[0m mae:  0.13203470408916473
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.336, 0.109, 0.19, 0.295, 0.14, 0.143, 0.11]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.1714312583208084
[2m[36m(func pid=103512)[0m mae:  0.09905397891998291
[2m[36m(func pid=103512)[0m rmse_per_class: [0.069, 0.23, 0.13, 0.29, 0.181, 0.175, 0.29, 0.118, 0.126, 0.105]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.20168641209602356
[2m[36m(func pid=104772)[0m mae:  0.11714676767587662
[2m[36m(func pid=104772)[0m rmse_per_class: [0.104, 0.249, 0.129, 0.311, 0.102, 0.313, 0.311, 0.132, 0.228, 0.139]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.3293 | Steps: 4 | Val loss: 0.2750 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.7743 | Steps: 4 | Val loss: 0.6001 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3579 | Steps: 4 | Val loss: 0.3062 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 17:54:15 (running for 00:38:32.02)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.329 |  0.15  |                   82 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.383 |  0.171 |                   38 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.397 |  0.202 |                   34 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.775 |  0.18  |                   29 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.1495582014322281
[2m[36m(func pid=93214)[0m mae:  0.1035618931055069
[2m[36m(func pid=93214)[0m rmse_per_class: [0.082, 0.224, 0.054, 0.28, 0.053, 0.152, 0.265, 0.12, 0.156, 0.11]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3916 | Steps: 4 | Val loss: 0.4619 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=106005)[0m rmse: 0.17957119643688202
[2m[36m(func pid=106005)[0m mae:  0.13187065720558167
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.099, 0.336, 0.109, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.1666467934846878
[2m[36m(func pid=103512)[0m mae:  0.09618481248617172
[2m[36m(func pid=103512)[0m rmse_per_class: [0.068, 0.225, 0.099, 0.287, 0.19, 0.17, 0.284, 0.118, 0.127, 0.099]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.1965772956609726
[2m[36m(func pid=104772)[0m mae:  0.11259639263153076
[2m[36m(func pid=104772)[0m rmse_per_class: [0.105, 0.238, 0.113, 0.314, 0.088, 0.249, 0.281, 0.132, 0.307, 0.139]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.3288 | Steps: 4 | Val loss: 0.2741 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.7694 | Steps: 4 | Val loss: 0.5974 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3391 | Steps: 4 | Val loss: 0.2985 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 17:54:20 (running for 00:38:37.37)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.329 |  0.149 |                   83 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.358 |  0.167 |                   39 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.392 |  0.197 |                   35 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.774 |  0.18  |                   30 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14910659193992615
[2m[36m(func pid=93214)[0m mae:  0.10316147655248642
[2m[36m(func pid=93214)[0m rmse_per_class: [0.08, 0.222, 0.056, 0.278, 0.053, 0.153, 0.266, 0.12, 0.156, 0.108]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4090 | Steps: 4 | Val loss: 0.4640 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=106005)[0m rmse: 0.1797581911087036
[2m[36m(func pid=106005)[0m mae:  0.1320069134235382
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.26, 0.1, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.16158214211463928
[2m[36m(func pid=103512)[0m mae:  0.093229278922081
[2m[36m(func pid=103512)[0m rmse_per_class: [0.07, 0.222, 0.083, 0.282, 0.191, 0.163, 0.265, 0.117, 0.127, 0.095]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.1947096884250641
[2m[36m(func pid=104772)[0m mae:  0.11078544706106186
[2m[36m(func pid=104772)[0m rmse_per_class: [0.101, 0.244, 0.128, 0.325, 0.079, 0.186, 0.313, 0.128, 0.319, 0.123]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.3328 | Steps: 4 | Val loss: 0.2721 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.7674 | Steps: 4 | Val loss: 0.5950 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3683 | Steps: 4 | Val loss: 0.2944 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 17:54:26 (running for 00:38:42.77)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.333 |  0.148 |                   84 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.339 |  0.162 |                   40 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.409 |  0.195 |                   36 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.769 |  0.18  |                   31 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.1477392613887787
[2m[36m(func pid=93214)[0m mae:  0.10205187648534775
[2m[36m(func pid=93214)[0m rmse_per_class: [0.077, 0.221, 0.055, 0.271, 0.053, 0.154, 0.266, 0.12, 0.153, 0.107]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4047 | Steps: 4 | Val loss: 0.4485 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=106005)[0m rmse: 0.17970223724842072
[2m[36m(func pid=106005)[0m mae:  0.1320119947195053
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.261, 0.098, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.1574574112892151
[2m[36m(func pid=103512)[0m mae:  0.0910954400897026
[2m[36m(func pid=103512)[0m rmse_per_class: [0.071, 0.221, 0.073, 0.279, 0.184, 0.16, 0.246, 0.117, 0.127, 0.096]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.19824066758155823
[2m[36m(func pid=104772)[0m mae:  0.11036497354507446
[2m[36m(func pid=104772)[0m rmse_per_class: [0.094, 0.261, 0.163, 0.321, 0.075, 0.191, 0.341, 0.136, 0.274, 0.126]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.3250 | Steps: 4 | Val loss: 0.2722 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.7669 | Steps: 4 | Val loss: 0.5919 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3725 | Steps: 4 | Val loss: 0.2913 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 17:54:31 (running for 00:38:48.11)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.325 |  0.148 |                   85 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.368 |  0.157 |                   41 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.405 |  0.198 |                   37 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.767 |  0.18  |                   32 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14766250550746918
[2m[36m(func pid=93214)[0m mae:  0.10190049558877945
[2m[36m(func pid=93214)[0m rmse_per_class: [0.074, 0.221, 0.057, 0.272, 0.054, 0.153, 0.264, 0.12, 0.154, 0.106]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4020 | Steps: 4 | Val loss: 0.4467 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=106005)[0m rmse: 0.17962902784347534
[2m[36m(func pid=106005)[0m mae:  0.1319466382265091
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.098, 0.337, 0.11, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.153049036860466
[2m[36m(func pid=103512)[0m mae:  0.08911217749118805
[2m[36m(func pid=103512)[0m rmse_per_class: [0.072, 0.223, 0.062, 0.277, 0.169, 0.159, 0.229, 0.115, 0.127, 0.096]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.2065819501876831
[2m[36m(func pid=104772)[0m mae:  0.11557184159755707
[2m[36m(func pid=104772)[0m rmse_per_class: [0.282, 0.27, 0.175, 0.312, 0.065, 0.191, 0.278, 0.186, 0.19, 0.116]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.3262 | Steps: 4 | Val loss: 0.2716 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.7587 | Steps: 4 | Val loss: 0.5881 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3555 | Steps: 4 | Val loss: 0.2937 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 17:54:37 (running for 00:38:53.51)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.147 |                   86 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.373 |  0.153 |                   42 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.402 |  0.207 |                   38 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.767 |  0.18  |                   33 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14719030261039734
[2m[36m(func pid=93214)[0m mae:  0.10127420723438263
[2m[36m(func pid=93214)[0m rmse_per_class: [0.073, 0.221, 0.058, 0.27, 0.055, 0.153, 0.262, 0.12, 0.155, 0.106]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4307 | Steps: 4 | Val loss: 0.4446 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=103512)[0m rmse: 0.15183502435684204
[2m[36m(func pid=103512)[0m mae:  0.08968321979045868
[2m[36m(func pid=103512)[0m rmse_per_class: [0.073, 0.226, 0.056, 0.276, 0.171, 0.163, 0.218, 0.113, 0.126, 0.095]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.1794409453868866
[2m[36m(func pid=106005)[0m mae:  0.13180330395698547
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.26, 0.098, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.21010713279247284
[2m[36m(func pid=104772)[0m mae:  0.12354938685894012
[2m[36m(func pid=104772)[0m rmse_per_class: [0.411, 0.268, 0.119, 0.294, 0.059, 0.189, 0.293, 0.206, 0.148, 0.116]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.3188 | Steps: 4 | Val loss: 0.2719 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3481 | Steps: 4 | Val loss: 0.2978 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.7549 | Steps: 4 | Val loss: 0.5853 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 17:54:42 (running for 00:38:58.80)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.319 |  0.147 |                   87 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.355 |  0.152 |                   43 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.431 |  0.21  |                   39 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.759 |  0.179 |                   34 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14717663824558258
[2m[36m(func pid=93214)[0m mae:  0.10113833844661713
[2m[36m(func pid=93214)[0m rmse_per_class: [0.072, 0.221, 0.061, 0.273, 0.056, 0.153, 0.259, 0.12, 0.156, 0.1]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4174 | Steps: 4 | Val loss: 0.4051 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=103512)[0m rmse: 0.15080851316452026
[2m[36m(func pid=103512)[0m mae:  0.09012430906295776
[2m[36m(func pid=103512)[0m rmse_per_class: [0.074, 0.232, 0.045, 0.272, 0.156, 0.175, 0.224, 0.112, 0.125, 0.093]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17935241758823395
[2m[36m(func pid=106005)[0m mae:  0.13175800442695618
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.26, 0.097, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.19571903347969055
[2m[36m(func pid=104772)[0m mae:  0.1084091067314148
[2m[36m(func pid=104772)[0m rmse_per_class: [0.256, 0.253, 0.115, 0.293, 0.059, 0.221, 0.295, 0.178, 0.145, 0.143]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.3351 | Steps: 4 | Val loss: 0.2719 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3659 | Steps: 4 | Val loss: 0.3017 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.7539 | Steps: 4 | Val loss: 0.5824 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 17:54:47 (running for 00:39:04.03)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.335 |  0.147 |                   88 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.348 |  0.151 |                   44 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.417 |  0.196 |                   40 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.755 |  0.179 |                   35 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14702877402305603
[2m[36m(func pid=93214)[0m mae:  0.10080359131097794
[2m[36m(func pid=93214)[0m rmse_per_class: [0.072, 0.219, 0.065, 0.273, 0.057, 0.153, 0.258, 0.119, 0.152, 0.101]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3609 | Steps: 4 | Val loss: 0.3835 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=103512)[0m rmse: 0.15215036273002625
[2m[36m(func pid=103512)[0m mae:  0.09172612428665161
[2m[36m(func pid=103512)[0m rmse_per_class: [0.076, 0.236, 0.042, 0.272, 0.142, 0.182, 0.238, 0.11, 0.127, 0.096]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.1794232279062271
[2m[36m(func pid=106005)[0m mae:  0.13175496459007263
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.26, 0.097, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.18003502488136292
[2m[36m(func pid=104772)[0m mae:  0.09865796566009521
[2m[36m(func pid=104772)[0m rmse_per_class: [0.095, 0.261, 0.095, 0.288, 0.056, 0.277, 0.279, 0.13, 0.144, 0.175]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.3341 | Steps: 4 | Val loss: 0.2737 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3401 | Steps: 4 | Val loss: 0.3040 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.7502 | Steps: 4 | Val loss: 0.5801 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
== Status ==
Current time: 2024-01-07 17:54:52 (running for 00:39:09.24)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.334 |  0.148 |                   89 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.366 |  0.152 |                   45 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.361 |  0.18  |                   41 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.754 |  0.179 |                   36 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14820243418216705
[2m[36m(func pid=93214)[0m mae:  0.10178528726100922
[2m[36m(func pid=93214)[0m rmse_per_class: [0.072, 0.219, 0.072, 0.277, 0.06, 0.153, 0.258, 0.116, 0.155, 0.101]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3585 | Steps: 4 | Val loss: 0.4181 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=103512)[0m rmse: 0.15217848122119904
[2m[36m(func pid=103512)[0m mae:  0.09275422990322113
[2m[36m(func pid=103512)[0m rmse_per_class: [0.073, 0.236, 0.04, 0.269, 0.124, 0.183, 0.252, 0.111, 0.136, 0.098]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17957128584384918
[2m[36m(func pid=106005)[0m mae:  0.13185812532901764
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.098, 0.337, 0.11, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.17447564005851746
[2m[36m(func pid=104772)[0m mae:  0.09834916144609451
[2m[36m(func pid=104772)[0m rmse_per_class: [0.101, 0.283, 0.076, 0.293, 0.055, 0.255, 0.259, 0.122, 0.14, 0.161]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.3410 | Steps: 4 | Val loss: 0.2736 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3407 | Steps: 4 | Val loss: 0.3094 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.7467 | Steps: 4 | Val loss: 0.5763 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=93214)[0m rmse: 0.14804457128047943
[2m[36m(func pid=93214)[0m mae:  0.10168151557445526
[2m[36m(func pid=93214)[0m rmse_per_class: [0.074, 0.218, 0.073, 0.274, 0.063, 0.154, 0.258, 0.113, 0.154, 0.1]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4483 | Steps: 4 | Val loss: 0.4385 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 17:54:58 (running for 00:39:14.59)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.341 |  0.148 |                   90 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.34  |  0.152 |                   46 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.358 |  0.174 |                   42 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.75  |  0.18  |                   37 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103512)[0m rmse: 0.15443459153175354
[2m[36m(func pid=103512)[0m mae:  0.0949014276266098
[2m[36m(func pid=103512)[0m rmse_per_class: [0.084, 0.234, 0.035, 0.267, 0.107, 0.18, 0.27, 0.114, 0.152, 0.103]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17956945300102234
[2m[36m(func pid=106005)[0m mae:  0.13187649846076965
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.26, 0.098, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.1741851419210434
[2m[36m(func pid=104772)[0m mae:  0.09963108599185944
[2m[36m(func pid=104772)[0m rmse_per_class: [0.104, 0.299, 0.064, 0.298, 0.056, 0.206, 0.258, 0.129, 0.143, 0.186]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.3237 | Steps: 4 | Val loss: 0.2728 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3204 | Steps: 4 | Val loss: 0.3101 | Batch size: 32 | lr: 0.01 | Duration: 3.17s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.7450 | Steps: 4 | Val loss: 0.5743 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4120 | Steps: 4 | Val loss: 0.4018 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 17:55:03 (running for 00:39:20.08)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.324 |  0.147 |                   91 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.341 |  0.154 |                   47 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.448 |  0.174 |                   43 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.747 |  0.18  |                   38 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14734826982021332
[2m[36m(func pid=93214)[0m mae:  0.1008593812584877
[2m[36m(func pid=93214)[0m rmse_per_class: [0.07, 0.218, 0.075, 0.273, 0.064, 0.155, 0.252, 0.113, 0.155, 0.099]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.15706834197044373
[2m[36m(func pid=103512)[0m mae:  0.09746602177619934
[2m[36m(func pid=103512)[0m rmse_per_class: [0.087, 0.225, 0.031, 0.27, 0.098, 0.184, 0.282, 0.117, 0.174, 0.103]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17964783310890198
[2m[36m(func pid=106005)[0m mae:  0.1319391429424286
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.26, 0.098, 0.337, 0.109, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.18002626299858093
[2m[36m(func pid=104772)[0m mae:  0.09990967810153961
[2m[36m(func pid=104772)[0m rmse_per_class: [0.097, 0.282, 0.076, 0.298, 0.059, 0.193, 0.268, 0.126, 0.167, 0.233]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.3155 | Steps: 4 | Val loss: 0.2727 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3460 | Steps: 4 | Val loss: 0.3111 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.7367 | Steps: 4 | Val loss: 0.5715 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 17:55:08 (running for 00:39:25.30)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.315 |  0.147 |                   92 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.32  |  0.157 |                   48 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.412 |  0.18  |                   44 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.745 |  0.18  |                   39 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14679376780986786
[2m[36m(func pid=93214)[0m mae:  0.10032160580158234
[2m[36m(func pid=93214)[0m rmse_per_class: [0.071, 0.219, 0.078, 0.271, 0.065, 0.155, 0.25, 0.111, 0.154, 0.094]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3164 | Steps: 4 | Val loss: 0.3998 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=103512)[0m rmse: 0.16017264127731323
[2m[36m(func pid=103512)[0m mae:  0.09980474412441254
[2m[36m(func pid=103512)[0m rmse_per_class: [0.085, 0.222, 0.028, 0.271, 0.079, 0.179, 0.285, 0.128, 0.212, 0.112]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17960551381111145
[2m[36m(func pid=106005)[0m mae:  0.13189703226089478
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.26, 0.099, 0.337, 0.109, 0.19, 0.294, 0.139, 0.143, 0.11]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.18847838044166565
[2m[36m(func pid=104772)[0m mae:  0.10209216177463531
[2m[36m(func pid=104772)[0m rmse_per_class: [0.087, 0.265, 0.101, 0.299, 0.071, 0.197, 0.266, 0.132, 0.236, 0.23]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.3219 | Steps: 4 | Val loss: 0.2729 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3424 | Steps: 4 | Val loss: 0.3189 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.7342 | Steps: 4 | Val loss: 0.5692 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 17:55:14 (running for 00:39:30.56)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.322 |  0.147 |                   93 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.346 |  0.16  |                   49 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.316 |  0.188 |                   45 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.737 |  0.18  |                   40 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.1465281993150711
[2m[36m(func pid=93214)[0m mae:  0.09969855099916458
[2m[36m(func pid=93214)[0m rmse_per_class: [0.071, 0.22, 0.078, 0.27, 0.069, 0.155, 0.248, 0.111, 0.151, 0.093]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3472 | Steps: 4 | Val loss: 0.4528 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=103512)[0m rmse: 0.16557081043720245
[2m[36m(func pid=103512)[0m mae:  0.10409005731344223
[2m[36m(func pid=103512)[0m rmse_per_class: [0.083, 0.222, 0.027, 0.281, 0.076, 0.172, 0.288, 0.142, 0.246, 0.12]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17958799004554749
[2m[36m(func pid=106005)[0m mae:  0.13188719749450684
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.26, 0.099, 0.337, 0.109, 0.19, 0.294, 0.139, 0.143, 0.11]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.20812669396400452
[2m[36m(func pid=104772)[0m mae:  0.11449875682592392
[2m[36m(func pid=104772)[0m rmse_per_class: [0.151, 0.272, 0.109, 0.306, 0.095, 0.205, 0.276, 0.151, 0.329, 0.186]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.3231 | Steps: 4 | Val loss: 0.2736 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3248 | Steps: 4 | Val loss: 0.3172 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.7291 | Steps: 4 | Val loss: 0.5662 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 17:55:19 (running for 00:39:35.81)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.323 |  0.147 |                   94 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.342 |  0.166 |                   50 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.347 |  0.208 |                   46 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.734 |  0.18  |                   41 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14710105955600739
[2m[36m(func pid=93214)[0m mae:  0.10023319721221924
[2m[36m(func pid=93214)[0m rmse_per_class: [0.069, 0.22, 0.073, 0.276, 0.077, 0.155, 0.245, 0.111, 0.153, 0.093]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3448 | Steps: 4 | Val loss: 0.4973 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=103512)[0m rmse: 0.16529276967048645
[2m[36m(func pid=103512)[0m mae:  0.10410048067569733
[2m[36m(func pid=103512)[0m rmse_per_class: [0.083, 0.222, 0.027, 0.277, 0.063, 0.165, 0.286, 0.147, 0.263, 0.121]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17952470481395721
[2m[36m(func pid=106005)[0m mae:  0.1318105310201645
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.098, 0.337, 0.109, 0.19, 0.294, 0.141, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.2174314707517624
[2m[36m(func pid=104772)[0m mae:  0.12411867082118988
[2m[36m(func pid=104772)[0m rmse_per_class: [0.258, 0.29, 0.096, 0.302, 0.108, 0.205, 0.28, 0.162, 0.333, 0.139]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.3258 | Steps: 4 | Val loss: 0.2717 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3255 | Steps: 4 | Val loss: 0.3257 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.7306 | Steps: 4 | Val loss: 0.5632 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
== Status ==
Current time: 2024-01-07 17:55:24 (running for 00:39:41.05)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.146 |                   95 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.325 |  0.165 |                   51 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.345 |  0.217 |                   47 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.729 |  0.18  |                   42 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.1455414593219757
[2m[36m(func pid=93214)[0m mae:  0.09890402853488922
[2m[36m(func pid=93214)[0m rmse_per_class: [0.068, 0.219, 0.068, 0.273, 0.082, 0.155, 0.242, 0.11, 0.149, 0.09]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4171 | Steps: 4 | Val loss: 0.5022 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=103512)[0m rmse: 0.17014047503471375
[2m[36m(func pid=103512)[0m mae:  0.1071903258562088
[2m[36m(func pid=103512)[0m rmse_per_class: [0.086, 0.227, 0.027, 0.286, 0.057, 0.161, 0.279, 0.155, 0.282, 0.143]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17948907613754272
[2m[36m(func pid=106005)[0m mae:  0.1318194568157196
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.098, 0.337, 0.109, 0.189, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.21341390907764435
[2m[36m(func pid=104772)[0m mae:  0.12346752732992172
[2m[36m(func pid=104772)[0m rmse_per_class: [0.281, 0.292, 0.077, 0.299, 0.108, 0.197, 0.272, 0.166, 0.321, 0.121]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.3279 | Steps: 4 | Val loss: 0.2716 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3209 | Steps: 4 | Val loss: 0.3245 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.7262 | Steps: 4 | Val loss: 0.5597 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3801 | Steps: 4 | Val loss: 0.4367 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 17:55:30 (running for 00:39:46.67)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.328 |  0.146 |                   96 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.326 |  0.17  |                   52 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.417 |  0.213 |                   48 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.731 |  0.179 |                   43 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14561882615089417
[2m[36m(func pid=93214)[0m mae:  0.09856723994016647
[2m[36m(func pid=93214)[0m rmse_per_class: [0.067, 0.218, 0.071, 0.273, 0.084, 0.156, 0.24, 0.11, 0.148, 0.091]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.17064671218395233
[2m[36m(func pid=103512)[0m mae:  0.1067405492067337
[2m[36m(func pid=103512)[0m rmse_per_class: [0.075, 0.23, 0.027, 0.284, 0.055, 0.16, 0.27, 0.165, 0.273, 0.169]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17946116626262665
[2m[36m(func pid=106005)[0m mae:  0.131837397813797
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.097, 0.337, 0.109, 0.189, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.19848516583442688
[2m[36m(func pid=104772)[0m mae:  0.11122052371501923
[2m[36m(func pid=104772)[0m rmse_per_class: [0.222, 0.284, 0.076, 0.295, 0.121, 0.205, 0.258, 0.156, 0.253, 0.115]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.3238 | Steps: 4 | Val loss: 0.2728 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3252 | Steps: 4 | Val loss: 0.3204 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.7227 | Steps: 4 | Val loss: 0.5571 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 17:55:35 (running for 00:39:51.87)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.324 |  0.147 |                   97 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.321 |  0.171 |                   53 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.38  |  0.198 |                   49 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.726 |  0.179 |                   44 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14659301936626434
[2m[36m(func pid=93214)[0m mae:  0.09940031170845032
[2m[36m(func pid=93214)[0m rmse_per_class: [0.067, 0.22, 0.069, 0.28, 0.085, 0.155, 0.236, 0.11, 0.151, 0.093]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.17000368237495422
[2m[36m(func pid=103512)[0m mae:  0.10548970848321915
[2m[36m(func pid=103512)[0m rmse_per_class: [0.074, 0.232, 0.027, 0.286, 0.057, 0.163, 0.256, 0.154, 0.258, 0.193]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3654 | Steps: 4 | Val loss: 0.4006 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=106005)[0m rmse: 0.1794203370809555
[2m[36m(func pid=106005)[0m mae:  0.13180024921894073
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.337, 0.109, 0.189, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.18254297971725464
[2m[36m(func pid=104772)[0m mae:  0.10152701288461685
[2m[36m(func pid=104772)[0m rmse_per_class: [0.115, 0.27, 0.079, 0.293, 0.125, 0.234, 0.249, 0.143, 0.192, 0.125]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.3226 | Steps: 4 | Val loss: 0.2728 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3368 | Steps: 4 | Val loss: 0.3178 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.7179 | Steps: 4 | Val loss: 0.5554 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 17:55:40 (running for 00:39:57.24)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.323 |  0.147 |                   98 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.325 |  0.17  |                   54 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.365 |  0.183 |                   50 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.723 |  0.179 |                   45 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14669902622699738
[2m[36m(func pid=93214)[0m mae:  0.09929775446653366
[2m[36m(func pid=93214)[0m rmse_per_class: [0.067, 0.218, 0.069, 0.28, 0.088, 0.156, 0.235, 0.109, 0.151, 0.094]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.16807302832603455
[2m[36m(func pid=103512)[0m mae:  0.10341618210077286
[2m[36m(func pid=103512)[0m rmse_per_class: [0.072, 0.231, 0.027, 0.285, 0.059, 0.165, 0.242, 0.149, 0.235, 0.215]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3282 | Steps: 4 | Val loss: 0.3968 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=106005)[0m rmse: 0.17934682965278625
[2m[36m(func pid=106005)[0m mae:  0.13174043595790863
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.26, 0.097, 0.337, 0.109, 0.189, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.18029603362083435
[2m[36m(func pid=104772)[0m mae:  0.1014816015958786
[2m[36m(func pid=104772)[0m rmse_per_class: [0.079, 0.268, 0.069, 0.318, 0.129, 0.239, 0.265, 0.131, 0.171, 0.134]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3265 | Steps: 4 | Val loss: 0.3157 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.3342 | Steps: 4 | Val loss: 0.2712 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.7149 | Steps: 4 | Val loss: 0.5529 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 17:55:46 (running for 00:40:02.58)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.334 |  0.145 |                   99 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.337 |  0.168 |                   55 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.328 |  0.18  |                   51 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.718 |  0.179 |                   46 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=93214)[0m rmse: 0.14537343382835388
[2m[36m(func pid=93214)[0m mae:  0.09790149331092834
[2m[36m(func pid=93214)[0m rmse_per_class: [0.067, 0.218, 0.067, 0.279, 0.089, 0.155, 0.232, 0.109, 0.146, 0.092]
[2m[36m(func pid=93214)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.16654840111732483
[2m[36m(func pid=103512)[0m mae:  0.1013048067688942
[2m[36m(func pid=103512)[0m rmse_per_class: [0.074, 0.235, 0.027, 0.287, 0.058, 0.165, 0.231, 0.152, 0.203, 0.232]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3728 | Steps: 4 | Val loss: 0.4050 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=106005)[0m rmse: 0.17947909235954285
[2m[36m(func pid=106005)[0m mae:  0.1318293660879135
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.261, 0.097, 0.337, 0.108, 0.189, 0.294, 0.141, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.1847664713859558
[2m[36m(func pid=104772)[0m mae:  0.10342210531234741
[2m[36m(func pid=104772)[0m rmse_per_class: [0.085, 0.32, 0.058, 0.319, 0.132, 0.219, 0.271, 0.135, 0.168, 0.139]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=93214)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.3263 | Steps: 4 | Val loss: 0.2697 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3035 | Steps: 4 | Val loss: 0.3106 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.7120 | Steps: 4 | Val loss: 0.5500 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 17:55:51 (running for 00:40:08.05)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00017 | RUNNING    | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.334 |  0.145 |                   99 |
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.303 |  0.163 |                   57 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.373 |  0.185 |                   52 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.715 |  0.179 |                   47 |
| train_01e98_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103512)[0m rmse: 0.162966787815094
[2m[36m(func pid=103512)[0m mae:  0.09848983585834503
[2m[36m(func pid=103512)[0m rmse_per_class: [0.071, 0.233, 0.029, 0.282, 0.06, 0.168, 0.224, 0.142, 0.181, 0.239]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=93214)[0m rmse: 0.14399567246437073
[2m[36m(func pid=93214)[0m mae:  0.0964757576584816
[2m[36m(func pid=93214)[0m rmse_per_class: [0.066, 0.217, 0.066, 0.28, 0.087, 0.154, 0.227, 0.109, 0.144, 0.09]
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4309 | Steps: 4 | Val loss: 0.4395 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=106005)[0m rmse: 0.17935124039649963
[2m[36m(func pid=106005)[0m mae:  0.13168369233608246
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.098, 0.337, 0.108, 0.189, 0.293, 0.141, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.1924973428249359
[2m[36m(func pid=104772)[0m mae:  0.1096421480178833
[2m[36m(func pid=104772)[0m rmse_per_class: [0.088, 0.361, 0.053, 0.311, 0.123, 0.211, 0.29, 0.147, 0.174, 0.166]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3134 | Steps: 4 | Val loss: 0.3060 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.7093 | Steps: 4 | Val loss: 0.5479 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=103512)[0m rmse: 0.15938569605350494
[2m[36m(func pid=103512)[0m mae:  0.09578825533390045
[2m[36m(func pid=103512)[0m rmse_per_class: [0.069, 0.229, 0.03, 0.285, 0.06, 0.166, 0.235, 0.131, 0.158, 0.23]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4140 | Steps: 4 | Val loss: 0.4370 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=106005)[0m rmse: 0.17939716577529907
[2m[36m(func pid=106005)[0m mae:  0.1317460834980011
[2m[36m(func pid=106005)[0m rmse_per_class: [0.117, 0.261, 0.097, 0.337, 0.107, 0.189, 0.293, 0.142, 0.143, 0.109]
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2948 | Steps: 4 | Val loss: 0.3035 | Batch size: 32 | lr: 0.01 | Duration: 2.69s
[2m[36m(func pid=104772)[0m rmse: 0.1934371441602707
[2m[36m(func pid=104772)[0m mae:  0.11070679128170013
[2m[36m(func pid=104772)[0m rmse_per_class: [0.079, 0.338, 0.049, 0.306, 0.117, 0.21, 0.3, 0.161, 0.192, 0.182]
== Status ==
Current time: 2024-01-07 17:55:56 (running for 00:40:13.31)
Memory usage on this node: 22.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.313 |  0.159 |                   58 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.431 |  0.192 |                   53 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.712 |  0.179 |                   48 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=117684)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=117684)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=117684)[0m Configuration completed!
[2m[36m(func pid=117684)[0m New optimizer parameters:
[2m[36m(func pid=117684)[0m SGD (
[2m[36m(func pid=117684)[0m Parameter Group 0
[2m[36m(func pid=117684)[0m     dampening: 0
[2m[36m(func pid=117684)[0m     differentiable: False
[2m[36m(func pid=117684)[0m     foreach: None
[2m[36m(func pid=117684)[0m     lr: 0.001
[2m[36m(func pid=117684)[0m     maximize: False
[2m[36m(func pid=117684)[0m     momentum: 0.9
[2m[36m(func pid=117684)[0m     nesterov: False
[2m[36m(func pid=117684)[0m     weight_decay: 1e-05
[2m[36m(func pid=117684)[0m )
[2m[36m(func pid=117684)[0m 
== Status ==
Current time: 2024-01-07 17:56:02 (running for 00:40:18.54)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.295 |  0.157 |                   59 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.414 |  0.193 |                   54 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.709 |  0.179 |                   49 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103512)[0m rmse: 0.15693844854831696
[2m[36m(func pid=103512)[0m mae:  0.0939013734459877
[2m[36m(func pid=103512)[0m rmse_per_class: [0.068, 0.225, 0.028, 0.28, 0.057, 0.167, 0.24, 0.129, 0.145, 0.231]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.7090 | Steps: 4 | Val loss: 0.5446 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3793 | Steps: 4 | Val loss: 0.4068 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8909 | Steps: 4 | Val loss: 0.6920 | Batch size: 32 | lr: 0.001 | Duration: 4.43s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3653 | Steps: 4 | Val loss: 0.2926 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=106005)[0m rmse: 0.17916299402713776
[2m[36m(func pid=106005)[0m mae:  0.13153593242168427
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.337, 0.108, 0.19, 0.293, 0.141, 0.143, 0.108]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.19186972081661224
[2m[36m(func pid=104772)[0m mae:  0.10737303644418716
[2m[36m(func pid=104772)[0m rmse_per_class: [0.093, 0.265, 0.05, 0.309, 0.109, 0.21, 0.291, 0.174, 0.234, 0.184]
[2m[36m(func pid=104772)[0m 
== Status ==
Current time: 2024-01-07 17:56:07 (running for 00:40:23.70)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.365 |  0.152 |                   60 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.379 |  0.192 |                   55 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.709 |  0.179 |                   50 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103512)[0m rmse: 0.15186262130737305
[2m[36m(func pid=103512)[0m mae:  0.0903673768043518
[2m[36m(func pid=103512)[0m rmse_per_class: [0.068, 0.221, 0.029, 0.273, 0.057, 0.164, 0.245, 0.127, 0.136, 0.199]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.18222376704216003
[2m[36m(func pid=117684)[0m mae:  0.13412520289421082
[2m[36m(func pid=117684)[0m rmse_per_class: [0.117, 0.266, 0.106, 0.339, 0.112, 0.19, 0.294, 0.143, 0.143, 0.112]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3530 | Steps: 4 | Val loss: 0.4075 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.7006 | Steps: 4 | Val loss: 0.5435 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3151 | Steps: 4 | Val loss: 0.2911 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.8763 | Steps: 4 | Val loss: 0.6726 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=104772)[0m rmse: 0.1920246183872223
[2m[36m(func pid=104772)[0m mae:  0.10863032191991806
[2m[36m(func pid=104772)[0m rmse_per_class: [0.179, 0.264, 0.051, 0.292, 0.086, 0.206, 0.262, 0.181, 0.263, 0.137]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17925556004047394
[2m[36m(func pid=106005)[0m mae:  0.13160330057144165
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.336, 0.107, 0.19, 0.293, 0.141, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.15032526850700378
[2m[36m(func pid=103512)[0m mae:  0.08916516602039337
[2m[36m(func pid=103512)[0m rmse_per_class: [0.07, 0.218, 0.031, 0.27, 0.055, 0.164, 0.254, 0.126, 0.136, 0.179]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.18185710906982422
[2m[36m(func pid=117684)[0m mae:  0.13383498787879944
[2m[36m(func pid=117684)[0m rmse_per_class: [0.117, 0.266, 0.105, 0.339, 0.112, 0.19, 0.294, 0.142, 0.143, 0.112]
== Status ==
Current time: 2024-01-07 17:56:12 (running for 00:40:29.08)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.315 |  0.15  |                   61 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.353 |  0.192 |                   56 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.701 |  0.179 |                   51 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.891 |  0.182 |                    1 |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3484 | Steps: 4 | Val loss: 0.4791 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.7022 | Steps: 4 | Val loss: 0.5412 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3236 | Steps: 4 | Val loss: 0.2849 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.8523 | Steps: 4 | Val loss: 0.6463 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=104772)[0m rmse: 0.1907166838645935
[2m[36m(func pid=104772)[0m mae:  0.11367963254451752
[2m[36m(func pid=104772)[0m rmse_per_class: [0.19, 0.285, 0.045, 0.307, 0.059, 0.194, 0.252, 0.194, 0.274, 0.107]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17922279238700867
[2m[36m(func pid=106005)[0m mae:  0.13159185647964478
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.098, 0.336, 0.107, 0.19, 0.293, 0.141, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
== Status ==
Current time: 2024-01-07 17:56:17 (running for 00:40:34.27)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.324 |  0.147 |                   62 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.348 |  0.191 |                   57 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.702 |  0.179 |                   52 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.876 |  0.182 |                    2 |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103512)[0m rmse: 0.14665000140666962
[2m[36m(func pid=103512)[0m mae:  0.08695276826620102
[2m[36m(func pid=103512)[0m rmse_per_class: [0.07, 0.216, 0.032, 0.264, 0.053, 0.16, 0.248, 0.13, 0.133, 0.16]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.1810784786939621
[2m[36m(func pid=117684)[0m mae:  0.13320541381835938
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.265, 0.103, 0.338, 0.111, 0.189, 0.294, 0.141, 0.142, 0.111]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3848 | Steps: 4 | Val loss: 0.5411 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.6969 | Steps: 4 | Val loss: 0.5370 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8159 | Steps: 4 | Val loss: 0.6177 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3421 | Steps: 4 | Val loss: 0.2778 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=104772)[0m rmse: 0.1937527060508728
[2m[36m(func pid=104772)[0m mae:  0.11807002872228622
[2m[36m(func pid=104772)[0m rmse_per_class: [0.155, 0.292, 0.049, 0.333, 0.056, 0.205, 0.259, 0.209, 0.284, 0.095]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17905516922473907
[2m[36m(func pid=106005)[0m mae:  0.13142937421798706
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.336, 0.108, 0.19, 0.294, 0.14, 0.143, 0.108]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.18032599985599518
[2m[36m(func pid=117684)[0m mae:  0.13258513808250427
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.264, 0.101, 0.337, 0.109, 0.189, 0.294, 0.14, 0.142, 0.11]
== Status ==
Current time: 2024-01-07 17:56:23 (running for 00:40:39.52)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.324 |  0.147 |                   62 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.385 |  0.194 |                   58 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.697 |  0.179 |                   53 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.816 |  0.18  |                    4 |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.14234203100204468
[2m[36m(func pid=103512)[0m mae:  0.08416739851236343
[2m[36m(func pid=103512)[0m rmse_per_class: [0.069, 0.212, 0.035, 0.264, 0.054, 0.157, 0.235, 0.123, 0.132, 0.142]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.6972 | Steps: 4 | Val loss: 0.5367 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4392 | Steps: 4 | Val loss: 0.5074 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3075 | Steps: 4 | Val loss: 0.2726 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7823 | Steps: 4 | Val loss: 0.5899 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=106005)[0m rmse: 0.1792825311422348
[2m[36m(func pid=106005)[0m mae:  0.13160432875156403
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.337, 0.108, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.2059263437986374
[2m[36m(func pid=104772)[0m mae:  0.12303592264652252
[2m[36m(func pid=104772)[0m rmse_per_class: [0.139, 0.284, 0.063, 0.334, 0.058, 0.257, 0.279, 0.219, 0.328, 0.099]
[2m[36m(func pid=104772)[0m 
== Status ==
Current time: 2024-01-07 17:56:28 (running for 00:40:44.92)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.342 |  0.142 |                   63 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.439 |  0.206 |                   59 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.697 |  0.179 |                   54 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.782 |  0.18  |                    5 |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103512)[0m rmse: 0.13977232575416565
[2m[36m(func pid=103512)[0m mae:  0.08248887956142426
[2m[36m(func pid=103512)[0m rmse_per_class: [0.07, 0.215, 0.039, 0.266, 0.055, 0.157, 0.227, 0.12, 0.13, 0.12]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.1802063286304474
[2m[36m(func pid=117684)[0m mae:  0.13244637846946716
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.264, 0.101, 0.337, 0.109, 0.189, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3886 | Steps: 4 | Val loss: 0.4574 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.6929 | Steps: 4 | Val loss: 0.5350 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3002 | Steps: 4 | Val loss: 0.2724 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.7459 | Steps: 4 | Val loss: 0.5615 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=106005)[0m rmse: 0.1791616529226303
[2m[36m(func pid=106005)[0m mae:  0.13151352107524872
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.26, 0.098, 0.337, 0.107, 0.19, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.20893724262714386
[2m[36m(func pid=104772)[0m mae:  0.11972556263208389
[2m[36m(func pid=104772)[0m rmse_per_class: [0.11, 0.264, 0.103, 0.31, 0.059, 0.288, 0.301, 0.222, 0.318, 0.115]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.1404949575662613
[2m[36m(func pid=103512)[0m mae:  0.08315740525722504
[2m[36m(func pid=103512)[0m rmse_per_class: [0.07, 0.223, 0.041, 0.268, 0.054, 0.162, 0.226, 0.119, 0.133, 0.109]
[2m[36m(func pid=103512)[0m 
== Status ==
Current time: 2024-01-07 17:56:33 (running for 00:40:50.14)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.14  |                   65 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.389 |  0.209 |                   60 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.693 |  0.179 |                   55 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.782 |  0.18  |                    5 |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.1796819269657135
[2m[36m(func pid=117684)[0m mae:  0.1320515275001526
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.263, 0.098, 0.337, 0.108, 0.189, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.6918 | Steps: 4 | Val loss: 0.5348 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3429 | Steps: 4 | Val loss: 0.4283 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3137 | Steps: 4 | Val loss: 0.2766 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.7148 | Steps: 4 | Val loss: 0.5378 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=104772)[0m rmse: 0.1973533034324646
[2m[36m(func pid=104772)[0m mae:  0.1089351624250412
[2m[36m(func pid=104772)[0m rmse_per_class: [0.096, 0.255, 0.112, 0.321, 0.065, 0.26, 0.305, 0.201, 0.238, 0.122]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17931391298770905
[2m[36m(func pid=106005)[0m mae:  0.13165047764778137
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.098, 0.336, 0.107, 0.189, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
== Status ==
Current time: 2024-01-07 17:56:38 (running for 00:40:55.43)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.14  |                   65 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.343 |  0.197 |                   61 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.692 |  0.179 |                   56 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.715 |  0.179 |                    7 |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103512)[0m rmse: 0.14404331147670746
[2m[36m(func pid=103512)[0m mae:  0.08604087680578232
[2m[36m(func pid=103512)[0m rmse_per_class: [0.069, 0.235, 0.042, 0.27, 0.054, 0.176, 0.237, 0.118, 0.136, 0.102]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17937436699867249
[2m[36m(func pid=117684)[0m mae:  0.13175950944423676
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.262, 0.098, 0.336, 0.107, 0.189, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3934 | Steps: 4 | Val loss: 0.4099 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.6861 | Steps: 4 | Val loss: 0.5325 | Batch size: 32 | lr: 0.0001 | Duration: 3.12s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3103 | Steps: 4 | Val loss: 0.2802 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.6849 | Steps: 4 | Val loss: 0.5166 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=104772)[0m rmse: 0.18343253433704376
[2m[36m(func pid=104772)[0m mae:  0.10189058631658554
[2m[36m(func pid=104772)[0m rmse_per_class: [0.084, 0.288, 0.087, 0.34, 0.07, 0.213, 0.291, 0.164, 0.175, 0.12]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17920725047588348
[2m[36m(func pid=106005)[0m mae:  0.1315688192844391
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.097, 0.336, 0.107, 0.189, 0.293, 0.14, 0.143, 0.11]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.1465582400560379
[2m[36m(func pid=103512)[0m mae:  0.08836029469966888
[2m[36m(func pid=103512)[0m rmse_per_class: [0.07, 0.235, 0.045, 0.272, 0.055, 0.186, 0.254, 0.117, 0.136, 0.095]
[2m[36m(func pid=103512)[0m 
== Status ==
Current time: 2024-01-07 17:56:44 (running for 00:41:00.76)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.31  |  0.147 |                   67 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.393 |  0.183 |                   62 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.686 |  0.179 |                   57 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.715 |  0.179 |                    7 |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17914463579654694
[2m[36m(func pid=117684)[0m mae:  0.13157406449317932
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.261, 0.097, 0.336, 0.106, 0.189, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3955 | Steps: 4 | Val loss: 0.4169 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.6854 | Steps: 4 | Val loss: 0.5283 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.6583 | Steps: 4 | Val loss: 0.4959 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2948 | Steps: 4 | Val loss: 0.2841 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=104772)[0m rmse: 0.17464199662208557
[2m[36m(func pid=104772)[0m mae:  0.09933613240718842
[2m[36m(func pid=104772)[0m rmse_per_class: [0.083, 0.321, 0.081, 0.316, 0.071, 0.2, 0.27, 0.144, 0.149, 0.112]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17915382981300354
[2m[36m(func pid=106005)[0m mae:  0.1315433382987976
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.097, 0.336, 0.107, 0.189, 0.293, 0.14, 0.143, 0.11]
[2m[36m(func pid=106005)[0m 
== Status ==
Current time: 2024-01-07 17:56:49 (running for 00:41:05.99)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.31  |  0.147 |                   67 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.395 |  0.175 |                   63 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.685 |  0.179 |                   58 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.658 |  0.179 |                    9 |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17922459542751312
[2m[36m(func pid=117684)[0m mae:  0.13164016604423523
[2m[36m(func pid=117684)[0m rmse_per_class: [0.117, 0.261, 0.096, 0.337, 0.106, 0.189, 0.293, 0.141, 0.143, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.14960548281669617
[2m[36m(func pid=103512)[0m mae:  0.09109838306903839
[2m[36m(func pid=103512)[0m rmse_per_class: [0.069, 0.232, 0.049, 0.273, 0.055, 0.201, 0.266, 0.117, 0.141, 0.092]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3713 | Steps: 4 | Val loss: 0.4096 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.6833 | Steps: 4 | Val loss: 0.5268 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.6328 | Steps: 4 | Val loss: 0.4761 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3372 | Steps: 4 | Val loss: 0.2864 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=104772)[0m rmse: 0.16955338418483734
[2m[36m(func pid=104772)[0m mae:  0.09654269367456436
[2m[36m(func pid=104772)[0m rmse_per_class: [0.085, 0.296, 0.078, 0.292, 0.076, 0.198, 0.265, 0.14, 0.138, 0.128]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.1790877878665924
[2m[36m(func pid=106005)[0m mae:  0.1314907968044281
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.096, 0.336, 0.108, 0.189, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
== Status ==
Current time: 2024-01-07 17:56:54 (running for 00:41:11.34)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.295 |  0.15  |                   68 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.371 |  0.17  |                   64 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.683 |  0.179 |                   59 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.633 |  0.179 |                   10 |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17879244685173035
[2m[36m(func pid=117684)[0m mae:  0.13130079209804535
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.261, 0.095, 0.337, 0.105, 0.189, 0.293, 0.141, 0.143, 0.108]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=103512)[0m rmse: 0.1499864161014557
[2m[36m(func pid=103512)[0m mae:  0.09187982976436615
[2m[36m(func pid=103512)[0m rmse_per_class: [0.07, 0.228, 0.046, 0.27, 0.054, 0.208, 0.27, 0.118, 0.147, 0.09]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4057 | Steps: 4 | Val loss: 0.4150 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.6797 | Steps: 4 | Val loss: 0.5251 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3006 | Steps: 4 | Val loss: 0.2900 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.6115 | Steps: 4 | Val loss: 0.4609 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=104772)[0m rmse: 0.17073754966259003
[2m[36m(func pid=104772)[0m mae:  0.09727195650339127
[2m[36m(func pid=104772)[0m rmse_per_class: [0.107, 0.268, 0.081, 0.303, 0.088, 0.182, 0.258, 0.15, 0.137, 0.134]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17899514734745026
[2m[36m(func pid=106005)[0m mae:  0.13142405450344086
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.26, 0.096, 0.337, 0.107, 0.19, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
== Status ==
Current time: 2024-01-07 17:57:00 (running for 00:41:16.61)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.337 |  0.15  |                   69 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.406 |  0.171 |                   65 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.68  |  0.179 |                   60 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.612 |  0.179 |                   11 |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103512)[0m rmse: 0.15213584899902344
[2m[36m(func pid=103512)[0m mae:  0.09358244389295578
[2m[36m(func pid=103512)[0m rmse_per_class: [0.074, 0.224, 0.056, 0.273, 0.055, 0.199, 0.275, 0.117, 0.159, 0.089]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.1785479187965393
[2m[36m(func pid=117684)[0m mae:  0.13112607598304749
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.26, 0.094, 0.336, 0.104, 0.189, 0.293, 0.141, 0.143, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4176 | Steps: 4 | Val loss: 0.4189 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.6785 | Steps: 4 | Val loss: 0.5226 | Batch size: 32 | lr: 0.0001 | Duration: 3.16s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2820 | Steps: 4 | Val loss: 0.2905 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.5924 | Steps: 4 | Val loss: 0.4476 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=104772)[0m rmse: 0.17915494740009308
[2m[36m(func pid=104772)[0m mae:  0.10217670351266861
[2m[36m(func pid=104772)[0m rmse_per_class: [0.157, 0.247, 0.085, 0.323, 0.114, 0.178, 0.253, 0.167, 0.14, 0.128]
[2m[36m(func pid=104772)[0m 
== Status ==
Current time: 2024-01-07 17:57:05 (running for 00:41:21.82)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.282 |  0.154 |                   71 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.418 |  0.179 |                   66 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.68  |  0.179 |                   60 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.612 |  0.179 |                   11 |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103512)[0m rmse: 0.1541149914264679
[2m[36m(func pid=103512)[0m mae:  0.09518949687480927
[2m[36m(func pid=103512)[0m rmse_per_class: [0.077, 0.212, 0.068, 0.275, 0.055, 0.2, 0.275, 0.118, 0.172, 0.088]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17911192774772644
[2m[36m(func pid=106005)[0m mae:  0.13157163560390472
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.261, 0.096, 0.337, 0.106, 0.189, 0.293, 0.14, 0.144, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17849509418010712
[2m[36m(func pid=117684)[0m mae:  0.13106867671012878
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.26, 0.095, 0.336, 0.103, 0.189, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3663 | Steps: 4 | Val loss: 0.4465 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3032 | Steps: 4 | Val loss: 0.2929 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.6765 | Steps: 4 | Val loss: 0.5203 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.5759 | Steps: 4 | Val loss: 0.4339 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=104772)[0m rmse: 0.20376399159431458
[2m[36m(func pid=104772)[0m mae:  0.11725039780139923
[2m[36m(func pid=104772)[0m rmse_per_class: [0.181, 0.241, 0.092, 0.325, 0.158, 0.235, 0.294, 0.192, 0.185, 0.134]
[2m[36m(func pid=104772)[0m 
== Status ==
Current time: 2024-01-07 17:57:10 (running for 00:41:27.13)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.303 |  0.156 |                   72 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.366 |  0.204 |                   67 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.678 |  0.179 |                   61 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.592 |  0.178 |                   12 |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103512)[0m rmse: 0.15608353912830353
[2m[36m(func pid=103512)[0m mae:  0.09619412571191788
[2m[36m(func pid=103512)[0m rmse_per_class: [0.076, 0.211, 0.074, 0.277, 0.054, 0.194, 0.27, 0.12, 0.193, 0.091]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17912286520004272
[2m[36m(func pid=106005)[0m mae:  0.131578266620636
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.337, 0.106, 0.19, 0.293, 0.14, 0.144, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17822380363941193
[2m[36m(func pid=117684)[0m mae:  0.13081742823123932
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.259, 0.094, 0.336, 0.102, 0.189, 0.292, 0.14, 0.143, 0.11]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3683 | Steps: 4 | Val loss: 0.4968 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3156 | Steps: 4 | Val loss: 0.2924 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.6703 | Steps: 4 | Val loss: 0.5189 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.5571 | Steps: 4 | Val loss: 0.4227 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=104772)[0m rmse: 0.2228720486164093
[2m[36m(func pid=104772)[0m mae:  0.12874960899353027
[2m[36m(func pid=104772)[0m rmse_per_class: [0.171, 0.26, 0.101, 0.33, 0.215, 0.228, 0.32, 0.206, 0.279, 0.119]
[2m[36m(func pid=104772)[0m 
== Status ==
Current time: 2024-01-07 17:57:16 (running for 00:41:32.51)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.316 |  0.156 |                   73 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.368 |  0.223 |                   68 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.676 |  0.179 |                   62 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.576 |  0.178 |                   13 |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103512)[0m rmse: 0.1562575101852417
[2m[36m(func pid=103512)[0m mae:  0.09566767513751984
[2m[36m(func pid=103512)[0m rmse_per_class: [0.077, 0.21, 0.074, 0.277, 0.055, 0.185, 0.263, 0.122, 0.205, 0.094]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17897936701774597
[2m[36m(func pid=106005)[0m mae:  0.13139554858207703
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.337, 0.107, 0.189, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.1781342476606369
[2m[36m(func pid=117684)[0m mae:  0.13076359033584595
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.259, 0.094, 0.336, 0.101, 0.189, 0.292, 0.14, 0.143, 0.11]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4317 | Steps: 4 | Val loss: 0.5099 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2930 | Steps: 4 | Val loss: 0.2951 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.6671 | Steps: 4 | Val loss: 0.5144 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.5458 | Steps: 4 | Val loss: 0.4124 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=104772)[0m rmse: 0.22968971729278564
[2m[36m(func pid=104772)[0m mae:  0.13166652619838715
[2m[36m(func pid=104772)[0m rmse_per_class: [0.128, 0.264, 0.127, 0.318, 0.232, 0.2, 0.316, 0.21, 0.386, 0.116]
[2m[36m(func pid=104772)[0m 
== Status ==
Current time: 2024-01-07 17:57:21 (running for 00:41:37.83)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00018 | RUNNING    | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.293 |  0.159 |                   74 |
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.432 |  0.23  |                   69 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.67  |  0.179 |                   63 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.557 |  0.178 |                   14 |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103512)[0m rmse: 0.15886512398719788
[2m[36m(func pid=103512)[0m mae:  0.09700138866901398
[2m[36m(func pid=103512)[0m rmse_per_class: [0.082, 0.21, 0.081, 0.282, 0.06, 0.178, 0.254, 0.125, 0.219, 0.097]
[2m[36m(func pid=103512)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17881837487220764
[2m[36m(func pid=106005)[0m mae:  0.1312742531299591
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.336, 0.107, 0.19, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17798297107219696
[2m[36m(func pid=117684)[0m mae:  0.13060776889324188
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.26, 0.094, 0.336, 0.1, 0.189, 0.292, 0.14, 0.143, 0.11]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4136 | Steps: 4 | Val loss: 0.4556 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=103512)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2995 | Steps: 4 | Val loss: 0.3040 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.6676 | Steps: 4 | Val loss: 0.5119 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.5302 | Steps: 4 | Val loss: 0.4025 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=104772)[0m rmse: 0.21356657147407532
[2m[36m(func pid=104772)[0m mae:  0.11874447017908096
[2m[36m(func pid=104772)[0m rmse_per_class: [0.107, 0.26, 0.149, 0.298, 0.197, 0.202, 0.276, 0.179, 0.358, 0.11]
[2m[36m(func pid=104772)[0m 
== Status ==
Current time: 2024-01-07 17:57:26 (running for 00:41:43.13)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 PENDING, 3 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.414 |  0.214 |                   70 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.667 |  0.179 |                   64 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.546 |  0.178 |                   15 |
| train_01e98_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=103512)[0m rmse: 0.1629621684551239
[2m[36m(func pid=103512)[0m mae:  0.09933336079120636
[2m[36m(func pid=103512)[0m rmse_per_class: [0.084, 0.211, 0.094, 0.292, 0.065, 0.17, 0.243, 0.128, 0.241, 0.103]
[2m[36m(func pid=106005)[0m rmse: 0.17872583866119385
[2m[36m(func pid=106005)[0m mae:  0.13124224543571472
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.095, 0.336, 0.106, 0.19, 0.293, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17777130007743835
[2m[36m(func pid=117684)[0m mae:  0.13036082684993744
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.259, 0.094, 0.335, 0.1, 0.189, 0.292, 0.14, 0.142, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3556 | Steps: 4 | Val loss: 0.3975 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.6649 | Steps: 4 | Val loss: 0.5109 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.5240 | Steps: 4 | Val loss: 0.3952 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=104772)[0m rmse: 0.18614104390144348
[2m[36m(func pid=104772)[0m mae:  0.1029081791639328
[2m[36m(func pid=104772)[0m rmse_per_class: [0.096, 0.248, 0.146, 0.294, 0.129, 0.207, 0.274, 0.137, 0.236, 0.094]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17900332808494568
[2m[36m(func pid=106005)[0m mae:  0.13147129118442535
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.336, 0.106, 0.19, 0.293, 0.14, 0.143, 0.11]
[2m[36m(func pid=117684)[0m rmse: 0.1775718480348587
[2m[36m(func pid=117684)[0m mae:  0.13023166358470917
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.258, 0.093, 0.335, 0.1, 0.189, 0.292, 0.14, 0.143, 0.11]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3581 | Steps: 4 | Val loss: 0.3789 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.5109 | Steps: 4 | Val loss: 0.3878 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 17:57:32 (running for 00:41:48.71)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.356 |  0.186 |                   71 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.668 |  0.179 |                   65 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.524 |  0.178 |                   17 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=122291)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=122291)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=122291)[0m Configuration completed!
[2m[36m(func pid=122291)[0m New optimizer parameters:
[2m[36m(func pid=122291)[0m SGD (
[2m[36m(func pid=122291)[0m Parameter Group 0
[2m[36m(func pid=122291)[0m     dampening: 0
[2m[36m(func pid=122291)[0m     differentiable: False
[2m[36m(func pid=122291)[0m     foreach: None
[2m[36m(func pid=122291)[0m     lr: 0.01
[2m[36m(func pid=122291)[0m     maximize: False
[2m[36m(func pid=122291)[0m     momentum: 0.9
[2m[36m(func pid=122291)[0m     nesterov: False
[2m[36m(func pid=122291)[0m     weight_decay: 1e-05
[2m[36m(func pid=122291)[0m )
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.17090174555778503
[2m[36m(func pid=104772)[0m mae:  0.09713944792747498
[2m[36m(func pid=104772)[0m rmse_per_class: [0.096, 0.243, 0.12, 0.288, 0.07, 0.196, 0.295, 0.129, 0.185, 0.088]
[2m[36m(func pid=104772)[0m 
== Status ==
Current time: 2024-01-07 17:57:37 (running for 00:41:53.96)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.358 |  0.171 |                   72 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.665 |  0.179 |                   66 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.511 |  0.178 |                   18 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17760011553764343
[2m[36m(func pid=117684)[0m mae:  0.1302897036075592
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.259, 0.093, 0.335, 0.099, 0.188, 0.291, 0.141, 0.143, 0.111]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.6596 | Steps: 4 | Val loss: 0.5090 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3505 | Steps: 4 | Val loss: 0.3737 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.5052 | Steps: 4 | Val loss: 0.3813 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8663 | Steps: 4 | Val loss: 0.6320 | Batch size: 32 | lr: 0.01 | Duration: 4.57s
[2m[36m(func pid=106005)[0m rmse: 0.17908097803592682
[2m[36m(func pid=106005)[0m mae:  0.131546288728714
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.337, 0.106, 0.189, 0.293, 0.14, 0.143, 0.11]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.16582436859607697
[2m[36m(func pid=104772)[0m mae:  0.0934113934636116
[2m[36m(func pid=104772)[0m rmse_per_class: [0.104, 0.274, 0.096, 0.288, 0.057, 0.18, 0.254, 0.139, 0.166, 0.101]
[2m[36m(func pid=104772)[0m 
== Status ==
Current time: 2024-01-07 17:57:42 (running for 00:41:59.31)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.35  |  0.166 |                   73 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.66  |  0.179 |                   67 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.511 |  0.178 |                   18 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.866 |  0.182 |                    1 |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.1774674952030182
[2m[36m(func pid=117684)[0m mae:  0.13019424676895142
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.258, 0.094, 0.335, 0.098, 0.188, 0.292, 0.14, 0.143, 0.111]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.18243852257728577
[2m[36m(func pid=122291)[0m mae:  0.13428547978401184
[2m[36m(func pid=122291)[0m rmse_per_class: [0.118, 0.267, 0.106, 0.339, 0.111, 0.191, 0.294, 0.144, 0.143, 0.112]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.6546 | Steps: 4 | Val loss: 0.5070 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3363 | Steps: 4 | Val loss: 0.4304 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.7216 | Steps: 4 | Val loss: 0.5040 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4938 | Steps: 4 | Val loss: 0.3753 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=106005)[0m rmse: 0.17900019884109497
[2m[36m(func pid=106005)[0m mae:  0.13142967224121094
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.336, 0.106, 0.19, 0.294, 0.14, 0.143, 0.109]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.18212354183197021
[2m[36m(func pid=104772)[0m mae:  0.1065499410033226
[2m[36m(func pid=104772)[0m rmse_per_class: [0.15, 0.3, 0.076, 0.304, 0.056, 0.218, 0.296, 0.154, 0.145, 0.122]
[2m[36m(func pid=104772)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17718307673931122
[2m[36m(func pid=117684)[0m mae:  0.1299494206905365
[2m[36m(func pid=117684)[0m rmse_per_class: [0.117, 0.259, 0.092, 0.334, 0.097, 0.188, 0.291, 0.141, 0.143, 0.11]
== Status ==
Current time: 2024-01-07 17:57:48 (running for 00:42:04.58)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00019 | RUNNING    | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.336 |  0.182 |                   74 |
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.655 |  0.179 |                   68 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.494 |  0.177 |                   20 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.866 |  0.182 |                    1 |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.18111629784107208
[2m[36m(func pid=122291)[0m mae:  0.13317833840847015
[2m[36m(func pid=122291)[0m rmse_per_class: [0.118, 0.267, 0.104, 0.339, 0.107, 0.189, 0.291, 0.143, 0.142, 0.112]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.6594 | Steps: 4 | Val loss: 0.5043 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=104772)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3749 | Steps: 4 | Val loss: 0.4778 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4850 | Steps: 4 | Val loss: 0.3697 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.5715 | Steps: 4 | Val loss: 0.4003 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=106005)[0m rmse: 0.17900940775871277
[2m[36m(func pid=106005)[0m mae:  0.13147097826004028
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.095, 0.337, 0.106, 0.189, 0.294, 0.14, 0.143, 0.11]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=104772)[0m rmse: 0.1957472264766693
[2m[36m(func pid=104772)[0m mae:  0.1175556406378746
[2m[36m(func pid=104772)[0m rmse_per_class: [0.222, 0.278, 0.079, 0.326, 0.056, 0.235, 0.324, 0.157, 0.14, 0.142]
== Status ==
Current time: 2024-01-07 17:57:53 (running for 00:42:09.78)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (1 PENDING, 3 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.659 |  0.179 |                   69 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.485 |  0.177 |                   21 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.722 |  0.181 |                    2 |
| train_01e98_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17700451612472534
[2m[36m(func pid=117684)[0m mae:  0.12981536984443665
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.258, 0.092, 0.335, 0.096, 0.188, 0.291, 0.142, 0.143, 0.111]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.1790546327829361
[2m[36m(func pid=122291)[0m mae:  0.1314743310213089
[2m[36m(func pid=122291)[0m rmse_per_class: [0.117, 0.266, 0.1, 0.338, 0.099, 0.188, 0.289, 0.142, 0.141, 0.112]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.6541 | Steps: 4 | Val loss: 0.5022 | Batch size: 32 | lr: 0.0001 | Duration: 3.10s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4826 | Steps: 4 | Val loss: 0.3663 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4744 | Steps: 4 | Val loss: 0.3425 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=106005)[0m rmse: 0.17901192605495453
[2m[36m(func pid=106005)[0m mae:  0.13145962357521057
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.337, 0.106, 0.189, 0.293, 0.14, 0.143, 0.11]
[2m[36m(func pid=106005)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17672137916088104
[2m[36m(func pid=117684)[0m mae:  0.12957444787025452
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.259, 0.091, 0.334, 0.095, 0.188, 0.29, 0.142, 0.142, 0.11]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.17647776007652283
[2m[36m(func pid=122291)[0m mae:  0.12935058772563934
[2m[36m(func pid=122291)[0m rmse_per_class: [0.116, 0.263, 0.094, 0.336, 0.091, 0.186, 0.286, 0.14, 0.14, 0.111]
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.6542 | Steps: 4 | Val loss: 0.5022 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4750 | Steps: 4 | Val loss: 0.3624 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 17:57:58 (running for 00:42:15.18)
Memory usage on this node: 22.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.654 |  0.179 |                   70 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.483 |  0.177 |                   22 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.571 |  0.179 |                    3 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=123603)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=123603)[0m Configuration completed!
[2m[36m(func pid=123603)[0m New optimizer parameters:
[2m[36m(func pid=123603)[0m SGD (
[2m[36m(func pid=123603)[0m Parameter Group 0
[2m[36m(func pid=123603)[0m     dampening: 0
[2m[36m(func pid=123603)[0m     differentiable: False
[2m[36m(func pid=123603)[0m     foreach: None
[2m[36m(func pid=123603)[0m     lr: 0.1
[2m[36m(func pid=123603)[0m     maximize: False
[2m[36m(func pid=123603)[0m     momentum: 0.9
[2m[36m(func pid=123603)[0m     nesterov: False
[2m[36m(func pid=123603)[0m     weight_decay: 1e-05
[2m[36m(func pid=123603)[0m )
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17908622324466705
[2m[36m(func pid=106005)[0m mae:  0.13153508305549622
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.337, 0.105, 0.189, 0.294, 0.14, 0.144, 0.11]
[2m[36m(func pid=106005)[0m 
== Status ==
Current time: 2024-01-07 17:58:03 (running for 00:42:20.45)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.654 |  0.179 |                   71 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.475 |  0.177 |                   23 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.474 |  0.176 |                    4 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17665281891822815
[2m[36m(func pid=117684)[0m mae:  0.1294817477464676
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.259, 0.091, 0.333, 0.096, 0.187, 0.29, 0.141, 0.142, 0.11]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4254 | Steps: 4 | Val loss: 0.3190 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.6517 | Steps: 4 | Val loss: 0.5012 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.6950 | Steps: 4 | Val loss: 0.3558 | Batch size: 32 | lr: 0.1 | Duration: 4.80s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4704 | Steps: 4 | Val loss: 0.3613 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=122291)[0m rmse: 0.17441636323928833
[2m[36m(func pid=122291)[0m mae:  0.1277196854352951
[2m[36m(func pid=122291)[0m rmse_per_class: [0.118, 0.26, 0.088, 0.334, 0.083, 0.186, 0.284, 0.139, 0.141, 0.111]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17912724614143372
[2m[36m(func pid=106005)[0m mae:  0.13154804706573486
[2m[36m(func pid=106005)[0m rmse_per_class: [0.115, 0.26, 0.097, 0.336, 0.105, 0.19, 0.294, 0.139, 0.143, 0.111]
[2m[36m(func pid=106005)[0m 
== Status ==
Current time: 2024-01-07 17:58:09 (running for 00:42:25.59)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.652 |  0.179 |                   72 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.475 |  0.177 |                   23 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.425 |  0.174 |                    5 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.695 |  0.182 |                    1 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=123603)[0m rmse: 0.18155506253242493
[2m[36m(func pid=123603)[0m mae:  0.13367927074432373
[2m[36m(func pid=123603)[0m rmse_per_class: [0.119, 0.268, 0.103, 0.338, 0.096, 0.19, 0.291, 0.146, 0.146, 0.118]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17662706971168518
[2m[36m(func pid=117684)[0m mae:  0.1295088231563568
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.259, 0.09, 0.334, 0.095, 0.187, 0.291, 0.14, 0.143, 0.111]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4096 | Steps: 4 | Val loss: 0.3128 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.6464 | Steps: 4 | Val loss: 0.4992 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4660 | Steps: 4 | Val loss: 0.3578 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.4261 | Steps: 4 | Val loss: 0.3492 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=122291)[0m rmse: 0.17279185354709625
[2m[36m(func pid=122291)[0m mae:  0.1264561116695404
[2m[36m(func pid=122291)[0m rmse_per_class: [0.119, 0.258, 0.083, 0.333, 0.079, 0.184, 0.282, 0.139, 0.142, 0.109]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.1791345626115799
[2m[36m(func pid=106005)[0m mae:  0.1315779983997345
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.097, 0.337, 0.106, 0.189, 0.294, 0.139, 0.143, 0.111]
[2m[36m(func pid=106005)[0m 
== Status ==
Current time: 2024-01-07 17:58:14 (running for 00:42:30.86)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.646 |  0.179 |                   73 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.466 |  0.176 |                   25 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.41  |  0.173 |                    6 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.695 |  0.182 |                    1 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.1762532889842987
[2m[36m(func pid=117684)[0m mae:  0.12913139164447784
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.258, 0.09, 0.333, 0.094, 0.188, 0.29, 0.14, 0.144, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.17506983876228333
[2m[36m(func pid=123603)[0m mae:  0.12877483665943146
[2m[36m(func pid=123603)[0m rmse_per_class: [0.115, 0.266, 0.075, 0.336, 0.074, 0.181, 0.283, 0.138, 0.15, 0.133]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4042 | Steps: 4 | Val loss: 0.3107 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.6453 | Steps: 4 | Val loss: 0.4958 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4578 | Steps: 4 | Val loss: 0.3532 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.4840 | Steps: 4 | Val loss: 0.3693 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=122291)[0m rmse: 0.1709679663181305
[2m[36m(func pid=122291)[0m mae:  0.12488992512226105
[2m[36m(func pid=122291)[0m rmse_per_class: [0.118, 0.255, 0.079, 0.332, 0.076, 0.184, 0.28, 0.137, 0.143, 0.107]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=106005)[0m rmse: 0.17904210090637207
[2m[36m(func pid=106005)[0m mae:  0.13151010870933533
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.26, 0.096, 0.337, 0.107, 0.189, 0.294, 0.139, 0.143, 0.11]
[2m[36m(func pid=106005)[0m 
== Status ==
Current time: 2024-01-07 17:58:19 (running for 00:42:36.13)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00020 | RUNNING    | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.645 |  0.179 |                   74 |
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.458 |  0.176 |                   26 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.404 |  0.171 |                    7 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.426 |  0.175 |                    2 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17613986134529114
[2m[36m(func pid=117684)[0m mae:  0.1290808618068695
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.258, 0.09, 0.334, 0.094, 0.188, 0.29, 0.14, 0.144, 0.11]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.1626991331577301
[2m[36m(func pid=123603)[0m mae:  0.11777005344629288
[2m[36m(func pid=123603)[0m rmse_per_class: [0.114, 0.25, 0.051, 0.33, 0.057, 0.173, 0.259, 0.129, 0.14, 0.124]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4042 | Steps: 4 | Val loss: 0.3112 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=106005)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.6451 | Steps: 4 | Val loss: 0.4951 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4564 | Steps: 4 | Val loss: 0.3480 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=122291)[0m rmse: 0.169892355799675
[2m[36m(func pid=122291)[0m mae:  0.12400796264410019
[2m[36m(func pid=122291)[0m rmse_per_class: [0.118, 0.252, 0.077, 0.332, 0.073, 0.183, 0.277, 0.136, 0.145, 0.107]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4770 | Steps: 4 | Val loss: 0.3231 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=106005)[0m rmse: 0.1793200820684433
[2m[36m(func pid=106005)[0m mae:  0.13172364234924316
[2m[36m(func pid=106005)[0m rmse_per_class: [0.116, 0.261, 0.096, 0.337, 0.107, 0.189, 0.294, 0.14, 0.143, 0.11]
== Status ==
Current time: 2024-01-07 17:58:24 (running for 00:42:41.34)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.456 |  0.176 |                   27 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.404 |  0.17  |                    8 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.484 |  0.163 |                    3 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17585960030555725
[2m[36m(func pid=117684)[0m mae:  0.128944993019104
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.257, 0.088, 0.334, 0.092, 0.188, 0.289, 0.14, 0.144, 0.11]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.3968 | Steps: 4 | Val loss: 0.3097 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=123603)[0m rmse: 0.15010681748390198
[2m[36m(func pid=123603)[0m mae:  0.10404396057128906
[2m[36m(func pid=123603)[0m rmse_per_class: [0.097, 0.234, 0.044, 0.31, 0.054, 0.164, 0.233, 0.12, 0.132, 0.113]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4545 | Steps: 4 | Val loss: 0.3457 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=122291)[0m rmse: 0.1683507263660431
[2m[36m(func pid=122291)[0m mae:  0.12267909198999405
[2m[36m(func pid=122291)[0m rmse_per_class: [0.119, 0.251, 0.073, 0.331, 0.071, 0.182, 0.273, 0.134, 0.145, 0.104]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4160 | Steps: 4 | Val loss: 0.2651 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 17:58:30 (running for 00:42:46.78)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.454 |  0.176 |                   28 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.397 |  0.168 |                    9 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.477 |  0.15  |                    4 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.1760195940732956
[2m[36m(func pid=117684)[0m mae:  0.12912485003471375
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.257, 0.089, 0.335, 0.092, 0.188, 0.289, 0.14, 0.145, 0.111]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4005 | Steps: 4 | Val loss: 0.3081 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=123603)[0m rmse: 0.14118924736976624
[2m[36m(func pid=123603)[0m mae:  0.09438635408878326
[2m[36m(func pid=123603)[0m rmse_per_class: [0.083, 0.225, 0.044, 0.281, 0.054, 0.16, 0.226, 0.116, 0.13, 0.093]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.16716432571411133
[2m[36m(func pid=122291)[0m mae:  0.12157013267278671
[2m[36m(func pid=122291)[0m rmse_per_class: [0.117, 0.25, 0.072, 0.331, 0.068, 0.18, 0.271, 0.133, 0.146, 0.102]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4519 | Steps: 4 | Val loss: 0.3442 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.3602 | Steps: 4 | Val loss: 0.2647 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
== Status ==
Current time: 2024-01-07 17:58:36 (running for 00:42:52.49)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.452 |  0.176 |                   29 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.401 |  0.167 |                   10 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.416 |  0.141 |                    5 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.1760653704404831
[2m[36m(func pid=117684)[0m mae:  0.12914790213108063
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.257, 0.088, 0.335, 0.092, 0.188, 0.288, 0.14, 0.145, 0.111]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3988 | Steps: 4 | Val loss: 0.3051 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=123603)[0m rmse: 0.14018391072750092
[2m[36m(func pid=123603)[0m mae:  0.0954732894897461
[2m[36m(func pid=123603)[0m rmse_per_class: [0.09, 0.221, 0.04, 0.271, 0.054, 0.157, 0.232, 0.115, 0.135, 0.088]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.16589415073394775
[2m[36m(func pid=122291)[0m mae:  0.12056688219308853
[2m[36m(func pid=122291)[0m rmse_per_class: [0.116, 0.25, 0.069, 0.33, 0.067, 0.179, 0.267, 0.132, 0.147, 0.103]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4469 | Steps: 4 | Val loss: 0.3415 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.3801 | Steps: 4 | Val loss: 0.2799 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 17:58:41 (running for 00:42:57.90)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.447 |  0.176 |                   30 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.399 |  0.166 |                   11 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.36  |  0.14  |                    6 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.1759641021490097
[2m[36m(func pid=117684)[0m mae:  0.12906195223331451
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.257, 0.088, 0.335, 0.092, 0.188, 0.288, 0.141, 0.145, 0.111]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4006 | Steps: 4 | Val loss: 0.3013 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=123603)[0m rmse: 0.14795680344104767
[2m[36m(func pid=123603)[0m mae:  0.10293646156787872
[2m[36m(func pid=123603)[0m rmse_per_class: [0.092, 0.219, 0.031, 0.275, 0.053, 0.158, 0.263, 0.113, 0.177, 0.098]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.16435804963111877
[2m[36m(func pid=122291)[0m mae:  0.11935488134622574
[2m[36m(func pid=122291)[0m rmse_per_class: [0.114, 0.249, 0.066, 0.327, 0.066, 0.178, 0.265, 0.131, 0.147, 0.102]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4460 | Steps: 4 | Val loss: 0.3403 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.3485 | Steps: 4 | Val loss: 0.2838 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.3917 | Steps: 4 | Val loss: 0.2989 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 17:58:46 (running for 00:43:03.34)
Memory usage on this node: 22.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.446 |  0.176 |                   31 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.401 |  0.164 |                   12 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.38  |  0.148 |                    7 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17614220082759857
[2m[36m(func pid=117684)[0m mae:  0.12918664515018463
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.258, 0.088, 0.336, 0.091, 0.187, 0.287, 0.141, 0.145, 0.112]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.15580028295516968
[2m[36m(func pid=123603)[0m mae:  0.1076720580458641
[2m[36m(func pid=123603)[0m rmse_per_class: [0.084, 0.226, 0.057, 0.289, 0.054, 0.155, 0.27, 0.111, 0.187, 0.126]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.16348496079444885
[2m[36m(func pid=122291)[0m mae:  0.11874494701623917
[2m[36m(func pid=122291)[0m rmse_per_class: [0.113, 0.247, 0.065, 0.323, 0.064, 0.177, 0.264, 0.13, 0.149, 0.102]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4423 | Steps: 4 | Val loss: 0.3389 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.3299 | Steps: 4 | Val loss: 0.2876 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.3929 | Steps: 4 | Val loss: 0.2968 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 17:58:52 (running for 00:43:08.70)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.442 |  0.176 |                   32 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.392 |  0.163 |                   13 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.348 |  0.156 |                    8 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17596903443336487
[2m[36m(func pid=117684)[0m mae:  0.12905599176883698
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.257, 0.088, 0.335, 0.091, 0.187, 0.288, 0.14, 0.145, 0.112]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.15921151638031006
[2m[36m(func pid=123603)[0m mae:  0.10714121907949448
[2m[36m(func pid=123603)[0m rmse_per_class: [0.073, 0.235, 0.133, 0.297, 0.068, 0.155, 0.244, 0.108, 0.153, 0.126]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.16275611519813538
[2m[36m(func pid=122291)[0m mae:  0.11819163709878922
[2m[36m(func pid=122291)[0m rmse_per_class: [0.112, 0.246, 0.065, 0.321, 0.063, 0.177, 0.264, 0.129, 0.15, 0.101]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4406 | Steps: 4 | Val loss: 0.3371 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3395 | Steps: 4 | Val loss: 0.2794 | Batch size: 32 | lr: 0.1 | Duration: 3.19s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.3832 | Steps: 4 | Val loss: 0.2956 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=117684)[0m rmse: 0.17549771070480347
[2m[36m(func pid=117684)[0m mae:  0.1286524534225464
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.257, 0.087, 0.335, 0.091, 0.187, 0.287, 0.14, 0.145, 0.111]
== Status ==
Current time: 2024-01-07 17:58:57 (running for 00:43:14.08)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.441 |  0.175 |                   33 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.393 |  0.163 |                   14 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.33  |  0.159 |                    9 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.16236421465873718
[2m[36m(func pid=122291)[0m mae:  0.11793690919876099
[2m[36m(func pid=122291)[0m rmse_per_class: [0.113, 0.244, 0.064, 0.321, 0.063, 0.176, 0.264, 0.128, 0.15, 0.101]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.15283331274986267
[2m[36m(func pid=123603)[0m mae:  0.10106612741947174
[2m[36m(func pid=123603)[0m rmse_per_class: [0.074, 0.225, 0.109, 0.296, 0.084, 0.154, 0.225, 0.108, 0.145, 0.108]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4378 | Steps: 4 | Val loss: 0.3344 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3926 | Steps: 4 | Val loss: 0.2938 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3207 | Steps: 4 | Val loss: 0.2700 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
== Status ==
Current time: 2024-01-07 17:59:03 (running for 00:43:19.50)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.438 |  0.175 |                   34 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.383 |  0.162 |                   15 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.34  |  0.153 |                   10 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17497627437114716
[2m[36m(func pid=117684)[0m mae:  0.12823334336280823
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.256, 0.087, 0.334, 0.089, 0.188, 0.286, 0.14, 0.144, 0.111]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.1613381803035736
[2m[36m(func pid=122291)[0m mae:  0.11719129979610443
[2m[36m(func pid=122291)[0m rmse_per_class: [0.114, 0.241, 0.063, 0.318, 0.062, 0.175, 0.265, 0.127, 0.148, 0.1]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14614620804786682
[2m[36m(func pid=123603)[0m mae:  0.09671684354543686
[2m[36m(func pid=123603)[0m rmse_per_class: [0.084, 0.216, 0.054, 0.294, 0.081, 0.154, 0.224, 0.109, 0.149, 0.097]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4362 | Steps: 4 | Val loss: 0.3324 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3792 | Steps: 4 | Val loss: 0.2929 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=117684)[0m rmse: 0.17481665313243866
[2m[36m(func pid=117684)[0m mae:  0.1281123012304306
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.256, 0.086, 0.333, 0.089, 0.188, 0.286, 0.14, 0.144, 0.111]
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.3234 | Steps: 4 | Val loss: 0.2708 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 17:59:08 (running for 00:43:24.88)
Memory usage on this node: 22.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.436 |  0.175 |                   35 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.393 |  0.161 |                   16 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.321 |  0.146 |                   11 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.16097047924995422
[2m[36m(func pid=122291)[0m mae:  0.11700962483882904
[2m[36m(func pid=122291)[0m rmse_per_class: [0.112, 0.239, 0.062, 0.318, 0.062, 0.174, 0.266, 0.127, 0.149, 0.101]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.145523339509964
[2m[36m(func pid=123603)[0m mae:  0.0968109592795372
[2m[36m(func pid=123603)[0m rmse_per_class: [0.086, 0.22, 0.032, 0.29, 0.081, 0.155, 0.234, 0.11, 0.16, 0.088]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4309 | Steps: 4 | Val loss: 0.3315 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3745 | Steps: 4 | Val loss: 0.2925 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 17:59:13 (running for 00:43:30.28)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.431 |  0.175 |                   36 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.379 |  0.161 |                   17 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.323 |  0.146 |                   12 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17483291029930115
[2m[36m(func pid=117684)[0m mae:  0.12818413972854614
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.256, 0.086, 0.333, 0.088, 0.187, 0.287, 0.139, 0.144, 0.112]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.3109 | Steps: 4 | Val loss: 0.2644 | Batch size: 32 | lr: 0.1 | Duration: 3.27s
[2m[36m(func pid=122291)[0m rmse: 0.16081641614437103
[2m[36m(func pid=122291)[0m mae:  0.11703348159790039
[2m[36m(func pid=122291)[0m rmse_per_class: [0.111, 0.238, 0.063, 0.318, 0.062, 0.174, 0.267, 0.127, 0.147, 0.101]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4267 | Steps: 4 | Val loss: 0.3306 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=123603)[0m rmse: 0.14078208804130554
[2m[36m(func pid=123603)[0m mae:  0.09312857687473297
[2m[36m(func pid=123603)[0m rmse_per_class: [0.073, 0.217, 0.027, 0.279, 0.078, 0.152, 0.234, 0.11, 0.148, 0.09]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3757 | Steps: 4 | Val loss: 0.2907 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 17:59:19 (running for 00:43:35.90)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.427 |  0.175 |                   37 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.375 |  0.161 |                   18 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.311 |  0.141 |                   13 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17456835508346558
[2m[36m(func pid=117684)[0m mae:  0.12792906165122986
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.256, 0.085, 0.332, 0.089, 0.187, 0.287, 0.14, 0.144, 0.111]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.3170 | Steps: 4 | Val loss: 0.2659 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=122291)[0m rmse: 0.1595519632101059
[2m[36m(func pid=122291)[0m mae:  0.11597754806280136
[2m[36m(func pid=122291)[0m rmse_per_class: [0.109, 0.235, 0.061, 0.318, 0.062, 0.172, 0.267, 0.126, 0.144, 0.101]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14290885627269745
[2m[36m(func pid=123603)[0m mae:  0.0939384400844574
[2m[36m(func pid=123603)[0m rmse_per_class: [0.066, 0.215, 0.027, 0.281, 0.075, 0.152, 0.232, 0.126, 0.143, 0.112]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4270 | Steps: 4 | Val loss: 0.3287 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3724 | Steps: 4 | Val loss: 0.2890 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 17:59:24 (running for 00:43:41.32)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.427 |  0.174 |                   38 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.376 |  0.16  |                   19 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.317 |  0.143 |                   14 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17431923747062683
[2m[36m(func pid=117684)[0m mae:  0.12775714695453644
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.255, 0.085, 0.333, 0.088, 0.187, 0.286, 0.139, 0.144, 0.111]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.3104 | Steps: 4 | Val loss: 0.2664 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=122291)[0m rmse: 0.15846994519233704
[2m[36m(func pid=122291)[0m mae:  0.11499878019094467
[2m[36m(func pid=122291)[0m rmse_per_class: [0.106, 0.233, 0.061, 0.318, 0.062, 0.172, 0.265, 0.125, 0.142, 0.102]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4284 | Steps: 4 | Val loss: 0.3273 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=123603)[0m rmse: 0.14363573491573334
[2m[36m(func pid=123603)[0m mae:  0.09354912489652634
[2m[36m(func pid=123603)[0m rmse_per_class: [0.063, 0.219, 0.028, 0.284, 0.076, 0.151, 0.225, 0.121, 0.142, 0.128]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3755 | Steps: 4 | Val loss: 0.2869 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 17:59:30 (running for 00:43:46.69)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.428 |  0.174 |                   39 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.372 |  0.158 |                   20 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.31  |  0.144 |                   15 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17413003742694855
[2m[36m(func pid=117684)[0m mae:  0.12761512398719788
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.255, 0.085, 0.333, 0.088, 0.187, 0.286, 0.139, 0.143, 0.11]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3124 | Steps: 4 | Val loss: 0.2680 | Batch size: 32 | lr: 0.1 | Duration: 3.22s
[2m[36m(func pid=122291)[0m rmse: 0.1570950448513031
[2m[36m(func pid=122291)[0m mae:  0.11369893699884415
[2m[36m(func pid=122291)[0m rmse_per_class: [0.103, 0.232, 0.06, 0.318, 0.062, 0.171, 0.262, 0.124, 0.14, 0.101]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4250 | Steps: 4 | Val loss: 0.3252 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=123603)[0m rmse: 0.14527568221092224
[2m[36m(func pid=123603)[0m mae:  0.09421096742153168
[2m[36m(func pid=123603)[0m rmse_per_class: [0.063, 0.218, 0.03, 0.283, 0.079, 0.152, 0.224, 0.109, 0.161, 0.135]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3738 | Steps: 4 | Val loss: 0.2860 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=117684)[0m rmse: 0.17368093132972717
[2m[36m(func pid=117684)[0m mae:  0.12724342942237854
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.254, 0.084, 0.333, 0.087, 0.186, 0.285, 0.138, 0.144, 0.11]
[2m[36m(func pid=117684)[0m 
== Status ==
Current time: 2024-01-07 17:59:35 (running for 00:43:52.28)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.425 |  0.174 |                   40 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.375 |  0.157 |                   21 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.312 |  0.145 |                   16 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.15662389993667603
[2m[36m(func pid=122291)[0m mae:  0.11321108043193817
[2m[36m(func pid=122291)[0m rmse_per_class: [0.101, 0.232, 0.06, 0.316, 0.062, 0.169, 0.262, 0.123, 0.139, 0.103]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3161 | Steps: 4 | Val loss: 0.2661 | Batch size: 32 | lr: 0.1 | Duration: 3.18s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4221 | Steps: 4 | Val loss: 0.3238 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=123603)[0m rmse: 0.14508084952831268
[2m[36m(func pid=123603)[0m mae:  0.09401179105043411
[2m[36m(func pid=123603)[0m rmse_per_class: [0.07, 0.217, 0.034, 0.274, 0.079, 0.154, 0.223, 0.109, 0.175, 0.117]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3677 | Steps: 4 | Val loss: 0.2857 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 17:59:41 (running for 00:43:57.63)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.422 |  0.173 |                   41 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.374 |  0.157 |                   22 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.316 |  0.145 |                   17 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17325817048549652
[2m[36m(func pid=117684)[0m mae:  0.12691804766654968
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.253, 0.082, 0.334, 0.087, 0.186, 0.285, 0.138, 0.143, 0.108]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.15643003582954407
[2m[36m(func pid=122291)[0m mae:  0.1130329817533493
[2m[36m(func pid=122291)[0m rmse_per_class: [0.1, 0.231, 0.061, 0.315, 0.062, 0.168, 0.262, 0.123, 0.139, 0.103]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3080 | Steps: 4 | Val loss: 0.2646 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4208 | Steps: 4 | Val loss: 0.3221 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3663 | Steps: 4 | Val loss: 0.2832 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=123603)[0m rmse: 0.14377225935459137
[2m[36m(func pid=123603)[0m mae:  0.09287381172180176
[2m[36m(func pid=123603)[0m rmse_per_class: [0.077, 0.217, 0.041, 0.278, 0.073, 0.152, 0.217, 0.109, 0.17, 0.105]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 17:59:46 (running for 00:44:03.30)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.421 |  0.173 |                   42 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.368 |  0.156 |                   23 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.308 |  0.144 |                   18 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17310331761837006
[2m[36m(func pid=117684)[0m mae:  0.12676142156124115
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.252, 0.083, 0.334, 0.086, 0.186, 0.285, 0.139, 0.143, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.15493041276931763
[2m[36m(func pid=122291)[0m mae:  0.11172185093164444
[2m[36m(func pid=122291)[0m rmse_per_class: [0.099, 0.23, 0.061, 0.31, 0.062, 0.167, 0.26, 0.122, 0.138, 0.1]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3014 | Steps: 4 | Val loss: 0.2648 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4237 | Steps: 4 | Val loss: 0.3214 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3602 | Steps: 4 | Val loss: 0.2809 | Batch size: 32 | lr: 0.01 | Duration: 2.68s
[2m[36m(func pid=123603)[0m rmse: 0.14372071623802185
[2m[36m(func pid=123603)[0m mae:  0.09289591759443283
[2m[36m(func pid=123603)[0m rmse_per_class: [0.073, 0.217, 0.046, 0.28, 0.071, 0.152, 0.222, 0.108, 0.166, 0.101]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 17:59:52 (running for 00:44:08.63)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.424 |  0.173 |                   43 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.366 |  0.155 |                   24 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.301 |  0.144 |                   19 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17307521402835846
[2m[36m(func pid=117684)[0m mae:  0.12679800391197205
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.252, 0.083, 0.333, 0.085, 0.186, 0.285, 0.138, 0.144, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.1537734717130661
[2m[36m(func pid=122291)[0m mae:  0.11063097417354584
[2m[36m(func pid=122291)[0m rmse_per_class: [0.098, 0.229, 0.06, 0.304, 0.062, 0.167, 0.26, 0.122, 0.137, 0.1]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3026 | Steps: 4 | Val loss: 0.2612 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4210 | Steps: 4 | Val loss: 0.3209 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3611 | Steps: 4 | Val loss: 0.2795 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=123603)[0m rmse: 0.14137819409370422
[2m[36m(func pid=123603)[0m mae:  0.09109089523553848
[2m[36m(func pid=123603)[0m rmse_per_class: [0.066, 0.215, 0.059, 0.265, 0.068, 0.151, 0.233, 0.107, 0.146, 0.104]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 17:59:57 (running for 00:44:13.93)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.421 |  0.173 |                   44 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.36  |  0.154 |                   25 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.303 |  0.141 |                   20 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.1730612814426422
[2m[36m(func pid=117684)[0m mae:  0.12680162489414215
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.252, 0.083, 0.333, 0.086, 0.185, 0.285, 0.139, 0.143, 0.11]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.15304125845432281
[2m[36m(func pid=122291)[0m mae:  0.10999147593975067
[2m[36m(func pid=122291)[0m rmse_per_class: [0.096, 0.231, 0.06, 0.299, 0.063, 0.166, 0.258, 0.121, 0.137, 0.099]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.2946 | Steps: 4 | Val loss: 0.2616 | Batch size: 32 | lr: 0.1 | Duration: 3.24s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4201 | Steps: 4 | Val loss: 0.3205 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3659 | Steps: 4 | Val loss: 0.2790 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=123603)[0m rmse: 0.14210766553878784
[2m[36m(func pid=123603)[0m mae:  0.09146986901760101
[2m[36m(func pid=123603)[0m rmse_per_class: [0.065, 0.217, 0.062, 0.272, 0.062, 0.152, 0.236, 0.109, 0.143, 0.103]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 18:00:02 (running for 00:44:19.31)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.421 |  0.173 |                   44 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.366 |  0.153 |                   27 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.295 |  0.142 |                   21 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.15279266238212585
[2m[36m(func pid=122291)[0m mae:  0.10969503223896027
[2m[36m(func pid=122291)[0m rmse_per_class: [0.095, 0.231, 0.06, 0.297, 0.062, 0.166, 0.257, 0.121, 0.137, 0.101]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17306284606456757
[2m[36m(func pid=117684)[0m mae:  0.12679094076156616
[2m[36m(func pid=117684)[0m rmse_per_class: [0.114, 0.253, 0.083, 0.333, 0.086, 0.185, 0.285, 0.138, 0.144, 0.11]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3015 | Steps: 4 | Val loss: 0.2658 | Batch size: 32 | lr: 0.1 | Duration: 3.20s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3575 | Steps: 4 | Val loss: 0.2779 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4172 | Steps: 4 | Val loss: 0.3195 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=123603)[0m rmse: 0.14453156292438507
[2m[36m(func pid=123603)[0m mae:  0.09293308854103088
[2m[36m(func pid=123603)[0m rmse_per_class: [0.065, 0.22, 0.066, 0.289, 0.064, 0.153, 0.234, 0.11, 0.144, 0.102]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 18:00:08 (running for 00:44:24.85)
Memory usage on this node: 22.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.42  |  0.173 |                   45 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.357 |  0.152 |                   28 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.302 |  0.145 |                   22 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.15217919647693634
[2m[36m(func pid=122291)[0m mae:  0.10911683738231659
[2m[36m(func pid=122291)[0m rmse_per_class: [0.095, 0.23, 0.059, 0.293, 0.063, 0.167, 0.256, 0.121, 0.137, 0.102]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17296168208122253
[2m[36m(func pid=117684)[0m mae:  0.12667518854141235
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.252, 0.083, 0.333, 0.086, 0.186, 0.285, 0.138, 0.144, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3123 | Steps: 4 | Val loss: 0.2695 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3605 | Steps: 4 | Val loss: 0.2775 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4193 | Steps: 4 | Val loss: 0.3193 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=123603)[0m rmse: 0.1454261839389801
[2m[36m(func pid=123603)[0m mae:  0.09343279898166656
[2m[36m(func pid=123603)[0m rmse_per_class: [0.062, 0.228, 0.058, 0.303, 0.062, 0.15, 0.223, 0.11, 0.147, 0.11]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 18:00:13 (running for 00:44:29.99)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.417 |  0.173 |                   46 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.361 |  0.152 |                   29 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.312 |  0.145 |                   23 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.15188008546829224
[2m[36m(func pid=122291)[0m mae:  0.10880064964294434
[2m[36m(func pid=122291)[0m rmse_per_class: [0.094, 0.231, 0.059, 0.292, 0.063, 0.165, 0.257, 0.119, 0.136, 0.101]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.1728479564189911
[2m[36m(func pid=117684)[0m mae:  0.12660083174705505
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.252, 0.082, 0.333, 0.086, 0.186, 0.284, 0.137, 0.144, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.2935 | Steps: 4 | Val loss: 0.2660 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3540 | Steps: 4 | Val loss: 0.2763 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4169 | Steps: 4 | Val loss: 0.3188 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 18:00:18 (running for 00:44:35.23)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.419 |  0.173 |                   47 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.354 |  0.151 |                   30 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.312 |  0.145 |                   23 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.15110547840595245
[2m[36m(func pid=122291)[0m mae:  0.10812868922948837
[2m[36m(func pid=122291)[0m rmse_per_class: [0.093, 0.23, 0.058, 0.291, 0.064, 0.164, 0.255, 0.119, 0.136, 0.101]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17284992337226868
[2m[36m(func pid=117684)[0m mae:  0.126588374376297
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.253, 0.082, 0.333, 0.085, 0.186, 0.284, 0.137, 0.144, 0.11]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14393548667430878
[2m[36m(func pid=123603)[0m mae:  0.09234043210744858
[2m[36m(func pid=123603)[0m rmse_per_class: [0.063, 0.225, 0.051, 0.293, 0.067, 0.152, 0.218, 0.109, 0.151, 0.109]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3688 | Steps: 4 | Val loss: 0.2770 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4175 | Steps: 4 | Val loss: 0.3173 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3205 | Steps: 4 | Val loss: 0.2587 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 18:00:23 (running for 00:44:40.37)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.417 |  0.173 |                   48 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.369 |  0.152 |                   31 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.294 |  0.144 |                   24 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.15156790614128113
[2m[36m(func pid=122291)[0m mae:  0.10847042500972748
[2m[36m(func pid=122291)[0m rmse_per_class: [0.094, 0.231, 0.059, 0.295, 0.066, 0.163, 0.253, 0.119, 0.136, 0.101]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17247678339481354
[2m[36m(func pid=117684)[0m mae:  0.12626534700393677
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.253, 0.081, 0.332, 0.085, 0.185, 0.284, 0.136, 0.144, 0.11]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14062336087226868
[2m[36m(func pid=123603)[0m mae:  0.08970068395137787
[2m[36m(func pid=123603)[0m rmse_per_class: [0.065, 0.217, 0.047, 0.262, 0.066, 0.152, 0.218, 0.109, 0.148, 0.122]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3642 | Steps: 4 | Val loss: 0.2783 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4148 | Steps: 4 | Val loss: 0.3177 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.2943 | Steps: 4 | Val loss: 0.2629 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
== Status ==
Current time: 2024-01-07 18:00:29 (running for 00:44:45.75)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.417 |  0.172 |                   49 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.364 |  0.153 |                   32 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.321 |  0.141 |                   25 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.15260465443134308
[2m[36m(func pid=122291)[0m mae:  0.10915996134281158
[2m[36m(func pid=122291)[0m rmse_per_class: [0.093, 0.229, 0.062, 0.296, 0.066, 0.165, 0.253, 0.119, 0.136, 0.107]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.1728493869304657
[2m[36m(func pid=117684)[0m mae:  0.12655040621757507
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.253, 0.083, 0.332, 0.085, 0.186, 0.284, 0.137, 0.144, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14266686141490936
[2m[36m(func pid=123603)[0m mae:  0.09110623598098755
[2m[36m(func pid=123603)[0m rmse_per_class: [0.064, 0.229, 0.038, 0.26, 0.062, 0.151, 0.219, 0.12, 0.145, 0.137]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3565 | Steps: 4 | Val loss: 0.2798 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4136 | Steps: 4 | Val loss: 0.3173 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.2998 | Steps: 4 | Val loss: 0.2647 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 18:00:34 (running for 00:44:51.26)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.415 |  0.173 |                   50 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.356 |  0.154 |                   33 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.294 |  0.143 |                   26 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.1535993069410324
[2m[36m(func pid=122291)[0m mae:  0.10984426736831665
[2m[36m(func pid=122291)[0m rmse_per_class: [0.091, 0.234, 0.064, 0.3, 0.065, 0.165, 0.251, 0.119, 0.137, 0.11]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.1726125180721283
[2m[36m(func pid=117684)[0m mae:  0.12635301053524017
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.253, 0.082, 0.333, 0.085, 0.185, 0.284, 0.136, 0.143, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14399459958076477
[2m[36m(func pid=123603)[0m mae:  0.0923541933298111
[2m[36m(func pid=123603)[0m rmse_per_class: [0.076, 0.224, 0.035, 0.275, 0.064, 0.151, 0.221, 0.121, 0.148, 0.125]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3520 | Steps: 4 | Val loss: 0.2799 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4084 | Steps: 4 | Val loss: 0.3165 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.2681 | Steps: 4 | Val loss: 0.2650 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
== Status ==
Current time: 2024-01-07 18:00:40 (running for 00:44:56.53)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.414 |  0.173 |                   51 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.352 |  0.154 |                   34 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.3   |  0.144 |                   27 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.15352626144886017
[2m[36m(func pid=122291)[0m mae:  0.10975004732608795
[2m[36m(func pid=122291)[0m rmse_per_class: [0.091, 0.23, 0.064, 0.303, 0.065, 0.166, 0.25, 0.119, 0.136, 0.111]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.1725197732448578
[2m[36m(func pid=117684)[0m mae:  0.12627513706684113
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.253, 0.083, 0.333, 0.083, 0.185, 0.282, 0.137, 0.144, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14402489364147186
[2m[36m(func pid=123603)[0m mae:  0.09273216873407364
[2m[36m(func pid=123603)[0m rmse_per_class: [0.074, 0.221, 0.033, 0.278, 0.062, 0.151, 0.224, 0.11, 0.161, 0.125]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3601 | Steps: 4 | Val loss: 0.2772 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4123 | Steps: 4 | Val loss: 0.3161 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3058 | Steps: 4 | Val loss: 0.2708 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 18:00:45 (running for 00:45:01.91)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.408 |  0.173 |                   52 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.36  |  0.152 |                   35 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.268 |  0.144 |                   28 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.15154607594013214
[2m[36m(func pid=122291)[0m mae:  0.10796646773815155
[2m[36m(func pid=122291)[0m rmse_per_class: [0.089, 0.229, 0.061, 0.301, 0.065, 0.163, 0.247, 0.118, 0.135, 0.106]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.1726035326719284
[2m[36m(func pid=117684)[0m mae:  0.12634316086769104
[2m[36m(func pid=117684)[0m rmse_per_class: [0.117, 0.253, 0.083, 0.332, 0.083, 0.186, 0.282, 0.137, 0.144, 0.11]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14654970169067383
[2m[36m(func pid=123603)[0m mae:  0.09434648603200912
[2m[36m(func pid=123603)[0m rmse_per_class: [0.072, 0.228, 0.033, 0.287, 0.059, 0.154, 0.229, 0.11, 0.17, 0.124]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3482 | Steps: 4 | Val loss: 0.2750 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4094 | Steps: 4 | Val loss: 0.3157 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.2783 | Steps: 4 | Val loss: 0.2633 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 18:00:50 (running for 00:45:07.38)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.412 |  0.173 |                   53 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.348 |  0.15  |                   36 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.306 |  0.147 |                   29 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14988590776920319
[2m[36m(func pid=122291)[0m mae:  0.10654741525650024
[2m[36m(func pid=122291)[0m rmse_per_class: [0.088, 0.226, 0.06, 0.298, 0.065, 0.161, 0.247, 0.118, 0.135, 0.101]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17245279252529144
[2m[36m(func pid=117684)[0m mae:  0.12623950839042664
[2m[36m(func pid=117684)[0m rmse_per_class: [0.117, 0.252, 0.083, 0.332, 0.083, 0.186, 0.283, 0.137, 0.143, 0.11]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.142074316740036
[2m[36m(func pid=123603)[0m mae:  0.09081104397773743
[2m[36m(func pid=123603)[0m rmse_per_class: [0.065, 0.224, 0.035, 0.276, 0.071, 0.153, 0.223, 0.109, 0.155, 0.11]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3482 | Steps: 4 | Val loss: 0.2745 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4080 | Steps: 4 | Val loss: 0.3142 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.2957 | Steps: 4 | Val loss: 0.2640 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=122291)[0m rmse: 0.14922650158405304
[2m[36m(func pid=122291)[0m mae:  0.10588093101978302
[2m[36m(func pid=122291)[0m rmse_per_class: [0.087, 0.226, 0.059, 0.301, 0.065, 0.16, 0.244, 0.117, 0.135, 0.1]
== Status ==
Current time: 2024-01-07 18:00:56 (running for 00:45:12.68)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.409 |  0.172 |                   54 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.348 |  0.149 |                   37 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.278 |  0.142 |                   30 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17201080918312073
[2m[36m(func pid=117684)[0m mae:  0.1259329468011856
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.251, 0.082, 0.331, 0.081, 0.186, 0.283, 0.137, 0.144, 0.11]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14346656203269958
[2m[36m(func pid=123603)[0m mae:  0.09120719134807587
[2m[36m(func pid=123603)[0m rmse_per_class: [0.065, 0.222, 0.04, 0.275, 0.073, 0.154, 0.222, 0.109, 0.164, 0.111]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3449 | Steps: 4 | Val loss: 0.2751 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4094 | Steps: 4 | Val loss: 0.3135 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=122291)[0m rmse: 0.149641752243042
[2m[36m(func pid=122291)[0m mae:  0.106251560151577
[2m[36m(func pid=122291)[0m rmse_per_class: [0.087, 0.226, 0.059, 0.301, 0.065, 0.16, 0.244, 0.117, 0.135, 0.103]
[2m[36m(func pid=122291)[0m 
== Status ==
Current time: 2024-01-07 18:01:01 (running for 00:45:17.92)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.408 |  0.172 |                   55 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.345 |  0.15  |                   38 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.296 |  0.143 |                   31 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.2958 | Steps: 4 | Val loss: 0.2660 | Batch size: 32 | lr: 0.1 | Duration: 3.23s
[2m[36m(func pid=117684)[0m rmse: 0.1716325730085373
[2m[36m(func pid=117684)[0m mae:  0.12561997771263123
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.251, 0.082, 0.331, 0.082, 0.185, 0.282, 0.137, 0.143, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14623558521270752
[2m[36m(func pid=123603)[0m mae:  0.09298083186149597
[2m[36m(func pid=123603)[0m rmse_per_class: [0.066, 0.225, 0.049, 0.281, 0.082, 0.156, 0.221, 0.109, 0.158, 0.115]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3468 | Steps: 4 | Val loss: 0.2763 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4122 | Steps: 4 | Val loss: 0.3128 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 18:01:06 (running for 00:45:23.13)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.409 |  0.172 |                   56 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.347 |  0.15  |                   39 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.296 |  0.146 |                   32 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.15042607486248016
[2m[36m(func pid=122291)[0m mae:  0.10696256160736084
[2m[36m(func pid=122291)[0m rmse_per_class: [0.086, 0.224, 0.06, 0.306, 0.066, 0.16, 0.246, 0.116, 0.135, 0.106]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.1715579777956009
[2m[36m(func pid=117684)[0m mae:  0.12553417682647705
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.253, 0.081, 0.33, 0.082, 0.184, 0.282, 0.137, 0.142, 0.108]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.2917 | Steps: 4 | Val loss: 0.2674 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3575 | Steps: 4 | Val loss: 0.2783 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=123603)[0m rmse: 0.14696148037910461
[2m[36m(func pid=123603)[0m mae:  0.09372472763061523
[2m[36m(func pid=123603)[0m rmse_per_class: [0.065, 0.224, 0.046, 0.277, 0.071, 0.16, 0.223, 0.11, 0.171, 0.123]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4089 | Steps: 4 | Val loss: 0.3119 | Batch size: 32 | lr: 0.001 | Duration: 3.13s
[2m[36m(func pid=122291)[0m rmse: 0.1513533890247345
[2m[36m(func pid=122291)[0m mae:  0.10762478411197662
[2m[36m(func pid=122291)[0m rmse_per_class: [0.084, 0.225, 0.059, 0.314, 0.067, 0.161, 0.245, 0.116, 0.136, 0.107]
[2m[36m(func pid=122291)[0m 
== Status ==
Current time: 2024-01-07 18:01:11 (running for 00:45:28.31)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.412 |  0.172 |                   57 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.358 |  0.151 |                   40 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.292 |  0.147 |                   33 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m rmse: 0.17131991684436798
[2m[36m(func pid=117684)[0m mae:  0.12535108625888824
[2m[36m(func pid=117684)[0m rmse_per_class: [0.116, 0.251, 0.08, 0.33, 0.082, 0.184, 0.282, 0.137, 0.142, 0.108]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2858 | Steps: 4 | Val loss: 0.2616 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3518 | Steps: 4 | Val loss: 0.2795 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=123603)[0m rmse: 0.14296302199363708
[2m[36m(func pid=123603)[0m mae:  0.0908317118883133
[2m[36m(func pid=123603)[0m rmse_per_class: [0.069, 0.222, 0.045, 0.261, 0.066, 0.155, 0.223, 0.109, 0.158, 0.122]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4063 | Steps: 4 | Val loss: 0.3122 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 18:01:16 (running for 00:45:33.38)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.409 |  0.171 |                   58 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.352 |  0.152 |                   41 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.286 |  0.143 |                   34 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.15210719406604767
[2m[36m(func pid=122291)[0m mae:  0.10826468467712402
[2m[36m(func pid=122291)[0m rmse_per_class: [0.086, 0.23, 0.059, 0.315, 0.067, 0.16, 0.244, 0.116, 0.139, 0.106]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17145220935344696
[2m[36m(func pid=117684)[0m mae:  0.12548275291919708
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.252, 0.081, 0.33, 0.082, 0.184, 0.282, 0.137, 0.143, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2834 | Steps: 4 | Val loss: 0.2655 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3538 | Steps: 4 | Val loss: 0.2766 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=123603)[0m rmse: 0.14568471908569336
[2m[36m(func pid=123603)[0m mae:  0.09275968372821808
[2m[36m(func pid=123603)[0m rmse_per_class: [0.075, 0.218, 0.047, 0.27, 0.059, 0.155, 0.228, 0.109, 0.163, 0.132]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4068 | Steps: 4 | Val loss: 0.3122 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 18:01:21 (running for 00:45:38.41)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.406 |  0.171 |                   59 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.354 |  0.15  |                   42 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.283 |  0.146 |                   35 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.1502852737903595
[2m[36m(func pid=122291)[0m mae:  0.10682766139507294
[2m[36m(func pid=122291)[0m rmse_per_class: [0.086, 0.226, 0.054, 0.309, 0.066, 0.159, 0.245, 0.116, 0.139, 0.103]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17138341069221497
[2m[36m(func pid=117684)[0m mae:  0.12543319165706635
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.252, 0.081, 0.33, 0.082, 0.184, 0.282, 0.136, 0.143, 0.11]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3069 | Steps: 4 | Val loss: 0.2654 | Batch size: 32 | lr: 0.1 | Duration: 3.21s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3485 | Steps: 4 | Val loss: 0.2778 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4061 | Steps: 4 | Val loss: 0.3117 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=123603)[0m rmse: 0.14385035634040833
[2m[36m(func pid=123603)[0m mae:  0.09124155342578888
[2m[36m(func pid=123603)[0m rmse_per_class: [0.07, 0.219, 0.046, 0.285, 0.057, 0.156, 0.224, 0.11, 0.145, 0.127]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.15118351578712463
[2m[36m(func pid=122291)[0m mae:  0.1075565367937088
[2m[36m(func pid=122291)[0m rmse_per_class: [0.088, 0.227, 0.056, 0.31, 0.065, 0.16, 0.246, 0.116, 0.141, 0.104]
== Status ==
Current time: 2024-01-07 18:01:27 (running for 00:45:43.51)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.407 |  0.171 |                   60 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.349 |  0.151 |                   43 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.307 |  0.144 |                   36 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17125682532787323
[2m[36m(func pid=117684)[0m mae:  0.12529657781124115
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.252, 0.08, 0.329, 0.082, 0.184, 0.283, 0.136, 0.143, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2949 | Steps: 4 | Val loss: 0.2696 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3472 | Steps: 4 | Val loss: 0.2759 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4076 | Steps: 4 | Val loss: 0.3110 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=122291)[0m rmse: 0.1501876562833786
[2m[36m(func pid=122291)[0m mae:  0.10676644742488861
[2m[36m(func pid=122291)[0m rmse_per_class: [0.087, 0.225, 0.057, 0.304, 0.065, 0.159, 0.247, 0.115, 0.141, 0.102]
[2m[36m(func pid=122291)[0m 
== Status ==
Current time: 2024-01-07 18:01:32 (running for 00:45:48.65)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.406 |  0.171 |                   61 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.347 |  0.15  |                   44 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.307 |  0.144 |                   36 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=123603)[0m rmse: 0.14630074799060822
[2m[36m(func pid=123603)[0m mae:  0.09223773330450058
[2m[36m(func pid=123603)[0m rmse_per_class: [0.066, 0.223, 0.061, 0.295, 0.059, 0.157, 0.225, 0.113, 0.141, 0.123]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17096355557441711
[2m[36m(func pid=117684)[0m mae:  0.12504586577415466
[2m[36m(func pid=117684)[0m rmse_per_class: [0.114, 0.252, 0.08, 0.329, 0.082, 0.183, 0.283, 0.136, 0.143, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3456 | Steps: 4 | Val loss: 0.2769 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2645 | Steps: 4 | Val loss: 0.2735 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4086 | Steps: 4 | Val loss: 0.3098 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 18:01:37 (running for 00:45:53.95)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.408 |  0.171 |                   62 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.346 |  0.151 |                   45 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.295 |  0.146 |                   37 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.15076854825019836
[2m[36m(func pid=122291)[0m mae:  0.10727069526910782
[2m[36m(func pid=122291)[0m rmse_per_class: [0.088, 0.224, 0.057, 0.305, 0.066, 0.159, 0.249, 0.115, 0.142, 0.102]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14994093775749207
[2m[36m(func pid=123603)[0m mae:  0.09485451132059097
[2m[36m(func pid=123603)[0m rmse_per_class: [0.066, 0.224, 0.07, 0.298, 0.067, 0.156, 0.229, 0.113, 0.156, 0.119]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17051619291305542
[2m[36m(func pid=117684)[0m mae:  0.12464995682239532
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.252, 0.079, 0.329, 0.081, 0.182, 0.281, 0.136, 0.142, 0.108]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3439 | Steps: 4 | Val loss: 0.2754 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2888 | Steps: 4 | Val loss: 0.2754 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4036 | Steps: 4 | Val loss: 0.3103 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 18:01:42 (running for 00:45:59.19)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.409 |  0.171 |                   63 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.344 |  0.15  |                   46 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.265 |  0.15  |                   38 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.1497143805027008
[2m[36m(func pid=122291)[0m mae:  0.10642683506011963
[2m[36m(func pid=122291)[0m rmse_per_class: [0.087, 0.222, 0.054, 0.3, 0.068, 0.158, 0.252, 0.114, 0.142, 0.1]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.15169548988342285
[2m[36m(func pid=123603)[0m mae:  0.0962042585015297
[2m[36m(func pid=123603)[0m rmse_per_class: [0.072, 0.223, 0.061, 0.293, 0.067, 0.156, 0.234, 0.115, 0.175, 0.121]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17062561213970184
[2m[36m(func pid=117684)[0m mae:  0.12475436925888062
[2m[36m(func pid=117684)[0m rmse_per_class: [0.114, 0.252, 0.08, 0.33, 0.081, 0.182, 0.281, 0.135, 0.142, 0.108]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3395 | Steps: 4 | Val loss: 0.2743 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2822 | Steps: 4 | Val loss: 0.2747 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
== Status ==
Current time: 2024-01-07 18:01:48 (running for 00:46:04.55)
Memory usage on this node: 22.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.404 |  0.171 |                   64 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.34  |  0.149 |                   47 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.289 |  0.152 |                   39 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4031 | Steps: 4 | Val loss: 0.3104 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
[2m[36m(func pid=122291)[0m rmse: 0.1488756686449051
[2m[36m(func pid=122291)[0m mae:  0.1057172641158104
[2m[36m(func pid=122291)[0m rmse_per_class: [0.084, 0.222, 0.053, 0.3, 0.066, 0.16, 0.248, 0.114, 0.143, 0.099]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.15057708323001862
[2m[36m(func pid=123603)[0m mae:  0.09576722234487534
[2m[36m(func pid=123603)[0m rmse_per_class: [0.087, 0.221, 0.053, 0.294, 0.073, 0.156, 0.234, 0.111, 0.167, 0.109]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17065025866031647
[2m[36m(func pid=117684)[0m mae:  0.12479189783334732
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.251, 0.079, 0.331, 0.081, 0.182, 0.281, 0.135, 0.142, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3406 | Steps: 4 | Val loss: 0.2726 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3087 | Steps: 4 | Val loss: 0.2727 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 18:01:53 (running for 00:46:09.68)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.403 |  0.171 |                   65 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.341 |  0.148 |                   48 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.282 |  0.151 |                   40 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14753012359142303
[2m[36m(func pid=122291)[0m mae:  0.10452274978160858
[2m[36m(func pid=122291)[0m rmse_per_class: [0.082, 0.221, 0.05, 0.299, 0.065, 0.159, 0.244, 0.114, 0.143, 0.098]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4074 | Steps: 4 | Val loss: 0.3096 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=123603)[0m rmse: 0.14938080310821533
[2m[36m(func pid=123603)[0m mae:  0.09514342248439789
[2m[36m(func pid=123603)[0m rmse_per_class: [0.091, 0.217, 0.048, 0.295, 0.072, 0.156, 0.229, 0.114, 0.167, 0.105]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.170342355966568
[2m[36m(func pid=117684)[0m mae:  0.12453826516866684
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.251, 0.079, 0.33, 0.081, 0.182, 0.281, 0.135, 0.142, 0.108]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3426 | Steps: 4 | Val loss: 0.2712 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2843 | Steps: 4 | Val loss: 0.2648 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
== Status ==
Current time: 2024-01-07 18:01:58 (running for 00:46:14.83)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.407 |  0.17  |                   66 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.343 |  0.147 |                   49 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.309 |  0.149 |                   41 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14656555652618408
[2m[36m(func pid=122291)[0m mae:  0.10360096395015717
[2m[36m(func pid=122291)[0m rmse_per_class: [0.082, 0.22, 0.05, 0.297, 0.063, 0.16, 0.242, 0.113, 0.141, 0.098]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4014 | Steps: 4 | Val loss: 0.3084 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=123603)[0m rmse: 0.1437748223543167
[2m[36m(func pid=123603)[0m mae:  0.0915444940328598
[2m[36m(func pid=123603)[0m rmse_per_class: [0.067, 0.212, 0.05, 0.27, 0.066, 0.154, 0.225, 0.113, 0.176, 0.104]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.16993381083011627
[2m[36m(func pid=117684)[0m mae:  0.12424926459789276
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.25, 0.079, 0.329, 0.08, 0.182, 0.28, 0.135, 0.142, 0.107]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3472 | Steps: 4 | Val loss: 0.2717 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2747 | Steps: 4 | Val loss: 0.2581 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 18:02:03 (running for 00:46:20.08)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.401 |  0.17  |                   67 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.347 |  0.147 |                   50 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.284 |  0.144 |                   42 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14742180705070496
[2m[36m(func pid=122291)[0m mae:  0.10431386530399323
[2m[36m(func pid=122291)[0m rmse_per_class: [0.083, 0.22, 0.049, 0.294, 0.066, 0.162, 0.246, 0.114, 0.141, 0.1]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4027 | Steps: 4 | Val loss: 0.3083 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=123603)[0m rmse: 0.13836508989334106
[2m[36m(func pid=123603)[0m mae:  0.08747343719005585
[2m[36m(func pid=123603)[0m rmse_per_class: [0.063, 0.208, 0.05, 0.256, 0.061, 0.152, 0.223, 0.112, 0.154, 0.104]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17003031075000763
[2m[36m(func pid=117684)[0m mae:  0.1243366226553917
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.249, 0.08, 0.329, 0.079, 0.183, 0.281, 0.135, 0.142, 0.108]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3450 | Steps: 4 | Val loss: 0.2737 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2946 | Steps: 4 | Val loss: 0.2578 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 18:02:08 (running for 00:46:25.40)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.403 |  0.17  |                   68 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.345 |  0.149 |                   51 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.275 |  0.138 |                   43 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14868980646133423
[2m[36m(func pid=122291)[0m mae:  0.10514155775308609
[2m[36m(func pid=122291)[0m rmse_per_class: [0.082, 0.221, 0.054, 0.3, 0.068, 0.16, 0.247, 0.114, 0.141, 0.1]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4003 | Steps: 4 | Val loss: 0.3093 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=123603)[0m rmse: 0.13893289864063263
[2m[36m(func pid=123603)[0m mae:  0.08711139857769012
[2m[36m(func pid=123603)[0m rmse_per_class: [0.064, 0.208, 0.054, 0.26, 0.067, 0.152, 0.222, 0.109, 0.144, 0.11]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3369 | Steps: 4 | Val loss: 0.2730 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=117684)[0m rmse: 0.17039278149604797
[2m[36m(func pid=117684)[0m mae:  0.12461872398853302
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.249, 0.08, 0.33, 0.08, 0.183, 0.281, 0.135, 0.142, 0.108]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.14834068715572357
[2m[36m(func pid=122291)[0m mae:  0.10492654889822006
[2m[36m(func pid=122291)[0m rmse_per_class: [0.081, 0.222, 0.052, 0.297, 0.066, 0.161, 0.245, 0.113, 0.145, 0.101]
[2m[36m(func pid=122291)[0m 
== Status ==
Current time: 2024-01-07 18:02:14 (running for 00:46:30.53)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.4   |  0.17  |                   69 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.337 |  0.148 |                   52 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.295 |  0.139 |                   44 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2804 | Steps: 4 | Val loss: 0.2667 | Batch size: 32 | lr: 0.1 | Duration: 3.26s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4014 | Steps: 4 | Val loss: 0.3087 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=123603)[0m rmse: 0.1454375833272934
[2m[36m(func pid=123603)[0m mae:  0.09132776409387589
[2m[36m(func pid=123603)[0m rmse_per_class: [0.068, 0.213, 0.064, 0.284, 0.067, 0.154, 0.22, 0.112, 0.158, 0.114]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3319 | Steps: 4 | Val loss: 0.2737 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=117684)[0m rmse: 0.1700941026210785
[2m[36m(func pid=117684)[0m mae:  0.12434548139572144
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.248, 0.08, 0.33, 0.08, 0.183, 0.281, 0.134, 0.142, 0.108]
[2m[36m(func pid=117684)[0m 
== Status ==
Current time: 2024-01-07 18:02:19 (running for 00:46:35.79)
Memory usage on this node: 22.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.401 |  0.17  |                   70 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.332 |  0.149 |                   53 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.28  |  0.145 |                   45 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14890269935131073
[2m[36m(func pid=122291)[0m mae:  0.10530565679073334
[2m[36m(func pid=122291)[0m rmse_per_class: [0.082, 0.223, 0.051, 0.297, 0.067, 0.16, 0.246, 0.113, 0.148, 0.103]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2757 | Steps: 4 | Val loss: 0.2727 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4004 | Steps: 4 | Val loss: 0.3082 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3313 | Steps: 4 | Val loss: 0.2721 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=123603)[0m rmse: 0.14709410071372986
[2m[36m(func pid=123603)[0m mae:  0.09318807721138
[2m[36m(func pid=123603)[0m rmse_per_class: [0.078, 0.214, 0.056, 0.304, 0.063, 0.153, 0.218, 0.122, 0.157, 0.106]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17003029584884644
[2m[36m(func pid=117684)[0m mae:  0.12433014065027237
[2m[36m(func pid=117684)[0m rmse_per_class: [0.115, 0.248, 0.08, 0.329, 0.079, 0.182, 0.281, 0.135, 0.142, 0.109]
[2m[36m(func pid=117684)[0m 
== Status ==
Current time: 2024-01-07 18:02:24 (running for 00:46:41.04)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.4   |  0.17  |                   71 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.331 |  0.148 |                   54 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.276 |  0.147 |                   46 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14765700697898865
[2m[36m(func pid=122291)[0m mae:  0.10446672141551971
[2m[36m(func pid=122291)[0m rmse_per_class: [0.082, 0.224, 0.048, 0.292, 0.067, 0.158, 0.246, 0.113, 0.149, 0.097]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3008 | Steps: 4 | Val loss: 0.2774 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4046 | Steps: 4 | Val loss: 0.3085 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3412 | Steps: 4 | Val loss: 0.2711 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=123603)[0m rmse: 0.15041688084602356
[2m[36m(func pid=123603)[0m mae:  0.09523453563451767
[2m[36m(func pid=123603)[0m rmse_per_class: [0.087, 0.211, 0.063, 0.311, 0.061, 0.153, 0.226, 0.129, 0.162, 0.102]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=117684)[0m rmse: 0.17009639739990234
[2m[36m(func pid=117684)[0m mae:  0.12431780993938446
[2m[36m(func pid=117684)[0m rmse_per_class: [0.113, 0.249, 0.081, 0.33, 0.078, 0.182, 0.281, 0.134, 0.143, 0.109]
[2m[36m(func pid=117684)[0m 
== Status ==
Current time: 2024-01-07 18:02:29 (running for 00:46:46.17)
Memory usage on this node: 22.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.405 |  0.17  |                   72 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.341 |  0.147 |                   55 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.301 |  0.15  |                   47 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14705924689769745
[2m[36m(func pid=122291)[0m mae:  0.10377988964319229
[2m[36m(func pid=122291)[0m rmse_per_class: [0.082, 0.223, 0.048, 0.29, 0.065, 0.159, 0.245, 0.113, 0.148, 0.098]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4029 | Steps: 4 | Val loss: 0.3083 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2859 | Steps: 4 | Val loss: 0.2723 | Batch size: 32 | lr: 0.1 | Duration: 3.20s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3364 | Steps: 4 | Val loss: 0.2682 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=117684)[0m rmse: 0.169875830411911
[2m[36m(func pid=117684)[0m mae:  0.12412355095148087
[2m[36m(func pid=117684)[0m rmse_per_class: [0.113, 0.249, 0.08, 0.33, 0.078, 0.183, 0.28, 0.134, 0.143, 0.109]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14778582751750946
[2m[36m(func pid=123603)[0m mae:  0.09367769956588745
[2m[36m(func pid=123603)[0m rmse_per_class: [0.074, 0.213, 0.066, 0.294, 0.072, 0.157, 0.238, 0.116, 0.155, 0.093]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.14500537514686584
[2m[36m(func pid=122291)[0m mae:  0.10204529762268066
[2m[36m(func pid=122291)[0m rmse_per_class: [0.082, 0.22, 0.046, 0.282, 0.065, 0.157, 0.247, 0.112, 0.144, 0.096]
[2m[36m(func pid=122291)[0m 
== Status ==
Current time: 2024-01-07 18:02:34 (running for 00:46:51.39)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.403 |  0.17  |                   73 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.336 |  0.145 |                   56 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.286 |  0.148 |                   48 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3963 | Steps: 4 | Val loss: 0.3085 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2867 | Steps: 4 | Val loss: 0.2652 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3448 | Steps: 4 | Val loss: 0.2684 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=117684)[0m rmse: 0.1701158732175827
[2m[36m(func pid=117684)[0m mae:  0.12442080676555634
[2m[36m(func pid=117684)[0m rmse_per_class: [0.114, 0.25, 0.08, 0.33, 0.078, 0.182, 0.28, 0.135, 0.144, 0.108]
[2m[36m(func pid=117684)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.1433834731578827
[2m[36m(func pid=123603)[0m mae:  0.090571828186512
[2m[36m(func pid=123603)[0m rmse_per_class: [0.065, 0.207, 0.055, 0.275, 0.078, 0.159, 0.234, 0.11, 0.149, 0.102]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 18:02:40 (running for 00:46:56.61)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00021 | RUNNING    | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.396 |  0.17  |                   74 |
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.345 |  0.145 |                   57 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.287 |  0.143 |                   49 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14528927206993103
[2m[36m(func pid=122291)[0m mae:  0.10226938873529434
[2m[36m(func pid=122291)[0m rmse_per_class: [0.085, 0.219, 0.048, 0.283, 0.063, 0.159, 0.245, 0.113, 0.145, 0.094]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=117684)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4018 | Steps: 4 | Val loss: 0.3078 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2923 | Steps: 4 | Val loss: 0.2580 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3462 | Steps: 4 | Val loss: 0.2687 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=117684)[0m rmse: 0.169703871011734
[2m[36m(func pid=117684)[0m mae:  0.12405569851398468
[2m[36m(func pid=117684)[0m rmse_per_class: [0.114, 0.248, 0.079, 0.33, 0.079, 0.183, 0.28, 0.134, 0.144, 0.108]
[2m[36m(func pid=123603)[0m rmse: 0.13893994688987732
[2m[36m(func pid=123603)[0m mae:  0.08645062148571014
[2m[36m(func pid=123603)[0m rmse_per_class: [0.063, 0.208, 0.044, 0.256, 0.073, 0.152, 0.215, 0.11, 0.15, 0.118]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 18:02:45 (running for 00:47:01.69)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14925000444054604
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.346 |  0.145 |                   58 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.292 |  0.139 |                   50 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.1451779454946518
[2m[36m(func pid=122291)[0m mae:  0.10210319608449936
[2m[36m(func pid=122291)[0m rmse_per_class: [0.087, 0.218, 0.049, 0.286, 0.062, 0.157, 0.244, 0.113, 0.144, 0.092]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3403 | Steps: 4 | Val loss: 0.2675 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2979 | Steps: 4 | Val loss: 0.2595 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 18:02:50 (running for 00:47:06.70)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14925000444054604
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.346 |  0.145 |                   58 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.292 |  0.139 |                   50 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14407792687416077
[2m[36m(func pid=122291)[0m mae:  0.10104607045650482
[2m[36m(func pid=122291)[0m rmse_per_class: [0.083, 0.219, 0.046, 0.287, 0.063, 0.156, 0.241, 0.113, 0.14, 0.092]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14011827111244202
[2m[36m(func pid=123603)[0m mae:  0.08736453205347061
[2m[36m(func pid=123603)[0m rmse_per_class: [0.063, 0.212, 0.042, 0.256, 0.064, 0.153, 0.212, 0.111, 0.16, 0.129]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3254 | Steps: 4 | Val loss: 0.2685 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2725 | Steps: 4 | Val loss: 0.2662 | Batch size: 32 | lr: 0.1 | Duration: 3.21s
== Status ==
Current time: 2024-01-07 18:02:55 (running for 00:47:11.99)
Memory usage on this node: 19.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14925000444054604
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.34  |  0.144 |                   59 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.298 |  0.14  |                   51 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14474783837795258
[2m[36m(func pid=122291)[0m mae:  0.10145829617977142
[2m[36m(func pid=122291)[0m rmse_per_class: [0.084, 0.22, 0.047, 0.291, 0.063, 0.155, 0.241, 0.113, 0.141, 0.094]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14493630826473236
[2m[36m(func pid=123603)[0m mae:  0.09081624448299408
[2m[36m(func pid=123603)[0m rmse_per_class: [0.065, 0.207, 0.065, 0.275, 0.062, 0.154, 0.219, 0.112, 0.168, 0.122]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3258 | Steps: 4 | Val loss: 0.2692 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2793 | Steps: 4 | Val loss: 0.2765 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 18:03:01 (running for 00:47:17.58)
Memory usage on this node: 19.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14925000444054604
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.325 |  0.145 |                   60 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.273 |  0.145 |                   52 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.1453123241662979
[2m[36m(func pid=122291)[0m mae:  0.10187840461730957
[2m[36m(func pid=122291)[0m rmse_per_class: [0.086, 0.219, 0.048, 0.293, 0.065, 0.154, 0.244, 0.112, 0.139, 0.093]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.15193532407283783
[2m[36m(func pid=123603)[0m mae:  0.09529708325862885
[2m[36m(func pid=123603)[0m rmse_per_class: [0.066, 0.211, 0.08, 0.29, 0.059, 0.155, 0.232, 0.12, 0.165, 0.143]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3319 | Steps: 4 | Val loss: 0.2686 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3038 | Steps: 4 | Val loss: 0.2731 | Batch size: 32 | lr: 0.1 | Duration: 3.26s
== Status ==
Current time: 2024-01-07 18:03:06 (running for 00:47:23.06)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14925000444054604
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.332 |  0.145 |                   62 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.279 |  0.152 |                   53 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14501139521598816
[2m[36m(func pid=122291)[0m mae:  0.10159827768802643
[2m[36m(func pid=122291)[0m rmse_per_class: [0.087, 0.218, 0.048, 0.29, 0.065, 0.155, 0.245, 0.112, 0.14, 0.093]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14973053336143494
[2m[36m(func pid=123603)[0m mae:  0.09388839453458786
[2m[36m(func pid=123603)[0m rmse_per_class: [0.071, 0.213, 0.068, 0.283, 0.06, 0.154, 0.233, 0.119, 0.154, 0.142]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3368 | Steps: 4 | Val loss: 0.2676 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2721 | Steps: 4 | Val loss: 0.2735 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 18:03:11 (running for 00:47:28.28)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14925000444054604
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.337 |  0.144 |                   63 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.304 |  0.15  |                   54 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.1444491595029831
[2m[36m(func pid=122291)[0m mae:  0.10118062794208527
[2m[36m(func pid=122291)[0m rmse_per_class: [0.085, 0.22, 0.046, 0.288, 0.065, 0.154, 0.242, 0.112, 0.141, 0.091]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14880260825157166
[2m[36m(func pid=123603)[0m mae:  0.09378752112388611
[2m[36m(func pid=123603)[0m rmse_per_class: [0.066, 0.211, 0.053, 0.285, 0.058, 0.154, 0.224, 0.114, 0.199, 0.124]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3280 | Steps: 4 | Val loss: 0.2668 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2820 | Steps: 4 | Val loss: 0.2676 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 18:03:17 (running for 00:47:33.75)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14925000444054604
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.328 |  0.144 |                   64 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.272 |  0.149 |                   55 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14398837089538574
[2m[36m(func pid=122291)[0m mae:  0.10066588968038559
[2m[36m(func pid=122291)[0m rmse_per_class: [0.083, 0.22, 0.047, 0.286, 0.065, 0.154, 0.241, 0.112, 0.139, 0.092]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.1457832306623459
[2m[36m(func pid=123603)[0m mae:  0.09150280803442001
[2m[36m(func pid=123603)[0m rmse_per_class: [0.065, 0.214, 0.052, 0.268, 0.059, 0.154, 0.223, 0.113, 0.192, 0.119]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3194 | Steps: 4 | Val loss: 0.2656 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2627 | Steps: 4 | Val loss: 0.2581 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 18:03:22 (running for 00:47:39.26)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14925000444054604
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.319 |  0.143 |                   65 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.282 |  0.146 |                   56 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14324221014976501
[2m[36m(func pid=122291)[0m mae:  0.09983975440263748
[2m[36m(func pid=122291)[0m rmse_per_class: [0.081, 0.219, 0.048, 0.283, 0.066, 0.154, 0.24, 0.111, 0.137, 0.092]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.1383787989616394
[2m[36m(func pid=123603)[0m mae:  0.086246058344841
[2m[36m(func pid=123603)[0m rmse_per_class: [0.065, 0.213, 0.044, 0.25, 0.059, 0.154, 0.225, 0.112, 0.153, 0.109]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3329 | Steps: 4 | Val loss: 0.2646 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2953 | Steps: 4 | Val loss: 0.2585 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 18:03:28 (running for 00:47:44.69)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14925000444054604
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.333 |  0.143 |                   66 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.263 |  0.138 |                   57 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14253228902816772
[2m[36m(func pid=122291)[0m mae:  0.09912914782762527
[2m[36m(func pid=122291)[0m rmse_per_class: [0.08, 0.219, 0.05, 0.28, 0.065, 0.154, 0.239, 0.111, 0.136, 0.091]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.13913019001483917
[2m[36m(func pid=123603)[0m mae:  0.08587132394313812
[2m[36m(func pid=123603)[0m rmse_per_class: [0.066, 0.212, 0.042, 0.25, 0.063, 0.157, 0.233, 0.115, 0.142, 0.111]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3386 | Steps: 4 | Val loss: 0.2655 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2985 | Steps: 4 | Val loss: 0.2684 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 18:03:33 (running for 00:47:49.93)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14925000444054604
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.339 |  0.143 |                   67 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.295 |  0.139 |                   58 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14329716563224792
[2m[36m(func pid=122291)[0m mae:  0.09979553520679474
[2m[36m(func pid=122291)[0m rmse_per_class: [0.08, 0.218, 0.054, 0.28, 0.067, 0.154, 0.241, 0.111, 0.137, 0.091]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14763565361499786
[2m[36m(func pid=123603)[0m mae:  0.09094987064599991
[2m[36m(func pid=123603)[0m rmse_per_class: [0.067, 0.215, 0.046, 0.27, 0.089, 0.16, 0.237, 0.118, 0.145, 0.128]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3353 | Steps: 4 | Val loss: 0.2666 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2951 | Steps: 4 | Val loss: 0.2768 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=122291)[0m rmse: 0.14397114515304565
[2m[36m(func pid=122291)[0m mae:  0.10025908797979355
[2m[36m(func pid=122291)[0m rmse_per_class: [0.077, 0.219, 0.055, 0.282, 0.065, 0.154, 0.242, 0.111, 0.14, 0.094]
== Status ==
Current time: 2024-01-07 18:03:39 (running for 00:47:55.47)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14925000444054604
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.335 |  0.144 |                   68 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.298 |  0.148 |                   59 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.1523849070072174
[2m[36m(func pid=123603)[0m mae:  0.09462235867977142
[2m[36m(func pid=123603)[0m rmse_per_class: [0.076, 0.221, 0.057, 0.295, 0.091, 0.159, 0.237, 0.114, 0.152, 0.122]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3267 | Steps: 4 | Val loss: 0.2681 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2729 | Steps: 4 | Val loss: 0.2761 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
== Status ==
Current time: 2024-01-07 18:03:44 (running for 00:48:00.74)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14925000444054604
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.327 |  0.145 |                   69 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.295 |  0.152 |                   60 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14510759711265564
[2m[36m(func pid=122291)[0m mae:  0.10113583505153656
[2m[36m(func pid=122291)[0m rmse_per_class: [0.079, 0.219, 0.059, 0.285, 0.065, 0.155, 0.242, 0.111, 0.144, 0.092]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.15085533261299133
[2m[36m(func pid=123603)[0m mae:  0.09407498687505722
[2m[36m(func pid=123603)[0m rmse_per_class: [0.072, 0.217, 0.059, 0.302, 0.077, 0.157, 0.228, 0.117, 0.166, 0.114]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3271 | Steps: 4 | Val loss: 0.2686 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2848 | Steps: 4 | Val loss: 0.2707 | Batch size: 32 | lr: 0.1 | Duration: 3.22s
== Status ==
Current time: 2024-01-07 18:03:49 (running for 00:48:06.20)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14925000444054604
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.327 |  0.145 |                   70 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.273 |  0.151 |                   61 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14545339345932007
[2m[36m(func pid=122291)[0m mae:  0.10153913497924805
[2m[36m(func pid=122291)[0m rmse_per_class: [0.081, 0.218, 0.056, 0.285, 0.065, 0.154, 0.245, 0.111, 0.146, 0.092]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14638644456863403
[2m[36m(func pid=123603)[0m mae:  0.09215806424617767
[2m[36m(func pid=123603)[0m rmse_per_class: [0.067, 0.212, 0.048, 0.287, 0.064, 0.155, 0.225, 0.12, 0.178, 0.109]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3292 | Steps: 4 | Val loss: 0.2701 | Batch size: 32 | lr: 0.01 | Duration: 3.16s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2931 | Steps: 4 | Val loss: 0.2698 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
== Status ==
Current time: 2024-01-07 18:03:55 (running for 00:48:11.85)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14925000444054604
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.329 |  0.146 |                   71 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.285 |  0.146 |                   62 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14620967209339142
[2m[36m(func pid=122291)[0m mae:  0.10218481719493866
[2m[36m(func pid=122291)[0m rmse_per_class: [0.078, 0.221, 0.054, 0.294, 0.062, 0.154, 0.242, 0.11, 0.154, 0.092]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.1465807855129242
[2m[36m(func pid=123603)[0m mae:  0.0924295037984848
[2m[36m(func pid=123603)[0m rmse_per_class: [0.069, 0.212, 0.055, 0.281, 0.057, 0.156, 0.23, 0.118, 0.182, 0.105]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3289 | Steps: 4 | Val loss: 0.2700 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2803 | Steps: 4 | Val loss: 0.2692 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=122291)[0m rmse: 0.14607807993888855
[2m[36m(func pid=122291)[0m mae:  0.10214994102716446
[2m[36m(func pid=122291)[0m rmse_per_class: [0.077, 0.219, 0.052, 0.294, 0.063, 0.155, 0.243, 0.11, 0.155, 0.093]
[2m[36m(func pid=122291)[0m 
== Status ==
Current time: 2024-01-07 18:04:00 (running for 00:48:17.19)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14925000444054604
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.329 |  0.146 |                   72 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.293 |  0.147 |                   63 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=123603)[0m rmse: 0.14718396961688995
[2m[36m(func pid=123603)[0m mae:  0.09211887419223785
[2m[36m(func pid=123603)[0m rmse_per_class: [0.07, 0.215, 0.059, 0.279, 0.059, 0.168, 0.235, 0.117, 0.16, 0.109]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3247 | Steps: 4 | Val loss: 0.2687 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2906 | Steps: 4 | Val loss: 0.2704 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 18:04:06 (running for 00:48:22.51)
Memory usage on this node: 19.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14925000444054604
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.325 |  0.145 |                   73 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.28  |  0.147 |                   64 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14503999054431915
[2m[36m(func pid=122291)[0m mae:  0.10111856460571289
[2m[36m(func pid=122291)[0m rmse_per_class: [0.076, 0.218, 0.049, 0.292, 0.061, 0.155, 0.241, 0.11, 0.155, 0.095]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.1483003795146942
[2m[36m(func pid=123603)[0m mae:  0.09217841178178787
[2m[36m(func pid=123603)[0m rmse_per_class: [0.07, 0.216, 0.066, 0.287, 0.068, 0.166, 0.233, 0.114, 0.146, 0.117]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3354 | Steps: 4 | Val loss: 0.2686 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2688 | Steps: 4 | Val loss: 0.2698 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 18:04:11 (running for 00:48:28.00)
Memory usage on this node: 19.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14925000444054604
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.335 |  0.145 |                   74 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.291 |  0.148 |                   65 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14494994282722473
[2m[36m(func pid=122291)[0m mae:  0.10093627870082855
[2m[36m(func pid=122291)[0m rmse_per_class: [0.076, 0.219, 0.046, 0.293, 0.061, 0.154, 0.24, 0.111, 0.154, 0.095]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14748838543891907
[2m[36m(func pid=123603)[0m mae:  0.09108293056488037
[2m[36m(func pid=123603)[0m rmse_per_class: [0.07, 0.216, 0.065, 0.288, 0.069, 0.162, 0.227, 0.111, 0.142, 0.125]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3227 | Steps: 4 | Val loss: 0.2678 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 18:04:16 (running for 00:48:33.39)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.323 |  0.145 |                   75 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.269 |  0.147 |                   66 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.1445508897304535
[2m[36m(func pid=122291)[0m mae:  0.1006736308336258
[2m[36m(func pid=122291)[0m rmse_per_class: [0.078, 0.217, 0.044, 0.291, 0.062, 0.155, 0.24, 0.111, 0.152, 0.095]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2850 | Steps: 4 | Val loss: 0.2641 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=123603)[0m rmse: 0.14327743649482727
[2m[36m(func pid=123603)[0m mae:  0.08814671635627747
[2m[36m(func pid=123603)[0m rmse_per_class: [0.069, 0.217, 0.062, 0.275, 0.069, 0.155, 0.222, 0.109, 0.137, 0.117]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.3257 | Steps: 4 | Val loss: 0.2670 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 18:04:22 (running for 00:48:38.86)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.326 |  0.144 |                   76 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.285 |  0.143 |                   67 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14394651353359222
[2m[36m(func pid=122291)[0m mae:  0.1000865250825882
[2m[36m(func pid=122291)[0m rmse_per_class: [0.082, 0.217, 0.043, 0.29, 0.061, 0.154, 0.24, 0.11, 0.149, 0.094]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2692 | Steps: 4 | Val loss: 0.2682 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
[2m[36m(func pid=123603)[0m rmse: 0.14540903270244598
[2m[36m(func pid=123603)[0m mae:  0.09024502336978912
[2m[36m(func pid=123603)[0m rmse_per_class: [0.075, 0.216, 0.058, 0.274, 0.062, 0.156, 0.228, 0.114, 0.145, 0.126]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.3163 | Steps: 4 | Val loss: 0.2670 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 18:04:27 (running for 00:48:44.24)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.316 |  0.144 |                   77 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.269 |  0.145 |                   68 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14418166875839233
[2m[36m(func pid=122291)[0m mae:  0.10032616555690765
[2m[36m(func pid=122291)[0m rmse_per_class: [0.083, 0.218, 0.043, 0.287, 0.061, 0.154, 0.242, 0.11, 0.15, 0.094]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3192 | Steps: 4 | Val loss: 0.2754 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.3226 | Steps: 4 | Val loss: 0.2646 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=123603)[0m rmse: 0.14978908002376556
[2m[36m(func pid=123603)[0m mae:  0.0935322642326355
[2m[36m(func pid=123603)[0m rmse_per_class: [0.071, 0.224, 0.077, 0.294, 0.065, 0.154, 0.234, 0.115, 0.149, 0.115]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 18:04:33 (running for 00:48:49.65)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.323 |  0.142 |                   78 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.319 |  0.15  |                   69 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14243540167808533
[2m[36m(func pid=122291)[0m mae:  0.09897534549236298
[2m[36m(func pid=122291)[0m rmse_per_class: [0.079, 0.217, 0.042, 0.281, 0.062, 0.153, 0.243, 0.11, 0.147, 0.091]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2752 | Steps: 4 | Val loss: 0.2734 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.3313 | Steps: 4 | Val loss: 0.2639 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=123603)[0m rmse: 0.15083017945289612
[2m[36m(func pid=123603)[0m mae:  0.09365078806877136
[2m[36m(func pid=123603)[0m rmse_per_class: [0.069, 0.214, 0.11, 0.286, 0.063, 0.155, 0.229, 0.113, 0.155, 0.114]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 18:04:38 (running for 00:48:55.10)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.331 |  0.142 |                   79 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.275 |  0.151 |                   70 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14206859469413757
[2m[36m(func pid=122291)[0m mae:  0.09859515726566315
[2m[36m(func pid=122291)[0m rmse_per_class: [0.081, 0.216, 0.043, 0.278, 0.062, 0.153, 0.242, 0.11, 0.144, 0.091]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2773 | Steps: 4 | Val loss: 0.2763 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.3250 | Steps: 4 | Val loss: 0.2657 | Batch size: 32 | lr: 0.01 | Duration: 3.14s
[2m[36m(func pid=123603)[0m rmse: 0.15208160877227783
[2m[36m(func pid=123603)[0m mae:  0.09441535174846649
[2m[36m(func pid=123603)[0m rmse_per_class: [0.067, 0.224, 0.118, 0.292, 0.068, 0.155, 0.22, 0.115, 0.154, 0.109]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.14353352785110474
[2m[36m(func pid=122291)[0m mae:  0.09938008338212967
[2m[36m(func pid=122291)[0m rmse_per_class: [0.082, 0.218, 0.047, 0.286, 0.064, 0.154, 0.239, 0.11, 0.143, 0.092]
== Status ==
Current time: 2024-01-07 18:04:44 (running for 00:49:00.67)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.325 |  0.144 |                   80 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.277 |  0.152 |                   71 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3043 | Steps: 4 | Val loss: 0.2778 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.3220 | Steps: 4 | Val loss: 0.2642 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=123603)[0m rmse: 0.15264567732810974
[2m[36m(func pid=123603)[0m mae:  0.09487120807170868
[2m[36m(func pid=123603)[0m rmse_per_class: [0.069, 0.225, 0.094, 0.291, 0.068, 0.153, 0.223, 0.13, 0.169, 0.104]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 18:04:49 (running for 00:49:06.06)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.322 |  0.142 |                   81 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.304 |  0.153 |                   72 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.1423535943031311
[2m[36m(func pid=122291)[0m mae:  0.09839602559804916
[2m[36m(func pid=122291)[0m rmse_per_class: [0.079, 0.218, 0.043, 0.281, 0.066, 0.154, 0.239, 0.11, 0.14, 0.093]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2586 | Steps: 4 | Val loss: 0.2740 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.3358 | Steps: 4 | Val loss: 0.2651 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=123603)[0m rmse: 0.15127457678318024
[2m[36m(func pid=123603)[0m mae:  0.09437929838895798
[2m[36m(func pid=123603)[0m rmse_per_class: [0.07, 0.216, 0.09, 0.28, 0.066, 0.155, 0.235, 0.123, 0.18, 0.097]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 18:04:55 (running for 00:49:11.48)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.336 |  0.143 |                   82 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.259 |  0.151 |                   73 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14287365972995758
[2m[36m(func pid=122291)[0m mae:  0.09876801073551178
[2m[36m(func pid=122291)[0m rmse_per_class: [0.076, 0.22, 0.044, 0.287, 0.062, 0.154, 0.233, 0.111, 0.142, 0.1]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2552 | Steps: 4 | Val loss: 0.2711 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.3242 | Steps: 4 | Val loss: 0.2646 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=123603)[0m rmse: 0.14860758185386658
[2m[36m(func pid=123603)[0m mae:  0.09295104444026947
[2m[36m(func pid=123603)[0m rmse_per_class: [0.076, 0.216, 0.071, 0.279, 0.064, 0.156, 0.241, 0.118, 0.161, 0.104]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 18:05:00 (running for 00:49:16.99)
Memory usage on this node: 19.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14900000393390656
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.324 |  0.142 |                   83 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.255 |  0.149 |                   74 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.1424061506986618
[2m[36m(func pid=122291)[0m mae:  0.09809863567352295
[2m[36m(func pid=122291)[0m rmse_per_class: [0.076, 0.22, 0.043, 0.287, 0.061, 0.153, 0.23, 0.111, 0.141, 0.101]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2870 | Steps: 4 | Val loss: 0.2710 | Batch size: 32 | lr: 0.1 | Duration: 3.20s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.3209 | Steps: 4 | Val loss: 0.2670 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=123603)[0m rmse: 0.14564761519432068
[2m[36m(func pid=123603)[0m mae:  0.09088581800460815
[2m[36m(func pid=123603)[0m rmse_per_class: [0.074, 0.223, 0.051, 0.289, 0.061, 0.156, 0.233, 0.111, 0.152, 0.107]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.14425553381443024
[2m[36m(func pid=122291)[0m mae:  0.09932763874530792
[2m[36m(func pid=122291)[0m rmse_per_class: [0.078, 0.219, 0.047, 0.295, 0.065, 0.154, 0.232, 0.11, 0.141, 0.102]
[2m[36m(func pid=122291)[0m 
== Status ==
Current time: 2024-01-07 18:05:05 (running for 00:49:22.23)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.321 |  0.144 |                   84 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.287 |  0.146 |                   75 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2647 | Steps: 4 | Val loss: 0.2710 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.3245 | Steps: 4 | Val loss: 0.2670 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=123603)[0m rmse: 0.14561916887760162
[2m[36m(func pid=123603)[0m mae:  0.09085696935653687
[2m[36m(func pid=123603)[0m rmse_per_class: [0.087, 0.219, 0.045, 0.293, 0.06, 0.156, 0.228, 0.11, 0.16, 0.099]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 18:05:11 (running for 00:49:27.75)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.324 |  0.144 |                   85 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.265 |  0.146 |                   76 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14415469765663147
[2m[36m(func pid=122291)[0m mae:  0.09922506660223007
[2m[36m(func pid=122291)[0m rmse_per_class: [0.078, 0.218, 0.046, 0.295, 0.065, 0.153, 0.233, 0.11, 0.14, 0.104]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2663 | Steps: 4 | Val loss: 0.2729 | Batch size: 32 | lr: 0.1 | Duration: 3.20s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.3173 | Steps: 4 | Val loss: 0.2671 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=123603)[0m rmse: 0.1483553797006607
[2m[36m(func pid=123603)[0m mae:  0.09232492744922638
[2m[36m(func pid=123603)[0m rmse_per_class: [0.079, 0.216, 0.056, 0.295, 0.062, 0.158, 0.224, 0.111, 0.177, 0.106]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 18:05:16 (running for 00:49:33.20)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.317 |  0.144 |                   86 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.266 |  0.148 |                   77 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14425261318683624
[2m[36m(func pid=122291)[0m mae:  0.09942004084587097
[2m[36m(func pid=122291)[0m rmse_per_class: [0.076, 0.218, 0.046, 0.294, 0.067, 0.153, 0.234, 0.11, 0.14, 0.104]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2827 | Steps: 4 | Val loss: 0.2746 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.3415 | Steps: 4 | Val loss: 0.2669 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=123603)[0m rmse: 0.15106011927127838
[2m[36m(func pid=123603)[0m mae:  0.09336420893669128
[2m[36m(func pid=123603)[0m rmse_per_class: [0.066, 0.22, 0.07, 0.286, 0.062, 0.159, 0.225, 0.111, 0.178, 0.133]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 18:05:22 (running for 00:49:38.53)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.341 |  0.144 |                   87 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.283 |  0.151 |                   78 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14402565360069275
[2m[36m(func pid=122291)[0m mae:  0.09948135912418365
[2m[36m(func pid=122291)[0m rmse_per_class: [0.077, 0.219, 0.044, 0.296, 0.069, 0.153, 0.234, 0.11, 0.141, 0.098]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2785 | Steps: 4 | Val loss: 0.2789 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.3243 | Steps: 4 | Val loss: 0.2666 | Batch size: 32 | lr: 0.01 | Duration: 3.16s
[2m[36m(func pid=123603)[0m rmse: 0.1542438566684723
[2m[36m(func pid=123603)[0m mae:  0.09595735371112823
[2m[36m(func pid=123603)[0m rmse_per_class: [0.067, 0.22, 0.074, 0.288, 0.067, 0.16, 0.232, 0.112, 0.194, 0.13]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 18:05:27 (running for 00:49:44.08)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.324 |  0.144 |                   88 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.279 |  0.154 |                   79 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14387653768062592
[2m[36m(func pid=122291)[0m mae:  0.09913718700408936
[2m[36m(func pid=122291)[0m rmse_per_class: [0.076, 0.218, 0.045, 0.294, 0.069, 0.153, 0.235, 0.109, 0.14, 0.099]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2667 | Steps: 4 | Val loss: 0.2725 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.3174 | Steps: 4 | Val loss: 0.2668 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=123603)[0m rmse: 0.14894726872444153
[2m[36m(func pid=123603)[0m mae:  0.0922345444560051
[2m[36m(func pid=123603)[0m rmse_per_class: [0.065, 0.212, 0.063, 0.28, 0.063, 0.156, 0.229, 0.118, 0.184, 0.118]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 18:05:32 (running for 00:49:49.19)
Memory usage on this node: 19.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.317 |  0.144 |                   89 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.267 |  0.149 |                   80 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14409735798835754
[2m[36m(func pid=122291)[0m mae:  0.09919992834329605
[2m[36m(func pid=122291)[0m rmse_per_class: [0.077, 0.216, 0.049, 0.292, 0.066, 0.153, 0.236, 0.11, 0.143, 0.1]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2597 | Steps: 4 | Val loss: 0.2655 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.3277 | Steps: 4 | Val loss: 0.2668 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=123603)[0m rmse: 0.14363634586334229
[2m[36m(func pid=123603)[0m mae:  0.08928932249546051
[2m[36m(func pid=123603)[0m rmse_per_class: [0.071, 0.212, 0.049, 0.269, 0.059, 0.155, 0.232, 0.128, 0.157, 0.105]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 18:05:38 (running for 00:49:54.62)
Memory usage on this node: 19.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.328 |  0.144 |                   90 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.26  |  0.144 |                   81 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.1441417634487152
[2m[36m(func pid=122291)[0m mae:  0.0991746038198471
[2m[36m(func pid=122291)[0m rmse_per_class: [0.079, 0.217, 0.05, 0.292, 0.062, 0.152, 0.234, 0.11, 0.146, 0.099]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2864 | Steps: 4 | Val loss: 0.2641 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.3230 | Steps: 4 | Val loss: 0.2688 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=123603)[0m rmse: 0.14264033734798431
[2m[36m(func pid=123603)[0m mae:  0.0886651873588562
[2m[36m(func pid=123603)[0m rmse_per_class: [0.075, 0.213, 0.037, 0.266, 0.061, 0.157, 0.228, 0.126, 0.149, 0.115]
[2m[36m(func pid=123603)[0m 
== Status ==
Current time: 2024-01-07 18:05:43 (running for 00:49:59.85)
Memory usage on this node: 19.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.323 |  0.146 |                   91 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.286 |  0.143 |                   82 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14584681391716003
[2m[36m(func pid=122291)[0m mae:  0.10057829320430756
[2m[36m(func pid=122291)[0m rmse_per_class: [0.079, 0.219, 0.055, 0.293, 0.065, 0.153, 0.235, 0.11, 0.15, 0.101]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2633 | Steps: 4 | Val loss: 0.2701 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.3195 | Steps: 4 | Val loss: 0.2675 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 18:05:48 (running for 00:50:04.87)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.323 |  0.146 |                   91 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.286 |  0.143 |                   82 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=123603)[0m rmse: 0.14702141284942627
[2m[36m(func pid=123603)[0m mae:  0.09134391695261002
[2m[36m(func pid=123603)[0m rmse_per_class: [0.076, 0.216, 0.036, 0.274, 0.061, 0.159, 0.226, 0.116, 0.18, 0.126]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m rmse: 0.14504270255565643
[2m[36m(func pid=122291)[0m mae:  0.09972865879535675
[2m[36m(func pid=122291)[0m rmse_per_class: [0.078, 0.218, 0.052, 0.29, 0.065, 0.153, 0.236, 0.11, 0.147, 0.103]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.3278 | Steps: 4 | Val loss: 0.2671 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2627 | Steps: 4 | Val loss: 0.2744 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
== Status ==
Current time: 2024-01-07 18:05:53 (running for 00:50:10.29)
Memory usage on this node: 19.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.319 |  0.145 |                   92 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.263 |  0.147 |                   83 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14442621171474457
[2m[36m(func pid=122291)[0m mae:  0.0992048978805542
[2m[36m(func pid=122291)[0m rmse_per_class: [0.077, 0.216, 0.051, 0.29, 0.064, 0.152, 0.234, 0.11, 0.148, 0.102]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.14997096359729767
[2m[36m(func pid=123603)[0m mae:  0.09268775582313538
[2m[36m(func pid=123603)[0m rmse_per_class: [0.072, 0.218, 0.036, 0.277, 0.062, 0.16, 0.226, 0.115, 0.19, 0.145]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.3178 | Steps: 4 | Val loss: 0.2653 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2974 | Steps: 4 | Val loss: 0.2745 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
== Status ==
Current time: 2024-01-07 18:05:59 (running for 00:50:15.73)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.328 |  0.144 |                   93 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.263 |  0.15  |                   84 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14323419332504272
[2m[36m(func pid=122291)[0m mae:  0.098299041390419
[2m[36m(func pid=122291)[0m rmse_per_class: [0.075, 0.215, 0.05, 0.287, 0.066, 0.153, 0.234, 0.109, 0.146, 0.099]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.1500486135482788
[2m[36m(func pid=123603)[0m mae:  0.0920749232172966
[2m[36m(func pid=123603)[0m rmse_per_class: [0.07, 0.216, 0.037, 0.273, 0.063, 0.159, 0.224, 0.115, 0.203, 0.14]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.3255 | Steps: 4 | Val loss: 0.2636 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2847 | Steps: 4 | Val loss: 0.2765 | Batch size: 32 | lr: 0.1 | Duration: 3.28s
== Status ==
Current time: 2024-01-07 18:06:04 (running for 00:50:21.39)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.318 |  0.143 |                   94 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.297 |  0.15  |                   85 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14208026230335236
[2m[36m(func pid=122291)[0m mae:  0.09729716926813126
[2m[36m(func pid=122291)[0m rmse_per_class: [0.073, 0.215, 0.044, 0.282, 0.067, 0.153, 0.234, 0.109, 0.141, 0.102]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.1528538465499878
[2m[36m(func pid=123603)[0m mae:  0.0936862975358963
[2m[36m(func pid=123603)[0m rmse_per_class: [0.069, 0.216, 0.045, 0.275, 0.078, 0.163, 0.234, 0.114, 0.199, 0.136]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.3242 | Steps: 4 | Val loss: 0.2646 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2690 | Steps: 4 | Val loss: 0.2782 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
== Status ==
Current time: 2024-01-07 18:06:10 (running for 00:50:27.01)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.324 |  0.143 |                   96 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.285 |  0.153 |                   86 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.14293266832828522
[2m[36m(func pid=122291)[0m mae:  0.09785439819097519
[2m[36m(func pid=122291)[0m rmse_per_class: [0.075, 0.215, 0.047, 0.285, 0.067, 0.153, 0.231, 0.109, 0.143, 0.103]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.154793381690979
[2m[36m(func pid=123603)[0m mae:  0.09539087116718292
[2m[36m(func pid=123603)[0m rmse_per_class: [0.09, 0.217, 0.058, 0.281, 0.077, 0.165, 0.242, 0.115, 0.18, 0.123]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.3227 | Steps: 4 | Val loss: 0.2639 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2816 | Steps: 4 | Val loss: 0.2782 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 18:06:15 (running for 00:50:32.37)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.323 |  0.142 |                   97 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.269 |  0.155 |                   87 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)

[2m[36m(func pid=122291)[0m rmse: 0.14243802428245544

[2m[36m(func pid=122291)[0m mae:  0.0974988117814064
[2m[36m(func pid=122291)[0m rmse_per_class: [0.073, 0.216, 0.047, 0.285, 0.067, 0.153, 0.23, 0.11, 0.142, 0.101]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.15382248163223267
[2m[36m(func pid=123603)[0m mae:  0.09507174789905548
[2m[36m(func pid=123603)[0m rmse_per_class: [0.087, 0.218, 0.067, 0.29, 0.081, 0.164, 0.236, 0.113, 0.172, 0.111]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.3205 | Steps: 4 | Val loss: 0.2630 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2674 | Steps: 4 | Val loss: 0.2821 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 18:06:21 (running for 00:50:37.86)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.321 |  0.142 |                   98 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.282 |  0.154 |                   88 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.1420784741640091
[2m[36m(func pid=122291)[0m mae:  0.09709098935127258
[2m[36m(func pid=122291)[0m rmse_per_class: [0.073, 0.216, 0.046, 0.281, 0.067, 0.154, 0.23, 0.11, 0.14, 0.105]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.15437021851539612
[2m[36m(func pid=123603)[0m mae:  0.09539748728275299
[2m[36m(func pid=123603)[0m rmse_per_class: [0.074, 0.221, 0.071, 0.299, 0.07, 0.161, 0.233, 0.114, 0.183, 0.118]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.3194 | Steps: 4 | Val loss: 0.2637 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2689 | Steps: 4 | Val loss: 0.2790 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 18:06:26 (running for 00:50:43.09)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00022 | RUNNING    | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.319 |  0.143 |                   99 |
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.267 |  0.154 |                   89 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=122291)[0m rmse: 0.1426076591014862
[2m[36m(func pid=122291)[0m mae:  0.09746924787759781
[2m[36m(func pid=122291)[0m rmse_per_class: [0.073, 0.216, 0.049, 0.281, 0.066, 0.154, 0.23, 0.11, 0.142, 0.104]
[2m[36m(func pid=122291)[0m 
[2m[36m(func pid=123603)[0m rmse: 0.15247900784015656
[2m[36m(func pid=123603)[0m mae:  0.09398800879716873
[2m[36m(func pid=123603)[0m rmse_per_class: [0.076, 0.221, 0.063, 0.3, 0.068, 0.161, 0.228, 0.118, 0.17, 0.12]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=122291)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.3125 | Steps: 4 | Val loss: 0.2655 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2686 | Steps: 4 | Val loss: 0.2798 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=122291)[0m rmse: 0.14364084601402283
[2m[36m(func pid=122291)[0m mae:  0.09804833680391312
[2m[36m(func pid=122291)[0m rmse_per_class: [0.073, 0.217, 0.054, 0.29, 0.066, 0.153, 0.231, 0.11, 0.14, 0.103]
== Status ==
Current time: 2024-01-07 18:06:31 (running for 00:50:48.44)
Memory usage on this node: 19.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.269 |  0.152 |                   90 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
| train_01e98_00018 | TERMINATED | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.163 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=123603)[0m rmse: 0.15486903488636017
[2m[36m(func pid=123603)[0m mae:  0.0954451635479927
[2m[36m(func pid=123603)[0m rmse_per_class: [0.09, 0.221, 0.068, 0.295, 0.065, 0.159, 0.231, 0.123, 0.174, 0.122]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2827 | Steps: 4 | Val loss: 0.2762 | Batch size: 32 | lr: 0.1 | Duration: 3.22s
== Status ==
Current time: 2024-01-07 18:06:38 (running for 00:50:55.24)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.269 |  0.155 |                   91 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
| train_01e98_00018 | TERMINATED | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.163 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=123603)[0m rmse: 0.15242955088615417
[2m[36m(func pid=123603)[0m mae:  0.09387772530317307
[2m[36m(func pid=123603)[0m rmse_per_class: [0.082, 0.217, 0.066, 0.287, 0.061, 0.163, 0.235, 0.123, 0.163, 0.128]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2760 | Steps: 4 | Val loss: 0.2752 | Batch size: 32 | lr: 0.1 | Duration: 3.21s
== Status ==
Current time: 2024-01-07 18:06:44 (running for 00:51:01.15)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.283 |  0.152 |                   92 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
| train_01e98_00018 | TERMINATED | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.163 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=123603)[0m rmse: 0.15157589316368103
[2m[36m(func pid=123603)[0m mae:  0.09272748231887817
[2m[36m(func pid=123603)[0m rmse_per_class: [0.079, 0.219, 0.074, 0.283, 0.062, 0.16, 0.233, 0.12, 0.156, 0.13]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2729 | Steps: 4 | Val loss: 0.2765 | Batch size: 32 | lr: 0.1 | Duration: 3.21s
== Status ==
Current time: 2024-01-07 18:06:50 (running for 00:51:06.93)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.276 |  0.152 |                   93 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
| train_01e98_00018 | TERMINATED | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.163 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=123603)[0m rmse: 0.15212200582027435
[2m[36m(func pid=123603)[0m mae:  0.09293358027935028
[2m[36m(func pid=123603)[0m rmse_per_class: [0.073, 0.22, 0.068, 0.284, 0.06, 0.159, 0.228, 0.118, 0.169, 0.144]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2702 | Steps: 4 | Val loss: 0.2760 | Batch size: 32 | lr: 0.1 | Duration: 3.24s
== Status ==
Current time: 2024-01-07 18:06:56 (running for 00:51:12.86)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.273 |  0.152 |                   94 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
| train_01e98_00018 | TERMINATED | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.163 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=123603)[0m rmse: 0.1502278745174408
[2m[36m(func pid=123603)[0m mae:  0.09233086556196213
[2m[36m(func pid=123603)[0m rmse_per_class: [0.075, 0.22, 0.057, 0.286, 0.058, 0.159, 0.225, 0.114, 0.173, 0.136]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2570 | Steps: 4 | Val loss: 0.2726 | Batch size: 32 | lr: 0.1 | Duration: 3.19s
== Status ==
Current time: 2024-01-07 18:07:02 (running for 00:51:18.61)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.27  |  0.15  |                   95 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
| train_01e98_00018 | TERMINATED | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.163 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=123603)[0m rmse: 0.14879314601421356
[2m[36m(func pid=123603)[0m mae:  0.09158173203468323
[2m[36m(func pid=123603)[0m rmse_per_class: [0.077, 0.217, 0.062, 0.28, 0.063, 0.158, 0.225, 0.114, 0.167, 0.126]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2645 | Steps: 4 | Val loss: 0.2720 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 18:07:07 (running for 00:51:24.16)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.257 |  0.149 |                   96 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
| train_01e98_00018 | TERMINATED | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.163 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=123603)[0m rmse: 0.1483197659254074
[2m[36m(func pid=123603)[0m mae:  0.09117059409618378
[2m[36m(func pid=123603)[0m rmse_per_class: [0.076, 0.218, 0.056, 0.281, 0.068, 0.157, 0.225, 0.119, 0.166, 0.118]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2608 | Steps: 4 | Val loss: 0.2683 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
== Status ==
Current time: 2024-01-07 18:07:13 (running for 00:51:29.69)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.264 |  0.148 |                   97 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
| train_01e98_00018 | TERMINATED | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.163 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=123603)[0m rmse: 0.14559400081634521
[2m[36m(func pid=123603)[0m mae:  0.08964236825704575
[2m[36m(func pid=123603)[0m rmse_per_class: [0.073, 0.215, 0.052, 0.275, 0.069, 0.157, 0.225, 0.122, 0.162, 0.107]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2735 | Steps: 4 | Val loss: 0.2708 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
== Status ==
Current time: 2024-01-07 18:07:19 (running for 00:51:35.49)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.261 |  0.146 |                   98 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
| train_01e98_00018 | TERMINATED | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.163 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=123603)[0m rmse: 0.14735998213291168
[2m[36m(func pid=123603)[0m mae:  0.09103445708751678
[2m[36m(func pid=123603)[0m rmse_per_class: [0.068, 0.217, 0.052, 0.274, 0.068, 0.158, 0.231, 0.12, 0.182, 0.102]
[2m[36m(func pid=123603)[0m 
[2m[36m(func pid=123603)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2772 | Steps: 4 | Val loss: 0.2747 | Batch size: 32 | lr: 0.1 | Duration: 3.25s
== Status ==
Current time: 2024-01-07 18:07:24 (running for 00:51:41.30)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00023 | RUNNING    | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.273 |  0.147 |                   99 |
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
| train_01e98_00018 | TERMINATED | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.163 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=123603)[0m rmse: 0.15061749517917633
[2m[36m(func pid=123603)[0m mae:  0.09287195652723312
[2m[36m(func pid=123603)[0m rmse_per_class: [0.066, 0.22, 0.046, 0.276, 0.064, 0.159, 0.231, 0.118, 0.179, 0.146]
== Status ==
Current time: 2024-01-07 18:07:25 (running for 00:51:42.24)
Memory usage on this node: 16.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=24
Bracket: Iter 75.000: -0.14875000342726707
Resources requested: 0/72 CPUs, 0/4 GPUs, 0.0/119.99 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/BarlowTwins
Number of trials: 24/24 (24 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_01e98_00000 | TERMINATED | 192.168.7.53:11611  | 0.0001 |       0.99 |         0      |  0.404 |  0.171 |                   75 |
| train_01e98_00001 | TERMINATED | 192.168.7.53:11990  | 0.001  |       0.99 |         0      |  0.345 |  0.147 |                  100 |
| train_01e98_00002 | TERMINATED | 192.168.7.53:12418  | 0.01   |       0.99 |         0      |  0.276 |  0.156 |                  100 |
| train_01e98_00003 | TERMINATED | 192.168.7.53:12847  | 0.1    |       0.99 |         0      |  0.317 |  0.186 |                   75 |
| train_01e98_00004 | TERMINATED | 192.168.7.53:31109  | 0.0001 |       0.9  |         0      |  0.644 |  0.179 |                   75 |
| train_01e98_00005 | TERMINATED | 192.168.7.53:31653  | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   75 |
| train_01e98_00006 | TERMINATED | 192.168.7.53:35640  | 0.01   |       0.9  |         0      |  0.32  |  0.142 |                  100 |
| train_01e98_00007 | TERMINATED | 192.168.7.53:36548  | 0.1    |       0.9  |         0      |  0.286 |  0.139 |                  100 |
| train_01e98_00008 | TERMINATED | 192.168.7.53:50163  | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.171 |                   75 |
| train_01e98_00009 | TERMINATED | 192.168.7.53:50292  | 0.001  |       0.99 |         0.0001 |  0.319 |  0.15  |                  100 |
| train_01e98_00010 | TERMINATED | 192.168.7.53:60251  | 0.01   |       0.99 |         0.0001 |  0.297 |  0.156 |                   75 |
| train_01e98_00011 | TERMINATED | 192.168.7.53:60747  | 0.1    |       0.99 |         0.0001 |  0.352 |  0.206 |                   75 |
| train_01e98_00012 | TERMINATED | 192.168.7.53:68837  | 0.0001 |       0.9  |         0.0001 |  0.641 |  0.179 |                   75 |
| train_01e98_00013 | TERMINATED | 192.168.7.53:74973  | 0.001  |       0.9  |         0.0001 |  0.397 |  0.169 |                   75 |
| train_01e98_00014 | TERMINATED | 192.168.7.53:78743  | 0.01   |       0.9  |         0.0001 |  0.317 |  0.143 |                  100 |
| train_01e98_00015 | TERMINATED | 192.168.7.53:79710  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.147 |                  100 |
| train_01e98_00016 | TERMINATED | 192.168.7.53:87539  | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.171 |                   75 |
| train_01e98_00017 | TERMINATED | 192.168.7.53:93214  | 0.001  |       0.99 |         1e-05  |  0.326 |  0.144 |                  100 |
| train_01e98_00018 | TERMINATED | 192.168.7.53:103512 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.163 |                   75 |
| train_01e98_00019 | TERMINATED | 192.168.7.53:104772 | 0.1    |       0.99 |         1e-05  |  0.375 |  0.196 |                   75 |
| train_01e98_00020 | TERMINATED | 192.168.7.53:106005 | 0.0001 |       0.9  |         1e-05  |  0.645 |  0.179 |                   75 |
| train_01e98_00021 | TERMINATED | 192.168.7.53:117684 | 0.001  |       0.9  |         1e-05  |  0.402 |  0.17  |                   75 |
| train_01e98_00022 | TERMINATED | 192.168.7.53:122291 | 0.01   |       0.9  |         1e-05  |  0.312 |  0.144 |                  100 |
| train_01e98_00023 | TERMINATED | 192.168.7.53:123603 | 0.1    |       0.9  |         1e-05  |  0.277 |  0.151 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+


2024-01-07 18:07:25,792	INFO tune.py:798 -- Total run time: 3103.35 seconds (3102.22 seconds for the tuning loop).
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 1341353.1 ON aap04 CANCELLED AT 2024-01-07T18:07:31 ***
srun: error: aap04: task 0: Exited with exit code 1
