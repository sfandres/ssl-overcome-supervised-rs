IP Head: 192.168.7.53:6379
STARTING HEAD at aap04
2024-01-07 05:55:23,594	INFO usage_lib.py:461 -- Usage stats collection is enabled by default without user confirmation because this terminal is detected to be non-interactive. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.
2024-01-07 05:55:23,594	INFO scripts.py:710 -- Local node IP: 192.168.7.53
2024-01-07 05:55:26,123	SUCC scripts.py:747 -- --------------------
2024-01-07 05:55:26,124	SUCC scripts.py:748 -- Ray runtime started.
2024-01-07 05:55:26,124	SUCC scripts.py:749 -- --------------------
2024-01-07 05:55:26,124	INFO scripts.py:751 -- Next steps
2024-01-07 05:55:26,124	INFO scripts.py:752 -- To connect to this Ray runtime from another node, run
2024-01-07 05:55:26,124	INFO scripts.py:755 --   ray start --address='192.168.7.53:6379'
2024-01-07 05:55:26,124	INFO scripts.py:771 -- Alternatively, use the following Python code:
2024-01-07 05:55:26,124	INFO scripts.py:773 -- import ray
2024-01-07 05:55:26,124	INFO scripts.py:777 -- ray.init(address='auto', _node_ip_address='192.168.7.53')
2024-01-07 05:55:26,124	INFO scripts.py:790 -- To see the status of the cluster, use
2024-01-07 05:55:26,124	INFO scripts.py:791 --   ray status
2024-01-07 05:55:26,124	INFO scripts.py:801 -- If connection fails, check your firewall settings and network configuration.
2024-01-07 05:55:26,124	INFO scripts.py:809 -- To terminate the Ray runtime, run
2024-01-07 05:55:26,124	INFO scripts.py:810 --   ray stop
2024-01-07 05:55:26,125	INFO scripts.py:891 -- --block
2024-01-07 05:55:26,125	INFO scripts.py:892 -- This command will now block forever until terminated by a signal.
2024-01-07 05:55:26,125	INFO scripts.py:895 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.

torch initial seed:              14228270901550634186
torch current seed:              42
torch.cuda.is_available():       True
torch.cuda.device_count():       4
torch.cuda.current_device():     0
torch.cuda.device(0):            <torch.cuda.device object at 0x7f2c7c863130>
torch.cuda.get_device_name(0):   Tesla V100-PCIE-32GB
torch.backends.cudnn.benchmark:  False
os.sched_getaffinity:            72
os.cpu_count():                  72

model_name:          Supervised
task_name:           multilabel
backbone_name:       resnet18
input_data:          None
dataset_name:        Sentinel2AndaluciaLULC
dataset_level:       Level_N2
train_rate:          5
epochs:              100
learning_rate:       0.01
save_every:          5
batch_size:          32
num_workers:         4
ini_weights:         imagenet
seed:                42
dropout:             None
transfer_learning:   LP
show:                False
verbose:             False
balanced_dataset:    False
torch_compile:       False
distributed:         False
ray_tune:            gridsearch
load_best_hyperparameters: False
grace_period:        75
num_samples_trials:  1
gpus_per_trial:      1

Using ImageNet weights

Supervised model resnet18 with imagenet weights
Old final fully-connected layer: Linear(in_features=512, out_features=1000, bias=True)
No dropout layer
New final fully-connected layer: Linear(in_features=512, out_features=10, bias=True)
Linear probing adjusted
Device: 0

Setting a new configuration using tune.grid_search

2024-01-07 05:56:08,118	INFO worker.py:1364 -- Connecting to existing Ray cluster at address: 192.168.7.53:6379...
2024-01-07 05:56:08,136	INFO worker.py:1553 -- Connected to Ray cluster.
2024-01-07 05:56:31,616	WARNING worker.py:1866 -- Warning: The actor ImplicitFunc is very large (44 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.
== Status ==
Current time: 2024-01-07 05:56:31 (running for 00:00:22.78)
Memory usage on this node: 13.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (23 PENDING, 1 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |
|-------------------+----------+---------------------+--------+------------+----------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |
| train_12613_00001 | PENDING  |                     | 0.001  |       0.99 |         0      |
| train_12613_00002 | PENDING  |                     | 0.01   |       0.99 |         0      |
| train_12613_00003 | PENDING  |                     | 0.1    |       0.99 |         0      |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+---------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134465)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=134465)[0m Configuration completed!
[2m[36m(func pid=134465)[0m New optimizer parameters:
[2m[36m(func pid=134465)[0m SGD (
[2m[36m(func pid=134465)[0m Parameter Group 0
[2m[36m(func pid=134465)[0m     dampening: 0
[2m[36m(func pid=134465)[0m     differentiable: False
[2m[36m(func pid=134465)[0m     foreach: None
[2m[36m(func pid=134465)[0m     lr: 0.0001
[2m[36m(func pid=134465)[0m     maximize: False
[2m[36m(func pid=134465)[0m     momentum: 0.99
[2m[36m(func pid=134465)[0m     nesterov: False
[2m[36m(func pid=134465)[0m     weight_decay: 0
[2m[36m(func pid=134465)[0m )
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0837 | Steps: 2 | Val loss: 0.8121 | Batch size: 32 | lr: 0.0001 | Duration: 4.90s
[2m[36m(func pid=134465)[0m rmse: 0.17868109047412872
[2m[36m(func pid=134465)[0m mae:  0.13117416203022003
[2m[36m(func pid=134465)[0m rmse_per_class: [0.105, 0.266, 0.086, 0.325, 0.101, 0.192, 0.304, 0.153, 0.139, 0.116]
== Status ==
Current time: 2024-01-07 05:56:41 (running for 00:00:32.28)
Memory usage on this node: 15.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (22 PENDING, 2 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |
|-------------------+----------+---------------------+--------+------------+----------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |
| train_12613_00002 | PENDING  |                     | 0.01   |       0.99 |         0      |
| train_12613_00003 | PENDING  |                     | 0.1    |       0.99 |         0      |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+---------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)

[2m[36m(func pid=134839)[0m Dataloader to compute accuracy: val

[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=134839)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=134839)[0m Configuration completed!
[2m[36m(func pid=134839)[0m New optimizer parameters:
[2m[36m(func pid=134839)[0m SGD (
[2m[36m(func pid=134839)[0m Parameter Group 0
[2m[36m(func pid=134839)[0m     dampening: 0
[2m[36m(func pid=134839)[0m     differentiable: False
[2m[36m(func pid=134839)[0m     foreach: None
[2m[36m(func pid=134839)[0m     lr: 0.001
[2m[36m(func pid=134839)[0m     maximize: False
[2m[36m(func pid=134839)[0m     momentum: 0.99
[2m[36m(func pid=134839)[0m     nesterov: False
[2m[36m(func pid=134839)[0m     weight_decay: 0
[2m[36m(func pid=134839)[0m )
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0739 | Steps: 2 | Val loss: 0.7932 | Batch size: 32 | lr: 0.001 | Duration: 4.37s
[2m[36m(func pid=134839)[0m rmse: 0.1786072552204132
[2m[36m(func pid=134839)[0m mae:  0.1311342418193817
[2m[36m(func pid=134839)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.325, 0.1, 0.192, 0.304, 0.153, 0.139, 0.116]
== Status ==
Current time: 2024-01-07 05:56:50 (running for 00:00:41.17)
Memory usage on this node: 17.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (21 PENDING, 3 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |
|-------------------+----------+---------------------+--------+------------+----------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |
| train_12613_00003 | PENDING  |                     | 0.1    |       0.99 |         0      |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+---------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=135261)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135261)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=135261)[0m Configuration completed!
[2m[36m(func pid=135261)[0m New optimizer parameters:
[2m[36m(func pid=135261)[0m SGD (
[2m[36m(func pid=135261)[0m Parameter Group 0
[2m[36m(func pid=135261)[0m     dampening: 0
[2m[36m(func pid=135261)[0m     differentiable: False
[2m[36m(func pid=135261)[0m     foreach: None
[2m[36m(func pid=135261)[0m     lr: 0.01
[2m[36m(func pid=135261)[0m     maximize: False
[2m[36m(func pid=135261)[0m     momentum: 0.99
[2m[36m(func pid=135261)[0m     nesterov: False
[2m[36m(func pid=135261)[0m     weight_decay: 0
[2m[36m(func pid=135261)[0m )
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0265 | Steps: 2 | Val loss: 0.6443 | Batch size: 32 | lr: 0.01 | Duration: 4.48s
[2m[36m(func pid=135261)[0m rmse: 0.17801925539970398
[2m[36m(func pid=135261)[0m mae:  0.130484476685524
[2m[36m(func pid=135261)[0m rmse_per_class: [0.104, 0.267, 0.086, 0.325, 0.097, 0.192, 0.301, 0.155, 0.139, 0.114]
== Status ==
Current time: 2024-01-07 05:56:58 (running for 00:00:49.85)
Memory usage on this node: 20.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |
|-------------------+----------+---------------------+--------+------------+----------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+---------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135687)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=135687)[0m Configuration completed!
[2m[36m(func pid=135687)[0m New optimizer parameters:
[2m[36m(func pid=135687)[0m SGD (
[2m[36m(func pid=135687)[0m Parameter Group 0
[2m[36m(func pid=135687)[0m     dampening: 0
[2m[36m(func pid=135687)[0m     differentiable: False
[2m[36m(func pid=135687)[0m     foreach: None
[2m[36m(func pid=135687)[0m     lr: 0.1
[2m[36m(func pid=135687)[0m     maximize: False
[2m[36m(func pid=135687)[0m     momentum: 0.99
[2m[36m(func pid=135687)[0m     nesterov: False
[2m[36m(func pid=135687)[0m     weight_decay: 0
[2m[36m(func pid=135687)[0m )
[2m[36m(func pid=135687)[0m 
== Status ==
Current time: 2024-01-07 05:57:06 (running for 00:00:57.97)
Memory usage on this node: 22.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |        |        |                      |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  1.074 |  0.179 |                    1 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |        |        |                      |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |        |        |                      |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0805 | Steps: 2 | Val loss: 0.8136 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0293 | Steps: 2 | Val loss: 0.7547 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.7040 | Steps: 2 | Val loss: 0.4175 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.7687 | Steps: 2 | Val loss: 0.3298 | Batch size: 32 | lr: 0.1 | Duration: 4.69s
== Status ==
Current time: 2024-01-07 05:57:11 (running for 00:01:03.01)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  1.084 |  0.179 |                    1 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  1.074 |  0.179 |                    1 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  1.026 |  0.178 |                    1 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |        |        |                      |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1790889948606491
[2m[36m(func pid=134465)[0m mae:  0.13149598240852356
[2m[36m(func pid=134465)[0m rmse_per_class: [0.104, 0.266, 0.088, 0.325, 0.102, 0.193, 0.305, 0.154, 0.139, 0.116]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.17899128794670105
[2m[36m(func pid=134839)[0m mae:  0.1313660442829132
[2m[36m(func pid=134839)[0m rmse_per_class: [0.104, 0.266, 0.088, 0.325, 0.101, 0.193, 0.305, 0.154, 0.139, 0.116]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.17663437128067017
[2m[36m(func pid=135261)[0m mae:  0.129006028175354
[2m[36m(func pid=135261)[0m rmse_per_class: [0.104, 0.269, 0.088, 0.326, 0.091, 0.192, 0.293, 0.152, 0.141, 0.109]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.17317335307598114
[2m[36m(func pid=135687)[0m mae:  0.12474770843982697
[2m[36m(func pid=135687)[0m rmse_per_class: [0.106, 0.274, 0.088, 0.344, 0.071, 0.191, 0.277, 0.131, 0.151, 0.097]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 1.0726 | Steps: 2 | Val loss: 0.8152 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.9533 | Steps: 2 | Val loss: 0.6934 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.4594 | Steps: 2 | Val loss: 0.3246 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.5794 | Steps: 2 | Val loss: 0.5025 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
== Status ==
Current time: 2024-01-07 05:57:17 (running for 00:01:08.34)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  1.073 |  0.18  |                    3 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  1.029 |  0.179 |                    2 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.704 |  0.177 |                    2 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.769 |  0.173 |                    1 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1795676052570343
[2m[36m(func pid=134465)[0m mae:  0.13186582922935486
[2m[36m(func pid=134465)[0m rmse_per_class: [0.105, 0.266, 0.089, 0.325, 0.103, 0.193, 0.307, 0.154, 0.138, 0.117]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.17922881245613098
[2m[36m(func pid=134839)[0m mae:  0.1314542591571808
[2m[36m(func pid=134839)[0m rmse_per_class: [0.104, 0.267, 0.088, 0.325, 0.101, 0.193, 0.305, 0.156, 0.139, 0.115]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.17451296746730804
[2m[36m(func pid=135261)[0m mae:  0.12671642005443573
[2m[36m(func pid=135261)[0m rmse_per_class: [0.106, 0.273, 0.093, 0.334, 0.082, 0.192, 0.28, 0.138, 0.145, 0.102]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.18899130821228027
[2m[36m(func pid=135687)[0m mae:  0.12603671848773956
[2m[36m(func pid=135687)[0m rmse_per_class: [0.099, 0.287, 0.057, 0.373, 0.056, 0.188, 0.413, 0.147, 0.176, 0.094]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 1.0555 | Steps: 2 | Val loss: 0.8114 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8448 | Steps: 2 | Val loss: 0.6143 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4349 | Steps: 2 | Val loss: 0.3463 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.8763 | Steps: 2 | Val loss: 0.6124 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 05:57:22 (running for 00:01:13.52)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  1.056 |  0.18  |                    4 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.953 |  0.179 |                    3 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.459 |  0.175 |                    3 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.579 |  0.189 |                    2 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17997074127197266
[2m[36m(func pid=134465)[0m mae:  0.13217423856258392
[2m[36m(func pid=134465)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.104, 0.193, 0.308, 0.154, 0.138, 0.117]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.17942282557487488
[2m[36m(func pid=134839)[0m mae:  0.13147780299186707
[2m[36m(func pid=134839)[0m rmse_per_class: [0.104, 0.267, 0.089, 0.325, 0.101, 0.193, 0.304, 0.156, 0.139, 0.115]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.17401070892810822
[2m[36m(func pid=135261)[0m mae:  0.12430207431316376
[2m[36m(func pid=135261)[0m rmse_per_class: [0.107, 0.276, 0.09, 0.345, 0.071, 0.192, 0.281, 0.132, 0.149, 0.096]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.2093183547258377
[2m[36m(func pid=135687)[0m mae:  0.13462485373020172
[2m[36m(func pid=135687)[0m rmse_per_class: [0.098, 0.298, 0.048, 0.385, 0.056, 0.2, 0.6, 0.155, 0.156, 0.097]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 1.0427 | Steps: 2 | Val loss: 0.8035 | Batch size: 32 | lr: 0.0001 | Duration: 2.67s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7295 | Steps: 2 | Val loss: 0.5298 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.5146 | Steps: 2 | Val loss: 0.4089 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.9719 | Steps: 2 | Val loss: 0.6062 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=134465)[0m rmse: 0.18025359511375427
[2m[36m(func pid=134465)[0m mae:  0.13238677382469177
[2m[36m(func pid=134465)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.104, 0.194, 0.309, 0.154, 0.138, 0.118]
[2m[36m(func pid=134465)[0m 
== Status ==
Current time: 2024-01-07 05:57:28 (running for 00:01:19.37)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  1.043 |  0.18  |                    5 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.729 |  0.179 |                    5 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.435 |  0.174 |                    4 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.876 |  0.209 |                    3 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134839)[0m rmse: 0.1794164478778839
[2m[36m(func pid=134839)[0m mae:  0.1313101351261139
[2m[36m(func pid=134839)[0m rmse_per_class: [0.105, 0.268, 0.091, 0.325, 0.1, 0.193, 0.303, 0.156, 0.139, 0.114]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.1766842007637024
[2m[36m(func pid=135261)[0m mae:  0.12251148372888565
[2m[36m(func pid=135261)[0m rmse_per_class: [0.107, 0.278, 0.079, 0.355, 0.062, 0.191, 0.316, 0.137, 0.15, 0.093]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.21767649054527283
[2m[36m(func pid=135687)[0m mae:  0.14030326902866364
[2m[36m(func pid=135687)[0m rmse_per_class: [0.102, 0.301, 0.049, 0.388, 0.056, 0.212, 0.664, 0.156, 0.152, 0.097]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 1.0185 | Steps: 2 | Val loss: 0.7908 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.6250 | Steps: 2 | Val loss: 0.4531 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.6136 | Steps: 2 | Val loss: 0.4768 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.9280 | Steps: 2 | Val loss: 0.5273 | Batch size: 32 | lr: 0.1 | Duration: 2.63s
[2m[36m(func pid=134465)[0m rmse: 0.1804904043674469
[2m[36m(func pid=134465)[0m mae:  0.13254691660404205
[2m[36m(func pid=134465)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.105, 0.194, 0.309, 0.154, 0.138, 0.119]
[2m[36m(func pid=134465)[0m 
== Status ==
Current time: 2024-01-07 05:57:33 (running for 00:01:24.48)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  1.019 |  0.18  |                    6 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.625 |  0.179 |                    6 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.515 |  0.177 |                    5 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.972 |  0.218 |                    4 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134839)[0m rmse: 0.17932289838790894
[2m[36m(func pid=134839)[0m mae:  0.13106989860534668
[2m[36m(func pid=134839)[0m rmse_per_class: [0.105, 0.269, 0.093, 0.327, 0.099, 0.193, 0.3, 0.154, 0.14, 0.113]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.19890424609184265
[2m[36m(func pid=135687)[0m mae:  0.12810035049915314
[2m[36m(func pid=135687)[0m rmse_per_class: [0.079, 0.295, 0.049, 0.386, 0.056, 0.177, 0.369, 0.156, 0.324, 0.097]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.18252737820148468
[2m[36m(func pid=135261)[0m mae:  0.12245623022317886
[2m[36m(func pid=135261)[0m rmse_per_class: [0.105, 0.282, 0.065, 0.365, 0.057, 0.19, 0.379, 0.144, 0.148, 0.092]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.9922 | Steps: 2 | Val loss: 0.7742 | Batch size: 32 | lr: 0.0001 | Duration: 2.67s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.5331 | Steps: 2 | Val loss: 0.3922 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.7450 | Steps: 2 | Val loss: 0.4700 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.6940 | Steps: 2 | Val loss: 0.5365 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=134465)[0m rmse: 0.18063955008983612
[2m[36m(func pid=134465)[0m mae:  0.132653146982193
[2m[36m(func pid=134465)[0m rmse_per_class: [0.105, 0.266, 0.091, 0.324, 0.105, 0.194, 0.309, 0.154, 0.138, 0.119]
[2m[36m(func pid=134465)[0m 
== Status ==
Current time: 2024-01-07 05:57:38 (running for 00:01:30.00)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.992 |  0.181 |                    7 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.533 |  0.179 |                    7 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.614 |  0.183 |                    6 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.928 |  0.199 |                    5 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134839)[0m rmse: 0.178965225815773
[2m[36m(func pid=134839)[0m mae:  0.1305783987045288
[2m[36m(func pid=134839)[0m rmse_per_class: [0.106, 0.27, 0.095, 0.329, 0.097, 0.193, 0.296, 0.15, 0.142, 0.111]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.1905308961868286
[2m[36m(func pid=135687)[0m mae:  0.1290835440158844
[2m[36m(func pid=135687)[0m rmse_per_class: [0.148, 0.242, 0.049, 0.353, 0.056, 0.31, 0.281, 0.156, 0.212, 0.097]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.18987824022769928
[2m[36m(func pid=135261)[0m mae:  0.12407499551773071
[2m[36m(func pid=135261)[0m rmse_per_class: [0.101, 0.285, 0.054, 0.373, 0.056, 0.189, 0.455, 0.149, 0.144, 0.093]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.9662 | Steps: 2 | Val loss: 0.7538 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4699 | Steps: 2 | Val loss: 0.3524 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.6977 | Steps: 2 | Val loss: 0.4567 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.7647 | Steps: 2 | Val loss: 0.5819 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=134465)[0m rmse: 0.18079052865505219
[2m[36m(func pid=134465)[0m mae:  0.13273146748542786
[2m[36m(func pid=134465)[0m rmse_per_class: [0.106, 0.267, 0.091, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.12]
[2m[36m(func pid=134465)[0m 
== Status ==
Current time: 2024-01-07 05:57:44 (running for 00:01:35.18)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.966 |  0.181 |                    8 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.47  |  0.178 |                    8 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.694 |  0.19  |                    7 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.745 |  0.191 |                    6 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134839)[0m rmse: 0.17849305272102356
[2m[36m(func pid=134839)[0m mae:  0.13001839816570282
[2m[36m(func pid=134839)[0m rmse_per_class: [0.107, 0.271, 0.097, 0.332, 0.094, 0.193, 0.291, 0.146, 0.144, 0.11]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.16354359686374664
[2m[36m(func pid=135687)[0m mae:  0.1093260869383812
[2m[36m(func pid=135687)[0m rmse_per_class: [0.074, 0.267, 0.048, 0.303, 0.056, 0.178, 0.324, 0.156, 0.133, 0.096]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.19743241369724274
[2m[36m(func pid=135261)[0m mae:  0.126877099275589
[2m[36m(func pid=135261)[0m rmse_per_class: [0.099, 0.288, 0.049, 0.378, 0.056, 0.19, 0.527, 0.153, 0.14, 0.095]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.9339 | Steps: 2 | Val loss: 0.7300 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.4345 | Steps: 2 | Val loss: 0.3315 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.6213 | Steps: 2 | Val loss: 0.3751 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=134465)[0m rmse: 0.18088434636592865
[2m[36m(func pid=134465)[0m mae:  0.13277487456798553
[2m[36m(func pid=134465)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.106, 0.194, 0.31, 0.155, 0.138, 0.12]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.8134 | Steps: 2 | Val loss: 0.6100 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 05:57:49 (running for 00:01:40.48)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.934 |  0.181 |                    9 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.435 |  0.178 |                    9 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.765 |  0.197 |                    8 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.698 |  0.164 |                    7 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134839)[0m rmse: 0.17806120216846466
[2m[36m(func pid=134839)[0m mae:  0.12944379448890686
[2m[36m(func pid=134839)[0m rmse_per_class: [0.108, 0.272, 0.099, 0.335, 0.091, 0.193, 0.286, 0.141, 0.147, 0.108]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.18251919746398926
[2m[36m(func pid=135687)[0m mae:  0.11461057513952255
[2m[36m(func pid=135687)[0m rmse_per_class: [0.076, 0.256, 0.027, 0.461, 0.056, 0.188, 0.28, 0.149, 0.136, 0.196]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.20392970740795135
[2m[36m(func pid=135261)[0m mae:  0.13004663586616516
[2m[36m(func pid=135261)[0m rmse_per_class: [0.098, 0.291, 0.048, 0.382, 0.056, 0.193, 0.584, 0.154, 0.137, 0.096]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.9043 | Steps: 2 | Val loss: 0.7050 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4208 | Steps: 2 | Val loss: 0.3258 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5158 | Steps: 2 | Val loss: 0.4547 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=134465)[0m rmse: 0.1809658408164978
[2m[36m(func pid=134465)[0m mae:  0.13281293213367462
[2m[36m(func pid=134465)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.106, 0.194, 0.31, 0.155, 0.138, 0.12]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.8420 | Steps: 2 | Val loss: 0.6222 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 05:57:54 (running for 00:01:45.71)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.904 |  0.181 |                   10 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.421 |  0.178 |                   10 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.813 |  0.204 |                    9 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.621 |  0.183 |                    8 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134839)[0m rmse: 0.1775481402873993
[2m[36m(func pid=134839)[0m mae:  0.1286708414554596
[2m[36m(func pid=134839)[0m rmse_per_class: [0.11, 0.273, 0.1, 0.339, 0.086, 0.193, 0.281, 0.137, 0.15, 0.106]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.20190224051475525
[2m[36m(func pid=135687)[0m mae:  0.12954901158809662
[2m[36m(func pid=135687)[0m rmse_per_class: [0.096, 0.299, 0.042, 0.289, 0.056, 0.221, 0.215, 0.131, 0.131, 0.538]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.8732 | Steps: 2 | Val loss: 0.6779 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=135261)[0m rmse: 0.20897388458251953
[2m[36m(func pid=135261)[0m mae:  0.13297387957572937
[2m[36m(func pid=135261)[0m rmse_per_class: [0.098, 0.293, 0.048, 0.384, 0.056, 0.197, 0.626, 0.155, 0.136, 0.096]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4190 | Steps: 2 | Val loss: 0.3312 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.5885 | Steps: 2 | Val loss: 0.6526 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=134465)[0m rmse: 0.18105122447013855
[2m[36m(func pid=134465)[0m mae:  0.13284501433372498
[2m[36m(func pid=134465)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.31, 0.155, 0.138, 0.121]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.8435 | Steps: 2 | Val loss: 0.6171 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 05:58:00 (running for 00:01:51.09)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.873 |  0.181 |                   11 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.419 |  0.177 |                   11 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.842 |  0.209 |                   10 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.516 |  0.202 |                    9 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134839)[0m rmse: 0.17712366580963135
[2m[36m(func pid=134839)[0m mae:  0.1278458684682846
[2m[36m(func pid=134839)[0m rmse_per_class: [0.111, 0.274, 0.1, 0.343, 0.082, 0.193, 0.277, 0.135, 0.153, 0.103]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.21908453106880188
[2m[36m(func pid=135687)[0m mae:  0.14150944352149963
[2m[36m(func pid=135687)[0m rmse_per_class: [0.096, 0.301, 0.106, 0.378, 0.056, 0.227, 0.247, 0.512, 0.157, 0.111]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.8389 | Steps: 2 | Val loss: 0.6505 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=135261)[0m rmse: 0.2125651091337204
[2m[36m(func pid=135261)[0m mae:  0.1353135108947754
[2m[36m(func pid=135261)[0m rmse_per_class: [0.099, 0.294, 0.049, 0.386, 0.056, 0.2, 0.655, 0.156, 0.134, 0.097]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4286 | Steps: 2 | Val loss: 0.3441 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.6781 | Steps: 2 | Val loss: 0.6608 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=134465)[0m rmse: 0.18104565143585205
[2m[36m(func pid=134465)[0m mae:  0.1327938735485077
[2m[36m(func pid=134465)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.309, 0.155, 0.138, 0.121]
[2m[36m(func pid=134465)[0m 
== Status ==
Current time: 2024-01-07 05:58:05 (running for 00:01:56.19)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.839 |  0.181 |                   12 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.429 |  0.177 |                   12 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.843 |  0.213 |                   11 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.588 |  0.219 |                   10 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134839)[0m rmse: 0.17696598172187805
[2m[36m(func pid=134839)[0m mae:  0.12709423899650574
[2m[36m(func pid=134839)[0m rmse_per_class: [0.112, 0.274, 0.099, 0.346, 0.077, 0.193, 0.275, 0.135, 0.156, 0.101]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.8318 | Steps: 2 | Val loss: 0.5987 | Batch size: 32 | lr: 0.01 | Duration: 3.13s
[2m[36m(func pid=135687)[0m rmse: 0.22979314625263214
[2m[36m(func pid=135687)[0m mae:  0.1455231010913849
[2m[36m(func pid=135687)[0m rmse_per_class: [0.084, 0.3, 0.147, 0.382, 0.056, 0.212, 0.235, 0.56, 0.227, 0.095]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.8031 | Steps: 2 | Val loss: 0.6222 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=135261)[0m rmse: 0.21421150863170624
[2m[36m(func pid=135261)[0m mae:  0.13647747039794922
[2m[36m(func pid=135261)[0m rmse_per_class: [0.099, 0.295, 0.049, 0.387, 0.056, 0.201, 0.669, 0.156, 0.134, 0.097]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4488 | Steps: 2 | Val loss: 0.3622 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.5997 | Steps: 2 | Val loss: 0.5515 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=134465)[0m rmse: 0.1810443252325058
[2m[36m(func pid=134465)[0m mae:  0.13274595141410828
[2m[36m(func pid=134465)[0m rmse_per_class: [0.106, 0.268, 0.09, 0.324, 0.105, 0.194, 0.309, 0.155, 0.138, 0.121]
[2m[36m(func pid=134465)[0m 
== Status ==
Current time: 2024-01-07 05:58:10 (running for 00:02:01.32)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.803 |  0.181 |                   13 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.449 |  0.177 |                   13 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.832 |  0.214 |                   12 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.678 |  0.23  |                   11 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134839)[0m rmse: 0.17709754407405853
[2m[36m(func pid=134839)[0m mae:  0.12639597058296204
[2m[36m(func pid=134839)[0m rmse_per_class: [0.113, 0.275, 0.097, 0.35, 0.073, 0.193, 0.277, 0.135, 0.159, 0.099]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.20749354362487793
[2m[36m(func pid=135687)[0m mae:  0.12160845100879669
[2m[36m(func pid=135687)[0m rmse_per_class: [0.101, 0.284, 0.12, 0.37, 0.052, 0.252, 0.246, 0.194, 0.36, 0.096]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.7973 | Steps: 2 | Val loss: 0.5695 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7709 | Steps: 2 | Val loss: 0.5947 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4704 | Steps: 2 | Val loss: 0.3826 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=135261)[0m rmse: 0.21326585114002228
[2m[36m(func pid=135261)[0m mae:  0.13585039973258972
[2m[36m(func pid=135261)[0m rmse_per_class: [0.098, 0.294, 0.049, 0.387, 0.056, 0.198, 0.663, 0.156, 0.135, 0.097]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4786 | Steps: 2 | Val loss: 0.5425 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=134465)[0m rmse: 0.1810535043478012
[2m[36m(func pid=134465)[0m mae:  0.13268893957138062
[2m[36m(func pid=134465)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.194, 0.309, 0.155, 0.138, 0.122]
[2m[36m(func pid=134465)[0m 
== Status ==
Current time: 2024-01-07 05:58:15 (running for 00:02:06.51)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.771 |  0.181 |                   14 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.47  |  0.178 |                   14 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.797 |  0.213 |                   13 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.6   |  0.207 |                   12 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134839)[0m rmse: 0.17753766477108002
[2m[36m(func pid=134839)[0m mae:  0.1258128434419632
[2m[36m(func pid=134839)[0m rmse_per_class: [0.114, 0.276, 0.093, 0.354, 0.069, 0.193, 0.281, 0.136, 0.162, 0.097]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.2171490639448166
[2m[36m(func pid=135687)[0m mae:  0.1332148164510727
[2m[36m(func pid=135687)[0m rmse_per_class: [0.121, 0.268, 0.033, 0.362, 0.178, 0.414, 0.279, 0.142, 0.278, 0.097]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7472 | Steps: 2 | Val loss: 0.5313 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.7315 | Steps: 2 | Val loss: 0.5654 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4974 | Steps: 2 | Val loss: 0.4034 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.5518 | Steps: 2 | Val loss: 0.5708 | Batch size: 32 | lr: 0.1 | Duration: 2.70s
[2m[36m(func pid=135261)[0m rmse: 0.20829470455646515
[2m[36m(func pid=135261)[0m mae:  0.13244479894638062
[2m[36m(func pid=135261)[0m rmse_per_class: [0.093, 0.29, 0.049, 0.386, 0.056, 0.189, 0.626, 0.156, 0.14, 0.097]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.180990532040596
[2m[36m(func pid=134465)[0m mae:  0.13259045779705048
[2m[36m(func pid=134465)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.194, 0.308, 0.154, 0.138, 0.122]
[2m[36m(func pid=134465)[0m 
== Status ==
Current time: 2024-01-07 05:58:20 (running for 00:02:11.62)
Memory usage on this node: 24.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.732 |  0.181 |                   15 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.47  |  0.178 |                   14 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.747 |  0.208 |                   14 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.552 |  0.198 |                   14 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134839)[0m rmse: 0.17825397849082947
[2m[36m(func pid=134839)[0m mae:  0.12536709010601044
[2m[36m(func pid=134839)[0m rmse_per_class: [0.113, 0.277, 0.09, 0.358, 0.065, 0.193, 0.288, 0.138, 0.165, 0.095]
[2m[36m(func pid=135687)[0m rmse: 0.1981552541255951
[2m[36m(func pid=135687)[0m mae:  0.12537908554077148
[2m[36m(func pid=135687)[0m rmse_per_class: [0.087, 0.246, 0.027, 0.328, 0.342, 0.242, 0.28, 0.155, 0.179, 0.097]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.7046 | Steps: 2 | Val loss: 0.4857 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.7017 | Steps: 2 | Val loss: 0.5380 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.5202 | Steps: 2 | Val loss: 0.4242 | Batch size: 32 | lr: 0.001 | Duration: 2.68s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.6262 | Steps: 2 | Val loss: 0.5066 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=135261)[0m rmse: 0.19736085832118988
[2m[36m(func pid=135261)[0m mae:  0.1253989189863205
[2m[36m(func pid=135261)[0m rmse_per_class: [0.084, 0.281, 0.049, 0.385, 0.056, 0.177, 0.531, 0.156, 0.158, 0.097]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.18094736337661743
[2m[36m(func pid=134465)[0m mae:  0.13249808549880981
[2m[36m(func pid=134465)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.103, 0.194, 0.307, 0.154, 0.139, 0.122]
[2m[36m(func pid=134465)[0m 
== Status ==
Current time: 2024-01-07 05:58:25 (running for 00:02:16.66)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.702 |  0.181 |                   16 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.52  |  0.179 |                   16 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.705 |  0.197 |                   15 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.552 |  0.198 |                   14 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134839)[0m rmse: 0.17923620343208313
[2m[36m(func pid=134839)[0m mae:  0.12496267259120941
[2m[36m(func pid=134839)[0m rmse_per_class: [0.113, 0.278, 0.086, 0.361, 0.062, 0.193, 0.298, 0.14, 0.168, 0.094]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.17352576553821564
[2m[36m(func pid=135687)[0m mae:  0.10417274385690689
[2m[36m(func pid=135687)[0m rmse_per_class: [0.069, 0.277, 0.031, 0.276, 0.243, 0.188, 0.23, 0.156, 0.17, 0.096]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.6452 | Steps: 2 | Val loss: 0.4381 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.6704 | Steps: 2 | Val loss: 0.5130 | Batch size: 32 | lr: 0.0001 | Duration: 2.66s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.5526 | Steps: 2 | Val loss: 0.4439 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.5823 | Steps: 2 | Val loss: 0.4978 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=135261)[0m rmse: 0.18209078907966614
[2m[36m(func pid=135261)[0m mae:  0.11704404652118683
[2m[36m(func pid=135261)[0m rmse_per_class: [0.08, 0.264, 0.049, 0.381, 0.056, 0.182, 0.358, 0.156, 0.198, 0.097]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.1808960735797882
[2m[36m(func pid=134465)[0m mae:  0.13240079581737518
[2m[36m(func pid=134465)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.103, 0.194, 0.306, 0.153, 0.139, 0.122]
[2m[36m(func pid=134465)[0m 
== Status ==
Current time: 2024-01-07 05:58:30 (running for 00:02:21.93)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.67  |  0.181 |                   17 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.52  |  0.179 |                   16 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.645 |  0.182 |                   16 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.582 |  0.169 |                   16 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134839)[0m rmse: 0.18023894727230072
[2m[36m(func pid=134839)[0m mae:  0.1245630607008934
[2m[36m(func pid=134839)[0m rmse_per_class: [0.112, 0.279, 0.081, 0.363, 0.06, 0.193, 0.311, 0.141, 0.169, 0.093]
[2m[36m(func pid=135687)[0m rmse: 0.1691914200782776
[2m[36m(func pid=135687)[0m mae:  0.09618690609931946
[2m[36m(func pid=135687)[0m rmse_per_class: [0.069, 0.242, 0.039, 0.321, 0.093, 0.212, 0.27, 0.156, 0.201, 0.09]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.6303 | Steps: 2 | Val loss: 0.4058 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.6391 | Steps: 2 | Val loss: 0.4886 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.5697 | Steps: 2 | Val loss: 0.4643 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.5610 | Steps: 2 | Val loss: 0.5421 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=135261)[0m rmse: 0.17425842583179474
[2m[36m(func pid=135261)[0m mae:  0.11591611057519913
[2m[36m(func pid=135261)[0m rmse_per_class: [0.091, 0.248, 0.049, 0.372, 0.056, 0.219, 0.222, 0.156, 0.232, 0.097]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.18080587685108185
[2m[36m(func pid=134465)[0m mae:  0.13225726783275604
[2m[36m(func pid=134465)[0m rmse_per_class: [0.107, 0.269, 0.092, 0.325, 0.102, 0.194, 0.305, 0.152, 0.139, 0.122]
[2m[36m(func pid=134465)[0m 
== Status ==
Current time: 2024-01-07 05:58:36 (running for 00:02:27.04)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.639 |  0.181 |                   18 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.57  |  0.182 |                   18 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.63  |  0.174 |                   17 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.582 |  0.169 |                   16 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134839)[0m rmse: 0.18152733147144318
[2m[36m(func pid=134839)[0m mae:  0.12433488667011261
[2m[36m(func pid=134839)[0m rmse_per_class: [0.112, 0.279, 0.076, 0.366, 0.058, 0.192, 0.325, 0.143, 0.171, 0.093]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.18677127361297607
[2m[36m(func pid=135687)[0m mae:  0.10661941766738892
[2m[36m(func pid=135687)[0m rmse_per_class: [0.077, 0.247, 0.045, 0.438, 0.06, 0.217, 0.3, 0.155, 0.234, 0.093]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.5474 | Steps: 2 | Val loss: 0.4045 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.6075 | Steps: 2 | Val loss: 0.4657 | Batch size: 32 | lr: 0.0001 | Duration: 2.72s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.5890 | Steps: 2 | Val loss: 0.4825 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.5745 | Steps: 2 | Val loss: 0.5793 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=135261)[0m rmse: 0.17665447294712067
[2m[36m(func pid=135261)[0m mae:  0.11997596174478531
[2m[36m(func pid=135261)[0m rmse_per_class: [0.104, 0.248, 0.049, 0.355, 0.056, 0.236, 0.238, 0.156, 0.227, 0.097]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.18075253069400787
[2m[36m(func pid=134465)[0m mae:  0.13215388357639313
[2m[36m(func pid=134465)[0m rmse_per_class: [0.107, 0.269, 0.092, 0.326, 0.101, 0.194, 0.304, 0.152, 0.14, 0.121]
[2m[36m(func pid=134465)[0m 
== Status ==
Current time: 2024-01-07 05:58:41 (running for 00:02:32.32)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.607 |  0.181 |                   19 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.589 |  0.183 |                   19 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.547 |  0.177 |                   18 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.561 |  0.187 |                   17 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134839)[0m rmse: 0.18290837109088898
[2m[36m(func pid=134839)[0m mae:  0.12417934834957123
[2m[36m(func pid=134839)[0m rmse_per_class: [0.111, 0.28, 0.071, 0.368, 0.057, 0.192, 0.342, 0.145, 0.171, 0.092]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.20233337581157684
[2m[36m(func pid=135687)[0m mae:  0.11265615373849869
[2m[36m(func pid=135687)[0m rmse_per_class: [0.079, 0.282, 0.047, 0.457, 0.056, 0.202, 0.307, 0.152, 0.242, 0.201]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.5846 | Steps: 2 | Val loss: 0.4213 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.5863 | Steps: 2 | Val loss: 0.4449 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.6117 | Steps: 2 | Val loss: 0.4976 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.5758 | Steps: 2 | Val loss: 0.5858 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=134465)[0m rmse: 0.18069151043891907
[2m[36m(func pid=134465)[0m mae:  0.13207559287548065
[2m[36m(func pid=134465)[0m rmse_per_class: [0.107, 0.27, 0.093, 0.327, 0.1, 0.194, 0.303, 0.151, 0.14, 0.121]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.17596657574176788
[2m[36m(func pid=135261)[0m mae:  0.12104324251413345
[2m[36m(func pid=135261)[0m rmse_per_class: [0.114, 0.258, 0.049, 0.324, 0.056, 0.22, 0.281, 0.156, 0.205, 0.096]
[2m[36m(func pid=135261)[0m 
== Status ==
Current time: 2024-01-07 05:58:46 (running for 00:02:37.51)
Memory usage on this node: 24.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.586 |  0.181 |                   20 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.612 |  0.184 |                   20 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.585 |  0.176 |                   19 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.574 |  0.202 |                   18 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134839)[0m rmse: 0.18431447446346283
[2m[36m(func pid=134839)[0m mae:  0.12420085817575455
[2m[36m(func pid=134839)[0m rmse_per_class: [0.109, 0.281, 0.066, 0.37, 0.056, 0.192, 0.358, 0.146, 0.171, 0.092]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.2022372931241989
[2m[36m(func pid=135687)[0m mae:  0.11033300310373306
[2m[36m(func pid=135687)[0m rmse_per_class: [0.079, 0.295, 0.049, 0.357, 0.056, 0.186, 0.296, 0.14, 0.228, 0.335]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.5583 | Steps: 2 | Val loss: 0.4251 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.5916 | Steps: 2 | Val loss: 0.4188 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.6354 | Steps: 2 | Val loss: 0.5118 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.6119 | Steps: 2 | Val loss: 0.5906 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=134465)[0m rmse: 0.18045400083065033
[2m[36m(func pid=134465)[0m mae:  0.13181602954864502
[2m[36m(func pid=134465)[0m rmse_per_class: [0.108, 0.27, 0.093, 0.327, 0.1, 0.194, 0.302, 0.15, 0.141, 0.121]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.16956056654453278
[2m[36m(func pid=135261)[0m mae:  0.11681137979030609
[2m[36m(func pid=135261)[0m rmse_per_class: [0.116, 0.26, 0.049, 0.285, 0.056, 0.195, 0.303, 0.156, 0.183, 0.093]
== Status ==
Current time: 2024-01-07 05:58:51 (running for 00:02:42.54)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.558 |  0.18  |                   21 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.612 |  0.184 |                   20 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.592 |  0.17  |                   20 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.576 |  0.202 |                   19 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.1859145313501358
[2m[36m(func pid=134839)[0m mae:  0.12428991496562958
[2m[36m(func pid=134839)[0m rmse_per_class: [0.108, 0.282, 0.062, 0.372, 0.056, 0.192, 0.376, 0.148, 0.172, 0.092]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.2022504359483719
[2m[36m(func pid=135687)[0m mae:  0.11184725910425186
[2m[36m(func pid=135687)[0m rmse_per_class: [0.083, 0.299, 0.049, 0.3, 0.056, 0.203, 0.32, 0.138, 0.207, 0.367]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.5362 | Steps: 2 | Val loss: 0.4080 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.5642 | Steps: 2 | Val loss: 0.3935 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.6517 | Steps: 2 | Val loss: 0.5229 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.6384 | Steps: 2 | Val loss: 0.6424 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 05:58:56 (running for 00:02:47.57)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.536 |  0.18  |                   22 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.635 |  0.186 |                   21 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.592 |  0.17  |                   20 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.612 |  0.202 |                   20 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.18023410439491272
[2m[36m(func pid=134465)[0m mae:  0.13157613575458527
[2m[36m(func pid=134465)[0m rmse_per_class: [0.108, 0.27, 0.093, 0.327, 0.099, 0.194, 0.301, 0.149, 0.141, 0.121]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.18732228875160217
[2m[36m(func pid=134839)[0m mae:  0.12443753331899643
[2m[36m(func pid=134839)[0m rmse_per_class: [0.107, 0.282, 0.059, 0.374, 0.056, 0.192, 0.392, 0.149, 0.171, 0.092]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.16332116723060608
[2m[36m(func pid=135261)[0m mae:  0.1116020455956459
[2m[36m(func pid=135261)[0m rmse_per_class: [0.105, 0.252, 0.049, 0.279, 0.056, 0.173, 0.312, 0.155, 0.165, 0.087]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.2081305980682373
[2m[36m(func pid=135687)[0m mae:  0.11663758754730225
[2m[36m(func pid=135687)[0m rmse_per_class: [0.084, 0.299, 0.049, 0.323, 0.056, 0.228, 0.343, 0.17, 0.207, 0.321]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.5157 | Steps: 2 | Val loss: 0.3927 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.6567 | Steps: 2 | Val loss: 0.5357 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4952 | Steps: 2 | Val loss: 0.3647 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.6451 | Steps: 2 | Val loss: 0.6859 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 05:59:01 (running for 00:02:52.77)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.516 |  0.18  |                   23 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.652 |  0.187 |                   22 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.564 |  0.163 |                   21 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.638 |  0.208 |                   21 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.18005160987377167
[2m[36m(func pid=134465)[0m mae:  0.13137224316596985
[2m[36m(func pid=134465)[0m rmse_per_class: [0.108, 0.271, 0.093, 0.327, 0.098, 0.194, 0.299, 0.148, 0.142, 0.12]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.18888990581035614
[2m[36m(func pid=134839)[0m mae:  0.12476394325494766
[2m[36m(func pid=134839)[0m rmse_per_class: [0.106, 0.283, 0.056, 0.375, 0.055, 0.192, 0.409, 0.15, 0.171, 0.093]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.22188201546669006
[2m[36m(func pid=135687)[0m mae:  0.12361464649438858
[2m[36m(func pid=135687)[0m rmse_per_class: [0.122, 0.291, 0.048, 0.34, 0.056, 0.243, 0.32, 0.287, 0.232, 0.28]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.16238608956336975
[2m[36m(func pid=135261)[0m mae:  0.10844016075134277
[2m[36m(func pid=135261)[0m rmse_per_class: [0.086, 0.239, 0.048, 0.319, 0.056, 0.164, 0.312, 0.153, 0.148, 0.097]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4969 | Steps: 2 | Val loss: 0.3798 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.6754 | Steps: 2 | Val loss: 0.5432 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.6930 | Steps: 2 | Val loss: 0.7100 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4422 | Steps: 2 | Val loss: 0.3560 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 05:59:06 (running for 00:02:57.97)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.497 |  0.18  |                   24 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.657 |  0.189 |                   23 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.495 |  0.162 |                   22 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.645 |  0.222 |                   22 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1798572689294815
[2m[36m(func pid=134465)[0m mae:  0.1311543732881546
[2m[36m(func pid=134465)[0m rmse_per_class: [0.109, 0.271, 0.094, 0.328, 0.097, 0.194, 0.297, 0.147, 0.142, 0.12]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.19055137038230896
[2m[36m(func pid=134839)[0m mae:  0.12520986795425415
[2m[36m(func pid=134839)[0m rmse_per_class: [0.104, 0.284, 0.053, 0.376, 0.055, 0.192, 0.427, 0.151, 0.17, 0.093]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.2313569039106369
[2m[36m(func pid=135687)[0m mae:  0.12999144196510315
[2m[36m(func pid=135687)[0m rmse_per_class: [0.186, 0.276, 0.045, 0.349, 0.056, 0.19, 0.316, 0.424, 0.269, 0.202]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.17390340566635132
[2m[36m(func pid=135261)[0m mae:  0.11333264410495758
[2m[36m(func pid=135261)[0m rmse_per_class: [0.068, 0.246, 0.046, 0.353, 0.056, 0.176, 0.309, 0.147, 0.136, 0.202]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4828 | Steps: 2 | Val loss: 0.3680 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.6924 | Steps: 2 | Val loss: 0.5500 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.6841 | Steps: 2 | Val loss: 0.6771 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4397 | Steps: 2 | Val loss: 0.3648 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 05:59:12 (running for 00:03:03.35)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.18  |                   25 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.675 |  0.191 |                   24 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.442 |  0.174 |                   23 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.693 |  0.231 |                   23 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17979878187179565
[2m[36m(func pid=134465)[0m mae:  0.1310630738735199
[2m[36m(func pid=134465)[0m rmse_per_class: [0.109, 0.271, 0.095, 0.329, 0.096, 0.194, 0.296, 0.146, 0.143, 0.12]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.19208648800849915
[2m[36m(func pid=134839)[0m mae:  0.12564168870449066
[2m[36m(func pid=134839)[0m rmse_per_class: [0.103, 0.284, 0.052, 0.377, 0.056, 0.192, 0.443, 0.151, 0.17, 0.093]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.22637078166007996
[2m[36m(func pid=135687)[0m mae:  0.12613873183727264
[2m[36m(func pid=135687)[0m rmse_per_class: [0.168, 0.313, 0.04, 0.355, 0.056, 0.192, 0.31, 0.401, 0.29, 0.139]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.18668580055236816
[2m[36m(func pid=135261)[0m mae:  0.12155063450336456
[2m[36m(func pid=135261)[0m rmse_per_class: [0.066, 0.269, 0.041, 0.331, 0.056, 0.194, 0.302, 0.13, 0.13, 0.346]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4648 | Steps: 2 | Val loss: 0.3579 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.6135 | Steps: 2 | Val loss: 0.6538 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.6935 | Steps: 2 | Val loss: 0.5554 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4164 | Steps: 2 | Val loss: 0.3764 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 05:59:17 (running for 00:03:08.50)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.465 |  0.18  |                   26 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.692 |  0.192 |                   25 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.44  |  0.187 |                   24 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.684 |  0.226 |                   24 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1796407848596573
[2m[36m(func pid=134465)[0m mae:  0.13087430596351624
[2m[36m(func pid=134465)[0m rmse_per_class: [0.109, 0.271, 0.095, 0.33, 0.095, 0.194, 0.295, 0.145, 0.143, 0.119]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.20663006603717804
[2m[36m(func pid=135687)[0m mae:  0.11635317653417587
[2m[36m(func pid=135687)[0m rmse_per_class: [0.09, 0.384, 0.033, 0.361, 0.057, 0.209, 0.325, 0.236, 0.277, 0.095]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.19356495141983032
[2m[36m(func pid=134839)[0m mae:  0.1261437088251114
[2m[36m(func pid=134839)[0m rmse_per_class: [0.102, 0.285, 0.05, 0.379, 0.056, 0.192, 0.458, 0.152, 0.169, 0.094]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.19241274893283844
[2m[36m(func pid=135261)[0m mae:  0.1264154016971588
[2m[36m(func pid=135261)[0m rmse_per_class: [0.074, 0.285, 0.032, 0.279, 0.056, 0.207, 0.291, 0.111, 0.129, 0.459]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4508 | Steps: 2 | Val loss: 0.3495 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.5465 | Steps: 2 | Val loss: 0.6553 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.7037 | Steps: 2 | Val loss: 0.5584 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4278 | Steps: 2 | Val loss: 0.3886 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 05:59:22 (running for 00:03:13.72)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.451 |  0.179 |                   27 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.694 |  0.194 |                   26 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.416 |  0.192 |                   25 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.613 |  0.207 |                   25 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17944487929344177
[2m[36m(func pid=134465)[0m mae:  0.13062773644924164
[2m[36m(func pid=134465)[0m rmse_per_class: [0.11, 0.272, 0.095, 0.33, 0.095, 0.194, 0.293, 0.144, 0.144, 0.118]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.1965055763721466
[2m[36m(func pid=135687)[0m mae:  0.11402010917663574
[2m[36m(func pid=135687)[0m rmse_per_class: [0.073, 0.38, 0.029, 0.359, 0.058, 0.217, 0.387, 0.14, 0.24, 0.083]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.19485996663570404
[2m[36m(func pid=134839)[0m mae:  0.12652423977851868
[2m[36m(func pid=134839)[0m rmse_per_class: [0.101, 0.285, 0.049, 0.379, 0.056, 0.192, 0.472, 0.152, 0.167, 0.094]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.1973554641008377
[2m[36m(func pid=135261)[0m mae:  0.1281341016292572
[2m[36m(func pid=135261)[0m rmse_per_class: [0.081, 0.291, 0.025, 0.256, 0.056, 0.215, 0.273, 0.176, 0.13, 0.471]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4463 | Steps: 2 | Val loss: 0.3428 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.5551 | Steps: 2 | Val loss: 0.6425 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.6970 | Steps: 2 | Val loss: 0.5628 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4379 | Steps: 2 | Val loss: 0.4175 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 05:59:27 (running for 00:03:18.81)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.446 |  0.179 |                   28 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.704 |  0.195 |                   27 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.428 |  0.197 |                   26 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.547 |  0.197 |                   26 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17926263809204102
[2m[36m(func pid=134465)[0m mae:  0.13044776022434235
[2m[36m(func pid=134465)[0m rmse_per_class: [0.11, 0.272, 0.096, 0.331, 0.094, 0.194, 0.291, 0.143, 0.145, 0.117]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.19575142860412598
[2m[36m(func pid=135687)[0m mae:  0.11179287731647491
[2m[36m(func pid=135687)[0m rmse_per_class: [0.082, 0.363, 0.035, 0.346, 0.061, 0.203, 0.404, 0.14, 0.238, 0.087]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.1962740570306778
[2m[36m(func pid=134839)[0m mae:  0.12702956795692444
[2m[36m(func pid=134839)[0m rmse_per_class: [0.1, 0.286, 0.049, 0.38, 0.056, 0.193, 0.486, 0.153, 0.166, 0.094]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.20732298493385315
[2m[36m(func pid=135261)[0m mae:  0.13298580050468445
[2m[36m(func pid=135261)[0m rmse_per_class: [0.085, 0.294, 0.036, 0.277, 0.056, 0.219, 0.254, 0.345, 0.132, 0.375]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.5807 | Steps: 2 | Val loss: 0.6344 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4386 | Steps: 2 | Val loss: 0.3375 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.7082 | Steps: 2 | Val loss: 0.5646 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 05:59:32 (running for 00:03:23.86)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.446 |  0.179 |                   28 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.697 |  0.196 |                   28 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.438 |  0.207 |                   27 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.581 |  0.193 |                   28 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=135687)[0m rmse: 0.1926618069410324
[2m[36m(func pid=135687)[0m mae:  0.10402234643697739
[2m[36m(func pid=135687)[0m rmse_per_class: [0.085, 0.328, 0.053, 0.33, 0.085, 0.199, 0.356, 0.144, 0.257, 0.089]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.1791733205318451
[2m[36m(func pid=134465)[0m mae:  0.13030977547168732
[2m[36m(func pid=134465)[0m rmse_per_class: [0.111, 0.272, 0.097, 0.332, 0.093, 0.194, 0.29, 0.141, 0.146, 0.116]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4419 | Steps: 2 | Val loss: 0.4630 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=134839)[0m rmse: 0.19750715792179108
[2m[36m(func pid=134839)[0m mae:  0.12749193608760834
[2m[36m(func pid=134839)[0m rmse_per_class: [0.1, 0.286, 0.048, 0.381, 0.056, 0.193, 0.498, 0.153, 0.165, 0.094]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.2151356041431427
[2m[36m(func pid=135261)[0m mae:  0.13937848806381226
[2m[36m(func pid=135261)[0m rmse_per_class: [0.089, 0.295, 0.056, 0.322, 0.056, 0.223, 0.241, 0.499, 0.134, 0.236]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.6327 | Steps: 2 | Val loss: 0.6547 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4309 | Steps: 2 | Val loss: 0.3332 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.7042 | Steps: 2 | Val loss: 0.5614 | Batch size: 32 | lr: 0.001 | Duration: 2.68s
== Status ==
Current time: 2024-01-07 05:59:38 (running for 00:03:29.09)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.439 |  0.179 |                   29 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.708 |  0.198 |                   29 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.442 |  0.215 |                   28 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.633 |  0.201 |                   29 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=135687)[0m rmse: 0.20068809390068054
[2m[36m(func pid=135687)[0m mae:  0.10747487843036652
[2m[36m(func pid=135687)[0m rmse_per_class: [0.083, 0.275, 0.058, 0.325, 0.133, 0.333, 0.311, 0.148, 0.25, 0.091]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.17893870174884796
[2m[36m(func pid=134465)[0m mae:  0.13006237149238586
[2m[36m(func pid=134465)[0m rmse_per_class: [0.111, 0.272, 0.097, 0.333, 0.092, 0.194, 0.288, 0.141, 0.146, 0.115]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.19833695888519287
[2m[36m(func pid=134839)[0m mae:  0.12781938910484314
[2m[36m(func pid=134839)[0m rmse_per_class: [0.099, 0.286, 0.048, 0.381, 0.056, 0.193, 0.506, 0.154, 0.165, 0.095]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4916 | Steps: 2 | Val loss: 0.5042 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.6688 | Steps: 2 | Val loss: 0.6791 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4248 | Steps: 2 | Val loss: 0.3300 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=135261)[0m rmse: 0.2178107053041458
[2m[36m(func pid=135261)[0m mae:  0.14306771755218506
[2m[36m(func pid=135261)[0m rmse_per_class: [0.093, 0.296, 0.08, 0.355, 0.056, 0.224, 0.235, 0.57, 0.137, 0.132]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.6983 | Steps: 2 | Val loss: 0.5562 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 05:59:43 (running for 00:03:34.30)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.431 |  0.179 |                   30 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.704 |  0.198 |                   30 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.492 |  0.218 |                   29 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.669 |  0.206 |                   30 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=135687)[0m rmse: 0.20600172877311707
[2m[36m(func pid=135687)[0m mae:  0.11259029060602188
[2m[36m(func pid=135687)[0m rmse_per_class: [0.088, 0.28, 0.053, 0.32, 0.166, 0.38, 0.313, 0.15, 0.217, 0.093]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.17871230840682983
[2m[36m(func pid=134465)[0m mae:  0.12981674075126648
[2m[36m(func pid=134465)[0m rmse_per_class: [0.112, 0.272, 0.098, 0.334, 0.091, 0.194, 0.287, 0.139, 0.147, 0.114]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.19917044043540955
[2m[36m(func pid=134839)[0m mae:  0.1281430572271347
[2m[36m(func pid=134839)[0m rmse_per_class: [0.099, 0.287, 0.048, 0.382, 0.056, 0.193, 0.514, 0.154, 0.165, 0.095]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4900 | Steps: 2 | Val loss: 0.5209 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.7078 | Steps: 2 | Val loss: 0.6921 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.7119 | Steps: 2 | Val loss: 0.5542 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4198 | Steps: 2 | Val loss: 0.3280 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=135261)[0m rmse: 0.21772590279579163
[2m[36m(func pid=135261)[0m mae:  0.14303657412528992
[2m[36m(func pid=135261)[0m rmse_per_class: [0.094, 0.295, 0.108, 0.37, 0.056, 0.223, 0.247, 0.553, 0.139, 0.094]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.20329323410987854
[2m[36m(func pid=135687)[0m mae:  0.10926715284585953
[2m[36m(func pid=135687)[0m rmse_per_class: [0.111, 0.295, 0.042, 0.311, 0.197, 0.279, 0.354, 0.15, 0.201, 0.094]
== Status ==
Current time: 2024-01-07 05:59:48 (running for 00:03:39.38)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.425 |  0.179 |                   31 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.698 |  0.199 |                   31 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.49  |  0.218 |                   30 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.708 |  0.203 |                   31 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.20012244582176208
[2m[36m(func pid=134839)[0m mae:  0.1285526603460312
[2m[36m(func pid=134839)[0m rmse_per_class: [0.098, 0.287, 0.048, 0.382, 0.056, 0.194, 0.522, 0.154, 0.164, 0.095]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.17861585319042206
[2m[36m(func pid=134465)[0m mae:  0.1296621710062027
[2m[36m(func pid=134465)[0m rmse_per_class: [0.112, 0.272, 0.098, 0.335, 0.09, 0.194, 0.285, 0.139, 0.148, 0.113]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.5126 | Steps: 2 | Val loss: 0.5134 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.6844 | Steps: 2 | Val loss: 0.7111 | Batch size: 32 | lr: 0.1 | Duration: 2.66s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4197 | Steps: 2 | Val loss: 0.3266 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.6928 | Steps: 2 | Val loss: 0.5487 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=135261)[0m rmse: 0.216004878282547
[2m[36m(func pid=135261)[0m mae:  0.13950762152671814
[2m[36m(func pid=135261)[0m rmse_per_class: [0.092, 0.291, 0.14, 0.375, 0.054, 0.219, 0.287, 0.472, 0.143, 0.089]
[2m[36m(func pid=135261)[0m 
== Status ==
Current time: 2024-01-07 05:59:53 (running for 00:03:44.43)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.42  |  0.179 |                   32 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.712 |  0.2   |                   32 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.513 |  0.216 |                   31 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.684 |  0.208 |                   32 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=135687)[0m rmse: 0.2080477774143219
[2m[36m(func pid=135687)[0m mae:  0.1102747768163681
[2m[36m(func pid=135687)[0m rmse_per_class: [0.2, 0.3, 0.033, 0.325, 0.237, 0.208, 0.355, 0.144, 0.186, 0.093]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.17835146188735962
[2m[36m(func pid=134465)[0m mae:  0.1293846070766449
[2m[36m(func pid=134465)[0m rmse_per_class: [0.112, 0.272, 0.099, 0.336, 0.089, 0.194, 0.284, 0.138, 0.148, 0.112]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.20045843720436096
[2m[36m(func pid=134839)[0m mae:  0.12866844236850739
[2m[36m(func pid=134839)[0m rmse_per_class: [0.098, 0.287, 0.048, 0.383, 0.056, 0.194, 0.525, 0.154, 0.165, 0.095]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4733 | Steps: 2 | Val loss: 0.4895 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.6829 | Steps: 2 | Val loss: 0.7320 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.6946 | Steps: 2 | Val loss: 0.5401 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4167 | Steps: 2 | Val loss: 0.3258 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=135261)[0m rmse: 0.21048963069915771
[2m[36m(func pid=135261)[0m mae:  0.13217663764953613
[2m[36m(func pid=135261)[0m rmse_per_class: [0.088, 0.282, 0.17, 0.376, 0.052, 0.209, 0.348, 0.341, 0.15, 0.089]
[2m[36m(func pid=135261)[0m 
== Status ==
Current time: 2024-01-07 05:59:58 (running for 00:03:49.53)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.42  |  0.178 |                   33 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.693 |  0.2   |                   33 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.473 |  0.21  |                   32 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.683 |  0.217 |                   33 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=135687)[0m rmse: 0.21714229881763458
[2m[36m(func pid=135687)[0m mae:  0.11517971754074097
[2m[36m(func pid=135687)[0m rmse_per_class: [0.305, 0.301, 0.031, 0.356, 0.253, 0.209, 0.315, 0.139, 0.175, 0.088]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.2008678913116455
[2m[36m(func pid=134839)[0m mae:  0.12880797684192657
[2m[36m(func pid=134839)[0m rmse_per_class: [0.097, 0.287, 0.048, 0.383, 0.056, 0.194, 0.53, 0.155, 0.164, 0.095]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.17813906073570251
[2m[36m(func pid=134465)[0m mae:  0.12910325825214386
[2m[36m(func pid=134465)[0m rmse_per_class: [0.112, 0.273, 0.099, 0.336, 0.088, 0.194, 0.282, 0.137, 0.149, 0.111]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4636 | Steps: 2 | Val loss: 0.4664 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.6829 | Steps: 2 | Val loss: 0.7061 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.6881 | Steps: 2 | Val loss: 0.5315 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4170 | Steps: 2 | Val loss: 0.3257 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=135261)[0m rmse: 0.19979865849018097
[2m[36m(func pid=135261)[0m mae:  0.12238262593746185
[2m[36m(func pid=135261)[0m rmse_per_class: [0.083, 0.269, 0.175, 0.376, 0.055, 0.189, 0.385, 0.215, 0.161, 0.09]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.21726591885089874
[2m[36m(func pid=135687)[0m mae:  0.11453835666179657
[2m[36m(func pid=135687)[0m rmse_per_class: [0.304, 0.299, 0.035, 0.36, 0.225, 0.214, 0.32, 0.14, 0.19, 0.087]
[2m[36m(func pid=135687)[0m 
== Status ==
Current time: 2024-01-07 06:00:03 (running for 00:03:54.68)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.417 |  0.178 |                   34 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.695 |  0.201 |                   34 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.464 |  0.2   |                   33 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.683 |  0.217 |                   34 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134839)[0m rmse: 0.2010059803724289
[2m[36m(func pid=134839)[0m mae:  0.12881962954998016
[2m[36m(func pid=134839)[0m rmse_per_class: [0.097, 0.286, 0.048, 0.383, 0.056, 0.193, 0.531, 0.155, 0.165, 0.096]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.17791728675365448
[2m[36m(func pid=134465)[0m mae:  0.12883639335632324
[2m[36m(func pid=134465)[0m rmse_per_class: [0.112, 0.273, 0.098, 0.337, 0.087, 0.194, 0.281, 0.137, 0.15, 0.11]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.6152 | Steps: 2 | Val loss: 0.6478 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4146 | Steps: 2 | Val loss: 0.4425 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.6709 | Steps: 2 | Val loss: 0.5237 | Batch size: 32 | lr: 0.001 | Duration: 2.68s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4184 | Steps: 2 | Val loss: 0.3263 | Batch size: 32 | lr: 0.0001 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 06:00:08 (running for 00:03:59.72)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.417 |  0.178 |                   35 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.688 |  0.201 |                   35 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.464 |  0.2   |                   33 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.615 |  0.212 |                   35 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=135687)[0m rmse: 0.2116514891386032
[2m[36m(func pid=135687)[0m mae:  0.10922044515609741
[2m[36m(func pid=135687)[0m rmse_per_class: [0.18, 0.29, 0.038, 0.34, 0.166, 0.208, 0.355, 0.172, 0.252, 0.114]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.18642932176589966
[2m[36m(func pid=135261)[0m mae:  0.11182594299316406
[2m[36m(func pid=135261)[0m rmse_per_class: [0.077, 0.255, 0.157, 0.373, 0.086, 0.167, 0.351, 0.131, 0.176, 0.091]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.20107965171337128
[2m[36m(func pid=134839)[0m mae:  0.12878799438476562
[2m[36m(func pid=134839)[0m rmse_per_class: [0.096, 0.286, 0.048, 0.383, 0.056, 0.193, 0.532, 0.155, 0.165, 0.096]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.1777912825345993
[2m[36m(func pid=134465)[0m mae:  0.1286252737045288
[2m[36m(func pid=134465)[0m rmse_per_class: [0.113, 0.273, 0.099, 0.338, 0.086, 0.194, 0.28, 0.136, 0.151, 0.109]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.5547 | Steps: 2 | Val loss: 0.5963 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3935 | Steps: 2 | Val loss: 0.4277 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.6687 | Steps: 2 | Val loss: 0.5142 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4151 | Steps: 2 | Val loss: 0.3275 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=135687)[0m rmse: 0.20282654464244843
[2m[36m(func pid=135687)[0m mae:  0.10725537687540054
[2m[36m(func pid=135687)[0m rmse_per_class: [0.088, 0.272, 0.044, 0.318, 0.094, 0.195, 0.381, 0.211, 0.279, 0.148]
[2m[36m(func pid=135687)[0m 
== Status ==
Current time: 2024-01-07 06:00:14 (running for 00:04:05.52)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.418 |  0.178 |                   36 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.671 |  0.201 |                   36 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.394 |  0.18  |                   35 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.555 |  0.203 |                   36 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=135261)[0m rmse: 0.1804535984992981
[2m[36m(func pid=135261)[0m mae:  0.10744289308786392
[2m[36m(func pid=135261)[0m rmse_per_class: [0.073, 0.254, 0.122, 0.372, 0.146, 0.175, 0.271, 0.113, 0.185, 0.093]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.2009098082780838
[2m[36m(func pid=134839)[0m mae:  0.12865105271339417
[2m[36m(func pid=134839)[0m rmse_per_class: [0.096, 0.286, 0.048, 0.383, 0.056, 0.193, 0.529, 0.155, 0.168, 0.096]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.17759530246257782
[2m[36m(func pid=134465)[0m mae:  0.12838804721832275
[2m[36m(func pid=134465)[0m rmse_per_class: [0.113, 0.273, 0.098, 0.339, 0.085, 0.194, 0.279, 0.136, 0.152, 0.108]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.5615 | Steps: 2 | Val loss: 0.5865 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3870 | Steps: 2 | Val loss: 0.4184 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4203 | Steps: 2 | Val loss: 0.3288 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.6534 | Steps: 2 | Val loss: 0.5039 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=135687)[0m rmse: 0.19886192679405212
[2m[36m(func pid=135687)[0m mae:  0.10653954744338989
[2m[36m(func pid=135687)[0m rmse_per_class: [0.096, 0.275, 0.047, 0.328, 0.058, 0.206, 0.339, 0.211, 0.259, 0.17]
[2m[36m(func pid=135687)[0m 
== Status ==
Current time: 2024-01-07 06:00:19 (running for 00:04:11.00)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.415 |  0.178 |                   37 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.669 |  0.201 |                   37 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.387 |  0.183 |                   36 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.562 |  0.199 |                   37 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17735899984836578
[2m[36m(func pid=134465)[0m mae:  0.1281065195798874
[2m[36m(func pid=134465)[0m rmse_per_class: [0.113, 0.273, 0.098, 0.339, 0.084, 0.194, 0.278, 0.135, 0.152, 0.108]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.2006647288799286
[2m[36m(func pid=134839)[0m mae:  0.1284322589635849
[2m[36m(func pid=134839)[0m rmse_per_class: [0.095, 0.285, 0.048, 0.383, 0.056, 0.192, 0.527, 0.155, 0.169, 0.096]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.18318329751491547
[2m[36m(func pid=135261)[0m mae:  0.11097665876150131
[2m[36m(func pid=135261)[0m rmse_per_class: [0.07, 0.263, 0.081, 0.371, 0.21, 0.218, 0.213, 0.125, 0.188, 0.094]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.6111 | Steps: 2 | Val loss: 0.6330 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4177 | Steps: 2 | Val loss: 0.3307 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.6418 | Steps: 2 | Val loss: 0.4928 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3834 | Steps: 2 | Val loss: 0.4196 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=135687)[0m rmse: 0.20474979281425476
[2m[36m(func pid=135687)[0m mae:  0.11084288358688354
[2m[36m(func pid=135687)[0m rmse_per_class: [0.103, 0.323, 0.049, 0.352, 0.057, 0.222, 0.292, 0.21, 0.229, 0.211]
[2m[36m(func pid=135687)[0m 
== Status ==
Current time: 2024-01-07 06:00:25 (running for 00:04:16.34)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.42  |  0.177 |                   38 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.653 |  0.201 |                   38 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.383 |  0.191 |                   37 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.611 |  0.205 |                   38 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=135261)[0m rmse: 0.1906178891658783
[2m[36m(func pid=135261)[0m mae:  0.11834065616130829
[2m[36m(func pid=135261)[0m rmse_per_class: [0.069, 0.272, 0.051, 0.369, 0.253, 0.253, 0.226, 0.139, 0.181, 0.095]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.17720399796962738
[2m[36m(func pid=134465)[0m mae:  0.12787148356437683
[2m[36m(func pid=134465)[0m rmse_per_class: [0.113, 0.273, 0.098, 0.34, 0.082, 0.194, 0.277, 0.135, 0.152, 0.107]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.19991132616996765
[2m[36m(func pid=134839)[0m mae:  0.1279483288526535
[2m[36m(func pid=134839)[0m rmse_per_class: [0.095, 0.284, 0.048, 0.383, 0.056, 0.191, 0.519, 0.155, 0.172, 0.096]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.6863 | Steps: 2 | Val loss: 0.7014 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4208 | Steps: 2 | Val loss: 0.3331 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.6274 | Steps: 2 | Val loss: 0.4802 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3897 | Steps: 2 | Val loss: 0.4331 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=135687)[0m rmse: 0.21057577431201935
[2m[36m(func pid=135687)[0m mae:  0.1164260134100914
[2m[36m(func pid=135687)[0m rmse_per_class: [0.1, 0.374, 0.049, 0.367, 0.057, 0.193, 0.286, 0.182, 0.217, 0.281]
[2m[36m(func pid=135687)[0m 
== Status ==
Current time: 2024-01-07 06:00:30 (running for 00:04:21.73)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.421 |  0.177 |                   40 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.642 |  0.2   |                   39 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.383 |  0.191 |                   37 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.686 |  0.211 |                   39 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17713011801242828
[2m[36m(func pid=134465)[0m mae:  0.12766018509864807
[2m[36m(func pid=134465)[0m rmse_per_class: [0.114, 0.273, 0.098, 0.341, 0.082, 0.194, 0.276, 0.135, 0.153, 0.106]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.19857116043567657
[2m[36m(func pid=134839)[0m mae:  0.12714633345603943
[2m[36m(func pid=134839)[0m rmse_per_class: [0.094, 0.282, 0.048, 0.382, 0.056, 0.19, 0.506, 0.155, 0.175, 0.096]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.19517259299755096
[2m[36m(func pid=135261)[0m mae:  0.12371820211410522
[2m[36m(func pid=135261)[0m rmse_per_class: [0.068, 0.275, 0.035, 0.365, 0.268, 0.266, 0.257, 0.147, 0.175, 0.096]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.6775 | Steps: 2 | Val loss: 0.7415 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4295 | Steps: 2 | Val loss: 0.3356 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.6228 | Steps: 2 | Val loss: 0.4658 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4126 | Steps: 2 | Val loss: 0.4471 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=135687)[0m rmse: 0.21095995604991913
[2m[36m(func pid=135687)[0m mae:  0.11790364980697632
[2m[36m(func pid=135687)[0m rmse_per_class: [0.086, 0.39, 0.049, 0.373, 0.057, 0.19, 0.318, 0.138, 0.212, 0.297]
[2m[36m(func pid=135687)[0m 
== Status ==
Current time: 2024-01-07 06:00:35 (running for 00:04:26.80)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.429 |  0.177 |                   41 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.627 |  0.199 |                   40 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.39  |  0.195 |                   38 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.678 |  0.211 |                   40 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17696872353553772
[2m[36m(func pid=134465)[0m mae:  0.1273953914642334
[2m[36m(func pid=134465)[0m rmse_per_class: [0.114, 0.274, 0.098, 0.341, 0.08, 0.194, 0.275, 0.135, 0.153, 0.105]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.19689224660396576
[2m[36m(func pid=134839)[0m mae:  0.12615299224853516
[2m[36m(func pid=134839)[0m rmse_per_class: [0.093, 0.281, 0.049, 0.382, 0.056, 0.188, 0.49, 0.155, 0.18, 0.096]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.19503703713417053
[2m[36m(func pid=135261)[0m mae:  0.12511804699897766
[2m[36m(func pid=135261)[0m rmse_per_class: [0.071, 0.277, 0.028, 0.357, 0.258, 0.264, 0.277, 0.151, 0.171, 0.096]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.6230 | Steps: 2 | Val loss: 0.7487 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4242 | Steps: 2 | Val loss: 0.3386 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.5969 | Steps: 2 | Val loss: 0.4532 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4475 | Steps: 2 | Val loss: 0.4479 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=135687)[0m rmse: 0.21382832527160645
[2m[36m(func pid=135687)[0m mae:  0.11781418323516846
[2m[36m(func pid=135687)[0m rmse_per_class: [0.19, 0.328, 0.049, 0.374, 0.057, 0.212, 0.375, 0.135, 0.193, 0.226]
[2m[36m(func pid=135687)[0m 
== Status ==
Current time: 2024-01-07 06:00:41 (running for 00:04:32.20)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.424 |  0.177 |                   42 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.623 |  0.197 |                   41 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.413 |  0.195 |                   39 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.623 |  0.214 |                   41 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17687401175498962
[2m[36m(func pid=134465)[0m mae:  0.12723109126091003
[2m[36m(func pid=134465)[0m rmse_per_class: [0.114, 0.274, 0.098, 0.342, 0.079, 0.194, 0.275, 0.135, 0.154, 0.104]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.1948925256729126
[2m[36m(func pid=134839)[0m mae:  0.12502488493919373
[2m[36m(func pid=134839)[0m rmse_per_class: [0.092, 0.279, 0.049, 0.381, 0.056, 0.186, 0.468, 0.155, 0.187, 0.096]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.19186577200889587
[2m[36m(func pid=135261)[0m mae:  0.12303998321294785
[2m[36m(func pid=135261)[0m rmse_per_class: [0.077, 0.278, 0.027, 0.343, 0.232, 0.257, 0.282, 0.153, 0.175, 0.095]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.6282 | Steps: 2 | Val loss: 0.7573 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4345 | Steps: 2 | Val loss: 0.3410 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.5829 | Steps: 2 | Val loss: 0.4394 | Batch size: 32 | lr: 0.001 | Duration: 2.68s
[2m[36m(func pid=135687)[0m rmse: 0.21784467995166779
[2m[36m(func pid=135687)[0m mae:  0.12336273491382599
[2m[36m(func pid=135687)[0m rmse_per_class: [0.349, 0.276, 0.049, 0.369, 0.057, 0.213, 0.384, 0.146, 0.168, 0.169]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4453 | Steps: 2 | Val loss: 0.4328 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=134839)[0m rmse: 0.19260424375534058
[2m[36m(func pid=134839)[0m mae:  0.12377114593982697
[2m[36m(func pid=134839)[0m rmse_per_class: [0.092, 0.277, 0.049, 0.38, 0.056, 0.184, 0.444, 0.155, 0.194, 0.096]
[2m[36m(func pid=134839)[0m 
== Status ==
Current time: 2024-01-07 06:00:46 (running for 00:04:37.38)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.435 |  0.177 |                   43 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.583 |  0.193 |                   43 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.448 |  0.192 |                   40 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.628 |  0.218 |                   42 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17669041454792023
[2m[36m(func pid=134465)[0m mae:  0.12700633704662323
[2m[36m(func pid=134465)[0m rmse_per_class: [0.114, 0.273, 0.097, 0.343, 0.078, 0.194, 0.274, 0.135, 0.154, 0.103]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.6270 | Steps: 2 | Val loss: 0.7502 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=135261)[0m rmse: 0.18689300119876862
[2m[36m(func pid=135261)[0m mae:  0.118449367582798
[2m[36m(func pid=135261)[0m rmse_per_class: [0.085, 0.271, 0.027, 0.323, 0.199, 0.249, 0.277, 0.153, 0.191, 0.094]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.5686 | Steps: 2 | Val loss: 0.4260 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4357 | Steps: 2 | Val loss: 0.3440 | Batch size: 32 | lr: 0.0001 | Duration: 2.74s
[2m[36m(func pid=135687)[0m rmse: 0.21226899325847626
[2m[36m(func pid=135687)[0m mae:  0.11789945513010025
[2m[36m(func pid=135687)[0m rmse_per_class: [0.317, 0.273, 0.048, 0.351, 0.056, 0.191, 0.405, 0.151, 0.189, 0.141]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4503 | Steps: 2 | Val loss: 0.4085 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 06:00:51 (running for 00:04:42.46)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.436 |  0.177 |                   44 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.583 |  0.193 |                   43 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.445 |  0.187 |                   41 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.627 |  0.212 |                   43 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17658700048923492
[2m[36m(func pid=134465)[0m mae:  0.1268186867237091
[2m[36m(func pid=134465)[0m rmse_per_class: [0.114, 0.273, 0.097, 0.343, 0.077, 0.194, 0.274, 0.135, 0.155, 0.103]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.19004295766353607
[2m[36m(func pid=134839)[0m mae:  0.12248881161212921
[2m[36m(func pid=134839)[0m rmse_per_class: [0.092, 0.274, 0.049, 0.379, 0.056, 0.182, 0.415, 0.155, 0.203, 0.096]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.5878 | Steps: 2 | Val loss: 0.7513 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=135261)[0m rmse: 0.18019697070121765
[2m[36m(func pid=135261)[0m mae:  0.11189030110836029
[2m[36m(func pid=135261)[0m rmse_per_class: [0.093, 0.263, 0.028, 0.301, 0.16, 0.233, 0.264, 0.153, 0.213, 0.093]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.5396 | Steps: 2 | Val loss: 0.4124 | Batch size: 32 | lr: 0.001 | Duration: 2.68s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4394 | Steps: 2 | Val loss: 0.3473 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=135687)[0m rmse: 0.20387837290763855
[2m[36m(func pid=135687)[0m mae:  0.11476536840200424
[2m[36m(func pid=135687)[0m rmse_per_class: [0.12, 0.285, 0.046, 0.333, 0.056, 0.364, 0.37, 0.152, 0.211, 0.102]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4167 | Steps: 2 | Val loss: 0.3802 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 06:00:56 (running for 00:04:47.66)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.439 |  0.177 |                   45 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.569 |  0.19  |                   44 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.45  |  0.18  |                   42 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.588 |  0.204 |                   44 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1765536367893219
[2m[36m(func pid=134465)[0m mae:  0.12667562067508698
[2m[36m(func pid=134465)[0m rmse_per_class: [0.115, 0.273, 0.097, 0.344, 0.076, 0.194, 0.274, 0.135, 0.156, 0.102]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.18704423308372498
[2m[36m(func pid=134839)[0m mae:  0.12105201184749603
[2m[36m(func pid=134839)[0m rmse_per_class: [0.092, 0.27, 0.049, 0.378, 0.056, 0.18, 0.383, 0.155, 0.212, 0.096]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.5978 | Steps: 2 | Val loss: 0.7593 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=135261)[0m rmse: 0.171531543135643
[2m[36m(func pid=135261)[0m mae:  0.10395371913909912
[2m[36m(func pid=135261)[0m rmse_per_class: [0.096, 0.249, 0.03, 0.284, 0.127, 0.21, 0.243, 0.154, 0.233, 0.09]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4421 | Steps: 2 | Val loss: 0.3503 | Batch size: 32 | lr: 0.0001 | Duration: 2.67s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.5324 | Steps: 2 | Val loss: 0.3996 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=135687)[0m rmse: 0.20573823153972626
[2m[36m(func pid=135687)[0m mae:  0.11952750384807587
[2m[36m(func pid=135687)[0m rmse_per_class: [0.096, 0.295, 0.042, 0.324, 0.056, 0.471, 0.334, 0.153, 0.197, 0.089]
[2m[36m(func pid=135687)[0m 
== Status ==
Current time: 2024-01-07 06:01:01 (running for 00:04:52.70)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.442 |  0.176 |                   46 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.54  |  0.187 |                   45 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.417 |  0.172 |                   43 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.598 |  0.206 |                   45 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17634978890419006
[2m[36m(func pid=134465)[0m mae:  0.12641625106334686
[2m[36m(func pid=134465)[0m rmse_per_class: [0.115, 0.273, 0.096, 0.345, 0.075, 0.194, 0.274, 0.135, 0.156, 0.102]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.18398675322532654
[2m[36m(func pid=134839)[0m mae:  0.11964670568704605
[2m[36m(func pid=134839)[0m rmse_per_class: [0.092, 0.267, 0.049, 0.376, 0.056, 0.18, 0.349, 0.155, 0.221, 0.096]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4019 | Steps: 2 | Val loss: 0.3589 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.6583 | Steps: 2 | Val loss: 0.7408 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4451 | Steps: 2 | Val loss: 0.3530 | Batch size: 32 | lr: 0.0001 | Duration: 2.73s
[2m[36m(func pid=135261)[0m rmse: 0.16380101442337036
[2m[36m(func pid=135261)[0m mae:  0.09672416001558304
[2m[36m(func pid=135261)[0m rmse_per_class: [0.095, 0.236, 0.032, 0.281, 0.097, 0.186, 0.225, 0.153, 0.247, 0.085]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.5153 | Steps: 2 | Val loss: 0.3884 | Batch size: 32 | lr: 0.001 | Duration: 2.67s
[2m[36m(func pid=135687)[0m rmse: 0.19836442172527313
[2m[36m(func pid=135687)[0m mae:  0.11348609626293182
[2m[36m(func pid=135687)[0m rmse_per_class: [0.103, 0.298, 0.039, 0.323, 0.057, 0.282, 0.449, 0.15, 0.193, 0.089]
[2m[36m(func pid=135687)[0m 
== Status ==
Current time: 2024-01-07 06:01:06 (running for 00:04:57.80)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.442 |  0.176 |                   46 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.515 |  0.181 |                   47 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.402 |  0.164 |                   44 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.658 |  0.198 |                   46 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17620646953582764
[2m[36m(func pid=134465)[0m mae:  0.12619158625602722
[2m[36m(func pid=134465)[0m rmse_per_class: [0.115, 0.273, 0.095, 0.345, 0.074, 0.194, 0.273, 0.135, 0.157, 0.101]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.1810338795185089
[2m[36m(func pid=134839)[0m mae:  0.11844537407159805
[2m[36m(func pid=134839)[0m rmse_per_class: [0.094, 0.263, 0.049, 0.374, 0.056, 0.18, 0.315, 0.155, 0.229, 0.096]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3915 | Steps: 2 | Val loss: 0.3509 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.6013 | Steps: 2 | Val loss: 0.7214 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4494 | Steps: 2 | Val loss: 0.3558 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.5204 | Steps: 2 | Val loss: 0.3769 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=135261)[0m rmse: 0.1607738435268402
[2m[36m(func pid=135261)[0m mae:  0.09336430579423904
[2m[36m(func pid=135261)[0m rmse_per_class: [0.088, 0.231, 0.034, 0.295, 0.073, 0.173, 0.219, 0.153, 0.259, 0.082]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.19895228743553162
[2m[36m(func pid=135687)[0m mae:  0.11599018424749374
[2m[36m(func pid=135687)[0m rmse_per_class: [0.097, 0.295, 0.033, 0.336, 0.058, 0.206, 0.535, 0.14, 0.199, 0.09]
[2m[36m(func pid=135687)[0m 
== Status ==
Current time: 2024-01-07 06:01:11 (running for 00:05:03.02)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.449 |  0.176 |                   48 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.515 |  0.181 |                   47 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.391 |  0.161 |                   45 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.601 |  0.199 |                   47 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1759262979030609
[2m[36m(func pid=134465)[0m mae:  0.1257646679878235
[2m[36m(func pid=134465)[0m rmse_per_class: [0.115, 0.274, 0.094, 0.346, 0.073, 0.194, 0.273, 0.135, 0.156, 0.1]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.1781938374042511
[2m[36m(func pid=134839)[0m mae:  0.1175004094839096
[2m[36m(func pid=134839)[0m rmse_per_class: [0.095, 0.259, 0.049, 0.371, 0.056, 0.182, 0.283, 0.155, 0.236, 0.096]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3596 | Steps: 2 | Val loss: 0.3522 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.5918 | Steps: 2 | Val loss: 0.6847 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4542 | Steps: 2 | Val loss: 0.3591 | Batch size: 32 | lr: 0.0001 | Duration: 2.74s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4923 | Steps: 2 | Val loss: 0.3668 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=135261)[0m rmse: 0.1627323031425476
[2m[36m(func pid=135261)[0m mae:  0.09346401691436768
[2m[36m(func pid=135261)[0m rmse_per_class: [0.079, 0.237, 0.036, 0.315, 0.06, 0.176, 0.226, 0.152, 0.262, 0.084]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.1942296028137207
[2m[36m(func pid=135687)[0m mae:  0.1087050810456276
[2m[36m(func pid=135687)[0m rmse_per_class: [0.097, 0.28, 0.04, 0.364, 0.066, 0.211, 0.45, 0.142, 0.202, 0.09]
[2m[36m(func pid=135687)[0m 
== Status ==
Current time: 2024-01-07 06:01:17 (running for 00:05:08.07)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.454 |  0.176 |                   49 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.52  |  0.178 |                   48 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.36  |  0.163 |                   46 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.592 |  0.194 |                   48 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1759362518787384
[2m[36m(func pid=134465)[0m mae:  0.12564952671527863
[2m[36m(func pid=134465)[0m rmse_per_class: [0.115, 0.274, 0.093, 0.346, 0.072, 0.194, 0.273, 0.135, 0.157, 0.1]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.17574982345104218
[2m[36m(func pid=134839)[0m mae:  0.11695071309804916
[2m[36m(func pid=134839)[0m rmse_per_class: [0.098, 0.256, 0.049, 0.367, 0.056, 0.184, 0.257, 0.155, 0.24, 0.095]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3631 | Steps: 2 | Val loss: 0.3611 | Batch size: 32 | lr: 0.01 | Duration: 3.16s
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.6413 | Steps: 2 | Val loss: 0.6200 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4587 | Steps: 2 | Val loss: 0.3627 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4930 | Steps: 2 | Val loss: 0.3582 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=135687)[0m rmse: 0.1990455538034439
[2m[36m(func pid=135687)[0m mae:  0.10662230104207993
[2m[36m(func pid=135687)[0m rmse_per_class: [0.208, 0.268, 0.04, 0.344, 0.072, 0.217, 0.357, 0.215, 0.177, 0.091]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.16783253848552704
[2m[36m(func pid=135261)[0m mae:  0.09572552144527435
[2m[36m(func pid=135261)[0m rmse_per_class: [0.072, 0.25, 0.038, 0.333, 0.054, 0.186, 0.24, 0.15, 0.257, 0.099]
[2m[36m(func pid=135261)[0m 
== Status ==
Current time: 2024-01-07 06:01:22 (running for 00:05:13.39)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.459 |  0.176 |                   50 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.492 |  0.176 |                   49 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.363 |  0.168 |                   47 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.641 |  0.199 |                   49 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17577683925628662
[2m[36m(func pid=134465)[0m mae:  0.12537968158721924
[2m[36m(func pid=134465)[0m rmse_per_class: [0.115, 0.274, 0.092, 0.346, 0.071, 0.194, 0.273, 0.136, 0.157, 0.1]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.17394210398197174
[2m[36m(func pid=134839)[0m mae:  0.11681737750768661
[2m[36m(func pid=134839)[0m rmse_per_class: [0.101, 0.254, 0.049, 0.363, 0.056, 0.187, 0.237, 0.155, 0.242, 0.095]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.6035 | Steps: 2 | Val loss: 0.5840 | Batch size: 32 | lr: 0.1 | Duration: 2.67s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3761 | Steps: 2 | Val loss: 0.3747 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4608 | Steps: 2 | Val loss: 0.3659 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4822 | Steps: 2 | Val loss: 0.3512 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=135687)[0m rmse: 0.2002522051334381
[2m[36m(func pid=135687)[0m mae:  0.1120261400938034
[2m[36m(func pid=135687)[0m rmse_per_class: [0.365, 0.261, 0.034, 0.317, 0.073, 0.213, 0.287, 0.215, 0.148, 0.091]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.17368188500404358
[2m[36m(func pid=135261)[0m mae:  0.09867594391107559
[2m[36m(func pid=135261)[0m rmse_per_class: [0.069, 0.265, 0.04, 0.347, 0.053, 0.195, 0.253, 0.148, 0.243, 0.124]
[2m[36m(func pid=135261)[0m 
== Status ==
Current time: 2024-01-07 06:01:27 (running for 00:05:18.52)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.461 |  0.176 |                   51 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.493 |  0.174 |                   50 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.376 |  0.174 |                   48 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.603 |  0.2   |                   50 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17575857043266296
[2m[36m(func pid=134465)[0m mae:  0.12520518898963928
[2m[36m(func pid=134465)[0m rmse_per_class: [0.115, 0.274, 0.091, 0.347, 0.07, 0.194, 0.274, 0.136, 0.158, 0.099]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.17253896594047546
[2m[36m(func pid=134839)[0m mae:  0.11665109544992447
[2m[36m(func pid=134839)[0m rmse_per_class: [0.105, 0.252, 0.049, 0.358, 0.056, 0.191, 0.226, 0.155, 0.239, 0.095]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.6231 | Steps: 2 | Val loss: 0.6102 | Batch size: 32 | lr: 0.1 | Duration: 2.66s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3722 | Steps: 2 | Val loss: 0.3850 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4669 | Steps: 2 | Val loss: 0.3693 | Batch size: 32 | lr: 0.0001 | Duration: 2.72s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4598 | Steps: 2 | Val loss: 0.3453 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=135687)[0m rmse: 0.19237174093723297
[2m[36m(func pid=135687)[0m mae:  0.11069531738758087
[2m[36m(func pid=135687)[0m rmse_per_class: [0.324, 0.259, 0.031, 0.349, 0.073, 0.205, 0.284, 0.158, 0.152, 0.089]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.17766496539115906
[2m[36m(func pid=135261)[0m mae:  0.10062873363494873
[2m[36m(func pid=135261)[0m rmse_per_class: [0.068, 0.274, 0.042, 0.353, 0.053, 0.199, 0.262, 0.145, 0.227, 0.154]
[2m[36m(func pid=135261)[0m 
== Status ==
Current time: 2024-01-07 06:01:32 (running for 00:05:23.63)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.467 |  0.176 |                   52 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.482 |  0.173 |                   51 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.372 |  0.178 |                   49 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.623 |  0.192 |                   51 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17562898993492126
[2m[36m(func pid=134465)[0m mae:  0.12498997151851654
[2m[36m(func pid=134465)[0m rmse_per_class: [0.116, 0.274, 0.09, 0.347, 0.069, 0.194, 0.274, 0.136, 0.158, 0.099]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.17155933380126953
[2m[36m(func pid=134839)[0m mae:  0.11657671630382538
[2m[36m(func pid=134839)[0m rmse_per_class: [0.109, 0.252, 0.049, 0.351, 0.056, 0.194, 0.224, 0.155, 0.231, 0.095]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.5928 | Steps: 2 | Val loss: 0.6590 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3996 | Steps: 2 | Val loss: 0.3931 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4675 | Steps: 2 | Val loss: 0.3719 | Batch size: 32 | lr: 0.0001 | Duration: 2.69s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4681 | Steps: 2 | Val loss: 0.3408 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=135687)[0m rmse: 0.19372601807117462
[2m[36m(func pid=135687)[0m mae:  0.10855378955602646
[2m[36m(func pid=135687)[0m rmse_per_class: [0.163, 0.296, 0.032, 0.368, 0.104, 0.296, 0.277, 0.132, 0.185, 0.086]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.18113325536251068
[2m[36m(func pid=135261)[0m mae:  0.10211815685033798
[2m[36m(func pid=135261)[0m rmse_per_class: [0.069, 0.281, 0.043, 0.35, 0.053, 0.2, 0.265, 0.139, 0.214, 0.196]
[2m[36m(func pid=135261)[0m 
== Status ==
Current time: 2024-01-07 06:01:37 (running for 00:05:28.78)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.467 |  0.176 |                   53 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.46  |  0.172 |                   52 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.4   |  0.181 |                   50 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.593 |  0.194 |                   52 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17557114362716675
[2m[36m(func pid=134465)[0m mae:  0.12481458485126495
[2m[36m(func pid=134465)[0m rmse_per_class: [0.115, 0.274, 0.09, 0.347, 0.069, 0.194, 0.274, 0.136, 0.159, 0.098]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.17075711488723755
[2m[36m(func pid=134839)[0m mae:  0.1164533868432045
[2m[36m(func pid=134839)[0m rmse_per_class: [0.111, 0.252, 0.049, 0.343, 0.056, 0.197, 0.228, 0.155, 0.223, 0.094]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.6111 | Steps: 2 | Val loss: 0.7524 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4181 | Steps: 2 | Val loss: 0.4001 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4691 | Steps: 2 | Val loss: 0.3749 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=135687)[0m rmse: 0.20905837416648865
[2m[36m(func pid=135687)[0m mae:  0.11590045690536499
[2m[36m(func pid=135687)[0m rmse_per_class: [0.083, 0.348, 0.033, 0.375, 0.156, 0.339, 0.286, 0.133, 0.241, 0.096]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4714 | Steps: 2 | Val loss: 0.3383 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
== Status ==
Current time: 2024-01-07 06:01:42 (running for 00:05:33.89)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.467 |  0.176 |                   53 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.468 |  0.171 |                   53 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.418 |  0.183 |                   51 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.611 |  0.209 |                   53 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1754644364118576
[2m[36m(func pid=134465)[0m mae:  0.12458056211471558
[2m[36m(func pid=134465)[0m rmse_per_class: [0.116, 0.274, 0.088, 0.348, 0.068, 0.194, 0.275, 0.136, 0.159, 0.098]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.18318654596805573
[2m[36m(func pid=135261)[0m mae:  0.10332894325256348
[2m[36m(func pid=135261)[0m rmse_per_class: [0.07, 0.287, 0.045, 0.344, 0.054, 0.198, 0.264, 0.132, 0.197, 0.242]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.17023280262947083
[2m[36m(func pid=134839)[0m mae:  0.11642881482839584
[2m[36m(func pid=134839)[0m rmse_per_class: [0.116, 0.253, 0.049, 0.334, 0.056, 0.198, 0.236, 0.154, 0.213, 0.094]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.6032 | Steps: 2 | Val loss: 0.8209 | Batch size: 32 | lr: 0.1 | Duration: 2.62s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4747 | Steps: 2 | Val loss: 0.3771 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3811 | Steps: 2 | Val loss: 0.4072 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=135687)[0m rmse: 0.22269925475120544
[2m[36m(func pid=135687)[0m mae:  0.12024039030075073
[2m[36m(func pid=135687)[0m rmse_per_class: [0.094, 0.327, 0.034, 0.375, 0.198, 0.245, 0.376, 0.15, 0.287, 0.14]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4601 | Steps: 2 | Val loss: 0.3363 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 06:01:48 (running for 00:05:39.10)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.475 |  0.175 |                   55 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.471 |  0.17  |                   54 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.418 |  0.183 |                   51 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.603 |  0.223 |                   54 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17545020580291748
[2m[36m(func pid=134465)[0m mae:  0.12446917593479156
[2m[36m(func pid=134465)[0m rmse_per_class: [0.115, 0.274, 0.088, 0.348, 0.067, 0.194, 0.275, 0.136, 0.159, 0.097]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.18490925431251526
[2m[36m(func pid=135261)[0m mae:  0.104464590549469
[2m[36m(func pid=135261)[0m rmse_per_class: [0.072, 0.288, 0.046, 0.33, 0.054, 0.193, 0.26, 0.125, 0.185, 0.296]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.1692277491092682
[2m[36m(func pid=134839)[0m mae:  0.11592583358287811
[2m[36m(func pid=134839)[0m rmse_per_class: [0.117, 0.254, 0.049, 0.323, 0.056, 0.199, 0.245, 0.154, 0.202, 0.093]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.5967 | Steps: 2 | Val loss: 0.8480 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4789 | Steps: 2 | Val loss: 0.3791 | Batch size: 32 | lr: 0.0001 | Duration: 2.73s
[2m[36m(func pid=135687)[0m rmse: 0.23301224410533905
[2m[36m(func pid=135687)[0m mae:  0.13141830265522003
[2m[36m(func pid=135687)[0m rmse_per_class: [0.096, 0.282, 0.041, 0.373, 0.175, 0.212, 0.55, 0.155, 0.281, 0.164]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4614 | Steps: 2 | Val loss: 0.3357 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3988 | Steps: 2 | Val loss: 0.4128 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 06:01:53 (running for 00:05:44.17)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.479 |  0.175 |                   56 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.46  |  0.169 |                   55 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.381 |  0.185 |                   52 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.597 |  0.233 |                   55 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1754297912120819
[2m[36m(func pid=134465)[0m mae:  0.12434451282024384
[2m[36m(func pid=134465)[0m rmse_per_class: [0.115, 0.274, 0.087, 0.349, 0.067, 0.194, 0.276, 0.137, 0.16, 0.097]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.1681397259235382
[2m[36m(func pid=134839)[0m mae:  0.11526310443878174
[2m[36m(func pid=134839)[0m rmse_per_class: [0.118, 0.255, 0.049, 0.313, 0.056, 0.198, 0.254, 0.154, 0.192, 0.093]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.5945 | Steps: 2 | Val loss: 0.8501 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=135261)[0m rmse: 0.1858108937740326
[2m[36m(func pid=135261)[0m mae:  0.10531969368457794
[2m[36m(func pid=135261)[0m rmse_per_class: [0.073, 0.288, 0.047, 0.318, 0.054, 0.187, 0.257, 0.124, 0.177, 0.334]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4788 | Steps: 2 | Val loss: 0.3803 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=135687)[0m rmse: 0.2341296225786209
[2m[36m(func pid=135687)[0m mae:  0.13657815754413605
[2m[36m(func pid=135687)[0m rmse_per_class: [0.088, 0.295, 0.045, 0.369, 0.129, 0.213, 0.619, 0.156, 0.244, 0.184]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4593 | Steps: 2 | Val loss: 0.3355 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3935 | Steps: 2 | Val loss: 0.4191 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 06:01:58 (running for 00:05:49.31)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.479 |  0.175 |                   57 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.461 |  0.168 |                   56 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.399 |  0.186 |                   53 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.595 |  0.234 |                   56 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17535699903964996
[2m[36m(func pid=134465)[0m mae:  0.12425941228866577
[2m[36m(func pid=134465)[0m rmse_per_class: [0.115, 0.274, 0.086, 0.349, 0.066, 0.194, 0.277, 0.136, 0.16, 0.097]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.16684076189994812
[2m[36m(func pid=134839)[0m mae:  0.11442755162715912
[2m[36m(func pid=134839)[0m rmse_per_class: [0.118, 0.256, 0.048, 0.302, 0.056, 0.197, 0.263, 0.153, 0.183, 0.092]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.6091 | Steps: 2 | Val loss: 0.8052 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=135261)[0m rmse: 0.18718406558036804
[2m[36m(func pid=135261)[0m mae:  0.10627458244562149
[2m[36m(func pid=135261)[0m rmse_per_class: [0.074, 0.287, 0.047, 0.306, 0.055, 0.179, 0.255, 0.134, 0.174, 0.361]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4864 | Steps: 2 | Val loss: 0.3826 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=135687)[0m rmse: 0.22423401474952698
[2m[36m(func pid=135687)[0m mae:  0.12653636932373047
[2m[36m(func pid=135687)[0m rmse_per_class: [0.092, 0.298, 0.046, 0.355, 0.102, 0.215, 0.508, 0.155, 0.212, 0.259]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4505 | Steps: 2 | Val loss: 0.3354 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4086 | Steps: 2 | Val loss: 0.4214 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 06:02:03 (running for 00:05:54.41)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.486 |  0.175 |                   58 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.459 |  0.167 |                   57 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.394 |  0.187 |                   54 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.609 |  0.224 |                   57 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17529237270355225
[2m[36m(func pid=134465)[0m mae:  0.12408573925495148
[2m[36m(func pid=134465)[0m rmse_per_class: [0.115, 0.273, 0.085, 0.349, 0.065, 0.194, 0.278, 0.137, 0.161, 0.096]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.165470689535141
[2m[36m(func pid=134839)[0m mae:  0.11353833973407745
[2m[36m(func pid=134839)[0m rmse_per_class: [0.119, 0.255, 0.048, 0.292, 0.056, 0.195, 0.271, 0.153, 0.175, 0.091]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.5643 | Steps: 2 | Val loss: 0.7555 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=135261)[0m rmse: 0.1884700208902359
[2m[36m(func pid=135261)[0m mae:  0.10658995807170868
[2m[36m(func pid=135261)[0m rmse_per_class: [0.074, 0.285, 0.047, 0.296, 0.055, 0.171, 0.257, 0.164, 0.174, 0.362]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4873 | Steps: 2 | Val loss: 0.3850 | Batch size: 32 | lr: 0.0001 | Duration: 2.74s
[2m[36m(func pid=135687)[0m rmse: 0.22253894805908203
[2m[36m(func pid=135687)[0m mae:  0.12055164575576782
[2m[36m(func pid=135687)[0m rmse_per_class: [0.203, 0.299, 0.048, 0.336, 0.074, 0.322, 0.317, 0.147, 0.166, 0.313]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4521 | Steps: 2 | Val loss: 0.3350 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4047 | Steps: 2 | Val loss: 0.4253 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 06:02:08 (running for 00:05:59.44)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.487 |  0.175 |                   59 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.45  |  0.165 |                   58 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.409 |  0.188 |                   55 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.564 |  0.223 |                   58 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17524956166744232
[2m[36m(func pid=134465)[0m mae:  0.12391787767410278
[2m[36m(func pid=134465)[0m rmse_per_class: [0.115, 0.274, 0.084, 0.349, 0.065, 0.193, 0.279, 0.137, 0.161, 0.096]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.16383258998394012
[2m[36m(func pid=134839)[0m mae:  0.11248528957366943
[2m[36m(func pid=134839)[0m rmse_per_class: [0.118, 0.255, 0.048, 0.283, 0.056, 0.191, 0.278, 0.152, 0.167, 0.09]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.5028 | Steps: 2 | Val loss: 0.6709 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=135261)[0m rmse: 0.19101284444332123
[2m[36m(func pid=135261)[0m mae:  0.10807821899652481
[2m[36m(func pid=135261)[0m rmse_per_class: [0.074, 0.281, 0.047, 0.287, 0.055, 0.167, 0.264, 0.208, 0.171, 0.356]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4913 | Steps: 2 | Val loss: 0.3878 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=135687)[0m rmse: 0.2205290049314499
[2m[36m(func pid=135687)[0m mae:  0.12097253650426865
[2m[36m(func pid=135687)[0m rmse_per_class: [0.356, 0.296, 0.049, 0.326, 0.06, 0.289, 0.268, 0.147, 0.14, 0.275]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4482 | Steps: 2 | Val loss: 0.3340 | Batch size: 32 | lr: 0.001 | Duration: 2.69s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4151 | Steps: 2 | Val loss: 0.4286 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 06:02:13 (running for 00:06:04.46)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.491 |  0.175 |                   60 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.452 |  0.164 |                   59 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.405 |  0.191 |                   56 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.503 |  0.221 |                   59 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17512613534927368
[2m[36m(func pid=134465)[0m mae:  0.12361924350261688
[2m[36m(func pid=134465)[0m rmse_per_class: [0.115, 0.273, 0.082, 0.349, 0.064, 0.193, 0.279, 0.137, 0.162, 0.096]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.16216108202934265
[2m[36m(func pid=134839)[0m mae:  0.11138757318258286
[2m[36m(func pid=134839)[0m rmse_per_class: [0.115, 0.254, 0.048, 0.277, 0.056, 0.187, 0.285, 0.151, 0.159, 0.089]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.5702 | Steps: 2 | Val loss: 0.5904 | Batch size: 32 | lr: 0.1 | Duration: 2.70s
[2m[36m(func pid=135261)[0m rmse: 0.19276534020900726
[2m[36m(func pid=135261)[0m mae:  0.10910868644714355
[2m[36m(func pid=135261)[0m rmse_per_class: [0.074, 0.276, 0.046, 0.285, 0.055, 0.168, 0.27, 0.25, 0.175, 0.329]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4940 | Steps: 2 | Val loss: 0.3898 | Batch size: 32 | lr: 0.0001 | Duration: 2.66s
[2m[36m(func pid=135687)[0m rmse: 0.20819683372974396
[2m[36m(func pid=135687)[0m mae:  0.11565443128347397
[2m[36m(func pid=135687)[0m rmse_per_class: [0.412, 0.28, 0.049, 0.316, 0.057, 0.192, 0.253, 0.178, 0.139, 0.208]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4435 | Steps: 2 | Val loss: 0.3314 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 06:02:18 (running for 00:06:09.62)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.494 |  0.175 |                   61 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.448 |  0.162 |                   60 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.415 |  0.193 |                   57 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.57  |  0.208 |                   60 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17509406805038452
[2m[36m(func pid=134465)[0m mae:  0.12345900386571884
[2m[36m(func pid=134465)[0m rmse_per_class: [0.115, 0.273, 0.082, 0.349, 0.063, 0.193, 0.28, 0.138, 0.161, 0.096]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4057 | Steps: 2 | Val loss: 0.4289 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=134839)[0m rmse: 0.16052813827991486
[2m[36m(func pid=134839)[0m mae:  0.11029793322086334
[2m[36m(func pid=134839)[0m rmse_per_class: [0.112, 0.251, 0.048, 0.273, 0.056, 0.183, 0.289, 0.15, 0.154, 0.088]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.6107 | Steps: 2 | Val loss: 0.5485 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=135261)[0m rmse: 0.19205628335475922
[2m[36m(func pid=135261)[0m mae:  0.10912325233221054
[2m[36m(func pid=135261)[0m rmse_per_class: [0.074, 0.271, 0.046, 0.288, 0.055, 0.176, 0.276, 0.281, 0.178, 0.275]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4913 | Steps: 2 | Val loss: 0.3919 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=135687)[0m rmse: 0.18934252858161926
[2m[36m(func pid=135687)[0m mae:  0.10338171571493149
[2m[36m(func pid=135687)[0m rmse_per_class: [0.229, 0.27, 0.049, 0.31, 0.056, 0.199, 0.306, 0.177, 0.139, 0.159]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4491 | Steps: 2 | Val loss: 0.3276 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 06:02:23 (running for 00:06:14.87)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.491 |  0.175 |                   62 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.443 |  0.161 |                   61 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.406 |  0.192 |                   58 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.611 |  0.189 |                   61 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17502620816230774
[2m[36m(func pid=134465)[0m mae:  0.12320554256439209
[2m[36m(func pid=134465)[0m rmse_per_class: [0.115, 0.274, 0.08, 0.35, 0.063, 0.194, 0.28, 0.138, 0.162, 0.096]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4110 | Steps: 2 | Val loss: 0.4356 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=134839)[0m rmse: 0.15894055366516113
[2m[36m(func pid=134839)[0m mae:  0.10913792997598648
[2m[36m(func pid=134839)[0m rmse_per_class: [0.107, 0.249, 0.048, 0.272, 0.056, 0.179, 0.293, 0.148, 0.149, 0.089]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.6052 | Steps: 2 | Val loss: 0.5673 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4989 | Steps: 2 | Val loss: 0.3942 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=135261)[0m rmse: 0.19212807714939117
[2m[36m(func pid=135261)[0m mae:  0.11025551706552505
[2m[36m(func pid=135261)[0m rmse_per_class: [0.076, 0.265, 0.046, 0.301, 0.055, 0.193, 0.278, 0.298, 0.183, 0.228]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.18516233563423157
[2m[36m(func pid=135687)[0m mae:  0.10257917642593384
[2m[36m(func pid=135687)[0m rmse_per_class: [0.102, 0.326, 0.047, 0.317, 0.056, 0.208, 0.347, 0.173, 0.14, 0.135]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4315 | Steps: 2 | Val loss: 0.3234 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 06:02:29 (running for 00:06:20.19)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.499 |  0.175 |                   63 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.449 |  0.159 |                   62 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.411 |  0.192 |                   59 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.605 |  0.185 |                   62 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1750311553478241
[2m[36m(func pid=134465)[0m mae:  0.12309958040714264
[2m[36m(func pid=134465)[0m rmse_per_class: [0.115, 0.274, 0.079, 0.35, 0.062, 0.193, 0.281, 0.138, 0.163, 0.095]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.5985 | Steps: 2 | Val loss: 0.6161 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4198 | Steps: 2 | Val loss: 0.4357 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=134839)[0m rmse: 0.15771649777889252
[2m[36m(func pid=134839)[0m mae:  0.1081375703215599
[2m[36m(func pid=134839)[0m rmse_per_class: [0.101, 0.246, 0.047, 0.273, 0.056, 0.176, 0.295, 0.145, 0.144, 0.092]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.18984225392341614
[2m[36m(func pid=135687)[0m mae:  0.10489372909069061
[2m[36m(func pid=135687)[0m rmse_per_class: [0.091, 0.374, 0.044, 0.334, 0.056, 0.2, 0.336, 0.166, 0.158, 0.14]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4997 | Steps: 2 | Val loss: 0.3957 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=135261)[0m rmse: 0.1901853382587433
[2m[36m(func pid=135261)[0m mae:  0.10991945117712021
[2m[36m(func pid=135261)[0m rmse_per_class: [0.079, 0.259, 0.046, 0.314, 0.055, 0.213, 0.278, 0.29, 0.184, 0.183]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4254 | Steps: 2 | Val loss: 0.3201 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 06:02:34 (running for 00:06:25.59)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.5   |  0.175 |                   64 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.432 |  0.158 |                   63 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.42  |  0.19  |                   60 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.599 |  0.19  |                   63 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1750037968158722
[2m[36m(func pid=134465)[0m mae:  0.12295547872781754
[2m[36m(func pid=134465)[0m rmse_per_class: [0.114, 0.274, 0.079, 0.35, 0.062, 0.193, 0.282, 0.138, 0.162, 0.095]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.5183 | Steps: 2 | Val loss: 0.7280 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=134839)[0m rmse: 0.15735986828804016
[2m[36m(func pid=134839)[0m mae:  0.1077960953116417
[2m[36m(func pid=134839)[0m rmse_per_class: [0.097, 0.245, 0.047, 0.275, 0.056, 0.173, 0.298, 0.143, 0.141, 0.1]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4186 | Steps: 2 | Val loss: 0.4319 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4988 | Steps: 2 | Val loss: 0.3975 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=135687)[0m rmse: 0.19856324791908264
[2m[36m(func pid=135687)[0m mae:  0.10923099517822266
[2m[36m(func pid=135687)[0m rmse_per_class: [0.088, 0.298, 0.042, 0.339, 0.056, 0.33, 0.324, 0.151, 0.216, 0.143]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.18726083636283875
[2m[36m(func pid=135261)[0m mae:  0.1085248589515686
[2m[36m(func pid=135261)[0m rmse_per_class: [0.083, 0.257, 0.045, 0.326, 0.055, 0.233, 0.276, 0.266, 0.182, 0.15]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4065 | Steps: 2 | Val loss: 0.3156 | Batch size: 32 | lr: 0.001 | Duration: 2.70s
== Status ==
Current time: 2024-01-07 06:02:39 (running for 00:06:30.71)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.499 |  0.175 |                   65 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.425 |  0.157 |                   64 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.419 |  0.187 |                   61 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.518 |  0.199 |                   64 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17495223879814148
[2m[36m(func pid=134465)[0m mae:  0.1227705329656601
[2m[36m(func pid=134465)[0m rmse_per_class: [0.114, 0.274, 0.077, 0.351, 0.061, 0.193, 0.283, 0.138, 0.163, 0.095]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.5037 | Steps: 2 | Val loss: 0.8507 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=134839)[0m rmse: 0.15742503106594086
[2m[36m(func pid=134839)[0m mae:  0.10759385675191879
[2m[36m(func pid=134839)[0m rmse_per_class: [0.092, 0.244, 0.046, 0.276, 0.056, 0.17, 0.299, 0.139, 0.138, 0.114]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3679 | Steps: 2 | Val loss: 0.4276 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.5011 | Steps: 2 | Val loss: 0.3993 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=135687)[0m rmse: 0.2164354771375656
[2m[36m(func pid=135687)[0m mae:  0.12461362034082413
[2m[36m(func pid=135687)[0m rmse_per_class: [0.094, 0.295, 0.041, 0.352, 0.056, 0.451, 0.346, 0.154, 0.261, 0.113]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4043 | Steps: 2 | Val loss: 0.3119 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=135261)[0m rmse: 0.18396955728530884
[2m[36m(func pid=135261)[0m mae:  0.10660608857870102
[2m[36m(func pid=135261)[0m rmse_per_class: [0.09, 0.256, 0.044, 0.338, 0.055, 0.245, 0.275, 0.234, 0.183, 0.119]
[2m[36m(func pid=135261)[0m 
== Status ==
Current time: 2024-01-07 06:02:44 (running for 00:06:35.92)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.501 |  0.175 |                   66 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.407 |  0.157 |                   65 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.368 |  0.184 |                   62 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.504 |  0.216 |                   65 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17495833337306976
[2m[36m(func pid=134465)[0m mae:  0.1226230040192604
[2m[36m(func pid=134465)[0m rmse_per_class: [0.114, 0.273, 0.077, 0.351, 0.061, 0.193, 0.284, 0.139, 0.163, 0.095]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.5743 | Steps: 2 | Val loss: 0.9184 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=134839)[0m rmse: 0.15801292657852173
[2m[36m(func pid=134839)[0m mae:  0.10761705785989761
[2m[36m(func pid=134839)[0m rmse_per_class: [0.087, 0.243, 0.045, 0.278, 0.056, 0.169, 0.299, 0.134, 0.136, 0.132]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4027 | Steps: 2 | Val loss: 0.4201 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.5070 | Steps: 2 | Val loss: 0.4005 | Batch size: 32 | lr: 0.0001 | Duration: 2.69s
[2m[36m(func pid=135687)[0m rmse: 0.21690842509269714
[2m[36m(func pid=135687)[0m mae:  0.12550535798072815
[2m[36m(func pid=135687)[0m rmse_per_class: [0.102, 0.302, 0.041, 0.368, 0.056, 0.303, 0.461, 0.156, 0.286, 0.093]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3927 | Steps: 2 | Val loss: 0.3094 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=135261)[0m rmse: 0.18062147498130798
[2m[36m(func pid=135261)[0m mae:  0.10422597080469131
[2m[36m(func pid=135261)[0m rmse_per_class: [0.098, 0.258, 0.044, 0.345, 0.055, 0.25, 0.271, 0.201, 0.183, 0.101]
[2m[36m(func pid=135261)[0m 
== Status ==
Current time: 2024-01-07 06:02:50 (running for 00:06:41.08)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.507 |  0.175 |                   67 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.404 |  0.158 |                   66 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.181 |                   63 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.574 |  0.217 |                   66 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17501387000083923
[2m[36m(func pid=134465)[0m mae:  0.12247248739004135
[2m[36m(func pid=134465)[0m rmse_per_class: [0.114, 0.273, 0.076, 0.351, 0.06, 0.193, 0.286, 0.139, 0.163, 0.094]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.7123 | Steps: 2 | Val loss: 0.9669 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=134839)[0m rmse: 0.15925003588199615
[2m[36m(func pid=134839)[0m mae:  0.10811284929513931
[2m[36m(func pid=134839)[0m rmse_per_class: [0.083, 0.244, 0.044, 0.278, 0.056, 0.168, 0.3, 0.129, 0.134, 0.156]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3718 | Steps: 2 | Val loss: 0.4131 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.5049 | Steps: 2 | Val loss: 0.4007 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=135687)[0m rmse: 0.2186654508113861
[2m[36m(func pid=135687)[0m mae:  0.12984919548034668
[2m[36m(func pid=135687)[0m rmse_per_class: [0.167, 0.302, 0.04, 0.377, 0.056, 0.188, 0.547, 0.156, 0.263, 0.09]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3691 | Steps: 2 | Val loss: 0.3069 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=135261)[0m rmse: 0.1772662103176117
[2m[36m(func pid=135261)[0m mae:  0.10155992209911346
[2m[36m(func pid=135261)[0m rmse_per_class: [0.106, 0.265, 0.042, 0.351, 0.055, 0.239, 0.265, 0.174, 0.187, 0.089]
[2m[36m(func pid=135261)[0m 
== Status ==
Current time: 2024-01-07 06:02:55 (running for 00:06:46.26)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.505 |  0.175 |                   68 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.393 |  0.159 |                   67 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.372 |  0.177 |                   64 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.712 |  0.219 |                   67 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17494681477546692
[2m[36m(func pid=134465)[0m mae:  0.12232305854558945
[2m[36m(func pid=134465)[0m rmse_per_class: [0.114, 0.273, 0.075, 0.351, 0.06, 0.193, 0.287, 0.139, 0.163, 0.094]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.6952 | Steps: 2 | Val loss: 0.9348 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=134839)[0m rmse: 0.16032984852790833
[2m[36m(func pid=134839)[0m mae:  0.10844890028238297
[2m[36m(func pid=134839)[0m rmse_per_class: [0.079, 0.246, 0.043, 0.276, 0.056, 0.169, 0.299, 0.122, 0.133, 0.181]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3586 | Steps: 2 | Val loss: 0.4118 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.5158 | Steps: 2 | Val loss: 0.4007 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=135687)[0m rmse: 0.22235867381095886
[2m[36m(func pid=135687)[0m mae:  0.1310403048992157
[2m[36m(func pid=135687)[0m rmse_per_class: [0.298, 0.302, 0.039, 0.375, 0.057, 0.187, 0.48, 0.155, 0.236, 0.094]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3698 | Steps: 2 | Val loss: 0.3063 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=135261)[0m rmse: 0.17527316510677338
[2m[36m(func pid=135261)[0m mae:  0.0998787134885788
[2m[36m(func pid=135261)[0m rmse_per_class: [0.118, 0.274, 0.041, 0.355, 0.054, 0.222, 0.261, 0.154, 0.193, 0.082]
[2m[36m(func pid=135261)[0m 
== Status ==
Current time: 2024-01-07 06:03:00 (running for 00:06:51.46)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.516 |  0.175 |                   69 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.369 |  0.16  |                   68 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.359 |  0.175 |                   65 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.695 |  0.222 |                   68 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1748509705066681
[2m[36m(func pid=134465)[0m mae:  0.12206470966339111
[2m[36m(func pid=134465)[0m rmse_per_class: [0.113, 0.273, 0.074, 0.352, 0.06, 0.193, 0.288, 0.139, 0.163, 0.094]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.5937 | Steps: 2 | Val loss: 0.8454 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=134839)[0m rmse: 0.1620606780052185
[2m[36m(func pid=134839)[0m mae:  0.1092415302991867
[2m[36m(func pid=134839)[0m rmse_per_class: [0.075, 0.249, 0.041, 0.272, 0.056, 0.17, 0.299, 0.117, 0.131, 0.21]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3575 | Steps: 2 | Val loss: 0.4135 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=135687)[0m rmse: 0.22447922825813293
[2m[36m(func pid=135687)[0m mae:  0.12692463397979736
[2m[36m(func pid=135687)[0m rmse_per_class: [0.366, 0.301, 0.038, 0.361, 0.064, 0.212, 0.345, 0.152, 0.253, 0.153]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.5055 | Steps: 2 | Val loss: 0.4021 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3738 | Steps: 2 | Val loss: 0.3062 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=135261)[0m rmse: 0.17373764514923096
[2m[36m(func pid=135261)[0m mae:  0.09857681393623352
[2m[36m(func pid=135261)[0m rmse_per_class: [0.124, 0.29, 0.038, 0.356, 0.054, 0.202, 0.254, 0.142, 0.196, 0.08]
[2m[36m(func pid=135261)[0m 
== Status ==
Current time: 2024-01-07 06:03:05 (running for 00:06:56.70)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.506 |  0.175 |                   70 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.37  |  0.162 |                   69 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.357 |  0.174 |                   66 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.594 |  0.224 |                   69 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17488643527030945
[2m[36m(func pid=134465)[0m mae:  0.1218930333852768
[2m[36m(func pid=134465)[0m rmse_per_class: [0.113, 0.273, 0.073, 0.352, 0.06, 0.193, 0.29, 0.14, 0.162, 0.094]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4872 | Steps: 2 | Val loss: 0.7184 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=134839)[0m rmse: 0.16374073922634125
[2m[36m(func pid=134839)[0m mae:  0.1100521832704544
[2m[36m(func pid=134839)[0m rmse_per_class: [0.073, 0.252, 0.039, 0.266, 0.056, 0.173, 0.298, 0.114, 0.131, 0.237]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3586 | Steps: 2 | Val loss: 0.4200 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=135687)[0m rmse: 0.22590002417564392
[2m[36m(func pid=135687)[0m mae:  0.12061462551355362
[2m[36m(func pid=135687)[0m rmse_per_class: [0.221, 0.289, 0.039, 0.345, 0.077, 0.293, 0.291, 0.2, 0.253, 0.25]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.5162 | Steps: 2 | Val loss: 0.4031 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3544 | Steps: 2 | Val loss: 0.3070 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 06:03:10 (running for 00:07:01.92)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.516 |  0.175 |                   71 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.374 |  0.164 |                   70 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.357 |  0.174 |                   66 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.487 |  0.226 |                   70 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17481036484241486
[2m[36m(func pid=134465)[0m mae:  0.1216835007071495
[2m[36m(func pid=134465)[0m rmse_per_class: [0.113, 0.273, 0.072, 0.352, 0.059, 0.193, 0.291, 0.14, 0.162, 0.094]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.17395217716693878
[2m[36m(func pid=135261)[0m mae:  0.09860066324472427
[2m[36m(func pid=135261)[0m rmse_per_class: [0.131, 0.3, 0.037, 0.357, 0.054, 0.191, 0.252, 0.134, 0.203, 0.081]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4351 | Steps: 2 | Val loss: 0.6089 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=134839)[0m rmse: 0.1657431721687317
[2m[36m(func pid=134839)[0m mae:  0.11121692508459091
[2m[36m(func pid=134839)[0m rmse_per_class: [0.072, 0.255, 0.037, 0.259, 0.056, 0.176, 0.296, 0.117, 0.13, 0.26]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.21629512310028076
[2m[36m(func pid=135687)[0m mae:  0.11758890002965927
[2m[36m(func pid=135687)[0m rmse_per_class: [0.094, 0.33, 0.041, 0.34, 0.074, 0.256, 0.294, 0.248, 0.192, 0.294]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.5110 | Steps: 2 | Val loss: 0.4030 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3413 | Steps: 2 | Val loss: 0.4265 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3602 | Steps: 2 | Val loss: 0.3100 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 06:03:16 (running for 00:07:07.20)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.511 |  0.175 |                   72 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.354 |  0.166 |                   71 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.359 |  0.174 |                   67 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.435 |  0.216 |                   71 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1747635155916214
[2m[36m(func pid=134465)[0m mae:  0.12157624959945679
[2m[36m(func pid=134465)[0m rmse_per_class: [0.113, 0.273, 0.071, 0.352, 0.059, 0.193, 0.291, 0.14, 0.163, 0.094]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.17449206113815308
[2m[36m(func pid=135261)[0m mae:  0.09908954054117203
[2m[36m(func pid=135261)[0m rmse_per_class: [0.135, 0.305, 0.035, 0.355, 0.056, 0.183, 0.251, 0.128, 0.214, 0.082]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4860 | Steps: 2 | Val loss: 0.5772 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=134839)[0m rmse: 0.16860730946063995
[2m[36m(func pid=134839)[0m mae:  0.11297067254781723
[2m[36m(func pid=134839)[0m rmse_per_class: [0.071, 0.259, 0.034, 0.254, 0.056, 0.179, 0.295, 0.128, 0.13, 0.28]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.19639761745929718
[2m[36m(func pid=135687)[0m mae:  0.10995463281869888
[2m[36m(func pid=135687)[0m rmse_per_class: [0.097, 0.339, 0.044, 0.325, 0.067, 0.199, 0.293, 0.198, 0.152, 0.25]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.5087 | Steps: 2 | Val loss: 0.4031 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3479 | Steps: 2 | Val loss: 0.4342 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3503 | Steps: 2 | Val loss: 0.3134 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
== Status ==
Current time: 2024-01-07 06:03:21 (running for 00:07:12.36)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.509 |  0.175 |                   73 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.36  |  0.169 |                   72 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.341 |  0.174 |                   68 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.486 |  0.196 |                   72 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17468732595443726
[2m[36m(func pid=134465)[0m mae:  0.12144432216882706
[2m[36m(func pid=134465)[0m rmse_per_class: [0.113, 0.273, 0.07, 0.352, 0.059, 0.193, 0.292, 0.14, 0.163, 0.093]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.5940 | Steps: 2 | Val loss: 0.5687 | Batch size: 32 | lr: 0.1 | Duration: 2.70s
[2m[36m(func pid=135261)[0m rmse: 0.17560149729251862
[2m[36m(func pid=135261)[0m mae:  0.10009356588125229
[2m[36m(func pid=135261)[0m rmse_per_class: [0.125, 0.32, 0.033, 0.352, 0.063, 0.182, 0.248, 0.127, 0.223, 0.083]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.17183855175971985
[2m[36m(func pid=134839)[0m mae:  0.11481866985559464
[2m[36m(func pid=134839)[0m rmse_per_class: [0.072, 0.262, 0.032, 0.251, 0.056, 0.183, 0.292, 0.147, 0.13, 0.294]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.18604062497615814
[2m[36m(func pid=135687)[0m mae:  0.10572699457406998
[2m[36m(func pid=135687)[0m rmse_per_class: [0.095, 0.288, 0.048, 0.313, 0.068, 0.197, 0.353, 0.147, 0.145, 0.206]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.5182 | Steps: 2 | Val loss: 0.4032 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3579 | Steps: 2 | Val loss: 0.4424 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3442 | Steps: 2 | Val loss: 0.3182 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 06:03:26 (running for 00:07:17.53)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.518 |  0.175 |                   74 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.35  |  0.172 |                   73 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.348 |  0.176 |                   69 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.594 |  0.186 |                   73 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1746661365032196
[2m[36m(func pid=134465)[0m mae:  0.12132690846920013
[2m[36m(func pid=134465)[0m rmse_per_class: [0.113, 0.272, 0.069, 0.352, 0.058, 0.193, 0.293, 0.14, 0.163, 0.093]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.5202 | Steps: 2 | Val loss: 0.5367 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=135261)[0m rmse: 0.17727825045585632
[2m[36m(func pid=135261)[0m mae:  0.10111673176288605
[2m[36m(func pid=135261)[0m rmse_per_class: [0.114, 0.323, 0.032, 0.349, 0.073, 0.181, 0.25, 0.127, 0.239, 0.085]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.17578572034835815
[2m[36m(func pid=134839)[0m mae:  0.11721138656139374
[2m[36m(func pid=134839)[0m rmse_per_class: [0.072, 0.265, 0.031, 0.251, 0.056, 0.186, 0.29, 0.174, 0.129, 0.303]
[2m[36m(func pid=134839)[0m 
[2m[36m(func pid=135687)[0m rmse: 0.19112426042556763
[2m[36m(func pid=135687)[0m mae:  0.10299016535282135
[2m[36m(func pid=135687)[0m rmse_per_class: [0.154, 0.275, 0.049, 0.311, 0.091, 0.201, 0.337, 0.144, 0.144, 0.206]
[2m[36m(func pid=135687)[0m 
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.5116 | Steps: 2 | Val loss: 0.4039 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3743 | Steps: 2 | Val loss: 0.4510 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=134839)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3433 | Steps: 2 | Val loss: 0.3232 | Batch size: 32 | lr: 0.001 | Duration: 2.68s
== Status ==
Current time: 2024-01-07 06:03:31 (running for 00:07:22.62)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING  | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.512 |  0.175 |                   75 |
| train_12613_00001 | RUNNING  | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.344 |  0.176 |                   74 |
| train_12613_00002 | RUNNING  | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.358 |  0.177 |                   70 |
| train_12613_00003 | RUNNING  | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.52  |  0.191 |                   74 |
| train_12613_00004 | PENDING  |                     | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | PENDING  |                     | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING  |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING  |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING  |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING  |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING  |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING  |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING  |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING  |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING  |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING  |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING  |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING  |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING  |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING  |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17458732426166534
[2m[36m(func pid=134465)[0m mae:  0.12108378112316132
[2m[36m(func pid=134465)[0m rmse_per_class: [0.112, 0.272, 0.067, 0.352, 0.058, 0.193, 0.294, 0.14, 0.163, 0.093]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135687)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.5086 | Steps: 2 | Val loss: 0.6334 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=135261)[0m rmse: 0.1795816719532013
[2m[36m(func pid=135261)[0m mae:  0.10221850872039795
[2m[36m(func pid=135261)[0m rmse_per_class: [0.102, 0.324, 0.03, 0.344, 0.09, 0.184, 0.25, 0.129, 0.258, 0.085]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=134839)[0m rmse: 0.17964249849319458
[2m[36m(func pid=134839)[0m mae:  0.11954128742218018
[2m[36m(func pid=134839)[0m rmse_per_class: [0.073, 0.268, 0.031, 0.255, 0.056, 0.189, 0.288, 0.204, 0.13, 0.304]
[2m[36m(func pid=135687)[0m rmse: 0.2160119116306305
[2m[36m(func pid=135687)[0m mae:  0.1200500950217247
[2m[36m(func pid=135687)[0m rmse_per_class: [0.427, 0.283, 0.049, 0.326, 0.108, 0.234, 0.266, 0.146, 0.142, 0.18]
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.5161 | Steps: 2 | Val loss: 0.4033 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3873 | Steps: 2 | Val loss: 0.4568 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=134465)[0m rmse: 0.17446187138557434
[2m[36m(func pid=134465)[0m mae:  0.1209745779633522
[2m[36m(func pid=134465)[0m rmse_per_class: [0.113, 0.272, 0.067, 0.352, 0.058, 0.193, 0.294, 0.141, 0.163, 0.093]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.18177147209644318
[2m[36m(func pid=135261)[0m mae:  0.10308684408664703
[2m[36m(func pid=135261)[0m rmse_per_class: [0.087, 0.315, 0.029, 0.338, 0.112, 0.187, 0.254, 0.131, 0.279, 0.086]
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.5132 | Steps: 2 | Val loss: 0.4034 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=134465)[0m rmse: 0.1743512898683548
[2m[36m(func pid=134465)[0m mae:  0.12076188623905182
[2m[36m(func pid=134465)[0m rmse_per_class: [0.112, 0.272, 0.065, 0.352, 0.058, 0.193, 0.295, 0.141, 0.163, 0.093]
[2m[36m(func pid=151958)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=151958)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=151958)[0m Configuration completed!
[2m[36m(func pid=151958)[0m New optimizer parameters:
[2m[36m(func pid=151958)[0m SGD (
[2m[36m(func pid=151958)[0m Parameter Group 0
[2m[36m(func pid=151958)[0m     dampening: 0
[2m[36m(func pid=151958)[0m     differentiable: False
[2m[36m(func pid=151958)[0m     foreach: None
[2m[36m(func pid=151958)[0m     lr: 0.0001
[2m[36m(func pid=151958)[0m     maximize: False
[2m[36m(func pid=151958)[0m     momentum: 0.9
[2m[36m(func pid=151958)[0m     nesterov: False
[2m[36m(func pid=151958)[0m     weight_decay: 0
[2m[36m(func pid=151958)[0m )
[2m[36m(func pid=151958)[0m 
== Status ==
Current time: 2024-01-07 06:03:36 (running for 00:07:27.91)
Memory usage on this node: 19.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.17750000208616257
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.516 |  0.174 |                   76 |
| train_12613_00002 | RUNNING    | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.374 |  0.18  |                   71 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


== Status ==
Current time: 2024-01-07 06:03:44 (running for 00:07:35.13)
Memory usage on this node: 22.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.17750000208616257
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.513 |  0.174 |                   77 |
| train_12613_00002 | RUNNING    | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.374 |  0.18  |                   71 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |        |        |                      |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=152019)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=152019)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=152019)[0m Configuration completed!
[2m[36m(func pid=152019)[0m New optimizer parameters:
[2m[36m(func pid=152019)[0m SGD (
[2m[36m(func pid=152019)[0m Parameter Group 0
[2m[36m(func pid=152019)[0m     dampening: 0
[2m[36m(func pid=152019)[0m     differentiable: False
[2m[36m(func pid=152019)[0m     foreach: None
[2m[36m(func pid=152019)[0m     lr: 0.001
[2m[36m(func pid=152019)[0m     maximize: False
[2m[36m(func pid=152019)[0m     momentum: 0.9
[2m[36m(func pid=152019)[0m     nesterov: False
[2m[36m(func pid=152019)[0m     weight_decay: 0
[2m[36m(func pid=152019)[0m )
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0802 | Steps: 2 | Val loss: 0.8106 | Batch size: 32 | lr: 0.0001 | Duration: 4.50s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.5171 | Steps: 2 | Val loss: 0.4026 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4066 | Steps: 2 | Val loss: 0.4598 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0788 | Steps: 2 | Val loss: 0.7949 | Batch size: 32 | lr: 0.001 | Duration: 4.33s
[2m[36m(func pid=151958)[0m rmse: 0.17866279184818268
[2m[36m(func pid=151958)[0m mae:  0.1311919391155243
[2m[36m(func pid=151958)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.325, 0.1, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=151958)[0m 
== Status ==
Current time: 2024-01-07 06:03:49 (running for 00:07:40.26)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.17750000208616257
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.517 |  0.174 |                   78 |
| train_12613_00002 | RUNNING    | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.387 |  0.182 |                   72 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  1.08  |  0.179 |                    1 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |        |        |                      |
| train_12613_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17423862218856812
[2m[36m(func pid=134465)[0m mae:  0.12061595916748047
[2m[36m(func pid=134465)[0m rmse_per_class: [0.112, 0.272, 0.064, 0.352, 0.058, 0.193, 0.296, 0.141, 0.163, 0.093]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.1838153600692749
[2m[36m(func pid=135261)[0m mae:  0.10398832708597183
[2m[36m(func pid=135261)[0m rmse_per_class: [0.076, 0.297, 0.028, 0.331, 0.133, 0.191, 0.261, 0.133, 0.302, 0.086]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17863814532756805
[2m[36m(func pid=152019)[0m mae:  0.13115081191062927
[2m[36m(func pid=152019)[0m rmse_per_class: [0.105, 0.266, 0.086, 0.325, 0.1, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0795 | Steps: 2 | Val loss: 0.8135 | Batch size: 32 | lr: 0.0001 | Duration: 2.74s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.5148 | Steps: 2 | Val loss: 0.4011 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3870 | Steps: 2 | Val loss: 0.4576 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0337 | Steps: 2 | Val loss: 0.7594 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=151958)[0m rmse: 0.17910489439964294
[2m[36m(func pid=151958)[0m mae:  0.13154084980487823
[2m[36m(func pid=151958)[0m rmse_per_class: [0.105, 0.266, 0.088, 0.325, 0.102, 0.193, 0.305, 0.153, 0.139, 0.116]
[2m[36m(func pid=151958)[0m 
== Status ==
Current time: 2024-01-07 06:03:54 (running for 00:07:45.53)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.17750000208616257
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.515 |  0.174 |                   79 |
| train_12613_00002 | RUNNING    | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.407 |  0.184 |                   73 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  1.08  |  0.179 |                    2 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  1.079 |  0.179 |                    1 |
| train_12613_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17407044768333435
[2m[36m(func pid=134465)[0m mae:  0.12048561871051788
[2m[36m(func pid=134465)[0m rmse_per_class: [0.112, 0.272, 0.064, 0.351, 0.057, 0.192, 0.296, 0.141, 0.163, 0.093]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.1850956231355667
[2m[36m(func pid=135261)[0m mae:  0.10431566089391708
[2m[36m(func pid=135261)[0m rmse_per_class: [0.071, 0.283, 0.028, 0.324, 0.151, 0.191, 0.269, 0.135, 0.312, 0.086]
[2m[36m(func pid=135261)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17899803817272186
[2m[36m(func pid=152019)[0m mae:  0.13140012323856354
[2m[36m(func pid=152019)[0m rmse_per_class: [0.105, 0.266, 0.088, 0.325, 0.101, 0.192, 0.305, 0.154, 0.139, 0.115]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 1.0683 | Steps: 2 | Val loss: 0.8142 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.5074 | Steps: 2 | Val loss: 0.4019 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=135261)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4032 | Steps: 2 | Val loss: 0.4552 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.9611 | Steps: 2 | Val loss: 0.7102 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=151958)[0m rmse: 0.17958541214466095
[2m[36m(func pid=151958)[0m mae:  0.13191495835781097
[2m[36m(func pid=151958)[0m rmse_per_class: [0.105, 0.266, 0.089, 0.325, 0.103, 0.193, 0.307, 0.154, 0.139, 0.116]
[2m[36m(func pid=151958)[0m 
== Status ==
Current time: 2024-01-07 06:03:59 (running for 00:07:50.75)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.17750000208616257
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.507 |  0.174 |                   80 |
| train_12613_00002 | RUNNING    | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.387 |  0.185 |                   74 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  1.068 |  0.18  |                    3 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  1.034 |  0.179 |                    2 |
| train_12613_00006 | PENDING    |                     | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1741020381450653
[2m[36m(func pid=134465)[0m mae:  0.12041367590427399
[2m[36m(func pid=134465)[0m rmse_per_class: [0.112, 0.271, 0.063, 0.351, 0.057, 0.192, 0.296, 0.141, 0.163, 0.093]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=135261)[0m rmse: 0.18677091598510742
[2m[36m(func pid=135261)[0m mae:  0.10517909377813339
[2m[36m(func pid=135261)[0m rmse_per_class: [0.069, 0.266, 0.029, 0.318, 0.163, 0.191, 0.283, 0.137, 0.325, 0.087]
[2m[36m(func pid=152019)[0m rmse: 0.17928913235664368
[2m[36m(func pid=152019)[0m mae:  0.13153129816055298
[2m[36m(func pid=152019)[0m rmse_per_class: [0.104, 0.266, 0.089, 0.324, 0.101, 0.193, 0.305, 0.155, 0.139, 0.115]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 1.0626 | Steps: 2 | Val loss: 0.8149 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.5104 | Steps: 2 | Val loss: 0.4010 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8764 | Steps: 2 | Val loss: 0.6480 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=151958)[0m rmse: 0.17997296154499054
[2m[36m(func pid=151958)[0m mae:  0.13219128549098969
[2m[36m(func pid=151958)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.104, 0.193, 0.308, 0.154, 0.138, 0.117]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.17399320006370544
[2m[36m(func pid=134465)[0m mae:  0.12030129134654999
[2m[36m(func pid=134465)[0m rmse_per_class: [0.112, 0.271, 0.063, 0.351, 0.057, 0.192, 0.296, 0.141, 0.164, 0.093]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.1794738918542862
[2m[36m(func pid=152019)[0m mae:  0.13157926499843597
[2m[36m(func pid=152019)[0m rmse_per_class: [0.104, 0.267, 0.089, 0.324, 0.101, 0.193, 0.305, 0.156, 0.139, 0.115]
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 1.0441 | Steps: 2 | Val loss: 0.8108 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.5080 | Steps: 2 | Val loss: 0.4008 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 06:04:04 (running for 00:07:55.92)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.51  |  0.174 |                   81 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  1.063 |  0.18  |                    4 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.961 |  0.179 |                    3 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=153479)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=153479)[0m Configuration completed!
[2m[36m(func pid=153479)[0m New optimizer parameters:
[2m[36m(func pid=153479)[0m SGD (
[2m[36m(func pid=153479)[0m Parameter Group 0
[2m[36m(func pid=153479)[0m     dampening: 0
[2m[36m(func pid=153479)[0m     differentiable: False
[2m[36m(func pid=153479)[0m     foreach: None
[2m[36m(func pid=153479)[0m     lr: 0.01
[2m[36m(func pid=153479)[0m     maximize: False
[2m[36m(func pid=153479)[0m     momentum: 0.9
[2m[36m(func pid=153479)[0m     nesterov: False
[2m[36m(func pid=153479)[0m     weight_decay: 0
[2m[36m(func pid=153479)[0m )
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.18025493621826172
[2m[36m(func pid=151958)[0m mae:  0.13242633640766144
[2m[36m(func pid=151958)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.104, 0.194, 0.309, 0.154, 0.138, 0.118]
[2m[36m(func pid=151958)[0m 
== Status ==
Current time: 2024-01-07 06:04:10 (running for 00:08:01.29)
Memory usage on this node: 24.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.508 |  0.174 |                   82 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  1.044 |  0.18  |                    5 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.876 |  0.179 |                    4 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1739061176776886
[2m[36m(func pid=134465)[0m mae:  0.12015922367572784
[2m[36m(func pid=134465)[0m rmse_per_class: [0.111, 0.271, 0.062, 0.351, 0.057, 0.192, 0.297, 0.141, 0.164, 0.093]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7873 | Steps: 2 | Val loss: 0.5846 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 1.0311 | Steps: 2 | Val loss: 0.8054 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.5124 | Steps: 2 | Val loss: 0.4002 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0258 | Steps: 2 | Val loss: 0.6484 | Batch size: 32 | lr: 0.01 | Duration: 4.21s
[2m[36m(func pid=152019)[0m rmse: 0.1796136051416397
[2m[36m(func pid=152019)[0m mae:  0.13154152035713196
[2m[36m(func pid=152019)[0m rmse_per_class: [0.104, 0.268, 0.09, 0.324, 0.1, 0.193, 0.305, 0.157, 0.139, 0.116]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.18048617243766785
[2m[36m(func pid=151958)[0m mae:  0.1326056718826294
[2m[36m(func pid=151958)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.105, 0.194, 0.309, 0.154, 0.138, 0.119]
[2m[36m(func pid=151958)[0m 
== Status ==
Current time: 2024-01-07 06:04:15 (running for 00:08:06.55)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.512 |  0.174 |                   83 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  1.031 |  0.18  |                    6 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.787 |  0.18  |                    5 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |        |        |                      |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17389363050460815
[2m[36m(func pid=134465)[0m mae:  0.12001156806945801
[2m[36m(func pid=134465)[0m rmse_per_class: [0.112, 0.271, 0.061, 0.351, 0.057, 0.192, 0.297, 0.141, 0.164, 0.093]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.17793743312358856
[2m[36m(func pid=153479)[0m mae:  0.13040803372859955
[2m[36m(func pid=153479)[0m rmse_per_class: [0.104, 0.267, 0.085, 0.325, 0.097, 0.192, 0.301, 0.155, 0.139, 0.114]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.7063 | Steps: 2 | Val loss: 0.5234 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 1.0175 | Steps: 2 | Val loss: 0.7984 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.5107 | Steps: 2 | Val loss: 0.3986 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.7130 | Steps: 2 | Val loss: 0.4387 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=152019)[0m rmse: 0.17964884638786316
[2m[36m(func pid=152019)[0m mae:  0.13141992688179016
[2m[36m(func pid=152019)[0m rmse_per_class: [0.105, 0.268, 0.091, 0.325, 0.1, 0.194, 0.303, 0.156, 0.139, 0.115]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.1806534230709076
[2m[36m(func pid=151958)[0m mae:  0.1327238380908966
[2m[36m(func pid=151958)[0m rmse_per_class: [0.106, 0.266, 0.091, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.12]
[2m[36m(func pid=151958)[0m 
== Status ==
Current time: 2024-01-07 06:04:20 (running for 00:08:11.55)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.511 |  0.174 |                   84 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  1.017 |  0.181 |                    7 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.706 |  0.18  |                    6 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  1.026 |  0.178 |                    1 |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17381812632083893
[2m[36m(func pid=134465)[0m mae:  0.11995111405849457
[2m[36m(func pid=134465)[0m rmse_per_class: [0.112, 0.271, 0.061, 0.351, 0.057, 0.192, 0.297, 0.141, 0.164, 0.092]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1771322637796402
[2m[36m(func pid=153479)[0m mae:  0.12946157157421112
[2m[36m(func pid=153479)[0m rmse_per_class: [0.104, 0.269, 0.087, 0.328, 0.092, 0.192, 0.294, 0.154, 0.141, 0.11]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.6293 | Steps: 2 | Val loss: 0.4715 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 1.0035 | Steps: 2 | Val loss: 0.7856 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.5097 | Steps: 2 | Val loss: 0.3984 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.4745 | Steps: 2 | Val loss: 0.3375 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=152019)[0m rmse: 0.17967835068702698
[2m[36m(func pid=152019)[0m mae:  0.13131758570671082
[2m[36m(func pid=152019)[0m rmse_per_class: [0.105, 0.269, 0.093, 0.326, 0.1, 0.194, 0.302, 0.155, 0.139, 0.115]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.18072660267353058
[2m[36m(func pid=151958)[0m mae:  0.13278120756149292
[2m[36m(func pid=151958)[0m rmse_per_class: [0.106, 0.266, 0.09, 0.324, 0.104, 0.194, 0.31, 0.154, 0.138, 0.12]
[2m[36m(func pid=151958)[0m 
== Status ==
Current time: 2024-01-07 06:04:25 (running for 00:08:16.83)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.51  |  0.174 |                   85 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  1.004 |  0.181 |                    8 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.629 |  0.18  |                    7 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.713 |  0.177 |                    2 |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17369899153709412
[2m[36m(func pid=134465)[0m mae:  0.11973877251148224
[2m[36m(func pid=134465)[0m rmse_per_class: [0.111, 0.271, 0.06, 0.351, 0.057, 0.192, 0.298, 0.142, 0.164, 0.092]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1756696254014969
[2m[36m(func pid=153479)[0m mae:  0.12794312834739685
[2m[36m(func pid=153479)[0m rmse_per_class: [0.106, 0.271, 0.092, 0.334, 0.085, 0.192, 0.283, 0.143, 0.144, 0.105]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5686 | Steps: 2 | Val loss: 0.4287 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.9847 | Steps: 2 | Val loss: 0.7752 | Batch size: 32 | lr: 0.0001 | Duration: 2.69s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.5099 | Steps: 2 | Val loss: 0.3979 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4178 | Steps: 2 | Val loss: 0.3246 | Batch size: 32 | lr: 0.01 | Duration: 2.70s
[2m[36m(func pid=152019)[0m rmse: 0.17954717576503754
[2m[36m(func pid=152019)[0m mae:  0.1310785710811615
[2m[36m(func pid=152019)[0m rmse_per_class: [0.106, 0.27, 0.094, 0.327, 0.098, 0.194, 0.3, 0.153, 0.14, 0.115]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.1808646023273468
[2m[36m(func pid=151958)[0m mae:  0.13288165628910065
[2m[36m(func pid=151958)[0m rmse_per_class: [0.106, 0.266, 0.09, 0.324, 0.104, 0.194, 0.31, 0.154, 0.138, 0.121]
[2m[36m(func pid=151958)[0m 
== Status ==
Current time: 2024-01-07 06:04:31 (running for 00:08:22.06)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.51  |  0.174 |                   86 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.985 |  0.181 |                    9 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.569 |  0.18  |                    8 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.475 |  0.176 |                    3 |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1736089140176773
[2m[36m(func pid=134465)[0m mae:  0.1195552721619606
[2m[36m(func pid=134465)[0m rmse_per_class: [0.111, 0.271, 0.059, 0.351, 0.056, 0.192, 0.298, 0.142, 0.165, 0.092]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.17433322966098785
[2m[36m(func pid=153479)[0m mae:  0.12609462440013885
[2m[36m(func pid=153479)[0m rmse_per_class: [0.108, 0.273, 0.094, 0.34, 0.077, 0.192, 0.276, 0.134, 0.148, 0.101]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5218 | Steps: 2 | Val loss: 0.3964 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.9692 | Steps: 2 | Val loss: 0.7621 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.5099 | Steps: 2 | Val loss: 0.3976 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4487 | Steps: 2 | Val loss: 0.3435 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=152019)[0m rmse: 0.17929519712924957
[2m[36m(func pid=152019)[0m mae:  0.1307971477508545
[2m[36m(func pid=152019)[0m rmse_per_class: [0.106, 0.27, 0.094, 0.328, 0.097, 0.193, 0.297, 0.151, 0.141, 0.115]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.1809965968132019
[2m[36m(func pid=151958)[0m mae:  0.13298699259757996
[2m[36m(func pid=151958)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.311, 0.154, 0.138, 0.121]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1737920641899109
[2m[36m(func pid=153479)[0m mae:  0.12441110610961914
[2m[36m(func pid=153479)[0m rmse_per_class: [0.108, 0.274, 0.089, 0.346, 0.07, 0.192, 0.278, 0.133, 0.152, 0.098]
[2m[36m(func pid=153479)[0m 
== Status ==
Current time: 2024-01-07 06:04:36 (running for 00:08:27.30)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.51  |  0.174 |                   86 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.969 |  0.181 |                   10 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.522 |  0.179 |                    9 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.449 |  0.174 |                    5 |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17350536584854126
[2m[36m(func pid=134465)[0m mae:  0.11939848959445953
[2m[36m(func pid=134465)[0m rmse_per_class: [0.111, 0.27, 0.059, 0.351, 0.056, 0.192, 0.298, 0.142, 0.165, 0.092]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4856 | Steps: 2 | Val loss: 0.3720 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.9520 | Steps: 2 | Val loss: 0.7495 | Batch size: 32 | lr: 0.0001 | Duration: 2.69s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4803 | Steps: 2 | Val loss: 0.3641 | Batch size: 32 | lr: 0.01 | Duration: 2.58s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.5045 | Steps: 2 | Val loss: 0.3961 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=152019)[0m rmse: 0.17903734743595123
[2m[36m(func pid=152019)[0m mae:  0.13049311935901642
[2m[36m(func pid=152019)[0m rmse_per_class: [0.107, 0.27, 0.095, 0.329, 0.096, 0.193, 0.295, 0.149, 0.142, 0.114]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.18102355301380157
[2m[36m(func pid=151958)[0m mae:  0.13299325108528137
[2m[36m(func pid=151958)[0m rmse_per_class: [0.106, 0.266, 0.09, 0.324, 0.105, 0.194, 0.311, 0.154, 0.138, 0.122]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1734991818666458
[2m[36m(func pid=153479)[0m mae:  0.1227370947599411
[2m[36m(func pid=153479)[0m rmse_per_class: [0.107, 0.274, 0.082, 0.349, 0.064, 0.191, 0.285, 0.134, 0.154, 0.096]
[2m[36m(func pid=153479)[0m 
== Status ==
Current time: 2024-01-07 06:04:41 (running for 00:08:32.54)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.504 |  0.174 |                   88 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.952 |  0.181 |                   11 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.486 |  0.179 |                   10 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.48  |  0.173 |                    6 |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1735183447599411
[2m[36m(func pid=134465)[0m mae:  0.11937584728002548
[2m[36m(func pid=134465)[0m rmse_per_class: [0.111, 0.27, 0.058, 0.351, 0.056, 0.192, 0.298, 0.142, 0.165, 0.092]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4636 | Steps: 2 | Val loss: 0.3548 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.9301 | Steps: 2 | Val loss: 0.7363 | Batch size: 32 | lr: 0.0001 | Duration: 2.74s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.5040 | Steps: 2 | Val loss: 0.3758 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.5087 | Steps: 2 | Val loss: 0.3944 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=152019)[0m rmse: 0.17871707677841187
[2m[36m(func pid=152019)[0m mae:  0.13012012839317322
[2m[36m(func pid=152019)[0m rmse_per_class: [0.108, 0.271, 0.095, 0.33, 0.095, 0.193, 0.293, 0.146, 0.143, 0.114]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.18108369410037994
[2m[36m(func pid=151958)[0m mae:  0.1330060064792633
[2m[36m(func pid=151958)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.311, 0.154, 0.138, 0.122]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.17327168583869934
[2m[36m(func pid=153479)[0m mae:  0.12119553238153458
[2m[36m(func pid=153479)[0m rmse_per_class: [0.106, 0.273, 0.073, 0.35, 0.06, 0.191, 0.296, 0.136, 0.155, 0.094]
[2m[36m(func pid=153479)[0m 
== Status ==
Current time: 2024-01-07 06:04:46 (running for 00:08:37.76)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.509 |  0.173 |                   89 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.93  |  0.181 |                   12 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.464 |  0.179 |                   11 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.504 |  0.173 |                    7 |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17336414754390717
[2m[36m(func pid=134465)[0m mae:  0.11926450580358505
[2m[36m(func pid=134465)[0m rmse_per_class: [0.111, 0.27, 0.058, 0.35, 0.056, 0.192, 0.298, 0.142, 0.165, 0.092]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4470 | Steps: 2 | Val loss: 0.3434 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.9143 | Steps: 2 | Val loss: 0.7222 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5200 | Steps: 2 | Val loss: 0.3773 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.5090 | Steps: 2 | Val loss: 0.3922 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
[2m[36m(func pid=152019)[0m rmse: 0.17840704321861267
[2m[36m(func pid=152019)[0m mae:  0.12980656325817108
[2m[36m(func pid=152019)[0m rmse_per_class: [0.108, 0.271, 0.095, 0.331, 0.094, 0.193, 0.291, 0.144, 0.144, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.18111270666122437
[2m[36m(func pid=151958)[0m mae:  0.13301751017570496
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.105, 0.194, 0.311, 0.154, 0.138, 0.122]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.17243850231170654
[2m[36m(func pid=153479)[0m mae:  0.11946569383144379
[2m[36m(func pid=153479)[0m rmse_per_class: [0.105, 0.271, 0.064, 0.349, 0.057, 0.19, 0.302, 0.137, 0.154, 0.094]
[2m[36m(func pid=153479)[0m 
== Status ==
Current time: 2024-01-07 06:04:51 (running for 00:08:42.90)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.509 |  0.173 |                   90 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.914 |  0.181 |                   13 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.447 |  0.178 |                   12 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.52  |  0.172 |                    8 |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17320841550827026
[2m[36m(func pid=134465)[0m mae:  0.11915173381567001
[2m[36m(func pid=134465)[0m rmse_per_class: [0.111, 0.27, 0.058, 0.35, 0.056, 0.192, 0.297, 0.142, 0.165, 0.092]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4362 | Steps: 2 | Val loss: 0.3358 | Batch size: 32 | lr: 0.001 | Duration: 2.65s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.8961 | Steps: 2 | Val loss: 0.7113 | Batch size: 32 | lr: 0.0001 | Duration: 2.64s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5113 | Steps: 2 | Val loss: 0.3689 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.5017 | Steps: 2 | Val loss: 0.3901 | Batch size: 32 | lr: 0.0001 | Duration: 2.69s
[2m[36m(func pid=152019)[0m rmse: 0.17815537750720978
[2m[36m(func pid=152019)[0m mae:  0.12952136993408203
[2m[36m(func pid=152019)[0m rmse_per_class: [0.108, 0.271, 0.095, 0.332, 0.092, 0.193, 0.289, 0.143, 0.145, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.18118952214717865
[2m[36m(func pid=151958)[0m mae:  0.13306546211242676
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.104, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1710558831691742
[2m[36m(func pid=153479)[0m mae:  0.11795441806316376
[2m[36m(func pid=153479)[0m rmse_per_class: [0.105, 0.268, 0.057, 0.347, 0.056, 0.19, 0.301, 0.139, 0.155, 0.093]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.17308828234672546
[2m[36m(func pid=134465)[0m mae:  0.11902401596307755
[2m[36m(func pid=134465)[0m rmse_per_class: [0.11, 0.27, 0.057, 0.35, 0.056, 0.192, 0.298, 0.142, 0.165, 0.092]
[2m[36m(func pid=134465)[0m 
== Status ==
Current time: 2024-01-07 06:04:57 (running for 00:08:48.06)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.502 |  0.173 |                   91 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.896 |  0.181 |                   14 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.436 |  0.178 |                   13 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.511 |  0.171 |                    9 |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4262 | Steps: 2 | Val loss: 0.3309 | Batch size: 32 | lr: 0.001 | Duration: 2.71s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.8805 | Steps: 2 | Val loss: 0.6979 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4917 | Steps: 2 | Val loss: 0.3535 | Batch size: 32 | lr: 0.01 | Duration: 2.69s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.5032 | Steps: 2 | Val loss: 0.3883 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=152019)[0m rmse: 0.17785587906837463
[2m[36m(func pid=152019)[0m mae:  0.12924179434776306
[2m[36m(func pid=152019)[0m rmse_per_class: [0.109, 0.271, 0.095, 0.333, 0.091, 0.193, 0.287, 0.141, 0.146, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.181173175573349
[2m[36m(func pid=151958)[0m mae:  0.13304737210273743
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.267, 0.089, 0.324, 0.104, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1690237820148468
[2m[36m(func pid=153479)[0m mae:  0.11613678932189941
[2m[36m(func pid=153479)[0m rmse_per_class: [0.103, 0.266, 0.053, 0.341, 0.056, 0.189, 0.294, 0.139, 0.155, 0.093]
[2m[36m(func pid=153479)[0m 
== Status ==
Current time: 2024-01-07 06:05:02 (running for 00:08:53.17)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.503 |  0.173 |                   92 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.88  |  0.181 |                   15 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.426 |  0.178 |                   14 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.492 |  0.169 |                   10 |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.1730140596628189
[2m[36m(func pid=134465)[0m mae:  0.11894755065441132
[2m[36m(func pid=134465)[0m rmse_per_class: [0.11, 0.269, 0.057, 0.35, 0.056, 0.191, 0.298, 0.142, 0.165, 0.092]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.8665 | Steps: 2 | Val loss: 0.6853 | Batch size: 32 | lr: 0.0001 | Duration: 2.70s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4221 | Steps: 2 | Val loss: 0.3274 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4648 | Steps: 2 | Val loss: 0.3344 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.5061 | Steps: 2 | Val loss: 0.3879 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=151958)[0m rmse: 0.18116874992847443
[2m[36m(func pid=151958)[0m mae:  0.13301220536231995
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.267, 0.089, 0.324, 0.104, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.1775202453136444
[2m[36m(func pid=152019)[0m mae:  0.12890973687171936
[2m[36m(func pid=152019)[0m rmse_per_class: [0.109, 0.272, 0.094, 0.333, 0.09, 0.193, 0.286, 0.14, 0.147, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.16670064628124237
[2m[36m(func pid=153479)[0m mae:  0.11476918309926987
[2m[36m(func pid=153479)[0m rmse_per_class: [0.103, 0.264, 0.05, 0.335, 0.055, 0.189, 0.281, 0.14, 0.158, 0.093]
[2m[36m(func pid=153479)[0m 
== Status ==
Current time: 2024-01-07 06:05:07 (running for 00:08:58.26)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.506 |  0.173 |                   93 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.866 |  0.181 |                   16 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.422 |  0.178 |                   15 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.465 |  0.167 |                   11 |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17285598814487457
[2m[36m(func pid=134465)[0m mae:  0.11875516176223755
[2m[36m(func pid=134465)[0m rmse_per_class: [0.11, 0.269, 0.056, 0.349, 0.056, 0.192, 0.297, 0.142, 0.165, 0.092]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.8511 | Steps: 2 | Val loss: 0.6716 | Batch size: 32 | lr: 0.0001 | Duration: 2.59s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.4159 | Steps: 2 | Val loss: 0.3254 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4378 | Steps: 2 | Val loss: 0.3159 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.5002 | Steps: 2 | Val loss: 0.3866 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=151958)[0m rmse: 0.1811257302761078
[2m[36m(func pid=151958)[0m mae:  0.13295136392116547
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.104, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17735439538955688
[2m[36m(func pid=152019)[0m mae:  0.1287175863981247
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.271, 0.094, 0.334, 0.088, 0.193, 0.285, 0.14, 0.147, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.16422955691814423
[2m[36m(func pid=153479)[0m mae:  0.11353141069412231
[2m[36m(func pid=153479)[0m rmse_per_class: [0.102, 0.261, 0.049, 0.328, 0.055, 0.19, 0.266, 0.139, 0.159, 0.094]
[2m[36m(func pid=153479)[0m 
== Status ==
Current time: 2024-01-07 06:05:12 (running for 00:09:03.39)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.5   |  0.173 |                   94 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.851 |  0.181 |                   17 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.416 |  0.177 |                   16 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.438 |  0.164 |                   12 |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17276117205619812
[2m[36m(func pid=134465)[0m mae:  0.11860112845897675
[2m[36m(func pid=134465)[0m rmse_per_class: [0.11, 0.269, 0.056, 0.349, 0.056, 0.191, 0.297, 0.142, 0.165, 0.092]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.8382 | Steps: 2 | Val loss: 0.6595 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4167 | Steps: 2 | Val loss: 0.3240 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4137 | Steps: 2 | Val loss: 0.3010 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.4985 | Steps: 2 | Val loss: 0.3847 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=151958)[0m rmse: 0.1810925155878067
[2m[36m(func pid=151958)[0m mae:  0.13291344046592712
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.104, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17702673375606537
[2m[36m(func pid=152019)[0m mae:  0.12841376662254333
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.271, 0.093, 0.334, 0.087, 0.193, 0.284, 0.139, 0.147, 0.112]
[2m[36m(func pid=152019)[0m 
== Status ==
Current time: 2024-01-07 06:05:17 (running for 00:09:08.49)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.5   |  0.173 |                   94 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.838 |  0.181 |                   18 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.417 |  0.177 |                   17 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.414 |  0.162 |                   13 |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=134465)[0m rmse: 0.17263558506965637
[2m[36m(func pid=134465)[0m mae:  0.11848880350589752
[2m[36m(func pid=134465)[0m rmse_per_class: [0.11, 0.269, 0.055, 0.349, 0.056, 0.191, 0.297, 0.142, 0.165, 0.092]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1619875729084015
[2m[36m(func pid=153479)[0m mae:  0.11248032748699188
[2m[36m(func pid=153479)[0m rmse_per_class: [0.101, 0.259, 0.048, 0.319, 0.055, 0.19, 0.256, 0.137, 0.16, 0.094]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.8221 | Steps: 2 | Val loss: 0.6479 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4161 | Steps: 2 | Val loss: 0.3232 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.3944 | Steps: 2 | Val loss: 0.2924 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.4996 | Steps: 2 | Val loss: 0.3833 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=152019)[0m rmse: 0.1767135113477707
[2m[36m(func pid=152019)[0m mae:  0.1281604766845703
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.271, 0.091, 0.334, 0.086, 0.193, 0.283, 0.139, 0.148, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.1810658872127533
[2m[36m(func pid=151958)[0m mae:  0.1328926384449005
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.103, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=151958)[0m 
== Status ==
Current time: 2024-01-07 06:05:22 (running for 00:09:13.50)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.499 |  0.173 |                   95 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.822 |  0.181 |                   19 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.416 |  0.177 |                   18 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.394 |  0.16  |                   14 |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=153479)[0m rmse: 0.16032864153385162
[2m[36m(func pid=153479)[0m mae:  0.11202244460582733
[2m[36m(func pid=153479)[0m rmse_per_class: [0.1, 0.257, 0.048, 0.309, 0.055, 0.19, 0.252, 0.135, 0.161, 0.097]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.17241166532039642
[2m[36m(func pid=134465)[0m mae:  0.1182815209031105
[2m[36m(func pid=134465)[0m rmse_per_class: [0.11, 0.269, 0.055, 0.348, 0.056, 0.191, 0.296, 0.143, 0.165, 0.092]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.4128 | Steps: 2 | Val loss: 0.3228 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.8088 | Steps: 2 | Val loss: 0.6371 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.3755 | Steps: 2 | Val loss: 0.2893 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.4952 | Steps: 2 | Val loss: 0.3821 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=151958)[0m rmse: 0.18115612864494324
[2m[36m(func pid=151958)[0m mae:  0.1329299360513687
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.103, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.176551952958107
[2m[36m(func pid=152019)[0m mae:  0.12804846465587616
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.271, 0.091, 0.334, 0.084, 0.193, 0.283, 0.138, 0.148, 0.112]
[2m[36m(func pid=152019)[0m 
== Status ==
Current time: 2024-01-07 06:05:27 (running for 00:09:18.80)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.5   |  0.172 |                   96 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.809 |  0.181 |                   20 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.413 |  0.177 |                   19 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.376 |  0.159 |                   15 |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=153479)[0m rmse: 0.15908187627792358
[2m[36m(func pid=153479)[0m mae:  0.11167214810848236
[2m[36m(func pid=153479)[0m rmse_per_class: [0.1, 0.256, 0.047, 0.299, 0.055, 0.188, 0.255, 0.131, 0.158, 0.101]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.17215633392333984
[2m[36m(func pid=134465)[0m mae:  0.11810804903507233
[2m[36m(func pid=134465)[0m rmse_per_class: [0.111, 0.268, 0.054, 0.347, 0.056, 0.191, 0.294, 0.143, 0.165, 0.092]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.7927 | Steps: 2 | Val loss: 0.6261 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4110 | Steps: 2 | Val loss: 0.3223 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3709 | Steps: 2 | Val loss: 0.2907 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.4906 | Steps: 2 | Val loss: 0.3793 | Batch size: 32 | lr: 0.0001 | Duration: 2.74s
[2m[36m(func pid=151958)[0m rmse: 0.18117564916610718
[2m[36m(func pid=151958)[0m mae:  0.1329171061515808
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17626920342445374
[2m[36m(func pid=152019)[0m mae:  0.12778323888778687
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.271, 0.09, 0.334, 0.083, 0.193, 0.282, 0.138, 0.148, 0.112]
[2m[36m(func pid=152019)[0m 
== Status ==
Current time: 2024-01-07 06:05:33 (running for 00:09:24.06)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.495 |  0.172 |                   97 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.793 |  0.181 |                   21 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.411 |  0.176 |                   20 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.371 |  0.159 |                   16 |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=153479)[0m rmse: 0.158845454454422
[2m[36m(func pid=153479)[0m mae:  0.11203955113887787
[2m[36m(func pid=153479)[0m rmse_per_class: [0.1, 0.255, 0.047, 0.292, 0.055, 0.186, 0.263, 0.128, 0.157, 0.106]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.17194901406764984
[2m[36m(func pid=134465)[0m mae:  0.11800994724035263
[2m[36m(func pid=134465)[0m rmse_per_class: [0.111, 0.268, 0.054, 0.347, 0.056, 0.191, 0.293, 0.143, 0.166, 0.092]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.7816 | Steps: 2 | Val loss: 0.6152 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4115 | Steps: 2 | Val loss: 0.3218 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3709 | Steps: 2 | Val loss: 0.2930 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.4956 | Steps: 2 | Val loss: 0.3775 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=151958)[0m rmse: 0.18116798996925354
[2m[36m(func pid=151958)[0m mae:  0.13288363814353943
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.175885871052742
[2m[36m(func pid=152019)[0m mae:  0.12749142944812775
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.271, 0.089, 0.333, 0.082, 0.194, 0.281, 0.138, 0.148, 0.112]
[2m[36m(func pid=152019)[0m 
== Status ==
Current time: 2024-01-07 06:05:38 (running for 00:09:29.30)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.491 |  0.172 |                   98 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.782 |  0.181 |                   22 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.412 |  0.176 |                   21 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.371 |  0.159 |                   17 |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=153479)[0m rmse: 0.1590110808610916
[2m[36m(func pid=153479)[0m mae:  0.11267179250717163
[2m[36m(func pid=153479)[0m rmse_per_class: [0.099, 0.255, 0.047, 0.288, 0.055, 0.183, 0.271, 0.125, 0.155, 0.113]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.17176511883735657
[2m[36m(func pid=134465)[0m mae:  0.11780823767185211
[2m[36m(func pid=134465)[0m rmse_per_class: [0.11, 0.268, 0.053, 0.347, 0.056, 0.191, 0.293, 0.143, 0.165, 0.092]
[2m[36m(func pid=134465)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.7693 | Steps: 2 | Val loss: 0.6042 | Batch size: 32 | lr: 0.0001 | Duration: 2.74s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4101 | Steps: 2 | Val loss: 0.3213 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3654 | Steps: 2 | Val loss: 0.2942 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=134465)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.4830 | Steps: 2 | Val loss: 0.3759 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=151958)[0m rmse: 0.18110248446464539
[2m[36m(func pid=151958)[0m mae:  0.13281714916229248
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.31, 0.154, 0.139, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17556877434253693
[2m[36m(func pid=152019)[0m mae:  0.12723197042942047
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.271, 0.088, 0.333, 0.081, 0.193, 0.281, 0.137, 0.148, 0.112]
[2m[36m(func pid=152019)[0m 
== Status ==
Current time: 2024-01-07 06:05:43 (running for 00:09:34.51)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | RUNNING    | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.496 |  0.172 |                   99 |
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.769 |  0.181 |                   23 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.41  |  0.176 |                   22 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.365 |  0.16  |                   18 |
| train_12613_00007 | PENDING    |                     | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=153479)[0m rmse: 0.15984871983528137
[2m[36m(func pid=153479)[0m mae:  0.11357130855321884
[2m[36m(func pid=153479)[0m rmse_per_class: [0.098, 0.255, 0.047, 0.287, 0.055, 0.182, 0.275, 0.127, 0.152, 0.12]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=134465)[0m rmse: 0.17160913348197937
[2m[36m(func pid=134465)[0m mae:  0.11766967922449112
[2m[36m(func pid=134465)[0m rmse_per_class: [0.11, 0.267, 0.053, 0.347, 0.056, 0.191, 0.292, 0.143, 0.165, 0.092]
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.7597 | Steps: 2 | Val loss: 0.5941 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4090 | Steps: 2 | Val loss: 0.3208 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3586 | Steps: 2 | Val loss: 0.2945 | Batch size: 32 | lr: 0.01 | Duration: 2.71s
[2m[36m(func pid=151958)[0m rmse: 0.18099619448184967
[2m[36m(func pid=151958)[0m mae:  0.13272014260292053
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.309, 0.153, 0.139, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.1752452701330185
[2m[36m(func pid=152019)[0m mae:  0.12700456380844116
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.271, 0.087, 0.333, 0.08, 0.193, 0.281, 0.137, 0.148, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.16079923510551453
[2m[36m(func pid=153479)[0m mae:  0.11429966986179352
[2m[36m(func pid=153479)[0m rmse_per_class: [0.096, 0.255, 0.048, 0.288, 0.055, 0.182, 0.276, 0.136, 0.148, 0.124]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.7428 | Steps: 2 | Val loss: 0.5851 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4104 | Steps: 2 | Val loss: 0.3202 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3464 | Steps: 2 | Val loss: 0.2948 | Batch size: 32 | lr: 0.01 | Duration: 2.68s
[2m[36m(func pid=151958)[0m rmse: 0.18098184466362
[2m[36m(func pid=151958)[0m mae:  0.1326766461133957
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.309, 0.153, 0.139, 0.123]
== Status ==
Current time: 2024-01-07 06:05:48 (running for 00:09:39.60)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.76  |  0.181 |                   24 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.409 |  0.175 |                   23 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.359 |  0.161 |                   19 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17486484348773956
[2m[36m(func pid=152019)[0m mae:  0.12668944895267487
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.27, 0.086, 0.332, 0.08, 0.193, 0.28, 0.137, 0.148, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=158006)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=158006)[0m Configuration completed!
[2m[36m(func pid=158006)[0m New optimizer parameters:
[2m[36m(func pid=158006)[0m SGD (
[2m[36m(func pid=158006)[0m Parameter Group 0
[2m[36m(func pid=158006)[0m     dampening: 0
[2m[36m(func pid=158006)[0m     differentiable: False
[2m[36m(func pid=158006)[0m     foreach: None
[2m[36m(func pid=158006)[0m     lr: 0.1
[2m[36m(func pid=158006)[0m     maximize: False
[2m[36m(func pid=158006)[0m     momentum: 0.9
[2m[36m(func pid=158006)[0m     nesterov: False
[2m[36m(func pid=158006)[0m     weight_decay: 0
[2m[36m(func pid=158006)[0m )
[2m[36m(func pid=158006)[0m 
== Status ==
Current time: 2024-01-07 06:05:53 (running for 00:09:44.62)
Memory usage on this node: 23.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.743 |  0.181 |                   25 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.41  |  0.175 |                   24 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.346 |  0.162 |                   20 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=153479)[0m rmse: 0.161871075630188
[2m[36m(func pid=153479)[0m mae:  0.11493973433971405
[2m[36m(func pid=153479)[0m rmse_per_class: [0.094, 0.256, 0.05, 0.292, 0.056, 0.182, 0.274, 0.147, 0.144, 0.124]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4106 | Steps: 2 | Val loss: 0.3199 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.7345 | Steps: 2 | Val loss: 0.5769 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3471 | Steps: 2 | Val loss: 0.2953 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.7661 | Steps: 2 | Val loss: 0.3265 | Batch size: 32 | lr: 0.1 | Duration: 4.51s
[2m[36m(func pid=152019)[0m rmse: 0.17463937401771545
[2m[36m(func pid=152019)[0m mae:  0.12651889026165009
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.27, 0.084, 0.331, 0.079, 0.193, 0.28, 0.137, 0.149, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.18105530738830566
[2m[36m(func pid=151958)[0m mae:  0.13272453844547272
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.309, 0.153, 0.139, 0.123]
[2m[36m(func pid=151958)[0m 
== Status ==
Current time: 2024-01-07 06:05:58 (running for 00:09:49.95)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.735 |  0.181 |                   26 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.411 |  0.175 |                   25 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.347 |  0.163 |                   21 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |        |        |                      |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=153479)[0m rmse: 0.16264352202415466
[2m[36m(func pid=153479)[0m mae:  0.11534588038921356
[2m[36m(func pid=153479)[0m rmse_per_class: [0.092, 0.255, 0.053, 0.296, 0.059, 0.182, 0.272, 0.155, 0.141, 0.122]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.17296259105205536
[2m[36m(func pid=158006)[0m mae:  0.12472250312566757
[2m[36m(func pid=158006)[0m rmse_per_class: [0.105, 0.275, 0.086, 0.343, 0.073, 0.191, 0.277, 0.132, 0.15, 0.098]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.7232 | Steps: 2 | Val loss: 0.5672 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4069 | Steps: 2 | Val loss: 0.3197 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3400 | Steps: 2 | Val loss: 0.2963 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.5532 | Steps: 2 | Val loss: 0.4437 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=151958)[0m rmse: 0.1810525804758072
[2m[36m(func pid=151958)[0m mae:  0.1326894760131836
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.309, 0.154, 0.139, 0.123]
[2m[36m(func pid=152019)[0m rmse: 0.17449422180652618
[2m[36m(func pid=152019)[0m mae:  0.1264275312423706
[2m[36m(func pid=152019)[0m rmse_per_class: [0.111, 0.27, 0.083, 0.331, 0.078, 0.193, 0.28, 0.137, 0.149, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m 
== Status ==
Current time: 2024-01-07 06:06:04 (running for 00:09:55.11)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.723 |  0.181 |                   27 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.407 |  0.174 |                   26 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.34  |  0.163 |                   22 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.766 |  0.173 |                    1 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=153479)[0m rmse: 0.16316990554332733
[2m[36m(func pid=153479)[0m mae:  0.11556018888950348
[2m[36m(func pid=153479)[0m rmse_per_class: [0.09, 0.255, 0.058, 0.302, 0.064, 0.182, 0.267, 0.154, 0.141, 0.12]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.1855746954679489
[2m[36m(func pid=158006)[0m mae:  0.12390905618667603
[2m[36m(func pid=158006)[0m rmse_per_class: [0.099, 0.286, 0.059, 0.37, 0.056, 0.187, 0.406, 0.142, 0.157, 0.094]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.7133 | Steps: 2 | Val loss: 0.5597 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4113 | Steps: 2 | Val loss: 0.3190 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3338 | Steps: 2 | Val loss: 0.2967 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.7387 | Steps: 2 | Val loss: 0.4827 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=151958)[0m rmse: 0.18104758858680725
[2m[36m(func pid=151958)[0m mae:  0.13265539705753326
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.308, 0.154, 0.139, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17405740916728973
[2m[36m(func pid=152019)[0m mae:  0.12608696520328522
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.27, 0.082, 0.33, 0.077, 0.193, 0.279, 0.137, 0.149, 0.113]
[2m[36m(func pid=152019)[0m 
== Status ==
Current time: 2024-01-07 06:06:09 (running for 00:10:00.31)
Memory usage on this node: 24.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.713 |  0.181 |                   28 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.411 |  0.174 |                   27 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.334 |  0.163 |                   23 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.553 |  0.186 |                    2 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=153479)[0m rmse: 0.16280677914619446
[2m[36m(func pid=153479)[0m mae:  0.11518583446741104
[2m[36m(func pid=153479)[0m rmse_per_class: [0.088, 0.254, 0.062, 0.306, 0.072, 0.181, 0.262, 0.147, 0.142, 0.114]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.19888874888420105
[2m[36m(func pid=158006)[0m mae:  0.1283538043498993
[2m[36m(func pid=158006)[0m rmse_per_class: [0.099, 0.291, 0.048, 0.382, 0.056, 0.185, 0.517, 0.152, 0.163, 0.096]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.7018 | Steps: 2 | Val loss: 0.5525 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4043 | Steps: 2 | Val loss: 0.3183 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3343 | Steps: 2 | Val loss: 0.2956 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.7298 | Steps: 2 | Val loss: 0.4344 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=152019)[0m rmse: 0.1736476719379425
[2m[36m(func pid=152019)[0m mae:  0.12575086951255798
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.269, 0.081, 0.33, 0.077, 0.193, 0.279, 0.137, 0.149, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.18106123805046082
[2m[36m(func pid=151958)[0m mae:  0.13265623152256012
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.308, 0.154, 0.139, 0.122]
[2m[36m(func pid=151958)[0m 
== Status ==
Current time: 2024-01-07 06:06:14 (running for 00:10:05.45)
Memory usage on this node: 24.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.702 |  0.181 |                   29 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.404 |  0.174 |                   28 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.334 |  0.162 |                   24 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.739 |  0.199 |                    3 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=153479)[0m rmse: 0.16159385442733765
[2m[36m(func pid=153479)[0m mae:  0.11402910947799683
[2m[36m(func pid=153479)[0m rmse_per_class: [0.086, 0.252, 0.064, 0.308, 0.08, 0.18, 0.256, 0.138, 0.144, 0.108]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.19559402763843536
[2m[36m(func pid=158006)[0m mae:  0.12688061594963074
[2m[36m(func pid=158006)[0m rmse_per_class: [0.096, 0.285, 0.048, 0.383, 0.056, 0.18, 0.412, 0.154, 0.244, 0.097]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.6895 | Steps: 2 | Val loss: 0.5445 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4052 | Steps: 2 | Val loss: 0.3175 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3262 | Steps: 2 | Val loss: 0.2939 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.5923 | Steps: 2 | Val loss: 0.3700 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=151958)[0m rmse: 0.1810048520565033
[2m[36m(func pid=151958)[0m mae:  0.132618710398674
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.308, 0.153, 0.139, 0.122]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17327111959457397
[2m[36m(func pid=152019)[0m mae:  0.12547007203102112
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.269, 0.079, 0.329, 0.076, 0.193, 0.279, 0.137, 0.15, 0.112]
[2m[36m(func pid=152019)[0m 
== Status ==
Current time: 2024-01-07 06:06:19 (running for 00:10:10.52)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.689 |  0.181 |                   30 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.405 |  0.173 |                   29 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.326 |  0.16  |                   25 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.73  |  0.196 |                    4 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=153479)[0m rmse: 0.1602819561958313
[2m[36m(func pid=153479)[0m mae:  0.1128293126821518
[2m[36m(func pid=153479)[0m rmse_per_class: [0.085, 0.251, 0.064, 0.308, 0.087, 0.179, 0.25, 0.13, 0.144, 0.104]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.17639896273612976
[2m[36m(func pid=158006)[0m mae:  0.12119664996862411
[2m[36m(func pid=158006)[0m rmse_per_class: [0.092, 0.249, 0.049, 0.372, 0.056, 0.206, 0.227, 0.153, 0.264, 0.096]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.6842 | Steps: 2 | Val loss: 0.5373 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4069 | Steps: 2 | Val loss: 0.3168 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3265 | Steps: 2 | Val loss: 0.2913 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.5000 | Steps: 2 | Val loss: 0.3178 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=151958)[0m rmse: 0.18099546432495117
[2m[36m(func pid=151958)[0m mae:  0.13258777558803558
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.325, 0.102, 0.194, 0.308, 0.154, 0.139, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17295949161052704
[2m[36m(func pid=152019)[0m mae:  0.12520970404148102
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.269, 0.078, 0.328, 0.075, 0.193, 0.278, 0.137, 0.149, 0.112]
[2m[36m(func pid=152019)[0m 
== Status ==
Current time: 2024-01-07 06:06:24 (running for 00:10:15.79)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.684 |  0.181 |                   31 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.407 |  0.173 |                   30 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.326 |  0.159 |                   26 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.592 |  0.176 |                    5 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=153479)[0m rmse: 0.15869498252868652
[2m[36m(func pid=153479)[0m mae:  0.11144568026065826
[2m[36m(func pid=153479)[0m rmse_per_class: [0.084, 0.249, 0.062, 0.307, 0.09, 0.178, 0.246, 0.125, 0.145, 0.1]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.1616731435060501
[2m[36m(func pid=158006)[0m mae:  0.11018723249435425
[2m[36m(func pid=158006)[0m rmse_per_class: [0.121, 0.266, 0.047, 0.289, 0.056, 0.186, 0.283, 0.141, 0.136, 0.09]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.6741 | Steps: 2 | Val loss: 0.5300 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3194 | Steps: 2 | Val loss: 0.2883 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4080 | Steps: 2 | Val loss: 0.3163 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.3995 | Steps: 2 | Val loss: 0.3243 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 06:06:29 (running for 00:10:20.84)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.674 |  0.181 |                   32 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.407 |  0.173 |                   30 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.326 |  0.159 |                   26 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.5   |  0.162 |                    6 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.1809374988079071
[2m[36m(func pid=151958)[0m mae:  0.13250991702079773
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.325, 0.102, 0.194, 0.308, 0.154, 0.139, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17266994714736938
[2m[36m(func pid=152019)[0m mae:  0.12499520927667618
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.269, 0.077, 0.327, 0.075, 0.193, 0.278, 0.137, 0.148, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.15715110301971436
[2m[36m(func pid=153479)[0m mae:  0.11017140001058578
[2m[36m(func pid=153479)[0m rmse_per_class: [0.084, 0.248, 0.058, 0.302, 0.089, 0.177, 0.243, 0.122, 0.148, 0.099]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.16696566343307495
[2m[36m(func pid=158006)[0m mae:  0.110565185546875
[2m[36m(func pid=158006)[0m rmse_per_class: [0.075, 0.266, 0.033, 0.288, 0.056, 0.183, 0.291, 0.143, 0.131, 0.203]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.6708 | Steps: 2 | Val loss: 0.5230 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4057 | Steps: 2 | Val loss: 0.3159 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3260 | Steps: 2 | Val loss: 0.2859 | Batch size: 32 | lr: 0.01 | Duration: 2.71s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4248 | Steps: 2 | Val loss: 0.3421 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 06:06:34 (running for 00:10:26.03)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.671 |  0.181 |                   33 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.408 |  0.173 |                   31 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.319 |  0.157 |                   27 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.399 |  0.167 |                    7 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.1808108389377594
[2m[36m(func pid=151958)[0m mae:  0.1323961466550827
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.325, 0.102, 0.194, 0.307, 0.154, 0.139, 0.122]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1560198962688446
[2m[36m(func pid=153479)[0m mae:  0.10927049070596695
[2m[36m(func pid=153479)[0m rmse_per_class: [0.083, 0.248, 0.055, 0.298, 0.086, 0.177, 0.242, 0.121, 0.154, 0.097]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.1724826991558075
[2m[36m(func pid=152019)[0m mae:  0.1248784288764
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.268, 0.077, 0.327, 0.074, 0.193, 0.278, 0.137, 0.148, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.18263868987560272
[2m[36m(func pid=158006)[0m mae:  0.12015576660633087
[2m[36m(func pid=158006)[0m rmse_per_class: [0.086, 0.281, 0.054, 0.264, 0.054, 0.197, 0.249, 0.369, 0.133, 0.139]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.6614 | Steps: 2 | Val loss: 0.5173 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4017 | Steps: 2 | Val loss: 0.3153 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3131 | Steps: 2 | Val loss: 0.2830 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.3796 | Steps: 2 | Val loss: 0.3143 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 06:06:40 (running for 00:10:31.25)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.661 |  0.181 |                   34 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.406 |  0.172 |                   32 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.326 |  0.156 |                   28 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.425 |  0.183 |                    8 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.18086811900138855
[2m[36m(func pid=151958)[0m mae:  0.13245873153209686
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.325, 0.102, 0.194, 0.307, 0.154, 0.139, 0.122]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17217740416526794
[2m[36m(func pid=152019)[0m mae:  0.12466702610254288
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.268, 0.075, 0.327, 0.074, 0.192, 0.278, 0.137, 0.148, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.15450230240821838
[2m[36m(func pid=153479)[0m mae:  0.10809285938739777
[2m[36m(func pid=153479)[0m rmse_per_class: [0.083, 0.247, 0.051, 0.293, 0.081, 0.176, 0.242, 0.12, 0.155, 0.097]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.1650012582540512
[2m[36m(func pid=158006)[0m mae:  0.10522381216287613
[2m[36m(func pid=158006)[0m rmse_per_class: [0.073, 0.251, 0.104, 0.311, 0.07, 0.175, 0.224, 0.151, 0.204, 0.088]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.6527 | Steps: 2 | Val loss: 0.5101 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4036 | Steps: 2 | Val loss: 0.3148 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3143 | Steps: 2 | Val loss: 0.2811 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3121 | Steps: 2 | Val loss: 0.3253 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 06:06:45 (running for 00:10:36.43)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.653 |  0.181 |                   35 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.402 |  0.172 |                   33 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.313 |  0.155 |                   29 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.38  |  0.165 |                    9 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.18077944219112396
[2m[36m(func pid=151958)[0m mae:  0.13239078223705292
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.194, 0.307, 0.153, 0.139, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.15347090363502502
[2m[36m(func pid=153479)[0m mae:  0.1073811873793602
[2m[36m(func pid=153479)[0m rmse_per_class: [0.083, 0.246, 0.048, 0.289, 0.076, 0.176, 0.243, 0.12, 0.154, 0.099]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.1719774454832077
[2m[36m(func pid=152019)[0m mae:  0.12455993890762329
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.268, 0.074, 0.326, 0.073, 0.192, 0.279, 0.136, 0.148, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.17118360102176666
[2m[36m(func pid=158006)[0m mae:  0.11353032290935516
[2m[36m(func pid=158006)[0m rmse_per_class: [0.066, 0.243, 0.042, 0.338, 0.177, 0.175, 0.217, 0.133, 0.225, 0.094]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.6410 | Steps: 2 | Val loss: 0.5042 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3097 | Steps: 2 | Val loss: 0.2795 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4007 | Steps: 2 | Val loss: 0.3142 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3303 | Steps: 2 | Val loss: 0.3126 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
== Status ==
Current time: 2024-01-07 06:06:50 (running for 00:10:41.77)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.641 |  0.181 |                   36 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.404 |  0.172 |                   34 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.314 |  0.153 |                   30 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.312 |  0.171 |                   10 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.18071024119853973
[2m[36m(func pid=151958)[0m mae:  0.13230659067630768
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.194, 0.307, 0.153, 0.139, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.15252791345119476
[2m[36m(func pid=153479)[0m mae:  0.10660280287265778
[2m[36m(func pid=153479)[0m rmse_per_class: [0.083, 0.246, 0.045, 0.284, 0.072, 0.175, 0.245, 0.119, 0.152, 0.102]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17167975008487701
[2m[36m(func pid=152019)[0m mae:  0.12432887405157089
[2m[36m(func pid=152019)[0m rmse_per_class: [0.109, 0.268, 0.073, 0.325, 0.073, 0.192, 0.279, 0.136, 0.148, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.16552956402301788
[2m[36m(func pid=158006)[0m mae:  0.10889200866222382
[2m[36m(func pid=158006)[0m rmse_per_class: [0.077, 0.236, 0.029, 0.298, 0.157, 0.198, 0.241, 0.146, 0.18, 0.094]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.6356 | Steps: 2 | Val loss: 0.4992 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3098 | Steps: 2 | Val loss: 0.2782 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3995 | Steps: 2 | Val loss: 0.3137 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.3194 | Steps: 2 | Val loss: 0.2788 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
== Status ==
Current time: 2024-01-07 06:06:56 (running for 00:10:47.08)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.641 |  0.181 |                   36 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.401 |  0.172 |                   35 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.31  |  0.152 |                   32 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.33  |  0.166 |                   11 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.18081799149513245
[2m[36m(func pid=151958)[0m mae:  0.1323799341917038
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.1, 0.194, 0.307, 0.153, 0.139, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.15179073810577393
[2m[36m(func pid=153479)[0m mae:  0.10592391341924667
[2m[36m(func pid=153479)[0m rmse_per_class: [0.083, 0.246, 0.044, 0.28, 0.069, 0.174, 0.246, 0.119, 0.151, 0.105]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.1714780628681183
[2m[36m(func pid=152019)[0m mae:  0.12419216334819794
[2m[36m(func pid=152019)[0m rmse_per_class: [0.109, 0.267, 0.073, 0.325, 0.073, 0.192, 0.278, 0.136, 0.148, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14755165576934814
[2m[36m(func pid=158006)[0m mae:  0.09224995970726013
[2m[36m(func pid=158006)[0m rmse_per_class: [0.077, 0.236, 0.031, 0.253, 0.079, 0.182, 0.217, 0.142, 0.174, 0.084]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.6321 | Steps: 2 | Val loss: 0.4932 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3088 | Steps: 2 | Val loss: 0.2777 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.2840 | Steps: 2 | Val loss: 0.2768 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4007 | Steps: 2 | Val loss: 0.3134 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 06:07:01 (running for 00:10:52.38)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.632 |  0.181 |                   38 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.399 |  0.171 |                   36 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.31  |  0.152 |                   32 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.319 |  0.148 |                   12 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.18090727925300598
[2m[36m(func pid=151958)[0m mae:  0.13242168724536896
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.194, 0.307, 0.153, 0.139, 0.124]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1515374332666397
[2m[36m(func pid=153479)[0m mae:  0.10561825335025787
[2m[36m(func pid=153479)[0m rmse_per_class: [0.083, 0.246, 0.043, 0.277, 0.066, 0.174, 0.248, 0.12, 0.151, 0.107]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14397934079170227
[2m[36m(func pid=158006)[0m mae:  0.08775787055492401
[2m[36m(func pid=158006)[0m rmse_per_class: [0.062, 0.258, 0.031, 0.264, 0.053, 0.159, 0.206, 0.122, 0.158, 0.126]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17135129868984222
[2m[36m(func pid=152019)[0m mae:  0.12413009256124496
[2m[36m(func pid=152019)[0m rmse_per_class: [0.109, 0.267, 0.072, 0.325, 0.072, 0.192, 0.278, 0.136, 0.149, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.6215 | Steps: 2 | Val loss: 0.4882 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3055 | Steps: 2 | Val loss: 0.2777 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.2794 | Steps: 2 | Val loss: 0.2911 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4019 | Steps: 2 | Val loss: 0.3129 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 06:07:06 (running for 00:10:57.71)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.632 |  0.181 |                   38 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.401 |  0.171 |                   37 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.309 |  0.152 |                   33 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.284 |  0.144 |                   13 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=153479)[0m rmse: 0.15155281126499176
[2m[36m(func pid=153479)[0m mae:  0.10546796023845673
[2m[36m(func pid=153479)[0m rmse_per_class: [0.084, 0.247, 0.042, 0.276, 0.065, 0.173, 0.249, 0.12, 0.149, 0.112]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.18083222210407257
[2m[36m(func pid=151958)[0m mae:  0.13233962655067444
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.325, 0.101, 0.194, 0.306, 0.153, 0.139, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.1528504490852356
[2m[36m(func pid=158006)[0m mae:  0.09373946487903595
[2m[36m(func pid=158006)[0m rmse_per_class: [0.06, 0.255, 0.032, 0.248, 0.052, 0.163, 0.214, 0.122, 0.152, 0.23]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17111650109291077
[2m[36m(func pid=152019)[0m mae:  0.12394418567419052
[2m[36m(func pid=152019)[0m rmse_per_class: [0.11, 0.267, 0.072, 0.324, 0.072, 0.192, 0.278, 0.136, 0.148, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.6157 | Steps: 2 | Val loss: 0.4830 | Batch size: 32 | lr: 0.0001 | Duration: 2.73s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3061 | Steps: 2 | Val loss: 0.2772 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.2840 | Steps: 2 | Val loss: 0.3040 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3972 | Steps: 2 | Val loss: 0.3124 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 06:07:11 (running for 00:11:03.00)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.622 |  0.181 |                   39 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.402 |  0.171 |                   38 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.305 |  0.152 |                   34 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.284 |  0.161 |                   15 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.1807805746793747
[2m[36m(func pid=151958)[0m mae:  0.1322527378797531
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.325, 0.101, 0.194, 0.306, 0.153, 0.139, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.16084913909435272
[2m[36m(func pid=158006)[0m mae:  0.09926135838031769
[2m[36m(func pid=158006)[0m rmse_per_class: [0.06, 0.238, 0.032, 0.282, 0.053, 0.161, 0.232, 0.217, 0.168, 0.165]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.1708890199661255
[2m[36m(func pid=152019)[0m mae:  0.12378637492656708
[2m[36m(func pid=152019)[0m rmse_per_class: [0.109, 0.267, 0.071, 0.324, 0.072, 0.192, 0.278, 0.136, 0.148, 0.112]
[2m[36m(func pid=153479)[0m rmse: 0.15114575624465942
[2m[36m(func pid=153479)[0m mae:  0.10486152023077011
[2m[36m(func pid=153479)[0m rmse_per_class: [0.083, 0.247, 0.041, 0.273, 0.064, 0.173, 0.248, 0.121, 0.147, 0.115]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.2869 | Steps: 2 | Val loss: 0.2973 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.6107 | Steps: 2 | Val loss: 0.4777 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2978 | Steps: 2 | Val loss: 0.2773 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3982 | Steps: 2 | Val loss: 0.3120 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 06:07:17 (running for 00:11:08.19)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.616 |  0.181 |                   40 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.397 |  0.171 |                   39 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.306 |  0.151 |                   35 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.287 |  0.157 |                   16 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)

[2m[36m(func pid=158006)[0m rmse: 0.15652482211589813

[2m[36m(func pid=158006)[0m mae:  0.09751858562231064
[2m[36m(func pid=158006)[0m rmse_per_class: [0.062, 0.236, 0.034, 0.304, 0.061, 0.181, 0.235, 0.187, 0.18, 0.086]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.18068452179431915
[2m[36m(func pid=151958)[0m mae:  0.13217046856880188
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.325, 0.101, 0.194, 0.305, 0.152, 0.139, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.15114246308803558
[2m[36m(func pid=153479)[0m mae:  0.1046476811170578
[2m[36m(func pid=153479)[0m rmse_per_class: [0.081, 0.247, 0.04, 0.274, 0.064, 0.173, 0.246, 0.123, 0.145, 0.118]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17070424556732178
[2m[36m(func pid=152019)[0m mae:  0.1236346960067749
[2m[36m(func pid=152019)[0m rmse_per_class: [0.109, 0.267, 0.071, 0.323, 0.071, 0.192, 0.278, 0.136, 0.148, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.2668 | Steps: 2 | Val loss: 0.2807 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.6051 | Steps: 2 | Val loss: 0.4730 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4005 | Steps: 2 | Val loss: 0.3118 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3037 | Steps: 2 | Val loss: 0.2774 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 06:07:22 (running for 00:11:13.22)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.611 |  0.181 |                   41 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.398 |  0.171 |                   40 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.298 |  0.151 |                   36 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.267 |  0.148 |                   17 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=158006)[0m rmse: 0.148358553647995
[2m[36m(func pid=158006)[0m mae:  0.09227543324232101
[2m[36m(func pid=158006)[0m rmse_per_class: [0.072, 0.233, 0.033, 0.287, 0.08, 0.18, 0.213, 0.117, 0.185, 0.083]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.1807706654071808
[2m[36m(func pid=151958)[0m mae:  0.13224059343338013
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.325, 0.1, 0.194, 0.305, 0.152, 0.139, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17055973410606384
[2m[36m(func pid=152019)[0m mae:  0.12349752336740494
[2m[36m(func pid=152019)[0m rmse_per_class: [0.109, 0.267, 0.07, 0.323, 0.071, 0.192, 0.278, 0.136, 0.148, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.15101861953735352
[2m[36m(func pid=153479)[0m mae:  0.10445531457662582
[2m[36m(func pid=153479)[0m rmse_per_class: [0.081, 0.247, 0.04, 0.275, 0.064, 0.172, 0.246, 0.124, 0.145, 0.117]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.5962 | Steps: 2 | Val loss: 0.4687 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.2627 | Steps: 2 | Val loss: 0.2781 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3993 | Steps: 2 | Val loss: 0.3112 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3029 | Steps: 2 | Val loss: 0.2776 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 06:07:27 (running for 00:11:18.53)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.605 |  0.181 |                   42 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.401 |  0.171 |                   41 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.304 |  0.151 |                   37 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.267 |  0.148 |                   17 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.18073192238807678
[2m[36m(func pid=151958)[0m mae:  0.13218434154987335
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.325, 0.1, 0.194, 0.305, 0.152, 0.139, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17025795578956604
[2m[36m(func pid=152019)[0m mae:  0.12324142456054688
[2m[36m(func pid=152019)[0m rmse_per_class: [0.108, 0.266, 0.07, 0.322, 0.071, 0.191, 0.278, 0.136, 0.148, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.15093189477920532
[2m[36m(func pid=153479)[0m mae:  0.10420437157154083
[2m[36m(func pid=153479)[0m rmse_per_class: [0.079, 0.246, 0.04, 0.277, 0.064, 0.172, 0.244, 0.126, 0.146, 0.115]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14671239256858826
[2m[36m(func pid=158006)[0m mae:  0.09033852070569992
[2m[36m(func pid=158006)[0m rmse_per_class: [0.081, 0.229, 0.029, 0.259, 0.1, 0.166, 0.203, 0.112, 0.204, 0.083]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.5932 | Steps: 2 | Val loss: 0.4646 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4011 | Steps: 2 | Val loss: 0.3106 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.2692 | Steps: 2 | Val loss: 0.2811 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3014 | Steps: 2 | Val loss: 0.2779 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 06:07:32 (running for 00:11:23.82)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.596 |  0.181 |                   43 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.399 |  0.17  |                   42 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.303 |  0.151 |                   38 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.263 |  0.147 |                   18 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.18071147799491882
[2m[36m(func pid=151958)[0m mae:  0.1321553736925125
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.325, 0.1, 0.194, 0.305, 0.152, 0.139, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.17002734541893005
[2m[36m(func pid=152019)[0m mae:  0.12307208776473999
[2m[36m(func pid=152019)[0m rmse_per_class: [0.108, 0.266, 0.069, 0.322, 0.07, 0.191, 0.277, 0.136, 0.148, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14618591964244843
[2m[36m(func pid=158006)[0m mae:  0.08914221078157425
[2m[36m(func pid=158006)[0m rmse_per_class: [0.075, 0.235, 0.027, 0.254, 0.096, 0.164, 0.203, 0.114, 0.212, 0.082]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1509394347667694
[2m[36m(func pid=153479)[0m mae:  0.10404188930988312
[2m[36m(func pid=153479)[0m rmse_per_class: [0.078, 0.245, 0.039, 0.279, 0.065, 0.172, 0.242, 0.127, 0.148, 0.113]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3983 | Steps: 2 | Val loss: 0.3103 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.2593 | Steps: 2 | Val loss: 0.2779 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.5856 | Steps: 2 | Val loss: 0.4600 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2952 | Steps: 2 | Val loss: 0.2781 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 06:07:38 (running for 00:11:29.16)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.593 |  0.181 |                   44 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.398 |  0.17  |                   44 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.301 |  0.151 |                   39 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.269 |  0.146 |                   19 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m rmse: 0.16981737315654755
[2m[36m(func pid=152019)[0m mae:  0.12289416790008545
[2m[36m(func pid=152019)[0m rmse_per_class: [0.108, 0.266, 0.069, 0.321, 0.07, 0.191, 0.277, 0.136, 0.148, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14201821386814117
[2m[36m(func pid=158006)[0m mae:  0.08652232587337494
[2m[36m(func pid=158006)[0m rmse_per_class: [0.063, 0.234, 0.026, 0.253, 0.073, 0.163, 0.208, 0.11, 0.196, 0.093]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.1806519478559494
[2m[36m(func pid=151958)[0m mae:  0.13208982348442078
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.325, 0.1, 0.194, 0.305, 0.152, 0.139, 0.124]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.15088345110416412
[2m[36m(func pid=153479)[0m mae:  0.10402216762304306
[2m[36m(func pid=153479)[0m rmse_per_class: [0.078, 0.245, 0.04, 0.281, 0.067, 0.172, 0.241, 0.125, 0.151, 0.11]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3974 | Steps: 2 | Val loss: 0.3100 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.5825 | Steps: 2 | Val loss: 0.4565 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.2523 | Steps: 2 | Val loss: 0.2753 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2921 | Steps: 2 | Val loss: 0.2781 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 06:07:43 (running for 00:11:34.40)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.586 |  0.181 |                   45 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.397 |  0.17  |                   45 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.295 |  0.151 |                   40 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.259 |  0.142 |                   20 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m rmse: 0.16970553994178772
[2m[36m(func pid=152019)[0m mae:  0.12278535217046738
[2m[36m(func pid=152019)[0m rmse_per_class: [0.108, 0.266, 0.068, 0.321, 0.07, 0.191, 0.277, 0.136, 0.147, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.1806541532278061
[2m[36m(func pid=151958)[0m mae:  0.13209517300128937
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.1, 0.194, 0.305, 0.152, 0.139, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14212903380393982
[2m[36m(func pid=158006)[0m mae:  0.08668958395719528
[2m[36m(func pid=158006)[0m rmse_per_class: [0.062, 0.232, 0.028, 0.255, 0.062, 0.164, 0.212, 0.113, 0.173, 0.121]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1507195383310318
[2m[36m(func pid=153479)[0m mae:  0.10378994047641754
[2m[36m(func pid=153479)[0m rmse_per_class: [0.077, 0.245, 0.039, 0.282, 0.069, 0.171, 0.239, 0.124, 0.154, 0.107]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3931 | Steps: 2 | Val loss: 0.3097 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.5770 | Steps: 2 | Val loss: 0.4529 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2930 | Steps: 2 | Val loss: 0.2786 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.2508 | Steps: 2 | Val loss: 0.2765 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 06:07:48 (running for 00:11:39.41)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.582 |  0.181 |                   46 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.393 |  0.17  |                   46 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.292 |  0.151 |                   41 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.252 |  0.142 |                   21 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m rmse: 0.1695917844772339
[2m[36m(func pid=152019)[0m mae:  0.12267905473709106
[2m[36m(func pid=152019)[0m rmse_per_class: [0.108, 0.266, 0.068, 0.32, 0.07, 0.191, 0.277, 0.136, 0.147, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.18071135878562927
[2m[36m(func pid=151958)[0m mae:  0.13214629888534546
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.326, 0.1, 0.194, 0.305, 0.152, 0.14, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1509518325328827
[2m[36m(func pid=153479)[0m mae:  0.10396864265203476
[2m[36m(func pid=153479)[0m rmse_per_class: [0.077, 0.244, 0.039, 0.284, 0.07, 0.171, 0.238, 0.122, 0.156, 0.107]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14586496353149414
[2m[36m(func pid=158006)[0m mae:  0.08953507244586945
[2m[36m(func pid=158006)[0m rmse_per_class: [0.063, 0.231, 0.033, 0.269, 0.059, 0.166, 0.217, 0.132, 0.163, 0.125]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3941 | Steps: 2 | Val loss: 0.3093 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.5735 | Steps: 2 | Val loss: 0.4486 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2950 | Steps: 2 | Val loss: 0.2777 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.2499 | Steps: 2 | Val loss: 0.2824 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=152019)[0m rmse: 0.16937986016273499
[2m[36m(func pid=152019)[0m mae:  0.12251819670200348
[2m[36m(func pid=152019)[0m rmse_per_class: [0.108, 0.266, 0.067, 0.32, 0.07, 0.191, 0.277, 0.136, 0.147, 0.113]
[2m[36m(func pid=152019)[0m 
== Status ==
Current time: 2024-01-07 06:07:53 (running for 00:11:44.90)
Memory usage on this node: 24.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.577 |  0.181 |                   47 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.394 |  0.169 |                   47 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.295 |  0.15  |                   43 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.251 |  0.146 |                   22 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.1805865466594696
[2m[36m(func pid=151958)[0m mae:  0.13204315304756165
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.326, 0.1, 0.194, 0.304, 0.151, 0.14, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.15039107203483582
[2m[36m(func pid=153479)[0m mae:  0.10345451533794403
[2m[36m(func pid=153479)[0m rmse_per_class: [0.077, 0.243, 0.039, 0.283, 0.071, 0.171, 0.237, 0.121, 0.158, 0.104]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14905638992786407
[2m[36m(func pid=158006)[0m mae:  0.09148803353309631
[2m[36m(func pid=158006)[0m rmse_per_class: [0.07, 0.233, 0.037, 0.282, 0.063, 0.164, 0.22, 0.142, 0.165, 0.116]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3948 | Steps: 2 | Val loss: 0.3088 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2872 | Steps: 2 | Val loss: 0.2760 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.2481 | Steps: 2 | Val loss: 0.2830 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.5681 | Steps: 2 | Val loss: 0.4450 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=152019)[0m rmse: 0.1691492348909378
[2m[36m(func pid=152019)[0m mae:  0.12231260538101196
[2m[36m(func pid=152019)[0m rmse_per_class: [0.108, 0.266, 0.067, 0.319, 0.07, 0.191, 0.277, 0.136, 0.147, 0.112]
[2m[36m(func pid=152019)[0m 
== Status ==
Current time: 2024-01-07 06:07:58 (running for 00:11:50.01)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.574 |  0.181 |                   48 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.395 |  0.169 |                   48 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.295 |  0.15  |                   43 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.248 |  0.147 |                   24 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=153479)[0m rmse: 0.14936186373233795
[2m[36m(func pid=153479)[0m mae:  0.10251208394765854
[2m[36m(func pid=153479)[0m rmse_per_class: [0.076, 0.243, 0.039, 0.279, 0.072, 0.171, 0.236, 0.12, 0.157, 0.101]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14672014117240906
[2m[36m(func pid=158006)[0m mae:  0.08918704092502594
[2m[36m(func pid=158006)[0m rmse_per_class: [0.08, 0.232, 0.036, 0.27, 0.072, 0.162, 0.209, 0.121, 0.183, 0.103]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.18050411343574524
[2m[36m(func pid=151958)[0m mae:  0.13197840750217438
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.1, 0.194, 0.304, 0.151, 0.14, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3923 | Steps: 2 | Val loss: 0.3084 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.2464 | Steps: 2 | Val loss: 0.2823 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.5649 | Steps: 2 | Val loss: 0.4416 | Batch size: 32 | lr: 0.0001 | Duration: 2.72s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2887 | Steps: 2 | Val loss: 0.2749 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 06:08:03 (running for 00:11:55.02)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.568 |  0.181 |                   49 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.392 |  0.169 |                   49 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.287 |  0.149 |                   44 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.248 |  0.147 |                   24 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m rmse: 0.1689274162054062
[2m[36m(func pid=152019)[0m mae:  0.12210496515035629
[2m[36m(func pid=152019)[0m rmse_per_class: [0.107, 0.265, 0.067, 0.319, 0.069, 0.191, 0.276, 0.136, 0.147, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14513157308101654
[2m[36m(func pid=158006)[0m mae:  0.08773910254240036
[2m[36m(func pid=158006)[0m rmse_per_class: [0.08, 0.237, 0.035, 0.256, 0.07, 0.161, 0.203, 0.109, 0.209, 0.091]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.18060562014579773
[2m[36m(func pid=151958)[0m mae:  0.13203151524066925
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.1, 0.194, 0.304, 0.151, 0.14, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14873667061328888
[2m[36m(func pid=153479)[0m mae:  0.10193643718957901
[2m[36m(func pid=153479)[0m rmse_per_class: [0.075, 0.242, 0.039, 0.277, 0.072, 0.17, 0.235, 0.119, 0.157, 0.1]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3943 | Steps: 2 | Val loss: 0.3082 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.2417 | Steps: 2 | Val loss: 0.2767 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.5575 | Steps: 2 | Val loss: 0.4379 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2881 | Steps: 2 | Val loss: 0.2731 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=152019)[0m rmse: 0.1687924563884735
[2m[36m(func pid=152019)[0m mae:  0.12198296934366226
[2m[36m(func pid=152019)[0m rmse_per_class: [0.107, 0.265, 0.067, 0.319, 0.069, 0.191, 0.276, 0.136, 0.147, 0.112]
== Status ==
Current time: 2024-01-07 06:08:09 (running for 00:12:00.05)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.565 |  0.181 |                   50 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.394 |  0.169 |                   50 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.289 |  0.149 |                   45 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.246 |  0.145 |                   25 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.18058571219444275
[2m[36m(func pid=151958)[0m mae:  0.13200953602790833
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.326, 0.1, 0.194, 0.304, 0.151, 0.14, 0.123]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14215964078903198
[2m[36m(func pid=158006)[0m mae:  0.08609376847743988
[2m[36m(func pid=158006)[0m rmse_per_class: [0.07, 0.24, 0.033, 0.251, 0.062, 0.163, 0.205, 0.107, 0.204, 0.086]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14766183495521545
[2m[36m(func pid=153479)[0m mae:  0.1010190024971962
[2m[36m(func pid=153479)[0m rmse_per_class: [0.074, 0.241, 0.038, 0.274, 0.072, 0.17, 0.234, 0.119, 0.154, 0.099]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3922 | Steps: 2 | Val loss: 0.3082 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.5585 | Steps: 2 | Val loss: 0.4344 | Batch size: 32 | lr: 0.0001 | Duration: 2.64s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.2401 | Steps: 2 | Val loss: 0.2757 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2854 | Steps: 2 | Val loss: 0.2723 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=152019)[0m rmse: 0.16886921226978302
[2m[36m(func pid=152019)[0m mae:  0.12204380333423615
== Status ==
Current time: 2024-01-07 06:08:14 (running for 00:12:05.22)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.558 |  0.181 |                   51 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.392 |  0.169 |                   51 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.288 |  0.148 |                   46 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.242 |  0.142 |                   26 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)

[2m[36m(func pid=152019)[0m rmse_per_class: [0.107, 0.265, 0.067, 0.319, 0.069, 0.191, 0.276, 0.136, 0.147, 0.112]

[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.1805654615163803
[2m[36m(func pid=151958)[0m mae:  0.13197652995586395
[2m[36m(func pid=151958)[0m rmse_per_class: [0.107, 0.27, 0.092, 0.326, 0.1, 0.194, 0.304, 0.151, 0.14, 0.122]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14142438769340515
[2m[36m(func pid=158006)[0m mae:  0.08620703220367432
[2m[36m(func pid=158006)[0m rmse_per_class: [0.07, 0.237, 0.03, 0.251, 0.059, 0.174, 0.208, 0.108, 0.191, 0.086]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14714674651622772
[2m[36m(func pid=153479)[0m mae:  0.10056541860103607
[2m[36m(func pid=153479)[0m rmse_per_class: [0.073, 0.24, 0.038, 0.273, 0.071, 0.169, 0.235, 0.119, 0.154, 0.099]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3952 | Steps: 2 | Val loss: 0.3083 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.2524 | Steps: 2 | Val loss: 0.2740 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.5539 | Steps: 2 | Val loss: 0.4314 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2848 | Steps: 2 | Val loss: 0.2721 | Batch size: 32 | lr: 0.01 | Duration: 2.62s
== Status ==
Current time: 2024-01-07 06:08:19 (running for 00:12:10.36)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.558 |  0.181 |                   52 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.395 |  0.169 |                   52 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.285 |  0.147 |                   47 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.24  |  0.141 |                   27 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m rmse: 0.16887588798999786
[2m[36m(func pid=152019)[0m mae:  0.12205968052148819
[2m[36m(func pid=152019)[0m rmse_per_class: [0.107, 0.265, 0.067, 0.319, 0.069, 0.191, 0.276, 0.136, 0.147, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.13978895545005798
[2m[36m(func pid=158006)[0m mae:  0.08569072186946869
[2m[36m(func pid=158006)[0m rmse_per_class: [0.07, 0.23, 0.027, 0.256, 0.057, 0.165, 0.209, 0.116, 0.178, 0.09]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.18047013878822327
[2m[36m(func pid=151958)[0m mae:  0.1318892389535904
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.269, 0.092, 0.326, 0.1, 0.194, 0.303, 0.15, 0.14, 0.122]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14703144133090973
[2m[36m(func pid=153479)[0m mae:  0.10044195502996445
[2m[36m(func pid=153479)[0m rmse_per_class: [0.074, 0.24, 0.038, 0.273, 0.07, 0.169, 0.235, 0.118, 0.153, 0.101]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3902 | Steps: 2 | Val loss: 0.3079 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.2389 | Steps: 2 | Val loss: 0.2731 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.5468 | Steps: 2 | Val loss: 0.4285 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2855 | Steps: 2 | Val loss: 0.2717 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 06:08:24 (running for 00:12:15.66)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.554 |  0.18  |                   53 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.39  |  0.169 |                   53 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.285 |  0.147 |                   48 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.252 |  0.14  |                   28 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m rmse: 0.16867582499980927
[2m[36m(func pid=152019)[0m mae:  0.12189088761806488
[2m[36m(func pid=152019)[0m rmse_per_class: [0.107, 0.265, 0.066, 0.319, 0.069, 0.19, 0.275, 0.136, 0.147, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.1401926577091217
[2m[36m(func pid=158006)[0m mae:  0.0864260345697403
[2m[36m(func pid=158006)[0m rmse_per_class: [0.072, 0.227, 0.026, 0.265, 0.058, 0.161, 0.208, 0.124, 0.163, 0.096]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.18041029572486877
[2m[36m(func pid=151958)[0m mae:  0.131819948554039
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.326, 0.099, 0.194, 0.303, 0.151, 0.14, 0.122]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14678442478179932
[2m[36m(func pid=153479)[0m mae:  0.10017891973257065
[2m[36m(func pid=153479)[0m rmse_per_class: [0.074, 0.24, 0.037, 0.272, 0.07, 0.169, 0.234, 0.118, 0.152, 0.102]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.5470 | Steps: 2 | Val loss: 0.4256 | Batch size: 32 | lr: 0.0001 | Duration: 2.70s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3943 | Steps: 2 | Val loss: 0.3077 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.2410 | Steps: 2 | Val loss: 0.2805 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2788 | Steps: 2 | Val loss: 0.2717 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 06:08:29 (running for 00:12:20.85)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.547 |  0.18  |                   54 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.394 |  0.169 |                   54 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.286 |  0.147 |                   49 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.239 |  0.14  |                   29 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m rmse: 0.16859962046146393
[2m[36m(func pid=152019)[0m mae:  0.1218249574303627
[2m[36m(func pid=152019)[0m rmse_per_class: [0.106, 0.265, 0.066, 0.319, 0.069, 0.19, 0.275, 0.136, 0.147, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.1803932934999466
[2m[36m(func pid=151958)[0m mae:  0.1317910999059677
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.092, 0.326, 0.099, 0.194, 0.303, 0.15, 0.14, 0.122]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14424893260002136
[2m[36m(func pid=158006)[0m mae:  0.08881714940071106
[2m[36m(func pid=158006)[0m rmse_per_class: [0.081, 0.231, 0.028, 0.274, 0.063, 0.162, 0.207, 0.119, 0.17, 0.108]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14678296446800232
[2m[36m(func pid=153479)[0m mae:  0.1001548171043396
[2m[36m(func pid=153479)[0m rmse_per_class: [0.074, 0.239, 0.037, 0.272, 0.07, 0.169, 0.235, 0.118, 0.151, 0.103]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.5386 | Steps: 2 | Val loss: 0.4223 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3894 | Steps: 2 | Val loss: 0.3072 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.2392 | Steps: 2 | Val loss: 0.2862 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2806 | Steps: 2 | Val loss: 0.2725 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=151958)[0m rmse: 0.1802845597267151
[2m[36m(func pid=151958)[0m mae:  0.13170816004276276
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.099, 0.194, 0.303, 0.15, 0.141, 0.122]
[2m[36m(func pid=151958)[0m 
== Status ==
Current time: 2024-01-07 06:08:35 (running for 00:12:26.03)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.539 |  0.18  |                   56 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.394 |  0.169 |                   54 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.279 |  0.147 |                   50 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.144 |                   30 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m rmse: 0.16834017634391785
[2m[36m(func pid=152019)[0m mae:  0.12158304452896118
[2m[36m(func pid=152019)[0m rmse_per_class: [0.106, 0.265, 0.066, 0.318, 0.069, 0.19, 0.275, 0.135, 0.146, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14624843001365662
[2m[36m(func pid=158006)[0m mae:  0.08972245454788208
[2m[36m(func pid=158006)[0m rmse_per_class: [0.078, 0.235, 0.029, 0.273, 0.067, 0.167, 0.207, 0.109, 0.186, 0.111]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14721044898033142
[2m[36m(func pid=153479)[0m mae:  0.10034646093845367
[2m[36m(func pid=153479)[0m rmse_per_class: [0.075, 0.24, 0.037, 0.273, 0.07, 0.169, 0.235, 0.118, 0.151, 0.105]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.5342 | Steps: 2 | Val loss: 0.4197 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3925 | Steps: 2 | Val loss: 0.3069 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.2426 | Steps: 2 | Val loss: 0.2830 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2831 | Steps: 2 | Val loss: 0.2725 | Batch size: 32 | lr: 0.01 | Duration: 2.70s
== Status ==
Current time: 2024-01-07 06:08:40 (running for 00:12:31.17)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.534 |  0.18  |                   57 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.389 |  0.168 |                   55 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.281 |  0.147 |                   51 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.239 |  0.146 |                   31 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.18022435903549194
[2m[36m(func pid=151958)[0m mae:  0.13164222240447998
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.099, 0.194, 0.303, 0.15, 0.141, 0.122]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.16820785403251648
[2m[36m(func pid=152019)[0m mae:  0.12148215621709824
[2m[36m(func pid=152019)[0m rmse_per_class: [0.106, 0.264, 0.065, 0.318, 0.069, 0.19, 0.275, 0.136, 0.146, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.1456509530544281
[2m[36m(func pid=158006)[0m mae:  0.08934247493743896
[2m[36m(func pid=158006)[0m rmse_per_class: [0.073, 0.234, 0.031, 0.27, 0.071, 0.17, 0.207, 0.108, 0.19, 0.102]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14712639153003693
[2m[36m(func pid=153479)[0m mae:  0.10025602579116821
[2m[36m(func pid=153479)[0m rmse_per_class: [0.075, 0.24, 0.037, 0.272, 0.07, 0.168, 0.235, 0.118, 0.152, 0.104]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.5333 | Steps: 2 | Val loss: 0.4175 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3923 | Steps: 2 | Val loss: 0.3067 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.2394 | Steps: 2 | Val loss: 0.2745 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2836 | Steps: 2 | Val loss: 0.2728 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
== Status ==
Current time: 2024-01-07 06:08:45 (running for 00:12:36.34)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.533 |  0.18  |                   58 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.393 |  0.168 |                   56 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.283 |  0.147 |                   52 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.243 |  0.146 |                   32 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.18024292588233948
[2m[36m(func pid=151958)[0m mae:  0.13162590563297272
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.099, 0.194, 0.302, 0.15, 0.141, 0.122]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.142897367477417
[2m[36m(func pid=158006)[0m mae:  0.08776282519102097
[2m[36m(func pid=158006)[0m rmse_per_class: [0.069, 0.23, 0.031, 0.264, 0.073, 0.168, 0.207, 0.108, 0.185, 0.094]
[2m[36m(func pid=152019)[0m rmse: 0.1680828034877777
[2m[36m(func pid=152019)[0m mae:  0.12137623876333237
[2m[36m(func pid=152019)[0m rmse_per_class: [0.106, 0.264, 0.066, 0.317, 0.069, 0.19, 0.275, 0.135, 0.146, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14726443588733673
[2m[36m(func pid=153479)[0m mae:  0.10025451332330704
[2m[36m(func pid=153479)[0m rmse_per_class: [0.075, 0.24, 0.036, 0.273, 0.07, 0.168, 0.235, 0.118, 0.153, 0.104]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.5330 | Steps: 2 | Val loss: 0.4150 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3880 | Steps: 2 | Val loss: 0.3067 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2446 | Steps: 2 | Val loss: 0.2703 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2764 | Steps: 2 | Val loss: 0.2728 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 06:08:50 (running for 00:12:41.60)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.533 |  0.18  |                   59 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.392 |  0.168 |                   57 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.284 |  0.147 |                   53 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.239 |  0.143 |                   33 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.18026873469352722
[2m[36m(func pid=151958)[0m mae:  0.13165540993213654
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.1, 0.194, 0.302, 0.15, 0.141, 0.121]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.16810038685798645
[2m[36m(func pid=152019)[0m mae:  0.12140603363513947
[2m[36m(func pid=152019)[0m rmse_per_class: [0.106, 0.264, 0.066, 0.317, 0.069, 0.19, 0.275, 0.135, 0.146, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14153054356575012
[2m[36m(func pid=158006)[0m mae:  0.0867520123720169
[2m[36m(func pid=158006)[0m rmse_per_class: [0.073, 0.23, 0.032, 0.258, 0.068, 0.163, 0.207, 0.111, 0.182, 0.092]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1471642553806305
[2m[36m(func pid=153479)[0m mae:  0.09998783469200134
[2m[36m(func pid=153479)[0m rmse_per_class: [0.074, 0.241, 0.036, 0.272, 0.069, 0.168, 0.234, 0.119, 0.153, 0.106]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3898 | Steps: 2 | Val loss: 0.3068 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.5289 | Steps: 2 | Val loss: 0.4123 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2364 | Steps: 2 | Val loss: 0.2751 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2853 | Steps: 2 | Val loss: 0.2733 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 06:08:55 (running for 00:12:46.83)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.529 |  0.18  |                   60 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.388 |  0.168 |                   58 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.276 |  0.147 |                   54 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.245 |  0.142 |                   34 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.18020519614219666
[2m[36m(func pid=151958)[0m mae:  0.13158701360225677
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.099, 0.194, 0.302, 0.15, 0.141, 0.121]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.16814835369586945
[2m[36m(func pid=152019)[0m mae:  0.12145259231328964
[2m[36m(func pid=152019)[0m rmse_per_class: [0.106, 0.264, 0.066, 0.317, 0.069, 0.19, 0.275, 0.135, 0.147, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.143280029296875
[2m[36m(func pid=158006)[0m mae:  0.0874619334936142
[2m[36m(func pid=158006)[0m rmse_per_class: [0.076, 0.235, 0.032, 0.258, 0.063, 0.162, 0.207, 0.117, 0.186, 0.095]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14750681817531586
[2m[36m(func pid=153479)[0m mae:  0.10016244649887085
[2m[36m(func pid=153479)[0m rmse_per_class: [0.074, 0.242, 0.036, 0.272, 0.068, 0.168, 0.234, 0.12, 0.153, 0.108]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3865 | Steps: 2 | Val loss: 0.3066 | Batch size: 32 | lr: 0.001 | Duration: 2.64s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2487 | Steps: 2 | Val loss: 0.2834 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.5220 | Steps: 2 | Val loss: 0.4105 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2752 | Steps: 2 | Val loss: 0.2731 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=152019)[0m rmse: 0.16804173588752747
[2m[36m(func pid=152019)[0m mae:  0.12131716310977936
[2m[36m(func pid=152019)[0m rmse_per_class: [0.106, 0.264, 0.066, 0.317, 0.069, 0.19, 0.274, 0.135, 0.147, 0.112]
[2m[36m(func pid=152019)[0m 
== Status ==
Current time: 2024-01-07 06:09:01 (running for 00:12:52.04)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.522 |  0.18  |                   61 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.386 |  0.168 |                   60 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.285 |  0.148 |                   55 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.236 |  0.143 |                   35 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.18016374111175537
[2m[36m(func pid=151958)[0m mae:  0.13156577944755554
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.099, 0.194, 0.302, 0.15, 0.141, 0.121]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14605189859867096
[2m[36m(func pid=158006)[0m mae:  0.08931022137403488
[2m[36m(func pid=158006)[0m rmse_per_class: [0.076, 0.238, 0.03, 0.265, 0.06, 0.164, 0.21, 0.125, 0.189, 0.104]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1472547948360443
[2m[36m(func pid=153479)[0m mae:  0.09981147944927216
[2m[36m(func pid=153479)[0m rmse_per_class: [0.073, 0.242, 0.036, 0.272, 0.069, 0.168, 0.232, 0.121, 0.153, 0.107]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3850 | Steps: 2 | Val loss: 0.3063 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2383 | Steps: 2 | Val loss: 0.2839 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.5215 | Steps: 2 | Val loss: 0.4083 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2797 | Steps: 2 | Val loss: 0.2727 | Batch size: 32 | lr: 0.01 | Duration: 2.70s
== Status ==
Current time: 2024-01-07 06:09:06 (running for 00:12:57.10)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.522 |  0.18  |                   61 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.385 |  0.168 |                   61 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.275 |  0.147 |                   56 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.249 |  0.146 |                   36 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m rmse: 0.16789084672927856
[2m[36m(func pid=152019)[0m mae:  0.12120330333709717
[2m[36m(func pid=152019)[0m rmse_per_class: [0.106, 0.264, 0.066, 0.317, 0.069, 0.19, 0.274, 0.135, 0.147, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14617440104484558
[2m[36m(func pid=158006)[0m mae:  0.09013095498085022
[2m[36m(func pid=158006)[0m rmse_per_class: [0.074, 0.235, 0.03, 0.273, 0.065, 0.169, 0.214, 0.11, 0.18, 0.111]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.1801474243402481
[2m[36m(func pid=151958)[0m mae:  0.13154122233390808
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.092, 0.326, 0.098, 0.194, 0.302, 0.15, 0.141, 0.121]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14686891436576843
[2m[36m(func pid=153479)[0m mae:  0.09942992031574249
[2m[36m(func pid=153479)[0m rmse_per_class: [0.072, 0.242, 0.035, 0.272, 0.069, 0.168, 0.231, 0.121, 0.153, 0.106]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3862 | Steps: 2 | Val loss: 0.3062 | Batch size: 32 | lr: 0.001 | Duration: 2.71s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.5190 | Steps: 2 | Val loss: 0.4067 | Batch size: 32 | lr: 0.0001 | Duration: 2.73s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2405 | Steps: 2 | Val loss: 0.2812 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2800 | Steps: 2 | Val loss: 0.2718 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=152019)[0m rmse: 0.16782331466674805
[2m[36m(func pid=152019)[0m mae:  0.12114101648330688
[2m[36m(func pid=152019)[0m rmse_per_class: [0.106, 0.264, 0.065, 0.316, 0.07, 0.19, 0.274, 0.135, 0.147, 0.111]
[2m[36m(func pid=152019)[0m 
== Status ==
Current time: 2024-01-07 06:09:11 (running for 00:13:02.39)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.521 |  0.18  |                   62 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.386 |  0.168 |                   62 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.28  |  0.147 |                   57 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.24  |  0.145 |                   38 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.18019846081733704
[2m[36m(func pid=151958)[0m mae:  0.13157948851585388
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.098, 0.194, 0.302, 0.15, 0.141, 0.121]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14487585425376892
[2m[36m(func pid=158006)[0m mae:  0.08947404474020004
[2m[36m(func pid=158006)[0m rmse_per_class: [0.075, 0.237, 0.03, 0.276, 0.065, 0.166, 0.208, 0.107, 0.171, 0.114]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14623290300369263
[2m[36m(func pid=153479)[0m mae:  0.09885962307453156
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.24, 0.035, 0.272, 0.069, 0.168, 0.23, 0.121, 0.153, 0.104]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3838 | Steps: 2 | Val loss: 0.3058 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.5166 | Steps: 2 | Val loss: 0.4048 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2371 | Steps: 2 | Val loss: 0.2781 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2780 | Steps: 2 | Val loss: 0.2707 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=152019)[0m rmse: 0.1676381528377533
[2m[36m(func pid=152019)[0m mae:  0.1209615021944046
[2m[36m(func pid=152019)[0m rmse_per_class: [0.106, 0.264, 0.065, 0.316, 0.07, 0.19, 0.274, 0.135, 0.147, 0.111]
[2m[36m(func pid=152019)[0m 
== Status ==
Current time: 2024-01-07 06:09:16 (running for 00:13:07.43)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.519 |  0.18  |                   63 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.384 |  0.168 |                   63 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.28  |  0.146 |                   58 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.24  |  0.145 |                   38 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.18011948466300964
[2m[36m(func pid=151958)[0m mae:  0.13153670728206635
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.097, 0.194, 0.302, 0.15, 0.141, 0.121]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.1433664858341217
[2m[36m(func pid=158006)[0m mae:  0.08779700845479965
[2m[36m(func pid=158006)[0m rmse_per_class: [0.073, 0.235, 0.03, 0.27, 0.064, 0.164, 0.205, 0.107, 0.178, 0.107]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1454319953918457
[2m[36m(func pid=153479)[0m mae:  0.09820990264415741
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.238, 0.035, 0.271, 0.069, 0.167, 0.23, 0.121, 0.151, 0.102]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3829 | Steps: 2 | Val loss: 0.3055 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.5155 | Steps: 2 | Val loss: 0.4032 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2384 | Steps: 2 | Val loss: 0.2776 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2790 | Steps: 2 | Val loss: 0.2710 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
== Status ==
Current time: 2024-01-07 06:09:21 (running for 00:13:12.72)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.517 |  0.18  |                   64 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.383 |  0.167 |                   64 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.278 |  0.145 |                   59 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.237 |  0.143 |                   39 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.17992688715457916
[2m[36m(func pid=151958)[0m mae:  0.13138939440250397
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.097, 0.194, 0.301, 0.15, 0.141, 0.121]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.1674540638923645
[2m[36m(func pid=152019)[0m mae:  0.120810367166996
[2m[36m(func pid=152019)[0m rmse_per_class: [0.105, 0.264, 0.065, 0.316, 0.069, 0.189, 0.274, 0.135, 0.147, 0.111]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.1440519094467163
[2m[36m(func pid=158006)[0m mae:  0.08813166618347168
[2m[36m(func pid=158006)[0m rmse_per_class: [0.076, 0.238, 0.03, 0.262, 0.061, 0.164, 0.207, 0.11, 0.188, 0.105]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14550434052944183
[2m[36m(func pid=153479)[0m mae:  0.09830141067504883
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.238, 0.035, 0.271, 0.07, 0.167, 0.23, 0.12, 0.151, 0.102]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2328 | Steps: 2 | Val loss: 0.2808 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.5135 | Steps: 2 | Val loss: 0.4010 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3844 | Steps: 2 | Val loss: 0.3051 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2756 | Steps: 2 | Val loss: 0.2703 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 06:09:27 (running for 00:13:18.05)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.515 |  0.18  |                   65 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.384 |  0.167 |                   65 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.279 |  0.146 |                   60 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.238 |  0.144 |                   40 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m rmse: 0.16727757453918457
[2m[36m(func pid=152019)[0m mae:  0.12065611779689789
[2m[36m(func pid=152019)[0m rmse_per_class: [0.105, 0.264, 0.065, 0.315, 0.069, 0.189, 0.273, 0.135, 0.146, 0.111]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14637361466884613
[2m[36m(func pid=158006)[0m mae:  0.08944661915302277
[2m[36m(func pid=158006)[0m rmse_per_class: [0.074, 0.242, 0.03, 0.257, 0.06, 0.166, 0.216, 0.117, 0.195, 0.106]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.1799161434173584
[2m[36m(func pid=151958)[0m mae:  0.13136355578899384
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.09, 0.326, 0.098, 0.194, 0.301, 0.15, 0.141, 0.121]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14499744772911072
[2m[36m(func pid=153479)[0m mae:  0.09788044542074203
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.237, 0.035, 0.269, 0.069, 0.167, 0.23, 0.119, 0.153, 0.1]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3849 | Steps: 2 | Val loss: 0.3049 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2406 | Steps: 2 | Val loss: 0.2806 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.5083 | Steps: 2 | Val loss: 0.3985 | Batch size: 32 | lr: 0.0001 | Duration: 2.74s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2721 | Steps: 2 | Val loss: 0.2701 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 06:09:32 (running for 00:13:23.12)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.513 |  0.18  |                   66 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.384 |  0.167 |                   65 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.276 |  0.145 |                   61 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.146 |                   42 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=158006)[0m rmse: 0.14577165246009827
[2m[36m(func pid=158006)[0m mae:  0.08905351907014847
[2m[36m(func pid=158006)[0m rmse_per_class: [0.075, 0.242, 0.029, 0.259, 0.06, 0.165, 0.212, 0.116, 0.194, 0.106]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.17996588349342346
[2m[36m(func pid=151958)[0m mae:  0.13137204945087433
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.09, 0.327, 0.098, 0.194, 0.301, 0.149, 0.141, 0.121]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.1671355664730072
[2m[36m(func pid=152019)[0m mae:  0.12053034454584122
[2m[36m(func pid=152019)[0m rmse_per_class: [0.105, 0.264, 0.065, 0.315, 0.069, 0.189, 0.273, 0.134, 0.146, 0.111]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14485591650009155
[2m[36m(func pid=153479)[0m mae:  0.09779272973537445
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.237, 0.035, 0.269, 0.069, 0.167, 0.23, 0.119, 0.153, 0.099]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2375 | Steps: 2 | Val loss: 0.2765 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.5080 | Steps: 2 | Val loss: 0.3959 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3835 | Steps: 2 | Val loss: 0.3048 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2747 | Steps: 2 | Val loss: 0.2706 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 06:09:37 (running for 00:13:28.23)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.508 |  0.18  |                   67 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.385 |  0.167 |                   66 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.272 |  0.145 |                   62 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.238 |  0.143 |                   43 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=158006)[0m rmse: 0.1431400179862976
[2m[36m(func pid=158006)[0m mae:  0.08764754235744476
[2m[36m(func pid=158006)[0m rmse_per_class: [0.068, 0.235, 0.029, 0.266, 0.064, 0.163, 0.206, 0.111, 0.183, 0.107]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.17986392974853516
[2m[36m(func pid=151958)[0m mae:  0.1312669813632965
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.098, 0.194, 0.301, 0.149, 0.141, 0.121]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.1670953929424286
[2m[36m(func pid=152019)[0m mae:  0.12053011357784271
[2m[36m(func pid=152019)[0m rmse_per_class: [0.104, 0.263, 0.065, 0.315, 0.069, 0.189, 0.274, 0.134, 0.147, 0.111]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14521069824695587
[2m[36m(func pid=153479)[0m mae:  0.09798397123813629
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.237, 0.035, 0.27, 0.07, 0.167, 0.231, 0.118, 0.154, 0.099]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2403 | Steps: 2 | Val loss: 0.2772 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.5022 | Steps: 2 | Val loss: 0.3939 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3817 | Steps: 2 | Val loss: 0.3047 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2685 | Steps: 2 | Val loss: 0.2712 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 06:09:42 (running for 00:13:33.31)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.508 |  0.18  |                   68 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.383 |  0.167 |                   67 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.275 |  0.145 |                   63 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.24  |  0.143 |                   44 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=158006)[0m rmse: 0.1429838091135025
[2m[36m(func pid=158006)[0m mae:  0.08797714859247208
[2m[36m(func pid=158006)[0m rmse_per_class: [0.068, 0.234, 0.03, 0.274, 0.065, 0.163, 0.207, 0.114, 0.172, 0.105]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.16703982651233673
[2m[36m(func pid=152019)[0m mae:  0.12047582864761353
[2m[36m(func pid=152019)[0m rmse_per_class: [0.104, 0.263, 0.065, 0.315, 0.069, 0.189, 0.273, 0.135, 0.147, 0.111]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.17991109192371368
[2m[36m(func pid=151958)[0m mae:  0.13126736879348755
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.098, 0.194, 0.301, 0.149, 0.141, 0.121]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14552587270736694
[2m[36m(func pid=153479)[0m mae:  0.09809030592441559
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.237, 0.034, 0.271, 0.069, 0.167, 0.23, 0.119, 0.156, 0.101]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2392 | Steps: 2 | Val loss: 0.2805 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3836 | Steps: 2 | Val loss: 0.3047 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.5033 | Steps: 2 | Val loss: 0.3919 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2705 | Steps: 2 | Val loss: 0.2709 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 06:09:47 (running for 00:13:38.53)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.502 |  0.18  |                   69 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.382 |  0.167 |                   68 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.268 |  0.146 |                   64 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.239 |  0.144 |                   45 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=158006)[0m rmse: 0.14423084259033203
[2m[36m(func pid=158006)[0m mae:  0.08843828737735748
[2m[36m(func pid=158006)[0m rmse_per_class: [0.073, 0.234, 0.03, 0.269, 0.07, 0.165, 0.21, 0.112, 0.176, 0.103]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.16711615025997162
[2m[36m(func pid=152019)[0m mae:  0.12052947282791138
[2m[36m(func pid=152019)[0m rmse_per_class: [0.105, 0.263, 0.064, 0.315, 0.069, 0.189, 0.273, 0.135, 0.147, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.17991670966148376
[2m[36m(func pid=151958)[0m mae:  0.13127301633358002
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.327, 0.098, 0.194, 0.301, 0.149, 0.141, 0.122]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1453472077846527
[2m[36m(func pid=153479)[0m mae:  0.09779554605484009
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.237, 0.034, 0.27, 0.068, 0.166, 0.23, 0.12, 0.156, 0.103]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2354 | Steps: 2 | Val loss: 0.2842 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.5011 | Steps: 2 | Val loss: 0.3910 | Batch size: 32 | lr: 0.0001 | Duration: 2.72s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3837 | Steps: 2 | Val loss: 0.3046 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2666 | Steps: 2 | Val loss: 0.2707 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 06:09:52 (running for 00:13:43.94)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.503 |  0.18  |                   70 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.384 |  0.167 |                   69 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.271 |  0.145 |                   65 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.235 |  0.147 |                   46 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=158006)[0m rmse: 0.14693006873130798
[2m[36m(func pid=158006)[0m mae:  0.08956091105937958
[2m[36m(func pid=158006)[0m rmse_per_class: [0.085, 0.237, 0.032, 0.268, 0.071, 0.165, 0.208, 0.113, 0.19, 0.101]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=151958)[0m rmse: 0.17983081936836243
[2m[36m(func pid=151958)[0m mae:  0.13122358918190002
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.097, 0.194, 0.3, 0.149, 0.141, 0.122]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.16704222559928894
[2m[36m(func pid=152019)[0m mae:  0.12044602632522583
[2m[36m(func pid=152019)[0m rmse_per_class: [0.105, 0.263, 0.064, 0.314, 0.069, 0.189, 0.273, 0.135, 0.147, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14525572955608368
[2m[36m(func pid=153479)[0m mae:  0.09758548438549042
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.237, 0.034, 0.268, 0.068, 0.166, 0.229, 0.12, 0.156, 0.103]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2444 | Steps: 2 | Val loss: 0.2830 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4989 | Steps: 2 | Val loss: 0.3892 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2674 | Steps: 2 | Val loss: 0.2708 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3814 | Steps: 2 | Val loss: 0.3045 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=158006)[0m rmse: 0.1470729559659958
[2m[36m(func pid=158006)[0m mae:  0.08937834203243256
[2m[36m(func pid=158006)[0m rmse_per_class: [0.083, 0.241, 0.032, 0.264, 0.065, 0.165, 0.207, 0.111, 0.195, 0.108]
== Status ==
Current time: 2024-01-07 06:09:58 (running for 00:13:49.14)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.501 |  0.18  |                   71 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.384 |  0.167 |                   70 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.267 |  0.145 |                   66 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.244 |  0.147 |                   47 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.17977656424045563
[2m[36m(func pid=151958)[0m mae:  0.13118772208690643
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.092, 0.327, 0.097, 0.194, 0.3, 0.148, 0.141, 0.121]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.1670101135969162
[2m[36m(func pid=152019)[0m mae:  0.12042509019374847
[2m[36m(func pid=152019)[0m rmse_per_class: [0.104, 0.263, 0.064, 0.314, 0.069, 0.189, 0.273, 0.135, 0.147, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14518502354621887
[2m[36m(func pid=153479)[0m mae:  0.09744123369455338
[2m[36m(func pid=153479)[0m rmse_per_class: [0.07, 0.238, 0.034, 0.268, 0.068, 0.166, 0.228, 0.121, 0.156, 0.103]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4940 | Steps: 2 | Val loss: 0.3871 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2464 | Steps: 2 | Val loss: 0.2786 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3800 | Steps: 2 | Val loss: 0.3045 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2656 | Steps: 2 | Val loss: 0.2708 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 06:10:03 (running for 00:13:54.45)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.494 |  0.18  |                   73 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.381 |  0.167 |                   71 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.267 |  0.145 |                   67 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.244 |  0.147 |                   47 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.17965757846832275
[2m[36m(func pid=151958)[0m mae:  0.13108134269714355
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.092, 0.326, 0.097, 0.194, 0.3, 0.148, 0.141, 0.121]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14473514258861542
[2m[36m(func pid=158006)[0m mae:  0.08832976222038269
[2m[36m(func pid=158006)[0m rmse_per_class: [0.074, 0.236, 0.032, 0.27, 0.06, 0.165, 0.207, 0.111, 0.181, 0.11]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.16703584790229797
[2m[36m(func pid=152019)[0m mae:  0.12046568095684052
[2m[36m(func pid=152019)[0m rmse_per_class: [0.104, 0.263, 0.064, 0.314, 0.069, 0.189, 0.273, 0.134, 0.147, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14509519934654236
[2m[36m(func pid=153479)[0m mae:  0.0972672626376152
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.237, 0.034, 0.268, 0.068, 0.166, 0.228, 0.12, 0.156, 0.103]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4932 | Steps: 2 | Val loss: 0.3855 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2384 | Steps: 2 | Val loss: 0.2759 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3818 | Steps: 2 | Val loss: 0.3040 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2635 | Steps: 2 | Val loss: 0.2705 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 06:10:08 (running for 00:13:59.80)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.17875000461935997
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00004 | RUNNING    | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.493 |  0.18  |                   74 |
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.38  |  0.167 |                   72 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.266 |  0.145 |                   68 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.246 |  0.145 |                   48 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.1796979010105133
[2m[36m(func pid=151958)[0m mae:  0.13110916316509247
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.092, 0.326, 0.097, 0.194, 0.3, 0.148, 0.141, 0.121]
[2m[36m(func pid=151958)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14253494143486023
[2m[36m(func pid=158006)[0m mae:  0.08770503103733063
[2m[36m(func pid=158006)[0m rmse_per_class: [0.071, 0.231, 0.03, 0.279, 0.057, 0.164, 0.208, 0.115, 0.163, 0.108]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14489850401878357
[2m[36m(func pid=153479)[0m mae:  0.09700323641300201
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.237, 0.034, 0.267, 0.068, 0.166, 0.228, 0.12, 0.158, 0.101]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.16682234406471252
[2m[36m(func pid=152019)[0m mae:  0.12023918330669403
[2m[36m(func pid=152019)[0m rmse_per_class: [0.104, 0.263, 0.064, 0.313, 0.069, 0.189, 0.272, 0.134, 0.147, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=151958)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4901 | Steps: 2 | Val loss: 0.3835 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2434 | Steps: 2 | Val loss: 0.2801 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2668 | Steps: 2 | Val loss: 0.2706 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3788 | Steps: 2 | Val loss: 0.3039 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 06:10:14 (running for 00:14:05.08)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.18000000715255737
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 3 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.382 |  0.167 |                   73 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.263 |  0.145 |                   69 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.238 |  0.143 |                   49 |
| train_12613_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=151958)[0m rmse: 0.17963320016860962
[2m[36m(func pid=151958)[0m mae:  0.1310637891292572
[2m[36m(func pid=151958)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.097, 0.194, 0.3, 0.148, 0.141, 0.12]
[2m[36m(func pid=153479)[0m rmse: 0.1449306160211563
[2m[36m(func pid=153479)[0m mae:  0.09689274430274963
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.238, 0.033, 0.266, 0.068, 0.166, 0.227, 0.119, 0.16, 0.101]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14363834261894226
[2m[36m(func pid=158006)[0m mae:  0.08832572400569916
[2m[36m(func pid=158006)[0m rmse_per_class: [0.071, 0.231, 0.028, 0.271, 0.058, 0.163, 0.214, 0.12, 0.161, 0.119]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.1667257696390152
[2m[36m(func pid=152019)[0m mae:  0.12013077735900879
[2m[36m(func pid=152019)[0m rmse_per_class: [0.104, 0.263, 0.063, 0.313, 0.069, 0.189, 0.272, 0.134, 0.147, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2709 | Steps: 2 | Val loss: 0.2707 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2387 | Steps: 2 | Val loss: 0.2843 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3786 | Steps: 2 | Val loss: 0.3038 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=153479)[0m rmse: 0.14501523971557617
[2m[36m(func pid=153479)[0m mae:  0.09696514904499054
[2m[36m(func pid=153479)[0m rmse_per_class: [0.072, 0.238, 0.033, 0.266, 0.067, 0.166, 0.228, 0.118, 0.163, 0.1]
[2m[36m(func pid=158006)[0m rmse: 0.14457353949546814
[2m[36m(func pid=158006)[0m mae:  0.08829660713672638
[2m[36m(func pid=158006)[0m rmse_per_class: [0.077, 0.23, 0.029, 0.265, 0.066, 0.164, 0.215, 0.117, 0.165, 0.118]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.16667130589485168
[2m[36m(func pid=152019)[0m mae:  0.12011350691318512
[2m[36m(func pid=152019)[0m rmse_per_class: [0.104, 0.263, 0.063, 0.313, 0.069, 0.188, 0.272, 0.134, 0.147, 0.113]
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2457 | Steps: 2 | Val loss: 0.2821 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 06:10:19 (running for 00:14:10.47)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.18000000715255737
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.379 |  0.167 |                   74 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.267 |  0.145 |                   70 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.239 |  0.145 |                   51 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=169589)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=169589)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=169589)[0m Configuration completed!
[2m[36m(func pid=169589)[0m New optimizer parameters:
[2m[36m(func pid=169589)[0m SGD (
[2m[36m(func pid=169589)[0m Parameter Group 0
[2m[36m(func pid=169589)[0m     dampening: 0
[2m[36m(func pid=169589)[0m     differentiable: False
[2m[36m(func pid=169589)[0m     foreach: None
[2m[36m(func pid=169589)[0m     lr: 0.0001
[2m[36m(func pid=169589)[0m     maximize: False
[2m[36m(func pid=169589)[0m     momentum: 0.99
[2m[36m(func pid=169589)[0m     nesterov: False
[2m[36m(func pid=169589)[0m     weight_decay: 0.0001
[2m[36m(func pid=169589)[0m )
[2m[36m(func pid=169589)[0m 
== Status ==
Current time: 2024-01-07 06:10:24 (running for 00:14:15.98)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17624999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.379 |  0.167 |                   75 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.271 |  0.145 |                   71 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.246 |  0.144 |                   52 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=158006)[0m rmse: 0.14444220066070557
[2m[36m(func pid=158006)[0m mae:  0.0875619649887085
[2m[36m(func pid=158006)[0m rmse_per_class: [0.089, 0.233, 0.032, 0.264, 0.068, 0.164, 0.205, 0.11, 0.176, 0.103]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.3794 | Steps: 2 | Val loss: 0.3037 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2657 | Steps: 2 | Val loss: 0.2703 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0824 | Steps: 2 | Val loss: 0.8110 | Batch size: 32 | lr: 0.0001 | Duration: 4.45s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2371 | Steps: 2 | Val loss: 0.2800 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=152019)[0m rmse: 0.16661879420280457
[2m[36m(func pid=152019)[0m mae:  0.12010623514652252
[2m[36m(func pid=152019)[0m rmse_per_class: [0.104, 0.263, 0.063, 0.313, 0.069, 0.188, 0.273, 0.134, 0.147, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14476877450942993
[2m[36m(func pid=153479)[0m mae:  0.09677256643772125
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.238, 0.033, 0.266, 0.068, 0.165, 0.227, 0.117, 0.163, 0.099]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17871803045272827
[2m[36m(func pid=169589)[0m mae:  0.13123497366905212
[2m[36m(func pid=169589)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.325, 0.1, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=169589)[0m 
== Status ==
Current time: 2024-01-07 06:10:30 (running for 00:14:21.17)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17624999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.379 |  0.167 |                   76 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.266 |  0.145 |                   72 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.237 |  0.146 |                   53 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  1.082 |  0.179 |                    1 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=158006)[0m rmse: 0.1461752951145172
[2m[36m(func pid=158006)[0m mae:  0.08847492933273315
[2m[36m(func pid=158006)[0m rmse_per_class: [0.098, 0.236, 0.035, 0.267, 0.069, 0.165, 0.204, 0.108, 0.187, 0.093]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.3806 | Steps: 2 | Val loss: 0.3037 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2649 | Steps: 2 | Val loss: 0.2705 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2363 | Steps: 2 | Val loss: 0.2820 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0770 | Steps: 2 | Val loss: 0.8122 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=152019)[0m rmse: 0.16662339866161346
[2m[36m(func pid=152019)[0m mae:  0.12011177837848663
[2m[36m(func pid=152019)[0m rmse_per_class: [0.104, 0.263, 0.063, 0.313, 0.069, 0.188, 0.273, 0.134, 0.147, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1448575109243393
[2m[36m(func pid=153479)[0m mae:  0.09680435806512833
[2m[36m(func pid=153479)[0m rmse_per_class: [0.07, 0.238, 0.033, 0.267, 0.068, 0.165, 0.227, 0.117, 0.166, 0.098]
[2m[36m(func pid=153479)[0m 
== Status ==
Current time: 2024-01-07 06:10:35 (running for 00:14:26.28)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17624999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.381 |  0.167 |                   77 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.265 |  0.145 |                   73 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.236 |  0.147 |                   54 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  1.082 |  0.179 |                    1 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=158006)[0m rmse: 0.14707320928573608
[2m[36m(func pid=158006)[0m mae:  0.0894680768251419
[2m[36m(func pid=158006)[0m rmse_per_class: [0.081, 0.237, 0.035, 0.269, 0.067, 0.172, 0.206, 0.108, 0.194, 0.101]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17916598916053772
[2m[36m(func pid=169589)[0m mae:  0.1315864473581314
[2m[36m(func pid=169589)[0m rmse_per_class: [0.105, 0.266, 0.088, 0.325, 0.102, 0.193, 0.305, 0.153, 0.139, 0.116]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.3764 | Steps: 2 | Val loss: 0.3035 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2661 | Steps: 2 | Val loss: 0.2698 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2413 | Steps: 2 | Val loss: 0.2891 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 1.0728 | Steps: 2 | Val loss: 0.8126 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=152019)[0m rmse: 0.1664961874485016
[2m[36m(func pid=152019)[0m mae:  0.11999712139368057
[2m[36m(func pid=152019)[0m rmse_per_class: [0.103, 0.263, 0.063, 0.313, 0.069, 0.188, 0.273, 0.134, 0.147, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14453113079071045
[2m[36m(func pid=153479)[0m mae:  0.09647081047296524
[2m[36m(func pid=153479)[0m rmse_per_class: [0.07, 0.237, 0.033, 0.265, 0.068, 0.165, 0.227, 0.116, 0.166, 0.098]
[2m[36m(func pid=153479)[0m 
== Status ==
Current time: 2024-01-07 06:10:40 (running for 00:14:31.48)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17624999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.376 |  0.166 |                   78 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.266 |  0.145 |                   74 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.151 |                   55 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  1.077 |  0.179 |                    2 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=158006)[0m rmse: 0.15055839717388153
[2m[36m(func pid=158006)[0m mae:  0.09231862425804138
[2m[36m(func pid=158006)[0m rmse_per_class: [0.069, 0.235, 0.033, 0.271, 0.063, 0.172, 0.224, 0.116, 0.194, 0.128]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17952850461006165
[2m[36m(func pid=169589)[0m mae:  0.13187167048454285
[2m[36m(func pid=169589)[0m rmse_per_class: [0.105, 0.266, 0.089, 0.325, 0.103, 0.193, 0.307, 0.154, 0.139, 0.116]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.3787 | Steps: 2 | Val loss: 0.3031 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2635 | Steps: 2 | Val loss: 0.2707 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2451 | Steps: 2 | Val loss: 0.2889 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=152019)[0m rmse: 0.16627976298332214
[2m[36m(func pid=152019)[0m mae:  0.11981119960546494
[2m[36m(func pid=152019)[0m rmse_per_class: [0.103, 0.262, 0.063, 0.312, 0.069, 0.188, 0.272, 0.134, 0.147, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1451086550951004
[2m[36m(func pid=153479)[0m mae:  0.09683850407600403
[2m[36m(func pid=153479)[0m rmse_per_class: [0.069, 0.238, 0.033, 0.267, 0.068, 0.165, 0.227, 0.116, 0.167, 0.1]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 1.0563 | Steps: 2 | Val loss: 0.8087 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=158006)[0m rmse: 0.1492117941379547
[2m[36m(func pid=158006)[0m mae:  0.09177213907241821
[2m[36m(func pid=158006)[0m rmse_per_class: [0.071, 0.235, 0.03, 0.274, 0.061, 0.165, 0.221, 0.121, 0.183, 0.132]
[2m[36m(func pid=158006)[0m 
== Status ==
Current time: 2024-01-07 06:10:46 (running for 00:14:37.41)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.379 |  0.166 |                   79 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.264 |  0.145 |                   75 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.245 |  0.149 |                   56 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  1.056 |  0.18  |                    4 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=169589)[0m rmse: 0.17992669343948364
[2m[36m(func pid=169589)[0m mae:  0.13216762244701385
[2m[36m(func pid=169589)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.104, 0.193, 0.308, 0.154, 0.138, 0.117]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.3787 | Steps: 2 | Val loss: 0.3030 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2687 | Steps: 2 | Val loss: 0.2710 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2452 | Steps: 2 | Val loss: 0.2761 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=152019)[0m rmse: 0.16617897152900696
[2m[36m(func pid=152019)[0m mae:  0.11971332877874374
[2m[36m(func pid=152019)[0m rmse_per_class: [0.102, 0.262, 0.064, 0.312, 0.069, 0.188, 0.272, 0.133, 0.146, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14532716572284698
[2m[36m(func pid=153479)[0m mae:  0.09696127474308014
[2m[36m(func pid=153479)[0m rmse_per_class: [0.07, 0.238, 0.033, 0.267, 0.069, 0.165, 0.227, 0.117, 0.167, 0.101]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 1.0393 | Steps: 2 | Val loss: 0.8020 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=158006)[0m rmse: 0.1426182985305786
[2m[36m(func pid=158006)[0m mae:  0.08714357763528824
[2m[36m(func pid=158006)[0m rmse_per_class: [0.082, 0.231, 0.027, 0.265, 0.06, 0.163, 0.205, 0.114, 0.171, 0.107]
[2m[36m(func pid=158006)[0m 
== Status ==
Current time: 2024-01-07 06:10:51 (running for 00:14:42.83)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.379 |  0.166 |                   80 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.269 |  0.145 |                   76 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.245 |  0.143 |                   57 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  1.039 |  0.18  |                    5 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=169589)[0m rmse: 0.1802552342414856
[2m[36m(func pid=169589)[0m mae:  0.1324061155319214
[2m[36m(func pid=169589)[0m rmse_per_class: [0.105, 0.266, 0.091, 0.325, 0.105, 0.194, 0.308, 0.154, 0.138, 0.118]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.3758 | Steps: 2 | Val loss: 0.3028 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2712 | Steps: 2 | Val loss: 0.2703 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2337 | Steps: 2 | Val loss: 0.2769 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=152019)[0m rmse: 0.16606475412845612
[2m[36m(func pid=152019)[0m mae:  0.11962103843688965
[2m[36m(func pid=152019)[0m rmse_per_class: [0.102, 0.262, 0.064, 0.312, 0.069, 0.188, 0.272, 0.133, 0.146, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14480367302894592
[2m[36m(func pid=153479)[0m mae:  0.09650520980358124
[2m[36m(func pid=153479)[0m rmse_per_class: [0.07, 0.238, 0.033, 0.266, 0.068, 0.165, 0.226, 0.117, 0.165, 0.101]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 1.0169 | Steps: 2 | Val loss: 0.7906 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=158006)[0m rmse: 0.14311589300632477
[2m[36m(func pid=158006)[0m mae:  0.08715509623289108
[2m[36m(func pid=158006)[0m rmse_per_class: [0.096, 0.235, 0.026, 0.263, 0.059, 0.163, 0.206, 0.111, 0.178, 0.094]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.3723 | Steps: 2 | Val loss: 0.3026 | Batch size: 32 | lr: 0.001 | Duration: 2.69s
== Status ==
Current time: 2024-01-07 06:10:57 (running for 00:14:48.39)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.376 |  0.166 |                   81 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.271 |  0.145 |                   77 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.234 |  0.143 |                   58 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  1.017 |  0.18  |                    6 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=169589)[0m rmse: 0.18048785626888275
[2m[36m(func pid=169589)[0m mae:  0.1325785219669342
[2m[36m(func pid=169589)[0m rmse_per_class: [0.105, 0.266, 0.091, 0.325, 0.105, 0.194, 0.309, 0.154, 0.138, 0.118]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2617 | Steps: 2 | Val loss: 0.2686 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2444 | Steps: 2 | Val loss: 0.2846 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=152019)[0m rmse: 0.1659592241048813
[2m[36m(func pid=152019)[0m mae:  0.11953343451023102
[2m[36m(func pid=152019)[0m rmse_per_class: [0.102, 0.262, 0.063, 0.312, 0.068, 0.188, 0.272, 0.133, 0.147, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14367082715034485
[2m[36m(func pid=153479)[0m mae:  0.09552010893821716
[2m[36m(func pid=153479)[0m rmse_per_class: [0.069, 0.237, 0.032, 0.263, 0.068, 0.165, 0.225, 0.117, 0.162, 0.099]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.9952 | Steps: 2 | Val loss: 0.7756 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=158006)[0m rmse: 0.14518162608146667
[2m[36m(func pid=158006)[0m mae:  0.0884021744132042
[2m[36m(func pid=158006)[0m rmse_per_class: [0.084, 0.238, 0.027, 0.263, 0.06, 0.168, 0.208, 0.114, 0.194, 0.096]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2686 | Steps: 2 | Val loss: 0.2680 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.3755 | Steps: 2 | Val loss: 0.3023 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 06:11:02 (running for 00:14:53.78)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.372 |  0.166 |                   82 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.262 |  0.144 |                   78 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.244 |  0.145 |                   59 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.995 |  0.181 |                    7 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=169589)[0m rmse: 0.1806463897228241
[2m[36m(func pid=169589)[0m mae:  0.13268010318279266
[2m[36m(func pid=169589)[0m rmse_per_class: [0.106, 0.266, 0.091, 0.325, 0.105, 0.194, 0.309, 0.154, 0.138, 0.119]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2446 | Steps: 2 | Val loss: 0.2888 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=152019)[0m rmse: 0.1658490151166916
[2m[36m(func pid=152019)[0m mae:  0.11939970403909683
[2m[36m(func pid=152019)[0m rmse_per_class: [0.102, 0.262, 0.063, 0.312, 0.068, 0.188, 0.272, 0.133, 0.146, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14323660731315613
[2m[36m(func pid=153479)[0m mae:  0.09520281851291656
[2m[36m(func pid=153479)[0m rmse_per_class: [0.069, 0.235, 0.032, 0.262, 0.069, 0.165, 0.225, 0.117, 0.159, 0.099]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.9666 | Steps: 2 | Val loss: 0.7538 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=158006)[0m rmse: 0.14705049991607666
[2m[36m(func pid=158006)[0m mae:  0.0896715596318245
[2m[36m(func pid=158006)[0m rmse_per_class: [0.066, 0.238, 0.029, 0.27, 0.062, 0.173, 0.211, 0.117, 0.198, 0.107]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.3746 | Steps: 2 | Val loss: 0.3022 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2632 | Steps: 2 | Val loss: 0.2673 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 06:11:08 (running for 00:14:59.17)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.376 |  0.166 |                   83 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.269 |  0.143 |                   79 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.245 |  0.147 |                   60 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.967 |  0.181 |                    8 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=169589)[0m rmse: 0.1807781159877777
[2m[36m(func pid=169589)[0m mae:  0.13276442885398865
[2m[36m(func pid=169589)[0m rmse_per_class: [0.106, 0.267, 0.091, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.12]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2430 | Steps: 2 | Val loss: 0.2852 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=152019)[0m rmse: 0.16576707363128662
[2m[36m(func pid=152019)[0m mae:  0.11935188621282578
[2m[36m(func pid=152019)[0m rmse_per_class: [0.102, 0.262, 0.063, 0.312, 0.068, 0.188, 0.272, 0.133, 0.146, 0.112]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14263507723808289
[2m[36m(func pid=153479)[0m mae:  0.09468512237071991
[2m[36m(func pid=153479)[0m rmse_per_class: [0.07, 0.235, 0.032, 0.262, 0.069, 0.165, 0.224, 0.117, 0.157, 0.097]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14632095396518707
[2m[36m(func pid=158006)[0m mae:  0.08912919461727142
[2m[36m(func pid=158006)[0m rmse_per_class: [0.064, 0.237, 0.031, 0.275, 0.06, 0.168, 0.21, 0.116, 0.19, 0.112]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.9402 | Steps: 2 | Val loss: 0.7309 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.3716 | Steps: 2 | Val loss: 0.3021 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2665 | Steps: 2 | Val loss: 0.2681 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 06:11:13 (running for 00:15:04.58)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.375 |  0.166 |                   84 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.263 |  0.143 |                   80 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.243 |  0.146 |                   61 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.94  |  0.181 |                    9 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=169589)[0m rmse: 0.18090040981769562
[2m[36m(func pid=169589)[0m mae:  0.13285313546657562
[2m[36m(func pid=169589)[0m rmse_per_class: [0.106, 0.267, 0.091, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.12]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2329 | Steps: 2 | Val loss: 0.2797 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=152019)[0m rmse: 0.16572193801403046
[2m[36m(func pid=152019)[0m mae:  0.11932222545146942
[2m[36m(func pid=152019)[0m rmse_per_class: [0.102, 0.261, 0.063, 0.312, 0.068, 0.188, 0.272, 0.133, 0.146, 0.113]
[2m[36m(func pid=153479)[0m rmse: 0.14304611086845398
[2m[36m(func pid=153479)[0m mae:  0.09495009481906891
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.234, 0.032, 0.263, 0.069, 0.165, 0.225, 0.117, 0.156, 0.098]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14414450526237488
[2m[36m(func pid=158006)[0m mae:  0.08782592415809631
[2m[36m(func pid=158006)[0m rmse_per_class: [0.075, 0.234, 0.034, 0.271, 0.06, 0.164, 0.207, 0.114, 0.17, 0.112]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.9051 | Steps: 2 | Val loss: 0.7061 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.3790 | Steps: 2 | Val loss: 0.3019 | Batch size: 32 | lr: 0.001 | Duration: 2.71s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2649 | Steps: 2 | Val loss: 0.2680 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 06:11:18 (running for 00:15:09.91)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.372 |  0.166 |                   85 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.267 |  0.143 |                   81 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.233 |  0.144 |                   62 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.905 |  0.181 |                   10 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=169589)[0m rmse: 0.18092407286167145
[2m[36m(func pid=169589)[0m mae:  0.13284192979335785
[2m[36m(func pid=169589)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.121]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2376 | Steps: 2 | Val loss: 0.2822 | Batch size: 32 | lr: 0.1 | Duration: 2.70s
[2m[36m(func pid=152019)[0m rmse: 0.16561415791511536
[2m[36m(func pid=152019)[0m mae:  0.11922377347946167
[2m[36m(func pid=152019)[0m rmse_per_class: [0.102, 0.261, 0.063, 0.312, 0.068, 0.188, 0.271, 0.133, 0.146, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14283761382102966
[2m[36m(func pid=153479)[0m mae:  0.09478859603404999
[2m[36m(func pid=153479)[0m rmse_per_class: [0.07, 0.234, 0.032, 0.264, 0.068, 0.165, 0.225, 0.118, 0.154, 0.099]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14593783020973206
[2m[36m(func pid=158006)[0m mae:  0.08896755427122116
[2m[36m(func pid=158006)[0m rmse_per_class: [0.092, 0.236, 0.034, 0.268, 0.064, 0.164, 0.211, 0.112, 0.165, 0.113]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.8757 | Steps: 2 | Val loss: 0.6784 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.3749 | Steps: 2 | Val loss: 0.3019 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2692 | Steps: 2 | Val loss: 0.2680 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2324 | Steps: 2 | Val loss: 0.2791 | Batch size: 32 | lr: 0.1 | Duration: 2.63s
== Status ==
Current time: 2024-01-07 06:11:24 (running for 00:15:15.26)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.379 |  0.166 |                   86 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.265 |  0.143 |                   82 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.238 |  0.146 |                   63 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.876 |  0.181 |                   11 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=169589)[0m rmse: 0.18099725246429443
[2m[36m(func pid=169589)[0m mae:  0.1328456699848175
[2m[36m(func pid=169589)[0m rmse_per_class: [0.106, 0.267, 0.091, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.121]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.1656319797039032
[2m[36m(func pid=152019)[0m mae:  0.11924736201763153
[2m[36m(func pid=152019)[0m rmse_per_class: [0.101, 0.261, 0.062, 0.312, 0.068, 0.188, 0.271, 0.133, 0.146, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14276131987571716
[2m[36m(func pid=153479)[0m mae:  0.09464392066001892
[2m[36m(func pid=153479)[0m rmse_per_class: [0.07, 0.234, 0.032, 0.264, 0.068, 0.165, 0.225, 0.119, 0.153, 0.099]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14396004378795624
[2m[36m(func pid=158006)[0m mae:  0.08723251521587372
[2m[36m(func pid=158006)[0m rmse_per_class: [0.088, 0.234, 0.033, 0.261, 0.065, 0.164, 0.207, 0.11, 0.171, 0.107]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.8385 | Steps: 2 | Val loss: 0.6504 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.3752 | Steps: 2 | Val loss: 0.3015 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2572 | Steps: 2 | Val loss: 0.2681 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2382 | Steps: 2 | Val loss: 0.2801 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=169589)[0m rmse: 0.1809592992067337
[2m[36m(func pid=169589)[0m mae:  0.13275595009326935
[2m[36m(func pid=169589)[0m rmse_per_class: [0.106, 0.267, 0.091, 0.324, 0.104, 0.194, 0.309, 0.154, 0.138, 0.121]
== Status ==
Current time: 2024-01-07 06:11:29 (running for 00:15:20.50)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.375 |  0.166 |                   87 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.269 |  0.143 |                   83 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.232 |  0.144 |                   64 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.839 |  0.181 |                   12 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.1653956174850464
[2m[36m(func pid=152019)[0m mae:  0.11904631555080414
[2m[36m(func pid=152019)[0m rmse_per_class: [0.101, 0.261, 0.062, 0.311, 0.068, 0.187, 0.271, 0.133, 0.146, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14280764758586884
[2m[36m(func pid=153479)[0m mae:  0.09472277015447617
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.234, 0.032, 0.265, 0.068, 0.165, 0.225, 0.118, 0.153, 0.097]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.1437632292509079
[2m[36m(func pid=158006)[0m mae:  0.08698569238185883
[2m[36m(func pid=158006)[0m rmse_per_class: [0.076, 0.238, 0.03, 0.263, 0.063, 0.166, 0.206, 0.11, 0.182, 0.104]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.8034 | Steps: 2 | Val loss: 0.6225 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.3697 | Steps: 2 | Val loss: 0.3015 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2665 | Steps: 2 | Val loss: 0.2684 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2404 | Steps: 2 | Val loss: 0.2825 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 06:11:34 (running for 00:15:25.98)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.375 |  0.165 |                   88 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.257 |  0.143 |                   84 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.238 |  0.144 |                   65 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.803 |  0.181 |                   13 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=169589)[0m rmse: 0.18093135952949524
[2m[36m(func pid=169589)[0m mae:  0.1326903998851776
[2m[36m(func pid=169589)[0m rmse_per_class: [0.106, 0.268, 0.09, 0.324, 0.104, 0.194, 0.309, 0.155, 0.138, 0.121]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.16542887687683105
[2m[36m(func pid=152019)[0m mae:  0.11908086389303207
[2m[36m(func pid=152019)[0m rmse_per_class: [0.101, 0.261, 0.063, 0.311, 0.068, 0.187, 0.271, 0.133, 0.146, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14300654828548431
[2m[36m(func pid=153479)[0m mae:  0.09487863630056381
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.234, 0.032, 0.266, 0.068, 0.165, 0.225, 0.117, 0.154, 0.098]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14529316127300262
[2m[36m(func pid=158006)[0m mae:  0.08856552839279175
[2m[36m(func pid=158006)[0m rmse_per_class: [0.068, 0.239, 0.028, 0.272, 0.06, 0.168, 0.208, 0.113, 0.196, 0.101]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7730 | Steps: 2 | Val loss: 0.5946 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.3703 | Steps: 2 | Val loss: 0.3015 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2676 | Steps: 2 | Val loss: 0.2689 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2405 | Steps: 2 | Val loss: 0.2840 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=169589)[0m rmse: 0.1808852106332779
[2m[36m(func pid=169589)[0m mae:  0.13261032104492188
[2m[36m(func pid=169589)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.309, 0.155, 0.138, 0.121]
== Status ==
Current time: 2024-01-07 06:11:40 (running for 00:15:31.25)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.37  |  0.165 |                   89 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.267 |  0.143 |                   85 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.24  |  0.145 |                   66 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.773 |  0.181 |                   14 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.16542983055114746
[2m[36m(func pid=152019)[0m mae:  0.11905322223901749
[2m[36m(func pid=152019)[0m rmse_per_class: [0.102, 0.261, 0.062, 0.311, 0.068, 0.187, 0.271, 0.133, 0.147, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14319437742233276
[2m[36m(func pid=153479)[0m mae:  0.09497660398483276
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.234, 0.032, 0.267, 0.069, 0.165, 0.225, 0.117, 0.156, 0.097]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14636050164699554
[2m[36m(func pid=158006)[0m mae:  0.08978204429149628
[2m[36m(func pid=158006)[0m rmse_per_class: [0.07, 0.237, 0.028, 0.278, 0.06, 0.166, 0.208, 0.117, 0.198, 0.102]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.7370 | Steps: 2 | Val loss: 0.5669 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.3709 | Steps: 2 | Val loss: 0.3013 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2544 | Steps: 2 | Val loss: 0.2696 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2375 | Steps: 2 | Val loss: 0.2877 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
== Status ==
Current time: 2024-01-07 06:11:45 (running for 00:15:36.71)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.37  |  0.165 |                   90 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.268 |  0.143 |                   86 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.146 |                   67 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.737 |  0.181 |                   15 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=169589)[0m rmse: 0.1808488965034485
[2m[36m(func pid=169589)[0m mae:  0.13253185153007507
[2m[36m(func pid=169589)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.308, 0.154, 0.139, 0.121]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.1653601974248886
[2m[36m(func pid=152019)[0m mae:  0.11897758394479752
[2m[36m(func pid=152019)[0m rmse_per_class: [0.101, 0.261, 0.062, 0.311, 0.068, 0.187, 0.271, 0.133, 0.146, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14332489669322968
[2m[36m(func pid=153479)[0m mae:  0.09503050148487091
[2m[36m(func pid=153479)[0m rmse_per_class: [0.072, 0.234, 0.032, 0.269, 0.068, 0.165, 0.224, 0.117, 0.156, 0.096]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14883190393447876
[2m[36m(func pid=158006)[0m mae:  0.09159804880619049
[2m[36m(func pid=158006)[0m rmse_per_class: [0.073, 0.239, 0.029, 0.281, 0.065, 0.164, 0.214, 0.119, 0.194, 0.111]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.7007 | Steps: 2 | Val loss: 0.5392 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.3690 | Steps: 2 | Val loss: 0.3014 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2667 | Steps: 2 | Val loss: 0.2696 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2357 | Steps: 2 | Val loss: 0.2839 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 06:11:50 (running for 00:15:41.92)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.371 |  0.165 |                   91 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.254 |  0.143 |                   87 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.238 |  0.149 |                   68 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.701 |  0.181 |                   16 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=169589)[0m rmse: 0.180789053440094
[2m[36m(func pid=169589)[0m mae:  0.13242706656455994
[2m[36m(func pid=169589)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.307, 0.154, 0.139, 0.122]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.1653946340084076
[2m[36m(func pid=152019)[0m mae:  0.11899222433567047
[2m[36m(func pid=152019)[0m rmse_per_class: [0.102, 0.261, 0.063, 0.311, 0.068, 0.187, 0.271, 0.133, 0.147, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1432521790266037
[2m[36m(func pid=153479)[0m mae:  0.09499558061361313
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.234, 0.032, 0.268, 0.068, 0.165, 0.224, 0.117, 0.159, 0.094]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14614441990852356
[2m[36m(func pid=158006)[0m mae:  0.08943076431751251
[2m[36m(func pid=158006)[0m rmse_per_class: [0.071, 0.237, 0.031, 0.276, 0.068, 0.164, 0.208, 0.114, 0.182, 0.112]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.6722 | Steps: 2 | Val loss: 0.5131 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.3733 | Steps: 2 | Val loss: 0.3013 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2317 | Steps: 2 | Val loss: 0.2804 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2640 | Steps: 2 | Val loss: 0.2707 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 06:11:56 (running for 00:15:47.41)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.369 |  0.165 |                   92 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.267 |  0.143 |                   88 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.236 |  0.146 |                   69 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.672 |  0.181 |                   17 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=169589)[0m rmse: 0.18075886368751526
[2m[36m(func pid=169589)[0m mae:  0.13233336806297302
[2m[36m(func pid=169589)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.102, 0.194, 0.307, 0.153, 0.139, 0.122]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.16533473134040833
[2m[36m(func pid=152019)[0m mae:  0.11892296373844147
[2m[36m(func pid=152019)[0m rmse_per_class: [0.101, 0.261, 0.062, 0.311, 0.068, 0.187, 0.27, 0.133, 0.147, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14365527033805847
[2m[36m(func pid=158006)[0m mae:  0.08721750229597092
[2m[36m(func pid=158006)[0m rmse_per_class: [0.077, 0.235, 0.032, 0.269, 0.062, 0.164, 0.206, 0.111, 0.177, 0.103]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14393889904022217
[2m[36m(func pid=153479)[0m mae:  0.09539363533258438
[2m[36m(func pid=153479)[0m rmse_per_class: [0.073, 0.234, 0.032, 0.27, 0.068, 0.165, 0.224, 0.117, 0.162, 0.095]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.6436 | Steps: 2 | Val loss: 0.4895 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.3699 | Steps: 2 | Val loss: 0.3012 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2628 | Steps: 2 | Val loss: 0.2715 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2304 | Steps: 2 | Val loss: 0.2832 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 06:12:01 (running for 00:15:52.89)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.373 |  0.165 |                   93 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.264 |  0.144 |                   89 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.232 |  0.144 |                   70 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.644 |  0.181 |                   18 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=169589)[0m rmse: 0.18059511482715607
[2m[36m(func pid=169589)[0m mae:  0.13216324150562286
[2m[36m(func pid=169589)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.101, 0.194, 0.306, 0.153, 0.14, 0.122]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=152019)[0m rmse: 0.16528204083442688
[2m[36m(func pid=152019)[0m mae:  0.11885285377502441
[2m[36m(func pid=152019)[0m rmse_per_class: [0.101, 0.261, 0.062, 0.311, 0.068, 0.187, 0.27, 0.133, 0.147, 0.114]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14399810135364532
[2m[36m(func pid=158006)[0m mae:  0.08714406937360764
[2m[36m(func pid=158006)[0m rmse_per_class: [0.083, 0.238, 0.032, 0.262, 0.058, 0.17, 0.208, 0.112, 0.174, 0.103]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14449521899223328
[2m[36m(func pid=153479)[0m mae:  0.09580524265766144
[2m[36m(func pid=153479)[0m rmse_per_class: [0.074, 0.235, 0.032, 0.271, 0.068, 0.165, 0.224, 0.116, 0.164, 0.096]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.3694 | Steps: 2 | Val loss: 0.3010 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.6130 | Steps: 2 | Val loss: 0.4673 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2609 | Steps: 2 | Val loss: 0.2719 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2344 | Steps: 2 | Val loss: 0.2866 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 06:12:07 (running for 00:15:58.18)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.369 |  0.165 |                   95 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.263 |  0.144 |                   90 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.23  |  0.144 |                   71 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.644 |  0.181 |                   18 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m rmse: 0.16517633199691772
[2m[36m(func pid=152019)[0m mae:  0.11876144260168076
[2m[36m(func pid=152019)[0m rmse_per_class: [0.101, 0.261, 0.061, 0.311, 0.068, 0.187, 0.27, 0.133, 0.147, 0.114]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.1806444376707077
[2m[36m(func pid=169589)[0m mae:  0.1321364939212799
[2m[36m(func pid=169589)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.326, 0.101, 0.194, 0.304, 0.152, 0.14, 0.121]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1448037475347519
[2m[36m(func pid=153479)[0m mae:  0.09600092470645905
[2m[36m(func pid=153479)[0m rmse_per_class: [0.074, 0.236, 0.032, 0.271, 0.069, 0.165, 0.223, 0.117, 0.166, 0.096]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14616861939430237
[2m[36m(func pid=158006)[0m mae:  0.08875866234302521
[2m[36m(func pid=158006)[0m rmse_per_class: [0.09, 0.237, 0.031, 0.263, 0.054, 0.175, 0.216, 0.117, 0.176, 0.101]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.3683 | Steps: 2 | Val loss: 0.3009 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2397 | Steps: 2 | Val loss: 0.2807 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.5827 | Steps: 2 | Val loss: 0.4469 | Batch size: 32 | lr: 0.0001 | Duration: 3.16s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2612 | Steps: 2 | Val loss: 0.2710 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 06:12:12 (running for 00:16:03.32)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.368 |  0.165 |                   96 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.261 |  0.145 |                   91 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.234 |  0.146 |                   72 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.613 |  0.181 |                   19 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m rmse: 0.1651371419429779
[2m[36m(func pid=152019)[0m mae:  0.11875136196613312
[2m[36m(func pid=152019)[0m rmse_per_class: [0.101, 0.261, 0.061, 0.312, 0.067, 0.187, 0.269, 0.132, 0.147, 0.114]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14436033368110657
[2m[36m(func pid=153479)[0m mae:  0.09563116729259491
[2m[36m(func pid=153479)[0m rmse_per_class: [0.071, 0.235, 0.032, 0.272, 0.069, 0.165, 0.221, 0.117, 0.165, 0.097]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14329858124256134
[2m[36m(func pid=158006)[0m mae:  0.08719690144062042
[2m[36m(func pid=158006)[0m rmse_per_class: [0.081, 0.235, 0.029, 0.262, 0.054, 0.163, 0.211, 0.117, 0.178, 0.102]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.1805349737405777
[2m[36m(func pid=169589)[0m mae:  0.1319837123155594
[2m[36m(func pid=169589)[0m rmse_per_class: [0.108, 0.27, 0.092, 0.326, 0.1, 0.194, 0.303, 0.151, 0.14, 0.121]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.3690 | Steps: 2 | Val loss: 0.3008 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2641 | Steps: 2 | Val loss: 0.2702 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2481 | Steps: 2 | Val loss: 0.2769 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.5592 | Steps: 2 | Val loss: 0.4271 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 06:12:17 (running for 00:16:08.46)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.369 |  0.165 |                   97 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.261 |  0.144 |                   92 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.24  |  0.143 |                   73 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.583 |  0.181 |                   20 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m rmse: 0.1650555580854416
[2m[36m(func pid=152019)[0m mae:  0.11869391053915024
[2m[36m(func pid=152019)[0m rmse_per_class: [0.101, 0.26, 0.061, 0.312, 0.067, 0.187, 0.269, 0.132, 0.147, 0.114]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14277224242687225
[2m[36m(func pid=158006)[0m mae:  0.08720099925994873
[2m[36m(func pid=158006)[0m rmse_per_class: [0.074, 0.236, 0.027, 0.269, 0.054, 0.161, 0.205, 0.112, 0.184, 0.104]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1439342051744461
[2m[36m(func pid=153479)[0m mae:  0.09533414244651794
[2m[36m(func pid=153479)[0m rmse_per_class: [0.069, 0.234, 0.032, 0.271, 0.069, 0.165, 0.221, 0.118, 0.164, 0.097]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.1804741621017456
[2m[36m(func pid=169589)[0m mae:  0.13185517489910126
[2m[36m(func pid=169589)[0m rmse_per_class: [0.108, 0.27, 0.093, 0.326, 0.1, 0.194, 0.303, 0.15, 0.141, 0.12]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.3665 | Steps: 2 | Val loss: 0.3007 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2431 | Steps: 2 | Val loss: 0.2786 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2589 | Steps: 2 | Val loss: 0.2699 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.5375 | Steps: 2 | Val loss: 0.4098 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 06:12:22 (running for 00:16:13.74)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                   98 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.264 |  0.144 |                   93 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.248 |  0.143 |                   74 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.559 |  0.18  |                   21 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m rmse: 0.16503176093101501
[2m[36m(func pid=152019)[0m mae:  0.11866115033626556
[2m[36m(func pid=152019)[0m rmse_per_class: [0.101, 0.26, 0.061, 0.311, 0.067, 0.186, 0.269, 0.132, 0.147, 0.114]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14492705464363098
[2m[36m(func pid=158006)[0m mae:  0.08866071701049805
[2m[36m(func pid=158006)[0m rmse_per_class: [0.071, 0.239, 0.027, 0.275, 0.059, 0.164, 0.209, 0.11, 0.19, 0.104]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.1437237560749054
[2m[36m(func pid=153479)[0m mae:  0.09508360922336578
[2m[36m(func pid=153479)[0m rmse_per_class: [0.068, 0.234, 0.032, 0.271, 0.068, 0.164, 0.219, 0.118, 0.165, 0.097]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.18034067749977112
[2m[36m(func pid=169589)[0m mae:  0.1316864788532257
[2m[36m(func pid=169589)[0m rmse_per_class: [0.108, 0.27, 0.093, 0.327, 0.099, 0.194, 0.301, 0.149, 0.141, 0.12]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.3656 | Steps: 2 | Val loss: 0.3005 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2608 | Steps: 2 | Val loss: 0.2687 | Batch size: 32 | lr: 0.01 | Duration: 2.59s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2395 | Steps: 2 | Val loss: 0.2840 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.5129 | Steps: 2 | Val loss: 0.3946 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
== Status ==
Current time: 2024-01-07 06:12:27 (running for 00:16:18.98)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 4 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00005 | RUNNING    | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.366 |  0.165 |                   99 |
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.259 |  0.144 |                   94 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.243 |  0.145 |                   75 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.538 |  0.18  |                   22 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m rmse: 0.16487738490104675
[2m[36m(func pid=152019)[0m mae:  0.1185222864151001
[2m[36m(func pid=152019)[0m rmse_per_class: [0.101, 0.26, 0.062, 0.311, 0.067, 0.186, 0.269, 0.132, 0.147, 0.113]
[2m[36m(func pid=152019)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14758440852165222
[2m[36m(func pid=158006)[0m mae:  0.09011013805866241
[2m[36m(func pid=158006)[0m rmse_per_class: [0.079, 0.242, 0.027, 0.269, 0.07, 0.17, 0.21, 0.117, 0.185, 0.107]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14290033280849457
[2m[36m(func pid=153479)[0m mae:  0.09456239640712738
[2m[36m(func pid=153479)[0m rmse_per_class: [0.067, 0.233, 0.032, 0.268, 0.069, 0.164, 0.22, 0.116, 0.164, 0.096]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.18017084896564484
[2m[36m(func pid=169589)[0m mae:  0.13149186968803406
[2m[36m(func pid=169589)[0m rmse_per_class: [0.109, 0.271, 0.093, 0.327, 0.099, 0.194, 0.3, 0.148, 0.142, 0.12]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=152019)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.3665 | Steps: 2 | Val loss: 0.3003 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2669 | Steps: 2 | Val loss: 0.2694 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2391 | Steps: 2 | Val loss: 0.2886 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4957 | Steps: 2 | Val loss: 0.3803 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 06:12:33 (running for 00:16:24.19)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (15 PENDING, 3 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.261 |  0.143 |                   95 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.239 |  0.148 |                   76 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.513 |  0.18  |                   23 |
| train_12613_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=152019)[0m rmse: 0.16475537419319153
[2m[36m(func pid=152019)[0m mae:  0.11841201782226562
[2m[36m(func pid=152019)[0m rmse_per_class: [0.101, 0.26, 0.062, 0.31, 0.067, 0.186, 0.269, 0.132, 0.147, 0.113]
[2m[36m(func pid=153479)[0m rmse: 0.14337927103042603
[2m[36m(func pid=153479)[0m mae:  0.09473476558923721
[2m[36m(func pid=153479)[0m rmse_per_class: [0.066, 0.234, 0.031, 0.267, 0.07, 0.164, 0.22, 0.116, 0.165, 0.099]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14865824580192566
[2m[36m(func pid=158006)[0m mae:  0.09027060866355896
[2m[36m(func pid=158006)[0m rmse_per_class: [0.082, 0.238, 0.028, 0.264, 0.075, 0.166, 0.219, 0.131, 0.18, 0.105]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.18006756901741028
[2m[36m(func pid=169589)[0m mae:  0.13132469356060028
[2m[36m(func pid=169589)[0m rmse_per_class: [0.109, 0.271, 0.094, 0.328, 0.097, 0.194, 0.298, 0.147, 0.142, 0.12]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2542 | Steps: 2 | Val loss: 0.2689 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2338 | Steps: 2 | Val loss: 0.2854 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4797 | Steps: 2 | Val loss: 0.3690 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=153479)[0m rmse: 0.14305217564105988
[2m[36m(func pid=153479)[0m mae:  0.09450244158506393
[2m[36m(func pid=153479)[0m rmse_per_class: [0.066, 0.234, 0.031, 0.266, 0.07, 0.164, 0.22, 0.116, 0.164, 0.098]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.1450350284576416
[2m[36m(func pid=158006)[0m mae:  0.08777187019586563
[2m[36m(func pid=158006)[0m rmse_per_class: [0.083, 0.236, 0.032, 0.263, 0.065, 0.163, 0.208, 0.12, 0.181, 0.099]
[2m[36m(func pid=169589)[0m rmse: 0.17999756336212158
[2m[36m(func pid=169589)[0m mae:  0.13119956851005554
[2m[36m(func pid=169589)[0m rmse_per_class: [0.11, 0.271, 0.095, 0.329, 0.097, 0.194, 0.297, 0.146, 0.143, 0.119]
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2539 | Steps: 2 | Val loss: 0.2688 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 06:12:38 (running for 00:16:29.91)
Memory usage on this node: 22.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.254 |  0.143 |                   97 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.239 |  0.149 |                   77 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.496 |  0.18  |                   24 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=175366)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=175366)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=175366)[0m Configuration completed!
[2m[36m(func pid=175366)[0m New optimizer parameters:
[2m[36m(func pid=175366)[0m SGD (
[2m[36m(func pid=175366)[0m Parameter Group 0
[2m[36m(func pid=175366)[0m     dampening: 0
[2m[36m(func pid=175366)[0m     differentiable: False
[2m[36m(func pid=175366)[0m     foreach: None
[2m[36m(func pid=175366)[0m     lr: 0.001
[2m[36m(func pid=175366)[0m     maximize: False
[2m[36m(func pid=175366)[0m     momentum: 0.99
[2m[36m(func pid=175366)[0m     nesterov: False
[2m[36m(func pid=175366)[0m     weight_decay: 0.0001
[2m[36m(func pid=175366)[0m )
[2m[36m(func pid=175366)[0m 
== Status ==
Current time: 2024-01-07 06:12:44 (running for 00:16:35.17)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.254 |  0.143 |                   98 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.234 |  0.145 |                   78 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.48  |  0.18  |                   25 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=153479)[0m rmse: 0.1429189145565033
[2m[36m(func pid=153479)[0m mae:  0.09434448182582855
[2m[36m(func pid=153479)[0m rmse_per_class: [0.067, 0.233, 0.031, 0.266, 0.071, 0.164, 0.22, 0.116, 0.162, 0.098]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2384 | Steps: 2 | Val loss: 0.2806 | Batch size: 32 | lr: 0.1 | Duration: 2.70s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4690 | Steps: 2 | Val loss: 0.3591 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0749 | Steps: 2 | Val loss: 0.7934 | Batch size: 32 | lr: 0.001 | Duration: 4.35s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2542 | Steps: 2 | Val loss: 0.2693 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=158006)[0m rmse: 0.14307072758674622
[2m[36m(func pid=158006)[0m mae:  0.08659243583679199
[2m[36m(func pid=158006)[0m rmse_per_class: [0.081, 0.235, 0.035, 0.269, 0.054, 0.162, 0.208, 0.112, 0.178, 0.096]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17974084615707397
[2m[36m(func pid=169589)[0m mae:  0.13096395134925842
[2m[36m(func pid=169589)[0m rmse_per_class: [0.11, 0.271, 0.095, 0.33, 0.096, 0.194, 0.295, 0.144, 0.144, 0.118]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.17863142490386963
[2m[36m(func pid=175366)[0m mae:  0.13114139437675476
[2m[36m(func pid=175366)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.325, 0.1, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=175366)[0m 
== Status ==
Current time: 2024-01-07 06:12:49 (running for 00:16:40.37)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00006 | RUNNING    | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.254 |  0.143 |                   99 |
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.238 |  0.143 |                   79 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.469 |  0.18  |                   26 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  1.075 |  0.179 |                    1 |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=153479)[0m rmse: 0.14319977164268494
[2m[36m(func pid=153479)[0m mae:  0.0944848507642746
[2m[36m(func pid=153479)[0m rmse_per_class: [0.067, 0.234, 0.031, 0.266, 0.07, 0.164, 0.221, 0.117, 0.162, 0.1]
[2m[36m(func pid=153479)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2427 | Steps: 2 | Val loss: 0.2823 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4523 | Steps: 2 | Val loss: 0.3506 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0337 | Steps: 2 | Val loss: 0.7537 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=153479)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2506 | Steps: 2 | Val loss: 0.2696 | Batch size: 32 | lr: 0.01 | Duration: 2.71s
[2m[36m(func pid=158006)[0m rmse: 0.14487522840499878
[2m[36m(func pid=158006)[0m mae:  0.08851198107004166
[2m[36m(func pid=158006)[0m rmse_per_class: [0.082, 0.237, 0.034, 0.276, 0.052, 0.168, 0.208, 0.11, 0.177, 0.104]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17951218783855438
[2m[36m(func pid=169589)[0m mae:  0.1307222545146942
[2m[36m(func pid=169589)[0m rmse_per_class: [0.11, 0.271, 0.096, 0.33, 0.095, 0.194, 0.294, 0.143, 0.144, 0.117]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.17894738912582397
[2m[36m(func pid=175366)[0m mae:  0.13133834302425385
[2m[36m(func pid=175366)[0m rmse_per_class: [0.104, 0.266, 0.088, 0.325, 0.101, 0.192, 0.305, 0.154, 0.139, 0.115]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=153479)[0m rmse: 0.14320674538612366
[2m[36m(func pid=153479)[0m mae:  0.09440489113330841
[2m[36m(func pid=153479)[0m rmse_per_class: [0.068, 0.234, 0.031, 0.265, 0.069, 0.164, 0.222, 0.117, 0.16, 0.103]
== Status ==
Current time: 2024-01-07 06:12:54 (running for 00:16:45.39)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 3 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.243 |  0.145 |                   80 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.452 |  0.18  |                   27 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  1.034 |  0.179 |                    2 |
| train_12613_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2422 | Steps: 2 | Val loss: 0.2804 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4407 | Steps: 2 | Val loss: 0.3431 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.9516 | Steps: 2 | Val loss: 0.6914 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=158006)[0m rmse: 0.14590097963809967
[2m[36m(func pid=158006)[0m mae:  0.0894978940486908
[2m[36m(func pid=158006)[0m rmse_per_class: [0.086, 0.237, 0.03, 0.271, 0.052, 0.175, 0.212, 0.11, 0.172, 0.114]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17921225726604462
[2m[36m(func pid=169589)[0m mae:  0.13040825724601746
[2m[36m(func pid=169589)[0m rmse_per_class: [0.11, 0.272, 0.096, 0.331, 0.094, 0.194, 0.292, 0.143, 0.145, 0.116]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.17920076847076416
[2m[36m(func pid=175366)[0m mae:  0.13142970204353333
[2m[36m(func pid=175366)[0m rmse_per_class: [0.104, 0.267, 0.089, 0.325, 0.101, 0.193, 0.305, 0.156, 0.139, 0.115]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2440 | Steps: 2 | Val loss: 0.2764 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4416 | Steps: 2 | Val loss: 0.3377 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8487 | Steps: 2 | Val loss: 0.6127 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 06:12:59 (running for 00:16:50.40)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.242 |  0.146 |                   81 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.441 |  0.179 |                   28 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.952 |  0.179 |                    3 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=176440)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=176440)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=176440)[0m Configuration completed!
[2m[36m(func pid=176440)[0m New optimizer parameters:
[2m[36m(func pid=176440)[0m SGD (
[2m[36m(func pid=176440)[0m Parameter Group 0
[2m[36m(func pid=176440)[0m     dampening: 0
[2m[36m(func pid=176440)[0m     differentiable: False
[2m[36m(func pid=176440)[0m     foreach: None
[2m[36m(func pid=176440)[0m     lr: 0.01
[2m[36m(func pid=176440)[0m     maximize: False
[2m[36m(func pid=176440)[0m     momentum: 0.99
[2m[36m(func pid=176440)[0m     nesterov: False
[2m[36m(func pid=176440)[0m     weight_decay: 0.0001
[2m[36m(func pid=176440)[0m )
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14413657784461975
[2m[36m(func pid=158006)[0m mae:  0.08807378262281418
[2m[36m(func pid=158006)[0m rmse_per_class: [0.08, 0.239, 0.027, 0.262, 0.055, 0.167, 0.21, 0.115, 0.174, 0.111]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17914791405200958
[2m[36m(func pid=169589)[0m mae:  0.13029281795024872
[2m[36m(func pid=169589)[0m rmse_per_class: [0.11, 0.272, 0.097, 0.331, 0.093, 0.194, 0.29, 0.142, 0.146, 0.115]
[2m[36m(func pid=169589)[0m 
== Status ==
Current time: 2024-01-07 06:13:04 (running for 00:16:55.79)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.244 |  0.144 |                   82 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.442 |  0.179 |                   29 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.849 |  0.179 |                    4 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.1794012039899826
[2m[36m(func pid=175366)[0m mae:  0.13145945966243744
[2m[36m(func pid=175366)[0m rmse_per_class: [0.104, 0.267, 0.089, 0.325, 0.1, 0.193, 0.304, 0.157, 0.139, 0.115]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2349 | Steps: 2 | Val loss: 0.2771 | Batch size: 32 | lr: 0.1 | Duration: 2.67s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4301 | Steps: 2 | Val loss: 0.3334 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0285 | Steps: 2 | Val loss: 0.6447 | Batch size: 32 | lr: 0.01 | Duration: 4.42s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7287 | Steps: 2 | Val loss: 0.5296 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=158006)[0m rmse: 0.14385618269443512
[2m[36m(func pid=158006)[0m mae:  0.08742362260818481
[2m[36m(func pid=158006)[0m rmse_per_class: [0.075, 0.237, 0.027, 0.26, 0.066, 0.164, 0.208, 0.121, 0.182, 0.099]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.1789364218711853
[2m[36m(func pid=169589)[0m mae:  0.13007470965385437
[2m[36m(func pid=169589)[0m rmse_per_class: [0.111, 0.272, 0.098, 0.332, 0.092, 0.194, 0.289, 0.141, 0.147, 0.115]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.1779939830303192
[2m[36m(func pid=176440)[0m mae:  0.1304730474948883
[2m[36m(func pid=176440)[0m rmse_per_class: [0.104, 0.267, 0.085, 0.325, 0.097, 0.192, 0.301, 0.155, 0.139, 0.114]
[2m[36m(func pid=176440)[0m 
== Status ==
Current time: 2024-01-07 06:13:09 (running for 00:17:00.97)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.235 |  0.144 |                   83 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.43  |  0.179 |                   30 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.729 |  0.179 |                    5 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  1.028 |  0.178 |                    1 |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.17944754660129547
[2m[36m(func pid=175366)[0m mae:  0.13133667409420013
[2m[36m(func pid=175366)[0m rmse_per_class: [0.105, 0.268, 0.09, 0.325, 0.1, 0.193, 0.303, 0.157, 0.139, 0.114]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2396 | Steps: 2 | Val loss: 0.2824 | Batch size: 32 | lr: 0.1 | Duration: 2.68s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4269 | Steps: 2 | Val loss: 0.3302 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.7027 | Steps: 2 | Val loss: 0.4182 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=158006)[0m rmse: 0.14451274275779724
[2m[36m(func pid=158006)[0m mae:  0.0878731906414032
[2m[36m(func pid=158006)[0m rmse_per_class: [0.069, 0.235, 0.027, 0.264, 0.074, 0.165, 0.207, 0.122, 0.187, 0.094]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.6245 | Steps: 2 | Val loss: 0.4526 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=169589)[0m rmse: 0.17882195115089417
[2m[36m(func pid=169589)[0m mae:  0.12988319993019104
[2m[36m(func pid=169589)[0m rmse_per_class: [0.111, 0.273, 0.099, 0.333, 0.091, 0.194, 0.287, 0.139, 0.148, 0.113]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.17682255804538727
[2m[36m(func pid=176440)[0m mae:  0.12922948598861694
[2m[36m(func pid=176440)[0m rmse_per_class: [0.105, 0.269, 0.087, 0.328, 0.09, 0.192, 0.293, 0.153, 0.141, 0.11]
[2m[36m(func pid=176440)[0m 
== Status ==
Current time: 2024-01-07 06:13:15 (running for 00:17:06.30)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.24  |  0.145 |                   84 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.427 |  0.179 |                   31 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.624 |  0.179 |                    6 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.703 |  0.177 |                    2 |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.17938132584095
[2m[36m(func pid=175366)[0m mae:  0.13110515475273132
[2m[36m(func pid=175366)[0m rmse_per_class: [0.105, 0.269, 0.092, 0.327, 0.099, 0.193, 0.3, 0.155, 0.14, 0.114]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2378 | Steps: 2 | Val loss: 0.2870 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4237 | Steps: 2 | Val loss: 0.3278 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.4523 | Steps: 2 | Val loss: 0.3249 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=158006)[0m rmse: 0.14520566165447235
[2m[36m(func pid=158006)[0m mae:  0.08845749497413635
[2m[36m(func pid=158006)[0m rmse_per_class: [0.07, 0.237, 0.029, 0.271, 0.072, 0.168, 0.208, 0.112, 0.193, 0.093]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.5301 | Steps: 2 | Val loss: 0.3919 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=169589)[0m rmse: 0.17863520979881287
[2m[36m(func pid=169589)[0m mae:  0.1296573430299759
[2m[36m(func pid=169589)[0m rmse_per_class: [0.112, 0.273, 0.099, 0.334, 0.089, 0.194, 0.286, 0.139, 0.148, 0.113]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.1747000515460968
[2m[36m(func pid=176440)[0m mae:  0.12701155245304108
[2m[36m(func pid=176440)[0m rmse_per_class: [0.107, 0.272, 0.092, 0.336, 0.081, 0.192, 0.28, 0.139, 0.147, 0.102]
[2m[36m(func pid=176440)[0m 
== Status ==
Current time: 2024-01-07 06:13:20 (running for 00:17:11.47)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.238 |  0.145 |                   85 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.424 |  0.179 |                   32 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.53  |  0.179 |                    7 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.452 |  0.175 |                    3 |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.1790107786655426
[2m[36m(func pid=175366)[0m mae:  0.13060377538204193
[2m[36m(func pid=175366)[0m rmse_per_class: [0.106, 0.27, 0.094, 0.329, 0.096, 0.193, 0.296, 0.152, 0.142, 0.113]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2384 | Steps: 2 | Val loss: 0.2853 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4202 | Steps: 2 | Val loss: 0.3264 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4323 | Steps: 2 | Val loss: 0.3490 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=158006)[0m rmse: 0.1455780565738678
[2m[36m(func pid=158006)[0m mae:  0.08893052488565445
[2m[36m(func pid=158006)[0m rmse_per_class: [0.077, 0.238, 0.032, 0.277, 0.062, 0.173, 0.208, 0.109, 0.186, 0.093]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4697 | Steps: 2 | Val loss: 0.3518 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=169589)[0m rmse: 0.1784738004207611
[2m[36m(func pid=169589)[0m mae:  0.12942716479301453
[2m[36m(func pid=169589)[0m rmse_per_class: [0.112, 0.273, 0.1, 0.335, 0.088, 0.194, 0.284, 0.138, 0.149, 0.112]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.17455509305000305
[2m[36m(func pid=176440)[0m mae:  0.12483008950948715
[2m[36m(func pid=176440)[0m rmse_per_class: [0.109, 0.275, 0.091, 0.349, 0.069, 0.192, 0.279, 0.132, 0.153, 0.096]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.1785622239112854
[2m[36m(func pid=175366)[0m mae:  0.1300416886806488
[2m[36m(func pid=175366)[0m rmse_per_class: [0.107, 0.271, 0.096, 0.332, 0.094, 0.193, 0.291, 0.147, 0.144, 0.111]
[2m[36m(func pid=175366)[0m 
== Status ==
Current time: 2024-01-07 06:13:25 (running for 00:17:16.90)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.238 |  0.146 |                   86 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.42  |  0.178 |                   33 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.47  |  0.179 |                    8 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.432 |  0.175 |                    4 |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2374 | Steps: 2 | Val loss: 0.2775 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4166 | Steps: 2 | Val loss: 0.3259 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.5118 | Steps: 2 | Val loss: 0.4140 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=158006)[0m rmse: 0.14362090826034546
[2m[36m(func pid=158006)[0m mae:  0.08747876435518265
[2m[36m(func pid=158006)[0m rmse_per_class: [0.083, 0.234, 0.035, 0.275, 0.056, 0.168, 0.206, 0.11, 0.171, 0.097]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.4379 | Steps: 2 | Val loss: 0.3311 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=169589)[0m rmse: 0.17833846807479858
[2m[36m(func pid=169589)[0m mae:  0.12922954559326172
[2m[36m(func pid=169589)[0m rmse_per_class: [0.112, 0.273, 0.1, 0.336, 0.087, 0.194, 0.283, 0.137, 0.149, 0.111]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.17779149115085602
[2m[36m(func pid=176440)[0m mae:  0.12340869754552841
[2m[36m(func pid=176440)[0m rmse_per_class: [0.108, 0.278, 0.081, 0.36, 0.06, 0.191, 0.313, 0.137, 0.156, 0.093]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.1780063956975937
[2m[36m(func pid=175366)[0m mae:  0.12937283515930176
[2m[36m(func pid=175366)[0m rmse_per_class: [0.108, 0.272, 0.099, 0.335, 0.09, 0.193, 0.285, 0.141, 0.147, 0.108]
== Status ==
Current time: 2024-01-07 06:13:31 (running for 00:17:22.18)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.237 |  0.144 |                   87 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.417 |  0.178 |                   34 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.438 |  0.178 |                    9 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.512 |  0.178 |                    5 |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2405 | Steps: 2 | Val loss: 0.2756 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4164 | Steps: 2 | Val loss: 0.3260 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.6073 | Steps: 2 | Val loss: 0.4854 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=158006)[0m rmse: 0.14429225027561188
[2m[36m(func pid=158006)[0m mae:  0.08748232573270798
[2m[36m(func pid=158006)[0m rmse_per_class: [0.089, 0.235, 0.034, 0.26, 0.055, 0.163, 0.209, 0.115, 0.172, 0.11]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4167 | Steps: 2 | Val loss: 0.3258 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=169589)[0m rmse: 0.17815259099006653
[2m[36m(func pid=169589)[0m mae:  0.12899869680404663
[2m[36m(func pid=169589)[0m rmse_per_class: [0.113, 0.273, 0.1, 0.337, 0.086, 0.194, 0.281, 0.137, 0.151, 0.11]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.18388542532920837
[2m[36m(func pid=176440)[0m mae:  0.12330897152423859
[2m[36m(func pid=176440)[0m rmse_per_class: [0.105, 0.282, 0.067, 0.37, 0.056, 0.19, 0.38, 0.144, 0.153, 0.092]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2363 | Steps: 2 | Val loss: 0.2840 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
== Status ==
Current time: 2024-01-07 06:13:36 (running for 00:17:27.52)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.144 |                   88 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.416 |  0.178 |                   35 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.417 |  0.178 |                   10 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.607 |  0.184 |                    6 |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.17753055691719055
[2m[36m(func pid=175366)[0m mae:  0.1286323368549347
[2m[36m(func pid=175366)[0m rmse_per_class: [0.11, 0.273, 0.1, 0.339, 0.086, 0.193, 0.28, 0.138, 0.15, 0.106]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4205 | Steps: 2 | Val loss: 0.3267 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.7004 | Steps: 2 | Val loss: 0.5467 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=158006)[0m rmse: 0.14852330088615417
[2m[36m(func pid=158006)[0m mae:  0.08968429267406464
[2m[36m(func pid=158006)[0m rmse_per_class: [0.075, 0.245, 0.032, 0.257, 0.058, 0.162, 0.211, 0.125, 0.19, 0.129]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4224 | Steps: 2 | Val loss: 0.3317 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=169589)[0m rmse: 0.17804408073425293
[2m[36m(func pid=169589)[0m mae:  0.1288221776485443
[2m[36m(func pid=169589)[0m rmse_per_class: [0.113, 0.273, 0.1, 0.337, 0.086, 0.194, 0.28, 0.136, 0.151, 0.109]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.19154486060142517
[2m[36m(func pid=176440)[0m mae:  0.12521985173225403
[2m[36m(func pid=176440)[0m rmse_per_class: [0.101, 0.286, 0.055, 0.377, 0.055, 0.19, 0.458, 0.15, 0.149, 0.093]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2296 | Steps: 2 | Val loss: 0.2903 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 06:13:41 (running for 00:17:32.81)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.236 |  0.149 |                   89 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.421 |  0.178 |                   36 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.422 |  0.177 |                   11 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.7   |  0.192 |                    7 |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.17717616260051727
[2m[36m(func pid=175366)[0m mae:  0.12788277864456177
[2m[36m(func pid=175366)[0m rmse_per_class: [0.111, 0.274, 0.099, 0.343, 0.082, 0.194, 0.276, 0.135, 0.154, 0.103]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4186 | Steps: 2 | Val loss: 0.3278 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.7653 | Steps: 2 | Val loss: 0.5922 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=158006)[0m rmse: 0.14963959157466888
[2m[36m(func pid=158006)[0m mae:  0.09034551680088043
[2m[36m(func pid=158006)[0m rmse_per_class: [0.069, 0.247, 0.031, 0.263, 0.062, 0.164, 0.211, 0.126, 0.205, 0.12]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4281 | Steps: 2 | Val loss: 0.3453 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=169589)[0m rmse: 0.17785444855690002
[2m[36m(func pid=169589)[0m mae:  0.12860073149204254
[2m[36m(func pid=169589)[0m rmse_per_class: [0.113, 0.273, 0.1, 0.338, 0.084, 0.194, 0.279, 0.136, 0.152, 0.108]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.19921229779720306
[2m[36m(func pid=176440)[0m mae:  0.12824635207653046
[2m[36m(func pid=176440)[0m rmse_per_class: [0.099, 0.289, 0.049, 0.382, 0.056, 0.192, 0.533, 0.153, 0.145, 0.095]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2437 | Steps: 2 | Val loss: 0.2876 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 06:13:46 (running for 00:17:37.98)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.23  |  0.15  |                   90 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.419 |  0.178 |                   37 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.428 |  0.177 |                   12 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.765 |  0.199 |                    8 |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.1770198494195938
[2m[36m(func pid=175366)[0m mae:  0.12713013589382172
[2m[36m(func pid=175366)[0m rmse_per_class: [0.112, 0.274, 0.098, 0.347, 0.077, 0.194, 0.275, 0.134, 0.158, 0.101]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4239 | Steps: 2 | Val loss: 0.3294 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.8163 | Steps: 2 | Val loss: 0.6235 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=158006)[0m rmse: 0.14651988446712494
[2m[36m(func pid=158006)[0m mae:  0.08884476125240326
[2m[36m(func pid=158006)[0m rmse_per_class: [0.069, 0.239, 0.03, 0.269, 0.064, 0.166, 0.208, 0.116, 0.201, 0.103]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4505 | Steps: 2 | Val loss: 0.3627 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=169589)[0m rmse: 0.17779257893562317
[2m[36m(func pid=169589)[0m mae:  0.12845225632190704
[2m[36m(func pid=169589)[0m rmse_per_class: [0.113, 0.274, 0.101, 0.339, 0.084, 0.194, 0.278, 0.136, 0.152, 0.107]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.20650048553943634
[2m[36m(func pid=176440)[0m mae:  0.13200315833091736
[2m[36m(func pid=176440)[0m rmse_per_class: [0.099, 0.293, 0.048, 0.385, 0.056, 0.197, 0.596, 0.154, 0.141, 0.096]
[2m[36m(func pid=176440)[0m 
== Status ==
Current time: 2024-01-07 06:13:52 (running for 00:17:43.09)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.244 |  0.147 |                   91 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.424 |  0.178 |                   38 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.45  |  0.177 |                   13 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.816 |  0.207 |                    9 |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2441 | Steps: 2 | Val loss: 0.2763 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=175366)[0m rmse: 0.1772189438343048
[2m[36m(func pid=175366)[0m mae:  0.1264965832233429
[2m[36m(func pid=175366)[0m rmse_per_class: [0.112, 0.275, 0.097, 0.352, 0.073, 0.194, 0.276, 0.135, 0.161, 0.099]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4237 | Steps: 2 | Val loss: 0.3309 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.8344 | Steps: 2 | Val loss: 0.6343 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=158006)[0m rmse: 0.1422761082649231
[2m[36m(func pid=158006)[0m mae:  0.08644815534353256
[2m[36m(func pid=158006)[0m rmse_per_class: [0.073, 0.235, 0.03, 0.263, 0.064, 0.171, 0.206, 0.11, 0.18, 0.091]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4748 | Steps: 2 | Val loss: 0.3819 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=169589)[0m rmse: 0.1774417757987976
[2m[36m(func pid=169589)[0m mae:  0.12808629870414734
[2m[36m(func pid=169589)[0m rmse_per_class: [0.113, 0.274, 0.1, 0.339, 0.082, 0.194, 0.277, 0.135, 0.153, 0.107]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.21189796924591064
[2m[36m(func pid=176440)[0m mae:  0.13526201248168945
[2m[36m(func pid=176440)[0m rmse_per_class: [0.1, 0.295, 0.048, 0.387, 0.056, 0.201, 0.643, 0.155, 0.137, 0.096]
[2m[36m(func pid=176440)[0m 
== Status ==
Current time: 2024-01-07 06:13:57 (running for 00:17:48.38)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.244 |  0.142 |                   92 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.424 |  0.177 |                   39 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.475 |  0.177 |                   14 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.834 |  0.212 |                   10 |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2351 | Steps: 2 | Val loss: 0.2712 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=175366)[0m rmse: 0.17735061049461365
[2m[36m(func pid=175366)[0m mae:  0.12575721740722656
[2m[36m(func pid=175366)[0m rmse_per_class: [0.112, 0.275, 0.093, 0.355, 0.069, 0.194, 0.28, 0.136, 0.163, 0.097]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.8483 | Steps: 2 | Val loss: 0.6312 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4209 | Steps: 2 | Val loss: 0.3330 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=158006)[0m rmse: 0.14066489040851593
[2m[36m(func pid=158006)[0m mae:  0.08562590181827545
[2m[36m(func pid=158006)[0m rmse_per_class: [0.086, 0.232, 0.031, 0.255, 0.062, 0.165, 0.207, 0.11, 0.169, 0.091]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4915 | Steps: 2 | Val loss: 0.4022 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=176440)[0m rmse: 0.21578529477119446
[2m[36m(func pid=176440)[0m mae:  0.13790734112262726
[2m[36m(func pid=176440)[0m rmse_per_class: [0.101, 0.297, 0.048, 0.388, 0.056, 0.205, 0.674, 0.156, 0.136, 0.097]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17730887234210968
[2m[36m(func pid=169589)[0m mae:  0.12788483500480652
[2m[36m(func pid=169589)[0m rmse_per_class: [0.113, 0.274, 0.1, 0.34, 0.081, 0.194, 0.276, 0.135, 0.153, 0.106]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2361 | Steps: 2 | Val loss: 0.2786 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 06:14:02 (running for 00:17:53.63)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.235 |  0.141 |                   93 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.421 |  0.177 |                   40 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.491 |  0.178 |                   15 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.848 |  0.216 |                   11 |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.17793533205986023
[2m[36m(func pid=175366)[0m mae:  0.12518103420734406
[2m[36m(func pid=175366)[0m rmse_per_class: [0.112, 0.276, 0.089, 0.358, 0.065, 0.193, 0.288, 0.138, 0.166, 0.095]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.8428 | Steps: 2 | Val loss: 0.6139 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4244 | Steps: 2 | Val loss: 0.3356 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=158006)[0m rmse: 0.1441843956708908
[2m[36m(func pid=158006)[0m mae:  0.0879306048154831
[2m[36m(func pid=158006)[0m rmse_per_class: [0.092, 0.235, 0.031, 0.26, 0.06, 0.163, 0.212, 0.112, 0.173, 0.104]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.5156 | Steps: 2 | Val loss: 0.4229 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=176440)[0m rmse: 0.21744844317436218
[2m[36m(func pid=176440)[0m mae:  0.1391267478466034
[2m[36m(func pid=176440)[0m rmse_per_class: [0.102, 0.297, 0.049, 0.388, 0.056, 0.206, 0.687, 0.156, 0.136, 0.097]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.177188903093338
[2m[36m(func pid=169589)[0m mae:  0.12768778204917908
[2m[36m(func pid=169589)[0m rmse_per_class: [0.114, 0.274, 0.099, 0.341, 0.08, 0.194, 0.276, 0.135, 0.154, 0.105]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2480 | Steps: 2 | Val loss: 0.2836 | Batch size: 32 | lr: 0.1 | Duration: 2.70s
== Status ==
Current time: 2024-01-07 06:14:07 (running for 00:17:58.92)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.236 |  0.144 |                   94 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.424 |  0.177 |                   41 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.516 |  0.179 |                   16 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.843 |  0.217 |                   12 |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.17879381775856018
[2m[36m(func pid=175366)[0m mae:  0.12475192546844482
[2m[36m(func pid=175366)[0m rmse_per_class: [0.112, 0.277, 0.084, 0.361, 0.062, 0.193, 0.297, 0.14, 0.168, 0.094]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.8016 | Steps: 2 | Val loss: 0.5859 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=158006)[0m rmse: 0.1460333913564682
[2m[36m(func pid=158006)[0m mae:  0.08895006775856018
[2m[36m(func pid=158006)[0m rmse_per_class: [0.084, 0.239, 0.031, 0.271, 0.059, 0.163, 0.207, 0.116, 0.179, 0.112]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4296 | Steps: 2 | Val loss: 0.3381 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.5475 | Steps: 2 | Val loss: 0.4445 | Batch size: 32 | lr: 0.001 | Duration: 2.70s
[2m[36m(func pid=176440)[0m rmse: 0.216238334774971
[2m[36m(func pid=176440)[0m mae:  0.13828013837337494
[2m[36m(func pid=176440)[0m rmse_per_class: [0.102, 0.297, 0.049, 0.388, 0.056, 0.202, 0.677, 0.156, 0.138, 0.097]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.1770956814289093
[2m[36m(func pid=169589)[0m mae:  0.12751170992851257
[2m[36m(func pid=169589)[0m rmse_per_class: [0.114, 0.274, 0.099, 0.342, 0.079, 0.194, 0.275, 0.135, 0.154, 0.105]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2354 | Steps: 2 | Val loss: 0.2894 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 06:14:12 (running for 00:18:03.97)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.248 |  0.146 |                   95 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.43  |  0.177 |                   42 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.548 |  0.18  |                   17 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.802 |  0.216 |                   13 |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.17997457087039948
[2m[36m(func pid=175366)[0m mae:  0.12447263300418854
[2m[36m(func pid=175366)[0m rmse_per_class: [0.111, 0.277, 0.08, 0.364, 0.06, 0.193, 0.309, 0.142, 0.171, 0.093]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.1493251919746399
[2m[36m(func pid=158006)[0m mae:  0.09132398664951324
[2m[36m(func pid=158006)[0m rmse_per_class: [0.072, 0.243, 0.032, 0.288, 0.06, 0.166, 0.216, 0.125, 0.185, 0.107]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7576 | Steps: 2 | Val loss: 0.5513 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4300 | Steps: 2 | Val loss: 0.3407 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.5714 | Steps: 2 | Val loss: 0.4635 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=169589)[0m rmse: 0.17691586911678314
[2m[36m(func pid=169589)[0m mae:  0.12725424766540527
[2m[36m(func pid=169589)[0m rmse_per_class: [0.114, 0.274, 0.098, 0.342, 0.078, 0.194, 0.275, 0.135, 0.154, 0.104]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.2113150656223297
[2m[36m(func pid=176440)[0m mae:  0.13476617634296417
[2m[36m(func pid=176440)[0m rmse_per_class: [0.098, 0.294, 0.049, 0.388, 0.056, 0.193, 0.633, 0.156, 0.148, 0.097]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2346 | Steps: 2 | Val loss: 0.2952 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=175366)[0m rmse: 0.18107068538665771
[2m[36m(func pid=175366)[0m mae:  0.12415609508752823
[2m[36m(func pid=175366)[0m rmse_per_class: [0.111, 0.278, 0.075, 0.366, 0.058, 0.193, 0.323, 0.143, 0.171, 0.092]
[2m[36m(func pid=175366)[0m 
== Status ==
Current time: 2024-01-07 06:14:18 (running for 00:18:09.27)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.235 |  0.149 |                   96 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.43  |  0.177 |                   43 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.571 |  0.181 |                   18 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.758 |  0.211 |                   14 |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=158006)[0m rmse: 0.15150423347949982
[2m[36m(func pid=158006)[0m mae:  0.0925944522023201
[2m[36m(func pid=158006)[0m rmse_per_class: [0.078, 0.245, 0.031, 0.284, 0.063, 0.168, 0.212, 0.128, 0.195, 0.11]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.7294 | Steps: 2 | Val loss: 0.5049 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4370 | Steps: 2 | Val loss: 0.3436 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.5913 | Steps: 2 | Val loss: 0.4824 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=176440)[0m rmse: 0.20087847113609314
[2m[36m(func pid=176440)[0m mae:  0.12756890058517456
[2m[36m(func pid=176440)[0m rmse_per_class: [0.09, 0.288, 0.049, 0.387, 0.056, 0.178, 0.523, 0.156, 0.185, 0.097]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2362 | Steps: 2 | Val loss: 0.2958 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=169589)[0m rmse: 0.17678916454315186
[2m[36m(func pid=169589)[0m mae:  0.1270027756690979
[2m[36m(func pid=169589)[0m rmse_per_class: [0.115, 0.274, 0.098, 0.343, 0.077, 0.194, 0.274, 0.135, 0.155, 0.103]
[2m[36m(func pid=169589)[0m 
== Status ==
Current time: 2024-01-07 06:14:23 (running for 00:18:14.55)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.235 |  0.152 |                   97 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.437 |  0.177 |                   44 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.591 |  0.182 |                   19 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.729 |  0.201 |                   15 |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.18238240480422974
[2m[36m(func pid=175366)[0m mae:  0.1240159273147583
[2m[36m(func pid=175366)[0m rmse_per_class: [0.11, 0.279, 0.07, 0.368, 0.057, 0.193, 0.338, 0.145, 0.172, 0.092]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.15062233805656433
[2m[36m(func pid=158006)[0m mae:  0.0919937789440155
[2m[36m(func pid=158006)[0m rmse_per_class: [0.088, 0.243, 0.03, 0.277, 0.064, 0.165, 0.213, 0.12, 0.199, 0.107]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.6462 | Steps: 2 | Val loss: 0.4558 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4379 | Steps: 2 | Val loss: 0.3464 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.6128 | Steps: 2 | Val loss: 0.4963 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2416 | Steps: 2 | Val loss: 0.2895 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=176440)[0m rmse: 0.18642981350421906
[2m[36m(func pid=176440)[0m mae:  0.11961551010608673
[2m[36m(func pid=176440)[0m rmse_per_class: [0.081, 0.271, 0.049, 0.385, 0.056, 0.184, 0.341, 0.156, 0.244, 0.097]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17667065560817719
[2m[36m(func pid=169589)[0m mae:  0.12682795524597168
[2m[36m(func pid=169589)[0m rmse_per_class: [0.114, 0.274, 0.098, 0.344, 0.076, 0.194, 0.274, 0.135, 0.156, 0.103]
[2m[36m(func pid=169589)[0m 
== Status ==
Current time: 2024-01-07 06:14:28 (running for 00:18:19.88)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.236 |  0.151 |                   98 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.438 |  0.177 |                   45 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.613 |  0.184 |                   20 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.646 |  0.186 |                   16 |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.1837351769208908
[2m[36m(func pid=175366)[0m mae:  0.12390516698360443
[2m[36m(func pid=175366)[0m rmse_per_class: [0.108, 0.279, 0.066, 0.37, 0.056, 0.192, 0.355, 0.147, 0.171, 0.092]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14716574549674988
[2m[36m(func pid=158006)[0m mae:  0.0898757129907608
[2m[36m(func pid=158006)[0m rmse_per_class: [0.089, 0.242, 0.03, 0.275, 0.063, 0.164, 0.205, 0.11, 0.192, 0.103]
[2m[36m(func pid=158006)[0m 
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.6074 | Steps: 2 | Val loss: 0.4215 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4433 | Steps: 2 | Val loss: 0.3497 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.6335 | Steps: 2 | Val loss: 0.5091 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=158006)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2411 | Steps: 2 | Val loss: 0.2771 | Batch size: 32 | lr: 0.1 | Duration: 2.68s
[2m[36m(func pid=176440)[0m rmse: 0.179547980427742
[2m[36m(func pid=176440)[0m mae:  0.1194620132446289
[2m[36m(func pid=176440)[0m rmse_per_class: [0.086, 0.251, 0.049, 0.38, 0.056, 0.228, 0.214, 0.156, 0.278, 0.097]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.1765502393245697
[2m[36m(func pid=169589)[0m mae:  0.12655934691429138
[2m[36m(func pid=169589)[0m rmse_per_class: [0.114, 0.274, 0.097, 0.344, 0.075, 0.194, 0.274, 0.135, 0.156, 0.102]
[2m[36m(func pid=169589)[0m 
== Status ==
Current time: 2024-01-07 06:14:33 (running for 00:18:25.01)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00007 | RUNNING    | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.242 |  0.147 |                   99 |
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.443 |  0.177 |                   46 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.633 |  0.185 |                   21 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.607 |  0.18  |                   17 |
| train_12613_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.18506215512752533
[2m[36m(func pid=175366)[0m mae:  0.12380187213420868
[2m[36m(func pid=175366)[0m rmse_per_class: [0.107, 0.28, 0.061, 0.372, 0.056, 0.192, 0.374, 0.148, 0.169, 0.092]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=158006)[0m rmse: 0.14296181499958038
[2m[36m(func pid=158006)[0m mae:  0.086726613342762
[2m[36m(func pid=158006)[0m rmse_per_class: [0.08, 0.237, 0.031, 0.268, 0.057, 0.163, 0.206, 0.11, 0.177, 0.101]
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.5504 | Steps: 2 | Val loss: 0.4162 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4464 | Steps: 2 | Val loss: 0.3532 | Batch size: 32 | lr: 0.0001 | Duration: 3.12s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.6427 | Steps: 2 | Val loss: 0.5218 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=176440)[0m rmse: 0.1831328570842743
[2m[36m(func pid=176440)[0m mae:  0.12457703053951263
[2m[36m(func pid=176440)[0m rmse_per_class: [0.105, 0.248, 0.049, 0.37, 0.056, 0.249, 0.249, 0.156, 0.253, 0.097]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.1864924132823944
[2m[36m(func pid=175366)[0m mae:  0.12384621053934097
[2m[36m(func pid=175366)[0m rmse_per_class: [0.106, 0.28, 0.058, 0.374, 0.056, 0.192, 0.392, 0.149, 0.167, 0.092]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17650750279426575
[2m[36m(func pid=169589)[0m mae:  0.126414954662323
[2m[36m(func pid=169589)[0m rmse_per_class: [0.114, 0.275, 0.096, 0.345, 0.074, 0.194, 0.274, 0.135, 0.157, 0.101]
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.5931 | Steps: 2 | Val loss: 0.4255 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.6570 | Steps: 2 | Val loss: 0.5337 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 06:14:39 (running for 00:18:30.05)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.443 |  0.177 |                   46 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.643 |  0.186 |                   22 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.55  |  0.183 |                   18 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=180788)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=180788)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=180788)[0m Configuration completed!
[2m[36m(func pid=180788)[0m New optimizer parameters:
[2m[36m(func pid=180788)[0m SGD (
[2m[36m(func pid=180788)[0m Parameter Group 0
[2m[36m(func pid=180788)[0m     dampening: 0
[2m[36m(func pid=180788)[0m     differentiable: False
[2m[36m(func pid=180788)[0m     foreach: None
[2m[36m(func pid=180788)[0m     lr: 0.1
[2m[36m(func pid=180788)[0m     maximize: False
[2m[36m(func pid=180788)[0m     momentum: 0.99
[2m[36m(func pid=180788)[0m     nesterov: False
[2m[36m(func pid=180788)[0m     weight_decay: 0.0001
[2m[36m(func pid=180788)[0m )
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.18190747499465942
[2m[36m(func pid=176440)[0m mae:  0.1254720389842987
[2m[36m(func pid=176440)[0m rmse_per_class: [0.122, 0.266, 0.049, 0.341, 0.056, 0.233, 0.292, 0.156, 0.208, 0.096]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.18815255165100098
[2m[36m(func pid=175366)[0m mae:  0.12414121627807617
[2m[36m(func pid=175366)[0m rmse_per_class: [0.104, 0.281, 0.055, 0.375, 0.055, 0.192, 0.41, 0.15, 0.166, 0.093]
== Status ==
Current time: 2024-01-07 06:14:44 (running for 00:18:35.22)
Memory usage on this node: 23.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.446 |  0.177 |                   47 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.657 |  0.188 |                   23 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.593 |  0.182 |                   19 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4477 | Steps: 2 | Val loss: 0.3559 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.5797 | Steps: 2 | Val loss: 0.4206 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.6751 | Steps: 2 | Val loss: 0.5425 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.7698 | Steps: 2 | Val loss: 0.3286 | Batch size: 32 | lr: 0.1 | Duration: 4.24s
[2m[36m(func pid=169589)[0m rmse: 0.17638757824897766
[2m[36m(func pid=169589)[0m mae:  0.1261826902627945
[2m[36m(func pid=169589)[0m rmse_per_class: [0.114, 0.275, 0.095, 0.346, 0.073, 0.194, 0.274, 0.135, 0.157, 0.101]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.17405839264392853
[2m[36m(func pid=176440)[0m mae:  0.12011770159006119
[2m[36m(func pid=176440)[0m rmse_per_class: [0.129, 0.275, 0.049, 0.294, 0.056, 0.203, 0.313, 0.155, 0.172, 0.095]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.18988774716854095
[2m[36m(func pid=175366)[0m mae:  0.12458038330078125
[2m[36m(func pid=175366)[0m rmse_per_class: [0.103, 0.282, 0.053, 0.377, 0.055, 0.192, 0.43, 0.151, 0.164, 0.093]
== Status ==
Current time: 2024-01-07 06:14:49 (running for 00:18:40.41)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.448 |  0.176 |                   48 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.675 |  0.19  |                   24 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.58  |  0.174 |                   20 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.17263756692409515
[2m[36m(func pid=180788)[0m mae:  0.1241646409034729
[2m[36m(func pid=180788)[0m rmse_per_class: [0.106, 0.275, 0.086, 0.342, 0.071, 0.191, 0.277, 0.131, 0.149, 0.097]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4530 | Steps: 2 | Val loss: 0.3591 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.5776 | Steps: 2 | Val loss: 0.3952 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.6787 | Steps: 2 | Val loss: 0.5495 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.5856 | Steps: 2 | Val loss: 0.4918 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=169589)[0m rmse: 0.17629145085811615
[2m[36m(func pid=169589)[0m mae:  0.12598155438899994
[2m[36m(func pid=169589)[0m rmse_per_class: [0.114, 0.275, 0.094, 0.346, 0.072, 0.194, 0.274, 0.135, 0.158, 0.101]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.16558745503425598
[2m[36m(func pid=176440)[0m mae:  0.11331121623516083
[2m[36m(func pid=176440)[0m rmse_per_class: [0.12, 0.261, 0.049, 0.277, 0.056, 0.176, 0.321, 0.154, 0.151, 0.09]
[2m[36m(func pid=176440)[0m 
== Status ==
Current time: 2024-01-07 06:14:54 (running for 00:18:45.47)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.453 |  0.176 |                   49 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.679 |  0.192 |                   25 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.578 |  0.166 |                   21 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.77  |  0.173 |                    1 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.19150540232658386
[2m[36m(func pid=175366)[0m mae:  0.1250261813402176
[2m[36m(func pid=175366)[0m rmse_per_class: [0.102, 0.282, 0.051, 0.378, 0.056, 0.191, 0.448, 0.152, 0.162, 0.093]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.18896842002868652
[2m[36m(func pid=180788)[0m mae:  0.12379107624292374
[2m[36m(func pid=180788)[0m rmse_per_class: [0.1, 0.289, 0.053, 0.371, 0.056, 0.187, 0.453, 0.145, 0.143, 0.095]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.5333 | Steps: 2 | Val loss: 0.3707 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4636 | Steps: 2 | Val loss: 0.3629 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.6886 | Steps: 2 | Val loss: 0.5528 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.8673 | Steps: 2 | Val loss: 0.6015 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=176440)[0m rmse: 0.1633942574262619
[2m[36m(func pid=176440)[0m mae:  0.1091655045747757
[2m[36m(func pid=176440)[0m rmse_per_class: [0.099, 0.24, 0.048, 0.328, 0.056, 0.165, 0.322, 0.149, 0.14, 0.086]
[2m[36m(func pid=176440)[0m 
== Status ==
Current time: 2024-01-07 06:14:59 (running for 00:18:50.52)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.464 |  0.176 |                   50 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.679 |  0.192 |                   25 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.533 |  0.163 |                   22 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.586 |  0.189 |                    2 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=169589)[0m rmse: 0.17627759277820587
[2m[36m(func pid=169589)[0m mae:  0.12572816014289856
[2m[36m(func pid=169589)[0m rmse_per_class: [0.115, 0.275, 0.093, 0.346, 0.071, 0.194, 0.274, 0.136, 0.159, 0.099]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.19282057881355286
[2m[36m(func pid=175366)[0m mae:  0.12539301812648773
[2m[36m(func pid=175366)[0m rmse_per_class: [0.101, 0.283, 0.05, 0.379, 0.056, 0.191, 0.464, 0.152, 0.159, 0.094]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.21014352142810822
[2m[36m(func pid=180788)[0m mae:  0.13323983550071716
[2m[36m(func pid=180788)[0m rmse_per_class: [0.098, 0.297, 0.049, 0.386, 0.056, 0.19, 0.642, 0.154, 0.133, 0.097]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4464 | Steps: 2 | Val loss: 0.3553 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4628 | Steps: 2 | Val loss: 0.3658 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.7114 | Steps: 2 | Val loss: 0.5556 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.9876 | Steps: 2 | Val loss: 0.5990 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 06:15:04 (running for 00:18:55.65)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.464 |  0.176 |                   50 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.689 |  0.193 |                   26 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.446 |  0.17  |                   23 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.867 |  0.21  |                    3 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=176440)[0m rmse: 0.17002932727336884
[2m[36m(func pid=176440)[0m mae:  0.1105579361319542
[2m[36m(func pid=176440)[0m rmse_per_class: [0.073, 0.24, 0.046, 0.383, 0.056, 0.172, 0.319, 0.136, 0.134, 0.14]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.19409668445587158
[2m[36m(func pid=175366)[0m mae:  0.1258089691400528
[2m[36m(func pid=175366)[0m rmse_per_class: [0.101, 0.283, 0.049, 0.38, 0.056, 0.191, 0.477, 0.153, 0.158, 0.094]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17620208859443665
[2m[36m(func pid=169589)[0m mae:  0.12555481493473053
[2m[36m(func pid=169589)[0m rmse_per_class: [0.115, 0.275, 0.092, 0.347, 0.071, 0.194, 0.275, 0.136, 0.16, 0.099]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.21712520718574524
[2m[36m(func pid=180788)[0m mae:  0.1380670964717865
[2m[36m(func pid=180788)[0m rmse_per_class: [0.098, 0.3, 0.049, 0.388, 0.056, 0.195, 0.698, 0.156, 0.133, 0.097]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.7052 | Steps: 2 | Val loss: 0.5572 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4423 | Steps: 2 | Val loss: 0.3594 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4617 | Steps: 2 | Val loss: 0.3684 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.9001 | Steps: 2 | Val loss: 0.5073 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
== Status ==
Current time: 2024-01-07 06:15:09 (running for 00:19:00.82)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.463 |  0.176 |                   51 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.705 |  0.195 |                   28 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.446 |  0.17  |                   23 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.988 |  0.217 |                    4 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.19539791345596313
[2m[36m(func pid=175366)[0m mae:  0.12624861299991608
[2m[36m(func pid=175366)[0m rmse_per_class: [0.1, 0.283, 0.048, 0.38, 0.056, 0.191, 0.491, 0.153, 0.156, 0.094]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.1815897524356842
[2m[36m(func pid=176440)[0m mae:  0.1174643263220787
[2m[36m(func pid=176440)[0m rmse_per_class: [0.065, 0.267, 0.04, 0.36, 0.056, 0.19, 0.314, 0.115, 0.131, 0.279]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17605003714561462
[2m[36m(func pid=169589)[0m mae:  0.125271275639534
[2m[36m(func pid=169589)[0m rmse_per_class: [0.115, 0.275, 0.09, 0.348, 0.069, 0.194, 0.275, 0.136, 0.16, 0.099]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.18896232545375824
[2m[36m(func pid=180788)[0m mae:  0.12113885581493378
[2m[36m(func pid=180788)[0m rmse_per_class: [0.088, 0.295, 0.049, 0.387, 0.056, 0.21, 0.389, 0.156, 0.162, 0.097]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.7069 | Steps: 2 | Val loss: 0.5560 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4204 | Steps: 2 | Val loss: 0.3757 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4689 | Steps: 2 | Val loss: 0.3711 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.7506 | Steps: 2 | Val loss: 0.4798 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 06:15:15 (running for 00:19:06.06)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.462 |  0.176 |                   52 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.707 |  0.197 |                   29 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.442 |  0.182 |                   24 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.9   |  0.189 |                    5 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.19654789566993713
[2m[36m(func pid=175366)[0m mae:  0.12664003670215607
[2m[36m(func pid=175366)[0m rmse_per_class: [0.099, 0.284, 0.048, 0.381, 0.056, 0.192, 0.504, 0.153, 0.154, 0.095]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.1898222267627716
[2m[36m(func pid=176440)[0m mae:  0.12385709583759308
[2m[36m(func pid=176440)[0m rmse_per_class: [0.075, 0.285, 0.03, 0.281, 0.056, 0.204, 0.304, 0.128, 0.13, 0.404]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.1760377585887909
[2m[36m(func pid=169589)[0m mae:  0.12515544891357422
[2m[36m(func pid=169589)[0m rmse_per_class: [0.115, 0.275, 0.089, 0.348, 0.069, 0.194, 0.276, 0.136, 0.161, 0.098]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.19602543115615845
[2m[36m(func pid=180788)[0m mae:  0.13387231528759003
[2m[36m(func pid=180788)[0m rmse_per_class: [0.154, 0.247, 0.049, 0.355, 0.056, 0.305, 0.296, 0.156, 0.244, 0.097]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.7043 | Steps: 2 | Val loss: 0.5527 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4240 | Steps: 2 | Val loss: 0.4050 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4711 | Steps: 2 | Val loss: 0.3741 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.7422 | Steps: 2 | Val loss: 0.4387 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 06:15:20 (running for 00:19:11.20)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.469 |  0.176 |                   53 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.704 |  0.198 |                   30 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.42  |  0.19  |                   25 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.751 |  0.196 |                    6 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.19751477241516113
[2m[36m(func pid=175366)[0m mae:  0.12699005007743835
[2m[36m(func pid=175366)[0m rmse_per_class: [0.099, 0.284, 0.048, 0.381, 0.056, 0.191, 0.515, 0.154, 0.152, 0.095]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17602810263633728
[2m[36m(func pid=169589)[0m mae:  0.12503275275230408
[2m[36m(func pid=169589)[0m rmse_per_class: [0.115, 0.275, 0.089, 0.349, 0.068, 0.194, 0.276, 0.136, 0.161, 0.098]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.2021108865737915
[2m[36m(func pid=176440)[0m mae:  0.13173267245292664
[2m[36m(func pid=176440)[0m rmse_per_class: [0.085, 0.293, 0.025, 0.25, 0.056, 0.214, 0.289, 0.229, 0.131, 0.449]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.16626115143299103
[2m[36m(func pid=180788)[0m mae:  0.11180935055017471
[2m[36m(func pid=180788)[0m rmse_per_class: [0.071, 0.265, 0.049, 0.327, 0.056, 0.165, 0.325, 0.154, 0.153, 0.096]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.7079 | Steps: 2 | Val loss: 0.5501 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4640 | Steps: 2 | Val loss: 0.4411 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5710 | Steps: 2 | Val loss: 0.3480 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4750 | Steps: 2 | Val loss: 0.3773 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 06:15:25 (running for 00:19:16.34)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.471 |  0.176 |                   54 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.708 |  0.198 |                   31 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.424 |  0.202 |                   26 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.742 |  0.166 |                    7 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.1984187513589859
[2m[36m(func pid=175366)[0m mae:  0.12735576927661896
[2m[36m(func pid=175366)[0m rmse_per_class: [0.098, 0.284, 0.048, 0.382, 0.056, 0.191, 0.524, 0.154, 0.152, 0.095]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.17818039655685425
[2m[36m(func pid=180788)[0m mae:  0.11032401025295258
[2m[36m(func pid=180788)[0m rmse_per_class: [0.081, 0.263, 0.046, 0.455, 0.056, 0.197, 0.268, 0.112, 0.143, 0.159]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17594169080257416
[2m[36m(func pid=169589)[0m mae:  0.12481244653463364
[2m[36m(func pid=169589)[0m rmse_per_class: [0.115, 0.274, 0.087, 0.349, 0.067, 0.194, 0.277, 0.137, 0.161, 0.098]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.21380606293678284
[2m[36m(func pid=176440)[0m mae:  0.13901707530021667
[2m[36m(func pid=176440)[0m rmse_per_class: [0.092, 0.297, 0.033, 0.285, 0.056, 0.219, 0.267, 0.368, 0.132, 0.39]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.6999 | Steps: 2 | Val loss: 0.5439 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.4714 | Steps: 2 | Val loss: 0.5151 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4770 | Steps: 2 | Val loss: 0.3789 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4820 | Steps: 2 | Val loss: 0.4781 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 06:15:30 (running for 00:19:21.74)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.475 |  0.176 |                   55 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.7   |  0.199 |                   32 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.464 |  0.214 |                   27 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.571 |  0.178 |                    8 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.19887515902519226
[2m[36m(func pid=175366)[0m mae:  0.12749254703521729
[2m[36m(func pid=175366)[0m rmse_per_class: [0.098, 0.283, 0.048, 0.382, 0.056, 0.191, 0.529, 0.154, 0.151, 0.095]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.2137957513332367
[2m[36m(func pid=180788)[0m mae:  0.13808095455169678
[2m[36m(func pid=180788)[0m rmse_per_class: [0.104, 0.3, 0.031, 0.32, 0.056, 0.222, 0.22, 0.297, 0.134, 0.453]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17577654123306274
[2m[36m(func pid=169589)[0m mae:  0.12456109374761581
[2m[36m(func pid=169589)[0m rmse_per_class: [0.115, 0.274, 0.086, 0.349, 0.067, 0.194, 0.278, 0.137, 0.161, 0.097]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.21908259391784668
[2m[36m(func pid=176440)[0m mae:  0.14241714775562286
[2m[36m(func pid=176440)[0m rmse_per_class: [0.095, 0.298, 0.051, 0.328, 0.056, 0.221, 0.242, 0.486, 0.133, 0.281]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.6893 | Steps: 2 | Val loss: 0.5376 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.6148 | Steps: 2 | Val loss: 0.6001 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4858 | Steps: 2 | Val loss: 0.3807 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4812 | Steps: 2 | Val loss: 0.5031 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 06:15:35 (running for 00:19:26.94)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.477 |  0.176 |                   56 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.689 |  0.199 |                   33 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.482 |  0.219 |                   28 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.471 |  0.214 |                    9 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.19939981400966644
[2m[36m(func pid=175366)[0m mae:  0.12768110632896423
[2m[36m(func pid=175366)[0m rmse_per_class: [0.098, 0.283, 0.048, 0.382, 0.056, 0.191, 0.535, 0.154, 0.15, 0.096]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.21495592594146729
[2m[36m(func pid=180788)[0m mae:  0.13775388896465302
[2m[36m(func pid=180788)[0m rmse_per_class: [0.094, 0.301, 0.046, 0.38, 0.056, 0.216, 0.288, 0.433, 0.144, 0.193]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17567627131938934
[2m[36m(func pid=169589)[0m mae:  0.12442139536142349
[2m[36m(func pid=169589)[0m rmse_per_class: [0.115, 0.274, 0.085, 0.349, 0.066, 0.194, 0.279, 0.137, 0.161, 0.097]
[2m[36m(func pid=176440)[0m rmse: 0.21722643077373505
[2m[36m(func pid=176440)[0m mae:  0.14134861528873444
[2m[36m(func pid=176440)[0m rmse_per_class: [0.096, 0.298, 0.079, 0.356, 0.056, 0.221, 0.229, 0.525, 0.136, 0.176]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.6967 | Steps: 2 | Val loss: 0.5309 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.5140 | Steps: 2 | Val loss: 0.5085 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.5692 | Steps: 2 | Val loss: 0.5595 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4853 | Steps: 2 | Val loss: 0.3833 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 06:15:41 (running for 00:19:32.07)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.486 |  0.176 |                   57 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.697 |  0.2   |                   34 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.481 |  0.217 |                   29 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.615 |  0.215 |                   10 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.19977934658527374
[2m[36m(func pid=175366)[0m mae:  0.1277996152639389
[2m[36m(func pid=175366)[0m rmse_per_class: [0.097, 0.283, 0.048, 0.383, 0.056, 0.191, 0.54, 0.155, 0.149, 0.096]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.19927318394184113
[2m[36m(func pid=180788)[0m mae:  0.11849252879619598
[2m[36m(func pid=180788)[0m rmse_per_class: [0.083, 0.293, 0.141, 0.378, 0.061, 0.188, 0.357, 0.186, 0.212, 0.093]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.21406356990337372
[2m[36m(func pid=176440)[0m mae:  0.13855043053627014
[2m[36m(func pid=176440)[0m rmse_per_class: [0.097, 0.297, 0.11, 0.368, 0.056, 0.22, 0.264, 0.475, 0.14, 0.115]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17552778124809265
[2m[36m(func pid=169589)[0m mae:  0.12414765357971191
[2m[36m(func pid=169589)[0m rmse_per_class: [0.115, 0.274, 0.084, 0.349, 0.065, 0.194, 0.279, 0.137, 0.161, 0.097]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.6981 | Steps: 2 | Val loss: 0.5232 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4698 | Steps: 2 | Val loss: 0.5825 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4901 | Steps: 2 | Val loss: 0.3853 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.5110 | Steps: 2 | Val loss: 0.4984 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 06:15:46 (running for 00:19:37.11)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.485 |  0.176 |                   58 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.698 |  0.2   |                   35 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.514 |  0.214 |                   30 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.569 |  0.199 |                   11 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.19999843835830688
[2m[36m(func pid=175366)[0m mae:  0.1278257817029953
[2m[36m(func pid=175366)[0m rmse_per_class: [0.097, 0.282, 0.048, 0.383, 0.056, 0.191, 0.543, 0.155, 0.149, 0.096]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.2286716252565384
[2m[36m(func pid=180788)[0m mae:  0.14124004542827606
[2m[36m(func pid=180788)[0m rmse_per_class: [0.09, 0.281, 0.097, 0.383, 0.288, 0.436, 0.27, 0.132, 0.215, 0.095]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.1753704845905304
[2m[36m(func pid=169589)[0m mae:  0.12383417040109634
[2m[36m(func pid=169589)[0m rmse_per_class: [0.114, 0.274, 0.083, 0.349, 0.065, 0.194, 0.279, 0.137, 0.161, 0.096]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.21212518215179443
[2m[36m(func pid=176440)[0m mae:  0.1341519057750702
[2m[36m(func pid=176440)[0m rmse_per_class: [0.094, 0.294, 0.142, 0.373, 0.056, 0.215, 0.353, 0.356, 0.145, 0.094]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.6695 | Steps: 2 | Val loss: 0.5160 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.5148 | Steps: 2 | Val loss: 0.6262 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4908 | Steps: 2 | Val loss: 0.3883 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4897 | Steps: 2 | Val loss: 0.4838 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=175366)[0m rmse: 0.20004209876060486
[2m[36m(func pid=175366)[0m mae:  0.12777277827262878
[2m[36m(func pid=175366)[0m rmse_per_class: [0.096, 0.282, 0.048, 0.383, 0.056, 0.19, 0.544, 0.155, 0.149, 0.096]
== Status ==
Current time: 2024-01-07 06:15:51 (running for 00:19:42.56)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.49  |  0.175 |                   59 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.669 |  0.2   |                   36 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.511 |  0.212 |                   31 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.47  |  0.229 |                   12 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.2214878797531128
[2m[36m(func pid=180788)[0m mae:  0.1434154510498047
[2m[36m(func pid=180788)[0m rmse_per_class: [0.083, 0.26, 0.038, 0.381, 0.406, 0.291, 0.31, 0.152, 0.199, 0.097]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17543204128742218
[2m[36m(func pid=169589)[0m mae:  0.12375277280807495
[2m[36m(func pid=169589)[0m rmse_per_class: [0.114, 0.274, 0.082, 0.35, 0.064, 0.194, 0.28, 0.138, 0.162, 0.096]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.20869755744934082
[2m[36m(func pid=176440)[0m mae:  0.12887288630008698
[2m[36m(func pid=176440)[0m rmse_per_class: [0.09, 0.29, 0.164, 0.375, 0.055, 0.203, 0.434, 0.233, 0.155, 0.088]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.6559 | Steps: 2 | Val loss: 0.5045 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.6615 | Steps: 2 | Val loss: 0.5495 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4941 | Steps: 2 | Val loss: 0.3893 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4510 | Steps: 2 | Val loss: 0.4679 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 06:15:56 (running for 00:19:47.85)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.491 |  0.175 |                   60 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.656 |  0.199 |                   37 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.49  |  0.209 |                   32 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.515 |  0.221 |                   13 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.19942644238471985
[2m[36m(func pid=175366)[0m mae:  0.12733760476112366
[2m[36m(func pid=175366)[0m rmse_per_class: [0.096, 0.28, 0.048, 0.383, 0.056, 0.189, 0.54, 0.155, 0.149, 0.096]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.1958596557378769
[2m[36m(func pid=180788)[0m mae:  0.12091003358364105
[2m[36m(func pid=180788)[0m rmse_per_class: [0.089, 0.321, 0.028, 0.342, 0.217, 0.21, 0.259, 0.155, 0.241, 0.097]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.20075245201587677
[2m[36m(func pid=176440)[0m mae:  0.12231209129095078
[2m[36m(func pid=176440)[0m rmse_per_class: [0.084, 0.282, 0.176, 0.375, 0.052, 0.181, 0.456, 0.143, 0.17, 0.088]
[2m[36m(func pid=169589)[0m rmse: 0.1753540188074112
[2m[36m(func pid=169589)[0m mae:  0.1235494464635849
[2m[36m(func pid=169589)[0m rmse_per_class: [0.114, 0.274, 0.081, 0.35, 0.064, 0.193, 0.282, 0.138, 0.162, 0.096]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.6419 | Steps: 2 | Val loss: 0.4919 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.5831 | Steps: 2 | Val loss: 0.4531 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4962 | Steps: 2 | Val loss: 0.3911 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4212 | Steps: 2 | Val loss: 0.4535 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 06:16:02 (running for 00:19:53.05)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.494 |  0.175 |                   61 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.642 |  0.198 |                   38 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.451 |  0.201 |                   33 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.662 |  0.196 |                   14 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.19845250248908997
[2m[36m(func pid=175366)[0m mae:  0.12672385573387146
[2m[36m(func pid=175366)[0m rmse_per_class: [0.095, 0.279, 0.048, 0.383, 0.056, 0.188, 0.533, 0.155, 0.15, 0.096]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.16865703463554382
[2m[36m(func pid=180788)[0m mae:  0.09704292565584183
[2m[36m(func pid=180788)[0m rmse_per_class: [0.073, 0.301, 0.027, 0.283, 0.072, 0.19, 0.262, 0.155, 0.229, 0.095]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.1899428516626358
[2m[36m(func pid=176440)[0m mae:  0.11445103585720062
[2m[36m(func pid=176440)[0m rmse_per_class: [0.078, 0.269, 0.165, 0.373, 0.053, 0.162, 0.406, 0.113, 0.191, 0.09]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17525064945220947
[2m[36m(func pid=169589)[0m mae:  0.12328062206506729
[2m[36m(func pid=169589)[0m rmse_per_class: [0.114, 0.274, 0.08, 0.35, 0.063, 0.193, 0.283, 0.138, 0.161, 0.096]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.6367 | Steps: 2 | Val loss: 0.4817 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.5203 | Steps: 2 | Val loss: 0.4629 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3959 | Steps: 2 | Val loss: 0.4369 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4952 | Steps: 2 | Val loss: 0.3927 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 06:16:07 (running for 00:19:58.37)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.496 |  0.175 |                   62 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.637 |  0.197 |                   39 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.421 |  0.19  |                   34 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.583 |  0.169 |                   15 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.19735291600227356
[2m[36m(func pid=175366)[0m mae:  0.1260530650615692
[2m[36m(func pid=175366)[0m rmse_per_class: [0.094, 0.277, 0.049, 0.383, 0.056, 0.187, 0.524, 0.155, 0.152, 0.096]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.1717577427625656
[2m[36m(func pid=180788)[0m mae:  0.09699736535549164
[2m[36m(func pid=180788)[0m rmse_per_class: [0.076, 0.237, 0.03, 0.331, 0.056, 0.212, 0.304, 0.154, 0.23, 0.087]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.18256181478500366
[2m[36m(func pid=176440)[0m mae:  0.10839762538671494
[2m[36m(func pid=176440)[0m rmse_per_class: [0.075, 0.258, 0.136, 0.368, 0.075, 0.189, 0.303, 0.118, 0.212, 0.091]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17519113421440125
[2m[36m(func pid=169589)[0m mae:  0.12313690036535263
[2m[36m(func pid=169589)[0m rmse_per_class: [0.114, 0.274, 0.079, 0.35, 0.063, 0.193, 0.284, 0.138, 0.161, 0.095]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.6291 | Steps: 2 | Val loss: 0.4691 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.5190 | Steps: 2 | Val loss: 0.5232 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3909 | Steps: 2 | Val loss: 0.4257 | Batch size: 32 | lr: 0.01 | Duration: 2.71s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4967 | Steps: 2 | Val loss: 0.3940 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=175366)[0m rmse: 0.19565019011497498
[2m[36m(func pid=175366)[0m mae:  0.12506826221942902
[2m[36m(func pid=175366)[0m rmse_per_class: [0.093, 0.275, 0.049, 0.382, 0.056, 0.185, 0.509, 0.155, 0.155, 0.096]
== Status ==
Current time: 2024-01-07 06:16:12 (running for 00:20:03.60)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.495 |  0.175 |                   63 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.629 |  0.196 |                   40 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.396 |  0.183 |                   35 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.52  |  0.172 |                   16 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.18766669929027557
[2m[36m(func pid=180788)[0m mae:  0.10873724520206451
[2m[36m(func pid=180788)[0m rmse_per_class: [0.081, 0.267, 0.032, 0.479, 0.056, 0.205, 0.285, 0.146, 0.223, 0.103]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.1846088469028473
[2m[36m(func pid=176440)[0m mae:  0.11039908975362778
[2m[36m(func pid=176440)[0m rmse_per_class: [0.078, 0.257, 0.098, 0.365, 0.123, 0.26, 0.22, 0.133, 0.219, 0.093]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17519350349903107
[2m[36m(func pid=169589)[0m mae:  0.12298288196325302
[2m[36m(func pid=169589)[0m rmse_per_class: [0.114, 0.274, 0.078, 0.35, 0.062, 0.193, 0.285, 0.138, 0.162, 0.095]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.6028 | Steps: 2 | Val loss: 0.4568 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.5064 | Steps: 2 | Val loss: 0.5384 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3708 | Steps: 2 | Val loss: 0.4237 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.5003 | Steps: 2 | Val loss: 0.3949 | Batch size: 32 | lr: 0.0001 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 06:16:17 (running for 00:20:08.61)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.497 |  0.175 |                   64 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.603 |  0.194 |                   41 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.391 |  0.185 |                   36 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.519 |  0.188 |                   17 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.19371181726455688
[2m[36m(func pid=175366)[0m mae:  0.12397992610931396
[2m[36m(func pid=175366)[0m rmse_per_class: [0.093, 0.273, 0.049, 0.382, 0.056, 0.184, 0.491, 0.155, 0.158, 0.096]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.1951717585325241
[2m[36m(func pid=180788)[0m mae:  0.10875759273767471
[2m[36m(func pid=180788)[0m rmse_per_class: [0.081, 0.29, 0.037, 0.464, 0.056, 0.182, 0.272, 0.135, 0.205, 0.228]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.1936759352684021
[2m[36m(func pid=176440)[0m mae:  0.11827854067087173
[2m[36m(func pid=176440)[0m rmse_per_class: [0.08, 0.263, 0.061, 0.363, 0.184, 0.307, 0.227, 0.143, 0.215, 0.094]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.1750415861606598
[2m[36m(func pid=169589)[0m mae:  0.12277913093566895
[2m[36m(func pid=169589)[0m rmse_per_class: [0.114, 0.274, 0.077, 0.35, 0.062, 0.193, 0.285, 0.138, 0.161, 0.095]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.5987 | Steps: 2 | Val loss: 0.4427 | Batch size: 32 | lr: 0.001 | Duration: 2.71s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.5279 | Steps: 2 | Val loss: 0.5554 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3853 | Steps: 2 | Val loss: 0.4307 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 06:16:22 (running for 00:20:13.71)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.5   |  0.175 |                   65 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.599 |  0.191 |                   42 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.371 |  0.194 |                   37 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.506 |  0.195 |                   18 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.19109591841697693
[2m[36m(func pid=175366)[0m mae:  0.12254196405410767
[2m[36m(func pid=175366)[0m rmse_per_class: [0.092, 0.27, 0.049, 0.381, 0.056, 0.182, 0.468, 0.155, 0.162, 0.096]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.5030 | Steps: 2 | Val loss: 0.3960 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=180788)[0m rmse: 0.20427227020263672
[2m[36m(func pid=180788)[0m mae:  0.11133264005184174
[2m[36m(func pid=180788)[0m rmse_per_class: [0.083, 0.296, 0.044, 0.334, 0.056, 0.248, 0.277, 0.172, 0.18, 0.353]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.19966310262680054
[2m[36m(func pid=176440)[0m mae:  0.12513713538646698
[2m[36m(func pid=176440)[0m rmse_per_class: [0.08, 0.263, 0.038, 0.36, 0.238, 0.308, 0.263, 0.149, 0.203, 0.095]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17503663897514343
[2m[36m(func pid=169589)[0m mae:  0.12263902276754379
[2m[36m(func pid=169589)[0m rmse_per_class: [0.113, 0.274, 0.076, 0.351, 0.061, 0.193, 0.286, 0.139, 0.162, 0.095]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.5829 | Steps: 2 | Val loss: 0.4300 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.5644 | Steps: 2 | Val loss: 0.6151 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4105 | Steps: 2 | Val loss: 0.4457 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 06:16:28 (running for 00:20:19.06)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.503 |  0.175 |                   66 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.583 |  0.188 |                   43 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.385 |  0.2   |                   38 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.528 |  0.204 |                   19 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.18819431960582733
[2m[36m(func pid=175366)[0m mae:  0.12102671712636948
[2m[36m(func pid=175366)[0m rmse_per_class: [0.091, 0.266, 0.049, 0.381, 0.056, 0.181, 0.44, 0.155, 0.167, 0.096]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.5061 | Steps: 2 | Val loss: 0.3973 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=180788)[0m rmse: 0.20958013832569122
[2m[36m(func pid=180788)[0m mae:  0.11763860285282135
[2m[36m(func pid=180788)[0m rmse_per_class: [0.084, 0.298, 0.048, 0.309, 0.056, 0.257, 0.297, 0.202, 0.165, 0.379]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.19999130070209503
[2m[36m(func pid=176440)[0m mae:  0.12809118628501892
[2m[36m(func pid=176440)[0m rmse_per_class: [0.078, 0.261, 0.029, 0.353, 0.269, 0.286, 0.287, 0.151, 0.19, 0.095]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17501100897789001
[2m[36m(func pid=169589)[0m mae:  0.12245507538318634
[2m[36m(func pid=169589)[0m rmse_per_class: [0.113, 0.274, 0.075, 0.351, 0.061, 0.193, 0.288, 0.139, 0.162, 0.095]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.5664 | Steps: 2 | Val loss: 0.4175 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.6256 | Steps: 2 | Val loss: 0.6840 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4298 | Steps: 2 | Val loss: 0.4563 | Batch size: 32 | lr: 0.01 | Duration: 2.68s
== Status ==
Current time: 2024-01-07 06:16:33 (running for 00:20:24.26)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.506 |  0.175 |                   67 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.566 |  0.185 |                   44 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.411 |  0.2   |                   39 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.564 |  0.21  |                   20 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.185144305229187
[2m[36m(func pid=175366)[0m mae:  0.11952830851078033
[2m[36m(func pid=175366)[0m rmse_per_class: [0.09, 0.262, 0.049, 0.38, 0.056, 0.181, 0.409, 0.155, 0.174, 0.096]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.5031 | Steps: 2 | Val loss: 0.3985 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=180788)[0m rmse: 0.21270962059497833
[2m[36m(func pid=180788)[0m mae:  0.1213141530752182
[2m[36m(func pid=180788)[0m rmse_per_class: [0.089, 0.297, 0.049, 0.35, 0.056, 0.21, 0.353, 0.205, 0.165, 0.352]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.1971474140882492
[2m[36m(func pid=176440)[0m mae:  0.1275322586297989
[2m[36m(func pid=176440)[0m rmse_per_class: [0.078, 0.259, 0.027, 0.342, 0.278, 0.259, 0.296, 0.153, 0.184, 0.095]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=169589)[0m rmse: 0.17503416538238525
[2m[36m(func pid=169589)[0m mae:  0.12233062833547592
[2m[36m(func pid=169589)[0m rmse_per_class: [0.113, 0.274, 0.075, 0.351, 0.06, 0.193, 0.288, 0.139, 0.162, 0.094]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.5713 | Steps: 2 | Val loss: 0.4050 | Batch size: 32 | lr: 0.001 | Duration: 2.71s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.6384 | Steps: 2 | Val loss: 0.7028 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4667 | Steps: 2 | Val loss: 0.4535 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 06:16:38 (running for 00:20:29.36)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.503 |  0.175 |                   68 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.571 |  0.182 |                   45 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.43  |  0.197 |                   40 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.626 |  0.213 |                   21 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.18168863654136658
[2m[36m(func pid=175366)[0m mae:  0.11791938543319702
[2m[36m(func pid=175366)[0m rmse_per_class: [0.089, 0.258, 0.049, 0.378, 0.056, 0.181, 0.373, 0.155, 0.181, 0.096]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.5100 | Steps: 2 | Val loss: 0.3996 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=180788)[0m rmse: 0.22052590548992157
[2m[36m(func pid=180788)[0m mae:  0.12366578727960587
[2m[36m(func pid=180788)[0m rmse_per_class: [0.123, 0.288, 0.049, 0.37, 0.056, 0.187, 0.376, 0.242, 0.18, 0.335]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.19285865128040314
[2m[36m(func pid=176440)[0m mae:  0.12458193302154541
[2m[36m(func pid=176440)[0m rmse_per_class: [0.08, 0.262, 0.027, 0.326, 0.269, 0.234, 0.295, 0.153, 0.188, 0.095]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.5379 | Steps: 2 | Val loss: 0.3929 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=169589)[0m rmse: 0.175028458237648
[2m[36m(func pid=169589)[0m mae:  0.12221822887659073
[2m[36m(func pid=169589)[0m rmse_per_class: [0.113, 0.274, 0.073, 0.351, 0.06, 0.193, 0.289, 0.139, 0.163, 0.094]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.6007 | Steps: 2 | Val loss: 0.7055 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4649 | Steps: 2 | Val loss: 0.4296 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
== Status ==
Current time: 2024-01-07 06:16:43 (running for 00:20:34.58)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.51  |  0.175 |                   69 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.538 |  0.178 |                   46 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.467 |  0.193 |                   41 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.638 |  0.221 |                   22 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.17840197682380676
[2m[36m(func pid=175366)[0m mae:  0.1164897233247757
[2m[36m(func pid=175366)[0m rmse_per_class: [0.089, 0.255, 0.049, 0.377, 0.056, 0.183, 0.338, 0.155, 0.186, 0.096]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.5078 | Steps: 2 | Val loss: 0.4011 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=180788)[0m rmse: 0.22361913323402405
[2m[36m(func pid=180788)[0m mae:  0.12058021873235703
[2m[36m(func pid=180788)[0m rmse_per_class: [0.202, 0.286, 0.047, 0.375, 0.056, 0.189, 0.333, 0.263, 0.217, 0.266]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.18614110350608826
[2m[36m(func pid=176440)[0m mae:  0.11859766393899918
[2m[36m(func pid=176440)[0m rmse_per_class: [0.082, 0.266, 0.029, 0.305, 0.241, 0.214, 0.284, 0.153, 0.195, 0.093]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.5279 | Steps: 2 | Val loss: 0.3826 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=169589)[0m rmse: 0.17504039406776428
[2m[36m(func pid=169589)[0m mae:  0.12203748524188995
[2m[36m(func pid=169589)[0m rmse_per_class: [0.113, 0.274, 0.072, 0.351, 0.06, 0.193, 0.29, 0.139, 0.164, 0.094]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.5626 | Steps: 2 | Val loss: 0.7125 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4365 | Steps: 2 | Val loss: 0.3953 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 06:16:48 (running for 00:20:39.62)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.508 |  0.175 |                   70 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.528 |  0.175 |                   47 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.465 |  0.186 |                   42 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.601 |  0.224 |                   23 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.1754215806722641
[2m[36m(func pid=175366)[0m mae:  0.11544480174779892
[2m[36m(func pid=175366)[0m rmse_per_class: [0.09, 0.252, 0.049, 0.375, 0.056, 0.185, 0.304, 0.155, 0.193, 0.096]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.2143995761871338
[2m[36m(func pid=180788)[0m mae:  0.11490694433450699
[2m[36m(func pid=180788)[0m rmse_per_class: [0.212, 0.352, 0.045, 0.378, 0.058, 0.19, 0.295, 0.193, 0.255, 0.166]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.5152 | Steps: 2 | Val loss: 0.4019 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=176440)[0m rmse: 0.17693965137004852
[2m[36m(func pid=176440)[0m mae:  0.1098838672041893
[2m[36m(func pid=176440)[0m rmse_per_class: [0.081, 0.264, 0.031, 0.285, 0.2, 0.198, 0.259, 0.152, 0.209, 0.09]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.5191 | Steps: 2 | Val loss: 0.3731 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=169589)[0m rmse: 0.17489150166511536
[2m[36m(func pid=169589)[0m mae:  0.12173186242580414
[2m[36m(func pid=169589)[0m rmse_per_class: [0.113, 0.274, 0.07, 0.351, 0.059, 0.193, 0.29, 0.14, 0.164, 0.094]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.5567 | Steps: 2 | Val loss: 0.6948 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4139 | Steps: 2 | Val loss: 0.3665 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 06:16:53 (running for 00:20:44.96)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.515 |  0.175 |                   71 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.519 |  0.173 |                   48 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.437 |  0.177 |                   43 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.563 |  0.214 |                   24 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.1727050244808197
[2m[36m(func pid=175366)[0m mae:  0.11465062946081161
[2m[36m(func pid=175366)[0m rmse_per_class: [0.091, 0.25, 0.049, 0.373, 0.056, 0.188, 0.272, 0.155, 0.196, 0.096]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.20252183079719543
[2m[36m(func pid=180788)[0m mae:  0.11277520656585693
[2m[36m(func pid=180788)[0m rmse_per_class: [0.125, 0.391, 0.043, 0.377, 0.068, 0.192, 0.313, 0.142, 0.273, 0.101]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.5063 | Steps: 2 | Val loss: 0.4020 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=176440)[0m rmse: 0.16742785274982452
[2m[36m(func pid=176440)[0m mae:  0.1011582463979721
[2m[36m(func pid=176440)[0m rmse_per_class: [0.079, 0.256, 0.033, 0.276, 0.153, 0.184, 0.236, 0.152, 0.221, 0.085]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4921 | Steps: 2 | Val loss: 0.3638 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=169589)[0m rmse: 0.17485056817531586
[2m[36m(func pid=169589)[0m mae:  0.12162518501281738
[2m[36m(func pid=169589)[0m rmse_per_class: [0.113, 0.274, 0.07, 0.351, 0.059, 0.193, 0.291, 0.14, 0.164, 0.094]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.5494 | Steps: 2 | Val loss: 0.6744 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3887 | Steps: 2 | Val loss: 0.3490 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 06:16:59 (running for 00:20:50.42)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.506 |  0.175 |                   72 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.492 |  0.171 |                   49 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.414 |  0.167 |                   44 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.557 |  0.203 |                   25 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.17075516283512115
[2m[36m(func pid=175366)[0m mae:  0.11438052356243134
[2m[36m(func pid=175366)[0m rmse_per_class: [0.093, 0.25, 0.049, 0.37, 0.056, 0.192, 0.247, 0.155, 0.199, 0.096]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.1965811550617218
[2m[36m(func pid=180788)[0m mae:  0.11216159164905548
[2m[36m(func pid=180788)[0m rmse_per_class: [0.075, 0.361, 0.039, 0.371, 0.089, 0.193, 0.355, 0.14, 0.26, 0.081]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.5068 | Steps: 2 | Val loss: 0.4032 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=176440)[0m rmse: 0.16089391708374023
[2m[36m(func pid=176440)[0m mae:  0.09493296593427658
[2m[36m(func pid=176440)[0m rmse_per_class: [0.077, 0.24, 0.034, 0.284, 0.111, 0.179, 0.221, 0.152, 0.229, 0.081]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4822 | Steps: 2 | Val loss: 0.3563 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.5629 | Steps: 2 | Val loss: 0.6379 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=169589)[0m rmse: 0.17490410804748535
[2m[36m(func pid=169589)[0m mae:  0.12150386720895767
[2m[36m(func pid=169589)[0m rmse_per_class: [0.113, 0.274, 0.069, 0.351, 0.059, 0.193, 0.293, 0.14, 0.163, 0.094]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3680 | Steps: 2 | Val loss: 0.3426 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=175366)[0m rmse: 0.1696571409702301
[2m[36m(func pid=175366)[0m mae:  0.11459275335073471
[2m[36m(func pid=175366)[0m rmse_per_class: [0.096, 0.252, 0.049, 0.366, 0.056, 0.196, 0.231, 0.155, 0.2, 0.096]
[2m[36m(func pid=175366)[0m 
== Status ==
Current time: 2024-01-07 06:17:04 (running for 00:20:55.58)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.507 |  0.175 |                   73 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.482 |  0.17  |                   50 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.389 |  0.161 |                   45 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.549 |  0.197 |                   26 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=180788)[0m rmse: 0.19512850046157837
[2m[36m(func pid=180788)[0m mae:  0.10890692472457886
[2m[36m(func pid=180788)[0m rmse_per_class: [0.075, 0.326, 0.033, 0.353, 0.127, 0.191, 0.346, 0.146, 0.268, 0.087]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.5138 | Steps: 2 | Val loss: 0.4032 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=176440)[0m rmse: 0.15939262509346008
[2m[36m(func pid=176440)[0m mae:  0.09214773029088974
[2m[36m(func pid=176440)[0m rmse_per_class: [0.075, 0.23, 0.036, 0.301, 0.079, 0.183, 0.222, 0.15, 0.232, 0.085]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4777 | Steps: 2 | Val loss: 0.3512 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.5961 | Steps: 2 | Val loss: 0.6235 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=169589)[0m rmse: 0.174780935049057
[2m[36m(func pid=169589)[0m mae:  0.12129733711481094
[2m[36m(func pid=169589)[0m rmse_per_class: [0.112, 0.274, 0.068, 0.351, 0.059, 0.193, 0.294, 0.14, 0.163, 0.094]
[2m[36m(func pid=169589)[0m 
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3697 | Steps: 2 | Val loss: 0.3478 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 06:17:09 (running for 00:21:00.70)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.1614999957382679
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00008 | RUNNING    | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.514 |  0.175 |                   74 |
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.478 |  0.169 |                   51 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.368 |  0.159 |                   46 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.563 |  0.195 |                   27 |
| train_12613_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=175366)[0m rmse: 0.16944900155067444
[2m[36m(func pid=175366)[0m mae:  0.11507315933704376
[2m[36m(func pid=175366)[0m rmse_per_class: [0.099, 0.255, 0.049, 0.362, 0.056, 0.199, 0.223, 0.155, 0.2, 0.096]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.20134344696998596
[2m[36m(func pid=180788)[0m mae:  0.109294593334198
[2m[36m(func pid=180788)[0m rmse_per_class: [0.079, 0.299, 0.035, 0.331, 0.181, 0.289, 0.281, 0.146, 0.282, 0.09]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=169589)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.5187 | Steps: 2 | Val loss: 0.4034 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=176440)[0m rmse: 0.16313403844833374
[2m[36m(func pid=176440)[0m mae:  0.09312129765748978
[2m[36m(func pid=176440)[0m rmse_per_class: [0.072, 0.237, 0.039, 0.316, 0.06, 0.193, 0.235, 0.148, 0.23, 0.101]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4758 | Steps: 2 | Val loss: 0.3477 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.6073 | Steps: 2 | Val loss: 0.6288 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=169589)[0m rmse: 0.17467431724071503
[2m[36m(func pid=169589)[0m mae:  0.12110446393489838
[2m[36m(func pid=169589)[0m rmse_per_class: [0.112, 0.274, 0.067, 0.351, 0.058, 0.193, 0.295, 0.14, 0.163, 0.094]
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3654 | Steps: 2 | Val loss: 0.3584 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=175366)[0m rmse: 0.16978226602077484
[2m[36m(func pid=175366)[0m mae:  0.11580014228820801
[2m[36m(func pid=175366)[0m rmse_per_class: [0.103, 0.258, 0.049, 0.356, 0.056, 0.201, 0.225, 0.155, 0.199, 0.096]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.2068745195865631
[2m[36m(func pid=180788)[0m mae:  0.11222372204065323
[2m[36m(func pid=180788)[0m rmse_per_class: [0.082, 0.269, 0.043, 0.326, 0.199, 0.364, 0.277, 0.144, 0.273, 0.093]
[2m[36m(func pid=176440)[0m rmse: 0.16806721687316895
[2m[36m(func pid=176440)[0m mae:  0.09538304060697556
[2m[36m(func pid=176440)[0m rmse_per_class: [0.071, 0.249, 0.041, 0.325, 0.054, 0.201, 0.25, 0.146, 0.22, 0.124]
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4685 | Steps: 2 | Val loss: 0.3458 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=175366)[0m rmse: 0.17027071118354797
[2m[36m(func pid=175366)[0m mae:  0.11649016290903091
[2m[36m(func pid=175366)[0m rmse_per_class: [0.107, 0.261, 0.049, 0.35, 0.056, 0.203, 0.232, 0.155, 0.196, 0.095]
== Status ==
Current time: 2024-01-07 06:17:14 (running for 00:21:05.99)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.476 |  0.17  |                   52 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.37  |  0.163 |                   47 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.596 |  0.201 |                   28 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=187627)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=187627)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=187627)[0m Configuration completed!
[2m[36m(func pid=187627)[0m New optimizer parameters:
[2m[36m(func pid=187627)[0m SGD (
[2m[36m(func pid=187627)[0m Parameter Group 0
[2m[36m(func pid=187627)[0m     dampening: 0
[2m[36m(func pid=187627)[0m     differentiable: False
[2m[36m(func pid=187627)[0m     foreach: None
[2m[36m(func pid=187627)[0m     lr: 0.0001
[2m[36m(func pid=187627)[0m     maximize: False
[2m[36m(func pid=187627)[0m     momentum: 0.9
[2m[36m(func pid=187627)[0m     nesterov: False
[2m[36m(func pid=187627)[0m     weight_decay: 0.0001
[2m[36m(func pid=187627)[0m )
[2m[36m(func pid=187627)[0m 
== Status ==
Current time: 2024-01-07 06:17:21 (running for 00:21:13.03)
Memory usage on this node: 23.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.476 |  0.17  |                   52 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.37  |  0.163 |                   47 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.607 |  0.207 |                   29 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4629 | Steps: 2 | Val loss: 0.3446 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3620 | Steps: 2 | Val loss: 0.3679 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.6030 | Steps: 2 | Val loss: 0.6264 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0838 | Steps: 2 | Val loss: 0.8099 | Batch size: 32 | lr: 0.0001 | Duration: 4.58s
== Status ==
Current time: 2024-01-07 06:17:27 (running for 00:21:18.06)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.468 |  0.17  |                   53 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.365 |  0.168 |                   48 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.607 |  0.207 |                   29 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=175366)[0m rmse: 0.17048007249832153
[2m[36m(func pid=175366)[0m mae:  0.11681308597326279
[2m[36m(func pid=175366)[0m rmse_per_class: [0.11, 0.264, 0.049, 0.341, 0.056, 0.203, 0.24, 0.154, 0.192, 0.095]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.20138303935527802
[2m[36m(func pid=180788)[0m mae:  0.10669398307800293
[2m[36m(func pid=180788)[0m rmse_per_class: [0.09, 0.274, 0.046, 0.346, 0.189, 0.287, 0.287, 0.141, 0.26, 0.094]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.1729208528995514
[2m[36m(func pid=176440)[0m mae:  0.09775985032320023
[2m[36m(func pid=176440)[0m rmse_per_class: [0.069, 0.263, 0.042, 0.323, 0.053, 0.206, 0.265, 0.141, 0.209, 0.158]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.17858435213565826
[2m[36m(func pid=187627)[0m mae:  0.1311267614364624
[2m[36m(func pid=187627)[0m rmse_per_class: [0.105, 0.265, 0.086, 0.325, 0.1, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.6029 | Steps: 2 | Val loss: 0.6233 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4723 | Steps: 2 | Val loss: 0.3444 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4011 | Steps: 2 | Val loss: 0.3795 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0808 | Steps: 2 | Val loss: 0.8113 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 06:17:32 (running for 00:21:23.44)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.463 |  0.17  |                   54 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.362 |  0.173 |                   49 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.603 |  0.195 |                   31 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  1.084 |  0.179 |                    1 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.1954023838043213
[2m[36m(func pid=180788)[0m mae:  0.10454899072647095
[2m[36m(func pid=180788)[0m rmse_per_class: [0.106, 0.291, 0.037, 0.344, 0.14, 0.201, 0.364, 0.134, 0.242, 0.095]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.1704152226448059
[2m[36m(func pid=175366)[0m mae:  0.11695840209722519
[2m[36m(func pid=175366)[0m rmse_per_class: [0.114, 0.265, 0.049, 0.332, 0.056, 0.202, 0.25, 0.154, 0.187, 0.095]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.17746704816818237
[2m[36m(func pid=176440)[0m mae:  0.1002405658364296
[2m[36m(func pid=176440)[0m rmse_per_class: [0.069, 0.274, 0.044, 0.324, 0.053, 0.207, 0.268, 0.136, 0.198, 0.2]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.1790710836648941
[2m[36m(func pid=187627)[0m mae:  0.13151542842388153
[2m[36m(func pid=187627)[0m rmse_per_class: [0.104, 0.265, 0.088, 0.325, 0.102, 0.193, 0.306, 0.154, 0.139, 0.116]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.5761 | Steps: 2 | Val loss: 0.6293 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4729 | Steps: 2 | Val loss: 0.3430 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3929 | Steps: 2 | Val loss: 0.3890 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 1.0704 | Steps: 2 | Val loss: 0.8131 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=180788)[0m rmse: 0.1929793357849121
[2m[36m(func pid=180788)[0m mae:  0.10412021726369858
[2m[36m(func pid=180788)[0m rmse_per_class: [0.146, 0.297, 0.03, 0.345, 0.104, 0.199, 0.373, 0.124, 0.217, 0.094]
[2m[36m(func pid=180788)[0m 
== Status ==
Current time: 2024-01-07 06:17:37 (running for 00:21:28.71)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.472 |  0.17  |                   55 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.401 |  0.177 |                   50 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.576 |  0.193 |                   32 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  1.081 |  0.179 |                    2 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=175366)[0m rmse: 0.16951625049114227
[2m[36m(func pid=175366)[0m mae:  0.11645404994487762
[2m[36m(func pid=175366)[0m rmse_per_class: [0.116, 0.265, 0.049, 0.32, 0.056, 0.2, 0.259, 0.154, 0.183, 0.094]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.18053846061229706
[2m[36m(func pid=176440)[0m mae:  0.10205791890621185
[2m[36m(func pid=176440)[0m rmse_per_class: [0.07, 0.283, 0.045, 0.319, 0.054, 0.204, 0.266, 0.128, 0.186, 0.25]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.17951476573944092
[2m[36m(func pid=187627)[0m mae:  0.13185754418373108
[2m[36m(func pid=187627)[0m rmse_per_class: [0.105, 0.266, 0.089, 0.325, 0.103, 0.193, 0.307, 0.154, 0.139, 0.116]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.5905 | Steps: 2 | Val loss: 0.6376 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4743 | Steps: 2 | Val loss: 0.3411 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3909 | Steps: 2 | Val loss: 0.3967 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 1.0620 | Steps: 2 | Val loss: 0.8125 | Batch size: 32 | lr: 0.0001 | Duration: 2.68s
== Status ==
Current time: 2024-01-07 06:17:42 (running for 00:21:33.81)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.473 |  0.17  |                   56 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.393 |  0.181 |                   51 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.591 |  0.197 |                   33 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  1.07  |  0.18  |                    3 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.19699586927890778
[2m[36m(func pid=180788)[0m mae:  0.10461650788784027
[2m[36m(func pid=180788)[0m rmse_per_class: [0.209, 0.297, 0.031, 0.39, 0.087, 0.203, 0.283, 0.173, 0.204, 0.091]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.16824446618556976
[2m[36m(func pid=175366)[0m mae:  0.11561071872711182
[2m[36m(func pid=175366)[0m rmse_per_class: [0.118, 0.263, 0.049, 0.309, 0.056, 0.197, 0.266, 0.153, 0.178, 0.093]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.1823883354663849
[2m[36m(func pid=176440)[0m mae:  0.10320892184972763
[2m[36m(func pid=176440)[0m rmse_per_class: [0.071, 0.287, 0.046, 0.313, 0.054, 0.199, 0.259, 0.121, 0.181, 0.292]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.17991188168525696
[2m[36m(func pid=187627)[0m mae:  0.13215436041355133
[2m[36m(func pid=187627)[0m rmse_per_class: [0.104, 0.266, 0.09, 0.325, 0.104, 0.193, 0.308, 0.154, 0.138, 0.117]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.6003 | Steps: 2 | Val loss: 0.6233 | Batch size: 32 | lr: 0.1 | Duration: 2.66s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4663 | Steps: 2 | Val loss: 0.3386 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3940 | Steps: 2 | Val loss: 0.4051 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 1.0536 | Steps: 2 | Val loss: 0.8090 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 06:17:47 (running for 00:21:38.92)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.474 |  0.168 |                   57 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.391 |  0.182 |                   52 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.6   |  0.206 |                   34 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  1.062 |  0.18  |                    4 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.20570652186870575
[2m[36m(func pid=180788)[0m mae:  0.11011292040348053
[2m[36m(func pid=180788)[0m rmse_per_class: [0.24, 0.293, 0.035, 0.374, 0.064, 0.246, 0.274, 0.243, 0.2, 0.086]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.16673249006271362
[2m[36m(func pid=175366)[0m mae:  0.11461347341537476
[2m[36m(func pid=175366)[0m rmse_per_class: [0.12, 0.26, 0.049, 0.297, 0.056, 0.193, 0.273, 0.152, 0.174, 0.092]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.18371468782424927
[2m[36m(func pid=176440)[0m mae:  0.10405290126800537
[2m[36m(func pid=176440)[0m rmse_per_class: [0.072, 0.289, 0.046, 0.304, 0.055, 0.188, 0.253, 0.124, 0.178, 0.328]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18018752336502075
[2m[36m(func pid=187627)[0m mae:  0.13235977292060852
[2m[36m(func pid=187627)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.104, 0.193, 0.309, 0.154, 0.138, 0.118]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.5444 | Steps: 2 | Val loss: 0.5869 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4611 | Steps: 2 | Val loss: 0.3352 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3910 | Steps: 2 | Val loss: 0.4146 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 1.0358 | Steps: 2 | Val loss: 0.8036 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 06:17:53 (running for 00:21:44.06)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.466 |  0.167 |                   58 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.394 |  0.184 |                   53 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.544 |  0.2   |                   35 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  1.054 |  0.18  |                    5 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.19998624920845032
[2m[36m(func pid=180788)[0m mae:  0.10695947706699371
[2m[36m(func pid=180788)[0m rmse_per_class: [0.198, 0.282, 0.038, 0.342, 0.057, 0.319, 0.267, 0.189, 0.217, 0.092]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.16496258974075317
[2m[36m(func pid=175366)[0m mae:  0.11337798833847046
[2m[36m(func pid=175366)[0m rmse_per_class: [0.12, 0.257, 0.049, 0.287, 0.056, 0.189, 0.279, 0.151, 0.17, 0.091]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.18594679236412048
[2m[36m(func pid=176440)[0m mae:  0.10528604686260223
[2m[36m(func pid=176440)[0m rmse_per_class: [0.073, 0.29, 0.046, 0.296, 0.055, 0.177, 0.251, 0.15, 0.176, 0.347]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18042530119419098
[2m[36m(func pid=187627)[0m mae:  0.1325404942035675
[2m[36m(func pid=187627)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.105, 0.193, 0.309, 0.154, 0.138, 0.119]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.5012 | Steps: 2 | Val loss: 0.5559 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4532 | Steps: 2 | Val loss: 0.3295 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4108 | Steps: 2 | Val loss: 0.4264 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 1.0165 | Steps: 2 | Val loss: 0.7942 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 06:17:58 (running for 00:21:49.22)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.461 |  0.165 |                   59 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.391 |  0.186 |                   54 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.501 |  0.189 |                   36 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  1.036 |  0.18  |                    6 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.1888342797756195
[2m[36m(func pid=180788)[0m mae:  0.10093425214290619
[2m[36m(func pid=180788)[0m rmse_per_class: [0.129, 0.27, 0.043, 0.32, 0.056, 0.291, 0.293, 0.125, 0.234, 0.128]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.16253766417503357
[2m[36m(func pid=175366)[0m mae:  0.11152322590351105
[2m[36m(func pid=175366)[0m rmse_per_class: [0.117, 0.253, 0.048, 0.279, 0.056, 0.186, 0.282, 0.149, 0.164, 0.09]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.1908659040927887
[2m[36m(func pid=176440)[0m mae:  0.10819725692272186
[2m[36m(func pid=176440)[0m rmse_per_class: [0.073, 0.29, 0.046, 0.29, 0.055, 0.17, 0.255, 0.2, 0.176, 0.354]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18058748543262482
[2m[36m(func pid=187627)[0m mae:  0.13264641165733337
[2m[36m(func pid=187627)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.12]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4968 | Steps: 2 | Val loss: 0.5785 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4385 | Steps: 2 | Val loss: 0.3245 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3952 | Steps: 2 | Val loss: 0.4397 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 1.0043 | Steps: 2 | Val loss: 0.7851 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 06:18:03 (running for 00:21:54.57)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.453 |  0.163 |                   60 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.411 |  0.191 |                   55 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.497 |  0.195 |                   37 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  1.016 |  0.181 |                    7 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.1947537660598755
[2m[36m(func pid=180788)[0m mae:  0.1059679239988327
[2m[36m(func pid=180788)[0m rmse_per_class: [0.092, 0.275, 0.044, 0.326, 0.057, 0.189, 0.403, 0.142, 0.242, 0.177]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.160816952586174
[2m[36m(func pid=175366)[0m mae:  0.11026084423065186
[2m[36m(func pid=175366)[0m rmse_per_class: [0.115, 0.249, 0.048, 0.274, 0.056, 0.182, 0.287, 0.147, 0.162, 0.088]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.19615280628204346
[2m[36m(func pid=176440)[0m mae:  0.11147793382406235
[2m[36m(func pid=176440)[0m rmse_per_class: [0.075, 0.288, 0.046, 0.285, 0.056, 0.168, 0.266, 0.26, 0.177, 0.342]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18076404929161072
[2m[36m(func pid=187627)[0m mae:  0.13278703391551971
[2m[36m(func pid=187627)[0m rmse_per_class: [0.106, 0.266, 0.09, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.12]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.5098 | Steps: 2 | Val loss: 0.6407 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4138 | Steps: 2 | Val loss: 0.3194 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4279 | Steps: 2 | Val loss: 0.4539 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.9865 | Steps: 2 | Val loss: 0.7743 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 06:18:08 (running for 00:21:59.67)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.438 |  0.161 |                   61 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.395 |  0.196 |                   56 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.51  |  0.205 |                   38 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  1.004 |  0.181 |                    8 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.2047193944454193
[2m[36m(func pid=180788)[0m mae:  0.112315334379673
[2m[36m(func pid=180788)[0m rmse_per_class: [0.083, 0.312, 0.046, 0.344, 0.057, 0.187, 0.387, 0.152, 0.235, 0.245]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.15933652222156525
[2m[36m(func pid=175366)[0m mae:  0.10909851640462875
[2m[36m(func pid=175366)[0m rmse_per_class: [0.112, 0.246, 0.048, 0.272, 0.056, 0.178, 0.289, 0.145, 0.159, 0.088]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.20072321593761444
[2m[36m(func pid=176440)[0m mae:  0.11493899673223495
[2m[36m(func pid=176440)[0m rmse_per_class: [0.076, 0.287, 0.045, 0.285, 0.056, 0.176, 0.276, 0.311, 0.183, 0.312]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18087080121040344
[2m[36m(func pid=187627)[0m mae:  0.13285447657108307
[2m[36m(func pid=187627)[0m rmse_per_class: [0.106, 0.266, 0.09, 0.324, 0.106, 0.194, 0.31, 0.154, 0.138, 0.121]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.5339 | Steps: 2 | Val loss: 0.7294 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4084 | Steps: 2 | Val loss: 0.3137 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4410 | Steps: 2 | Val loss: 0.4706 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 06:18:13 (running for 00:22:04.80)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.414 |  0.159 |                   62 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.428 |  0.201 |                   57 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.534 |  0.216 |                   39 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.986 |  0.181 |                    9 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.2158823013305664
[2m[36m(func pid=180788)[0m mae:  0.12043990939855576
[2m[36m(func pid=180788)[0m rmse_per_class: [0.085, 0.362, 0.048, 0.361, 0.057, 0.196, 0.316, 0.153, 0.233, 0.348]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.9663 | Steps: 2 | Val loss: 0.7618 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=175366)[0m rmse: 0.15790307521820068
[2m[36m(func pid=175366)[0m mae:  0.10791169106960297
[2m[36m(func pid=175366)[0m rmse_per_class: [0.107, 0.243, 0.048, 0.271, 0.056, 0.175, 0.291, 0.142, 0.156, 0.089]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.20466585457324982
[2m[36m(func pid=176440)[0m mae:  0.11820073425769806
[2m[36m(func pid=176440)[0m rmse_per_class: [0.079, 0.284, 0.045, 0.293, 0.056, 0.195, 0.284, 0.346, 0.188, 0.277]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.1809270977973938
[2m[36m(func pid=187627)[0m mae:  0.1328863650560379
[2m[36m(func pid=187627)[0m rmse_per_class: [0.106, 0.266, 0.09, 0.324, 0.106, 0.194, 0.31, 0.154, 0.138, 0.121]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.5712 | Steps: 2 | Val loss: 0.7772 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4141 | Steps: 2 | Val loss: 0.3098 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4220 | Steps: 2 | Val loss: 0.4701 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 06:18:19 (running for 00:22:10.09)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.408 |  0.158 |                   63 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.441 |  0.205 |                   58 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.571 |  0.222 |                   40 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.966 |  0.181 |                   10 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.2220446616411209
[2m[36m(func pid=180788)[0m mae:  0.12466053664684296
[2m[36m(func pid=180788)[0m rmse_per_class: [0.098, 0.372, 0.048, 0.371, 0.057, 0.215, 0.299, 0.151, 0.231, 0.378]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.9510 | Steps: 2 | Val loss: 0.7482 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=175366)[0m rmse: 0.15732848644256592
[2m[36m(func pid=175366)[0m mae:  0.10730482637882233
[2m[36m(func pid=175366)[0m rmse_per_class: [0.104, 0.243, 0.048, 0.274, 0.056, 0.171, 0.293, 0.138, 0.153, 0.094]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.20385956764221191
[2m[36m(func pid=176440)[0m mae:  0.11769380420446396
[2m[36m(func pid=176440)[0m rmse_per_class: [0.086, 0.279, 0.044, 0.301, 0.056, 0.224, 0.284, 0.344, 0.193, 0.227]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.5603 | Steps: 2 | Val loss: 0.7535 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=187627)[0m rmse: 0.18100783228874207
[2m[36m(func pid=187627)[0m mae:  0.1329394280910492
[2m[36m(func pid=187627)[0m rmse_per_class: [0.106, 0.267, 0.091, 0.324, 0.105, 0.194, 0.31, 0.153, 0.138, 0.122]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3870 | Steps: 2 | Val loss: 0.3061 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4309 | Steps: 2 | Val loss: 0.4670 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 06:18:24 (running for 00:22:15.27)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.414 |  0.157 |                   64 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.422 |  0.204 |                   59 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.56  |  0.219 |                   41 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.951 |  0.181 |                   11 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.2189190685749054
[2m[36m(func pid=180788)[0m mae:  0.11983964592218399
[2m[36m(func pid=180788)[0m rmse_per_class: [0.142, 0.323, 0.049, 0.373, 0.057, 0.259, 0.292, 0.145, 0.222, 0.327]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.15700682997703552
[2m[36m(func pid=175366)[0m mae:  0.10669006407260895
[2m[36m(func pid=175366)[0m rmse_per_class: [0.097, 0.243, 0.047, 0.277, 0.056, 0.169, 0.294, 0.132, 0.148, 0.105]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.9333 | Steps: 2 | Val loss: 0.7344 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=176440)[0m rmse: 0.2015068531036377
[2m[36m(func pid=176440)[0m mae:  0.11668294668197632
[2m[36m(func pid=176440)[0m rmse_per_class: [0.091, 0.275, 0.044, 0.311, 0.056, 0.256, 0.281, 0.323, 0.197, 0.182]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18099434673786163
[2m[36m(func pid=187627)[0m mae:  0.13290205597877502
[2m[36m(func pid=187627)[0m rmse_per_class: [0.106, 0.267, 0.091, 0.324, 0.105, 0.194, 0.31, 0.153, 0.138, 0.122]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.5221 | Steps: 2 | Val loss: 0.7255 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3877 | Steps: 2 | Val loss: 0.3042 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3991 | Steps: 2 | Val loss: 0.4568 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 06:18:29 (running for 00:22:20.65)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.387 |  0.157 |                   65 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.431 |  0.202 |                   60 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.522 |  0.212 |                   42 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.933 |  0.181 |                   12 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.21189482510089874
[2m[36m(func pid=180788)[0m mae:  0.11474069207906723
[2m[36m(func pid=180788)[0m rmse_per_class: [0.205, 0.276, 0.048, 0.372, 0.056, 0.265, 0.322, 0.134, 0.209, 0.232]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.9159 | Steps: 2 | Val loss: 0.7211 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=175366)[0m rmse: 0.15783269703388214
[2m[36m(func pid=175366)[0m mae:  0.10680492222309113
[2m[36m(func pid=175366)[0m rmse_per_class: [0.091, 0.245, 0.047, 0.28, 0.056, 0.168, 0.296, 0.127, 0.145, 0.123]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.19653908908367157
[2m[36m(func pid=176440)[0m mae:  0.11391963064670563
[2m[36m(func pid=176440)[0m rmse_per_class: [0.099, 0.27, 0.043, 0.321, 0.056, 0.274, 0.275, 0.284, 0.198, 0.145]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18112164735794067
[2m[36m(func pid=187627)[0m mae:  0.13296344876289368
[2m[36m(func pid=187627)[0m rmse_per_class: [0.106, 0.267, 0.091, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.122]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.5020 | Steps: 2 | Val loss: 0.7289 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3945 | Steps: 2 | Val loss: 0.3040 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3887 | Steps: 2 | Val loss: 0.4456 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 06:18:34 (running for 00:22:25.92)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.388 |  0.158 |                   66 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.399 |  0.197 |                   61 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.502 |  0.211 |                   43 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.916 |  0.181 |                   13 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.21149060130119324
[2m[36m(func pid=180788)[0m mae:  0.11647830903530121
[2m[36m(func pid=180788)[0m rmse_per_class: [0.223, 0.282, 0.047, 0.367, 0.064, 0.241, 0.383, 0.133, 0.209, 0.165]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.159103661775589
[2m[36m(func pid=175366)[0m mae:  0.10720019042491913
[2m[36m(func pid=175366)[0m rmse_per_class: [0.086, 0.248, 0.046, 0.282, 0.056, 0.169, 0.297, 0.122, 0.143, 0.143]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.8989 | Steps: 2 | Val loss: 0.7079 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=176440)[0m rmse: 0.1911526620388031
[2m[36m(func pid=176440)[0m mae:  0.11035873740911484
[2m[36m(func pid=176440)[0m rmse_per_class: [0.111, 0.265, 0.042, 0.332, 0.056, 0.271, 0.273, 0.24, 0.2, 0.121]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18113622069358826
[2m[36m(func pid=187627)[0m mae:  0.132963165640831
[2m[36m(func pid=187627)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.122]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4956 | Steps: 2 | Val loss: 0.7472 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3847 | Steps: 2 | Val loss: 0.3054 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3874 | Steps: 2 | Val loss: 0.4368 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 06:18:40 (running for 00:22:31.28)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.395 |  0.159 |                   67 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.389 |  0.191 |                   62 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.496 |  0.216 |                   44 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.899 |  0.181 |                   14 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.21641449630260468
[2m[36m(func pid=180788)[0m mae:  0.11863778531551361
[2m[36m(func pid=180788)[0m rmse_per_class: [0.217, 0.29, 0.046, 0.356, 0.086, 0.228, 0.414, 0.174, 0.223, 0.131]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.16126468777656555
[2m[36m(func pid=175366)[0m mae:  0.10825373977422714
[2m[36m(func pid=175366)[0m rmse_per_class: [0.081, 0.253, 0.045, 0.282, 0.056, 0.17, 0.298, 0.117, 0.139, 0.171]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.8818 | Steps: 2 | Val loss: 0.6959 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=176440)[0m rmse: 0.18568623065948486
[2m[36m(func pid=176440)[0m mae:  0.10668756067752838
[2m[36m(func pid=176440)[0m rmse_per_class: [0.121, 0.262, 0.042, 0.342, 0.056, 0.249, 0.283, 0.199, 0.201, 0.102]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18119245767593384
[2m[36m(func pid=187627)[0m mae:  0.13299499452114105
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.105, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3698 | Steps: 2 | Val loss: 0.3070 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4782 | Steps: 2 | Val loss: 0.7488 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3698 | Steps: 2 | Val loss: 0.4272 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 06:18:45 (running for 00:22:36.65)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.385 |  0.161 |                   68 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.387 |  0.186 |                   63 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.478 |  0.215 |                   45 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.882 |  0.181 |                   15 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.2151980847120285
[2m[36m(func pid=180788)[0m mae:  0.1158672571182251
[2m[36m(func pid=180788)[0m rmse_per_class: [0.22, 0.288, 0.042, 0.338, 0.124, 0.242, 0.388, 0.177, 0.228, 0.104]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.16324105858802795
[2m[36m(func pid=175366)[0m mae:  0.10931031405925751
[2m[36m(func pid=175366)[0m rmse_per_class: [0.077, 0.258, 0.044, 0.278, 0.056, 0.173, 0.298, 0.114, 0.137, 0.198]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.8719 | Steps: 2 | Val loss: 0.6822 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=176440)[0m rmse: 0.18068353831768036
[2m[36m(func pid=176440)[0m mae:  0.10313867032527924
[2m[36m(func pid=176440)[0m rmse_per_class: [0.132, 0.26, 0.041, 0.351, 0.056, 0.218, 0.293, 0.163, 0.201, 0.091]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18121495842933655
[2m[36m(func pid=187627)[0m mae:  0.13299869000911713
[2m[36m(func pid=187627)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4693 | Steps: 2 | Val loss: 0.7158 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3582 | Steps: 2 | Val loss: 0.3092 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3557 | Steps: 2 | Val loss: 0.4233 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 06:18:50 (running for 00:22:41.88)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.37  |  0.163 |                   69 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.37  |  0.181 |                   64 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.469 |  0.209 |                   46 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.872 |  0.181 |                   16 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.209177166223526
[2m[36m(func pid=180788)[0m mae:  0.11134807765483856
[2m[36m(func pid=180788)[0m rmse_per_class: [0.227, 0.28, 0.04, 0.33, 0.146, 0.274, 0.344, 0.143, 0.221, 0.087]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.8541 | Steps: 2 | Val loss: 0.6713 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=175366)[0m rmse: 0.16541792452335358
[2m[36m(func pid=175366)[0m mae:  0.11062701046466827
[2m[36m(func pid=175366)[0m rmse_per_class: [0.073, 0.263, 0.042, 0.271, 0.056, 0.176, 0.298, 0.115, 0.134, 0.227]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.17738565802574158
[2m[36m(func pid=176440)[0m mae:  0.10104739665985107
[2m[36m(func pid=176440)[0m rmse_per_class: [0.137, 0.261, 0.04, 0.356, 0.055, 0.193, 0.306, 0.139, 0.204, 0.083]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.1812390387058258
[2m[36m(func pid=187627)[0m mae:  0.13299354910850525
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.105, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4734 | Steps: 2 | Val loss: 0.6511 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3576 | Steps: 2 | Val loss: 0.4233 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3676 | Steps: 2 | Val loss: 0.3128 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 06:18:56 (running for 00:22:47.10)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.358 |  0.165 |                   70 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.356 |  0.177 |                   65 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.473 |  0.205 |                   47 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.854 |  0.181 |                   17 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.20473608374595642
[2m[36m(func pid=180788)[0m mae:  0.10948264598846436
[2m[36m(func pid=180788)[0m rmse_per_class: [0.228, 0.271, 0.039, 0.327, 0.13, 0.281, 0.331, 0.149, 0.206, 0.085]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.8338 | Steps: 2 | Val loss: 0.6586 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=176440)[0m rmse: 0.17586243152618408
[2m[36m(func pid=176440)[0m mae:  0.09989772737026215
[2m[36m(func pid=176440)[0m rmse_per_class: [0.14, 0.268, 0.039, 0.359, 0.055, 0.178, 0.307, 0.126, 0.205, 0.081]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.16820427775382996
[2m[36m(func pid=175366)[0m mae:  0.11247893422842026
[2m[36m(func pid=175366)[0m rmse_per_class: [0.072, 0.267, 0.04, 0.263, 0.056, 0.18, 0.297, 0.123, 0.133, 0.252]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18123814463615417
[2m[36m(func pid=187627)[0m mae:  0.1329883635044098
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.267, 0.089, 0.324, 0.104, 0.194, 0.31, 0.155, 0.138, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4758 | Steps: 2 | Val loss: 0.5783 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3632 | Steps: 2 | Val loss: 0.4297 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3547 | Steps: 2 | Val loss: 0.3172 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=180788)[0m rmse: 0.1921154260635376
[2m[36m(func pid=180788)[0m mae:  0.10413320362567902
[2m[36m(func pid=180788)[0m rmse_per_class: [0.199, 0.261, 0.039, 0.315, 0.087, 0.249, 0.336, 0.154, 0.19, 0.09]
== Status ==
Current time: 2024-01-07 06:19:01 (running for 00:22:52.45)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.368 |  0.168 |                   71 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.358 |  0.176 |                   66 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.476 |  0.192 |                   48 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.834 |  0.181 |                   18 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.17569029331207275
[2m[36m(func pid=176440)[0m mae:  0.0998215451836586
[2m[36m(func pid=176440)[0m rmse_per_class: [0.136, 0.283, 0.038, 0.361, 0.055, 0.171, 0.299, 0.122, 0.211, 0.081]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.17146851122379303
[2m[36m(func pid=175366)[0m mae:  0.11453865468502045
[2m[36m(func pid=175366)[0m rmse_per_class: [0.072, 0.271, 0.038, 0.256, 0.056, 0.183, 0.295, 0.139, 0.132, 0.274]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.8207 | Steps: 2 | Val loss: 0.6473 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.5071 | Steps: 2 | Val loss: 0.5539 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=187627)[0m rmse: 0.18124523758888245
[2m[36m(func pid=187627)[0m mae:  0.1329956352710724
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.104, 0.194, 0.31, 0.155, 0.138, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3499 | Steps: 2 | Val loss: 0.4412 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3469 | Steps: 2 | Val loss: 0.3227 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 06:19:06 (running for 00:22:57.73)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.355 |  0.171 |                   72 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.35  |  0.177 |                   68 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.476 |  0.192 |                   48 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.821 |  0.181 |                   19 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=176440)[0m rmse: 0.17690154910087585
[2m[36m(func pid=176440)[0m mae:  0.10076749324798584
[2m[36m(func pid=176440)[0m rmse_per_class: [0.131, 0.306, 0.036, 0.362, 0.055, 0.171, 0.283, 0.123, 0.22, 0.082]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.18432381749153137
[2m[36m(func pid=180788)[0m mae:  0.10134804248809814
[2m[36m(func pid=180788)[0m rmse_per_class: [0.184, 0.255, 0.038, 0.311, 0.066, 0.209, 0.349, 0.152, 0.186, 0.093]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.17536072432994843
[2m[36m(func pid=175366)[0m mae:  0.11701729148626328
[2m[36m(func pid=175366)[0m rmse_per_class: [0.072, 0.273, 0.036, 0.252, 0.056, 0.187, 0.294, 0.16, 0.131, 0.293]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.8092 | Steps: 2 | Val loss: 0.6360 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3723 | Steps: 2 | Val loss: 0.4563 | Batch size: 32 | lr: 0.01 | Duration: 2.70s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.5292 | Steps: 2 | Val loss: 0.5601 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=187627)[0m rmse: 0.18129876255989075
[2m[36m(func pid=187627)[0m mae:  0.13299772143363953
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.194, 0.31, 0.155, 0.138, 0.124]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3634 | Steps: 2 | Val loss: 0.3287 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=176440)[0m rmse: 0.1790291965007782
[2m[36m(func pid=176440)[0m mae:  0.10256478935480118
[2m[36m(func pid=176440)[0m rmse_per_class: [0.121, 0.334, 0.035, 0.363, 0.056, 0.175, 0.267, 0.125, 0.232, 0.083]
[2m[36m(func pid=176440)[0m 
== Status ==
Current time: 2024-01-07 06:19:11 (running for 00:23:02.99)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.347 |  0.175 |                   73 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.372 |  0.179 |                   69 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.529 |  0.184 |                   50 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.809 |  0.181 |                   20 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.18356509506702423
[2m[36m(func pid=180788)[0m mae:  0.10024069249629974
[2m[36m(func pid=180788)[0m rmse_per_class: [0.171, 0.272, 0.037, 0.325, 0.063, 0.206, 0.317, 0.144, 0.211, 0.091]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.17929330468177795
[2m[36m(func pid=175366)[0m mae:  0.1194935217499733
[2m[36m(func pid=175366)[0m rmse_per_class: [0.073, 0.276, 0.034, 0.251, 0.056, 0.19, 0.293, 0.188, 0.13, 0.302]
[2m[36m(func pid=175366)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.7937 | Steps: 2 | Val loss: 0.6251 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3706 | Steps: 2 | Val loss: 0.4681 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4940 | Steps: 2 | Val loss: 0.6058 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=187627)[0m rmse: 0.18130755424499512
[2m[36m(func pid=187627)[0m mae:  0.1329837590456009
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.194, 0.31, 0.154, 0.138, 0.124]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=175366)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3760 | Steps: 2 | Val loss: 0.3350 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 06:19:16 (running for 00:23:08.02)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00009 | RUNNING    | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.363 |  0.179 |                   74 |
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.371 |  0.181 |                   70 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.529 |  0.184 |                   50 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.794 |  0.181 |                   21 |
| train_12613_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=176440)[0m rmse: 0.18094098567962646
[2m[36m(func pid=176440)[0m mae:  0.10413011163473129
[2m[36m(func pid=176440)[0m rmse_per_class: [0.106, 0.35, 0.033, 0.361, 0.059, 0.179, 0.26, 0.127, 0.25, 0.084]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.19552278518676758
[2m[36m(func pid=180788)[0m mae:  0.10633885860443115
[2m[36m(func pid=180788)[0m rmse_per_class: [0.161, 0.281, 0.036, 0.332, 0.06, 0.202, 0.296, 0.239, 0.258, 0.089]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=175366)[0m rmse: 0.18321916460990906
[2m[36m(func pid=175366)[0m mae:  0.12193518877029419
[2m[36m(func pid=175366)[0m rmse_per_class: [0.075, 0.279, 0.032, 0.253, 0.056, 0.193, 0.29, 0.219, 0.13, 0.306]
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.7801 | Steps: 2 | Val loss: 0.6146 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3757 | Steps: 2 | Val loss: 0.4762 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4769 | Steps: 2 | Val loss: 0.6590 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=187627)[0m rmse: 0.18123753368854523
[2m[36m(func pid=187627)[0m mae:  0.1329261213541031
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.31, 0.154, 0.138, 0.124]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.20648284256458282
[2m[36m(func pid=180788)[0m mae:  0.11353138834238052
[2m[36m(func pid=180788)[0m rmse_per_class: [0.188, 0.276, 0.04, 0.33, 0.056, 0.205, 0.314, 0.294, 0.275, 0.087]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.1826999932527542
[2m[36m(func pid=176440)[0m mae:  0.10567984730005264
[2m[36m(func pid=176440)[0m rmse_per_class: [0.091, 0.36, 0.032, 0.356, 0.067, 0.184, 0.251, 0.129, 0.271, 0.085]
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.7668 | Steps: 2 | Val loss: 0.6048 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4748 | Steps: 2 | Val loss: 0.6991 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=187627)[0m rmse: 0.1813039481639862
[2m[36m(func pid=187627)[0m mae:  0.13296440243721008
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.194, 0.309, 0.154, 0.139, 0.124]
== Status ==
Current time: 2024-01-07 06:19:22 (running for 00:23:13.40)
Memory usage on this node: 22.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.16899999603629112
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.371 |  0.181 |                   70 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.477 |  0.206 |                   52 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.78  |  0.181 |                   22 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=5093)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=5093)[0m Configuration completed!
[2m[36m(func pid=5093)[0m New optimizer parameters:
[2m[36m(func pid=5093)[0m SGD (
[2m[36m(func pid=5093)[0m Parameter Group 0
[2m[36m(func pid=5093)[0m     dampening: 0
[2m[36m(func pid=5093)[0m     differentiable: False
[2m[36m(func pid=5093)[0m     foreach: None
[2m[36m(func pid=5093)[0m     lr: 0.001
[2m[36m(func pid=5093)[0m     maximize: False
[2m[36m(func pid=5093)[0m     momentum: 0.9
[2m[36m(func pid=5093)[0m     nesterov: False
[2m[36m(func pid=5093)[0m     weight_decay: 0.0001
[2m[36m(func pid=5093)[0m )
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.20612356066703796
[2m[36m(func pid=180788)[0m mae:  0.1157459169626236
[2m[36m(func pid=180788)[0m rmse_per_class: [0.229, 0.29, 0.043, 0.343, 0.055, 0.215, 0.392, 0.174, 0.235, 0.085]
== Status ==
Current time: 2024-01-07 06:19:27 (running for 00:23:18.71)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.16899999603629112
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.376 |  0.183 |                   71 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.475 |  0.206 |                   53 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.767 |  0.181 |                   23 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3742 | Steps: 2 | Val loss: 0.4779 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.7539 | Steps: 2 | Val loss: 0.5953 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4613 | Steps: 2 | Val loss: 0.7572 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0803 | Steps: 2 | Val loss: 0.7947 | Batch size: 32 | lr: 0.001 | Duration: 4.47s
[2m[36m(func pid=176440)[0m rmse: 0.18406659364700317
[2m[36m(func pid=176440)[0m mae:  0.10657654702663422
[2m[36m(func pid=176440)[0m rmse_per_class: [0.081, 0.362, 0.03, 0.349, 0.083, 0.187, 0.245, 0.131, 0.287, 0.085]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18128037452697754
[2m[36m(func pid=187627)[0m mae:  0.13293017446994781
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.194, 0.309, 0.154, 0.139, 0.124]
[2m[36m(func pid=187627)[0m 
== Status ==
Current time: 2024-01-07 06:19:32 (running for 00:23:23.78)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.16899999603629112
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.374 |  0.184 |                   72 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.461 |  0.209 |                   54 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.754 |  0.181 |                   24 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.2093723714351654
[2m[36m(func pid=180788)[0m mae:  0.12050602585077286
[2m[36m(func pid=180788)[0m rmse_per_class: [0.269, 0.297, 0.046, 0.364, 0.056, 0.222, 0.416, 0.139, 0.197, 0.088]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.17863479256629944
[2m[36m(func pid=5093)[0m mae:  0.13113093376159668
[2m[36m(func pid=5093)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.325, 0.1, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3778 | Steps: 2 | Val loss: 0.4754 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.7397 | Steps: 2 | Val loss: 0.5862 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4544 | Steps: 2 | Val loss: 0.7678 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0339 | Steps: 2 | Val loss: 0.7600 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=176440)[0m rmse: 0.1850275695323944
[2m[36m(func pid=176440)[0m mae:  0.10655047744512558
[2m[36m(func pid=176440)[0m rmse_per_class: [0.072, 0.347, 0.029, 0.341, 0.107, 0.189, 0.244, 0.132, 0.304, 0.085]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18122367560863495
[2m[36m(func pid=187627)[0m mae:  0.13287712633609772
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.309, 0.154, 0.139, 0.124]
[2m[36m(func pid=187627)[0m 
== Status ==
Current time: 2024-01-07 06:19:37 (running for 00:23:29.02)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.16899999603629112
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.378 |  0.185 |                   73 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.454 |  0.216 |                   55 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.74  |  0.181 |                   25 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  1.08  |  0.179 |                    1 |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.21580097079277039
[2m[36m(func pid=180788)[0m mae:  0.12303797900676727
[2m[36m(func pid=180788)[0m rmse_per_class: [0.375, 0.293, 0.047, 0.369, 0.056, 0.234, 0.324, 0.146, 0.171, 0.143]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.1789730340242386
[2m[36m(func pid=5093)[0m mae:  0.13135384023189545
[2m[36m(func pid=5093)[0m rmse_per_class: [0.104, 0.266, 0.088, 0.325, 0.101, 0.193, 0.305, 0.155, 0.139, 0.115]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3961 | Steps: 2 | Val loss: 0.4669 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.7330 | Steps: 2 | Val loss: 0.5769 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.5218 | Steps: 2 | Val loss: 0.7833 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.9682 | Steps: 2 | Val loss: 0.7104 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=187627)[0m rmse: 0.1811419576406479
[2m[36m(func pid=187627)[0m mae:  0.13277491927146912
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.309, 0.153, 0.139, 0.124]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.18491661548614502
[2m[36m(func pid=176440)[0m mae:  0.1053105965256691
[2m[36m(func pid=176440)[0m rmse_per_class: [0.069, 0.32, 0.029, 0.33, 0.131, 0.191, 0.249, 0.133, 0.314, 0.085]
[2m[36m(func pid=176440)[0m 
[2m[36m(func pid=180788)[0m rmse: 0.2261768877506256
[2m[36m(func pid=180788)[0m mae:  0.12748059630393982
[2m[36m(func pid=180788)[0m rmse_per_class: [0.395, 0.284, 0.048, 0.371, 0.056, 0.224, 0.276, 0.147, 0.166, 0.297]
[2m[36m(func pid=180788)[0m 
== Status ==
Current time: 2024-01-07 06:19:43 (running for 00:23:34.37)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.16899999603629112
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00010 | RUNNING    | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.396 |  0.185 |                   74 |
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.522 |  0.226 |                   56 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.733 |  0.181 |                   26 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  1.034 |  0.179 |                    2 |
| train_12613_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=5093)[0m rmse: 0.179307222366333
[2m[36m(func pid=5093)[0m mae:  0.1315154731273651
[2m[36m(func pid=5093)[0m rmse_per_class: [0.104, 0.266, 0.089, 0.325, 0.102, 0.193, 0.305, 0.155, 0.139, 0.115]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.7286 | Steps: 2 | Val loss: 0.5685 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=176440)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3817 | Steps: 2 | Val loss: 0.4568 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.5138 | Steps: 2 | Val loss: 0.7791 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=187627)[0m rmse: 0.18105752766132355
[2m[36m(func pid=187627)[0m mae:  0.1326889991760254
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.309, 0.153, 0.138, 0.124]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=176440)[0m rmse: 0.18447791039943695
[2m[36m(func pid=176440)[0m mae:  0.10368207842111588
[2m[36m(func pid=176440)[0m rmse_per_class: [0.069, 0.296, 0.029, 0.32, 0.153, 0.19, 0.257, 0.133, 0.313, 0.084]
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8744 | Steps: 2 | Val loss: 0.6502 | Batch size: 32 | lr: 0.001 | Duration: 3.19s
[2m[36m(func pid=180788)[0m rmse: 0.22764115035533905
[2m[36m(func pid=180788)[0m mae:  0.12904703617095947
[2m[36m(func pid=180788)[0m rmse_per_class: [0.214, 0.316, 0.049, 0.372, 0.055, 0.204, 0.289, 0.147, 0.176, 0.455]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.7119 | Steps: 2 | Val loss: 0.5593 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=5093)[0m rmse: 0.17957819998264313
[2m[36m(func pid=5093)[0m mae:  0.13163986802101135
[2m[36m(func pid=5093)[0m rmse_per_class: [0.104, 0.267, 0.09, 0.324, 0.102, 0.193, 0.306, 0.156, 0.139, 0.115]
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.5038 | Steps: 2 | Val loss: 0.7252 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=187627)[0m rmse: 0.18099190294742584
[2m[36m(func pid=187627)[0m mae:  0.132621169090271
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.309, 0.154, 0.139, 0.123]
[2m[36m(func pid=180788)[0m rmse: 0.21957740187644958
[2m[36m(func pid=180788)[0m mae:  0.12689228355884552
[2m[36m(func pid=180788)[0m rmse_per_class: [0.12, 0.312, 0.048, 0.364, 0.055, 0.195, 0.307, 0.144, 0.173, 0.477]
== Status ==
Current time: 2024-01-07 06:19:48 (running for 00:23:39.75)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.514 |  0.228 |                   57 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.729 |  0.181 |                   27 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.968 |  0.179 |                    3 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=6491)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=6491)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=6491)[0m Configuration completed!
[2m[36m(func pid=6491)[0m New optimizer parameters:
[2m[36m(func pid=6491)[0m SGD (
[2m[36m(func pid=6491)[0m Parameter Group 0
[2m[36m(func pid=6491)[0m     dampening: 0
[2m[36m(func pid=6491)[0m     differentiable: False
[2m[36m(func pid=6491)[0m     foreach: None
[2m[36m(func pid=6491)[0m     lr: 0.01
[2m[36m(func pid=6491)[0m     maximize: False
[2m[36m(func pid=6491)[0m     momentum: 0.9
[2m[36m(func pid=6491)[0m     nesterov: False
[2m[36m(func pid=6491)[0m     weight_decay: 0.0001
[2m[36m(func pid=6491)[0m )
[2m[36m(func pid=6491)[0m 
== Status ==
Current time: 2024-01-07 06:19:55 (running for 00:23:46.46)
Memory usage on this node: 23.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.504 |  0.22  |                   58 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.729 |  0.181 |                   27 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.968 |  0.179 |                    3 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4763 | Steps: 2 | Val loss: 0.6413 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.7007 | Steps: 2 | Val loss: 0.5501 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7862 | Steps: 2 | Val loss: 0.5861 | Batch size: 32 | lr: 0.001 | Duration: 3.21s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0271 | Steps: 2 | Val loss: 0.6486 | Batch size: 32 | lr: 0.01 | Duration: 4.56s
== Status ==
Current time: 2024-01-07 06:20:00 (running for 00:23:51.47)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.504 |  0.22  |                   58 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.712 |  0.181 |                   28 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.874 |  0.18  |                    4 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.20959945023059845
[2m[36m(func pid=180788)[0m mae:  0.11857213079929352
[2m[36m(func pid=180788)[0m rmse_per_class: [0.125, 0.283, 0.047, 0.347, 0.055, 0.195, 0.328, 0.136, 0.181, 0.4]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18106292188167572
[2m[36m(func pid=187627)[0m mae:  0.132645383477211
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.308, 0.154, 0.139, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.17965184152126312
[2m[36m(func pid=5093)[0m mae:  0.13155949115753174
[2m[36m(func pid=5093)[0m rmse_per_class: [0.104, 0.267, 0.09, 0.325, 0.101, 0.193, 0.305, 0.157, 0.139, 0.115]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.1780402958393097
[2m[36m(func pid=6491)[0m mae:  0.13050392270088196
[2m[36m(func pid=6491)[0m rmse_per_class: [0.104, 0.267, 0.085, 0.325, 0.097, 0.192, 0.301, 0.155, 0.139, 0.114]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4395 | Steps: 2 | Val loss: 0.5788 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.6932 | Steps: 2 | Val loss: 0.5421 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.7030 | Steps: 2 | Val loss: 0.5246 | Batch size: 32 | lr: 0.001 | Duration: 3.20s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.7162 | Steps: 2 | Val loss: 0.4380 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 06:20:05 (running for 00:23:56.73)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.439 |  0.207 |                   60 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.701 |  0.181 |                   29 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.786 |  0.18  |                    5 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  1.027 |  0.178 |                    1 |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.20745031535625458
[2m[36m(func pid=180788)[0m mae:  0.1136055737733841
[2m[36m(func pid=180788)[0m rmse_per_class: [0.238, 0.285, 0.043, 0.33, 0.059, 0.204, 0.286, 0.139, 0.177, 0.315]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18110302090644836
[2m[36m(func pid=187627)[0m mae:  0.13263513147830963
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.103, 0.194, 0.308, 0.153, 0.139, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.17965345084667206
[2m[36m(func pid=5093)[0m mae:  0.13142114877700806
[2m[36m(func pid=5093)[0m rmse_per_class: [0.105, 0.268, 0.091, 0.325, 0.101, 0.194, 0.304, 0.156, 0.139, 0.115]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.1771250069141388
[2m[36m(func pid=6491)[0m mae:  0.12943415343761444
[2m[36m(func pid=6491)[0m rmse_per_class: [0.104, 0.269, 0.088, 0.327, 0.091, 0.192, 0.295, 0.155, 0.141, 0.11]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4387 | Steps: 2 | Val loss: 0.5763 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.6875 | Steps: 2 | Val loss: 0.5349 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.6236 | Steps: 2 | Val loss: 0.4711 | Batch size: 32 | lr: 0.001 | Duration: 3.13s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.4750 | Steps: 2 | Val loss: 0.3368 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 06:20:11 (running for 00:24:02.03)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.439 |  0.212 |                   61 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.693 |  0.181 |                   30 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.703 |  0.18  |                    6 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.716 |  0.177 |                    2 |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.21174319088459015
[2m[36m(func pid=180788)[0m mae:  0.11845364421606064
[2m[36m(func pid=180788)[0m rmse_per_class: [0.383, 0.294, 0.043, 0.325, 0.066, 0.211, 0.252, 0.163, 0.166, 0.213]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.1810900717973709
[2m[36m(func pid=187627)[0m mae:  0.1326301097869873
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.103, 0.194, 0.308, 0.153, 0.139, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.17948788404464722
[2m[36m(func pid=5093)[0m mae:  0.1311560720205307
[2m[36m(func pid=5093)[0m rmse_per_class: [0.105, 0.269, 0.092, 0.325, 0.099, 0.194, 0.302, 0.155, 0.139, 0.115]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.17585685849189758
[2m[36m(func pid=6491)[0m mae:  0.12811651825904846
[2m[36m(func pid=6491)[0m rmse_per_class: [0.105, 0.272, 0.092, 0.334, 0.085, 0.192, 0.284, 0.143, 0.146, 0.105]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4661 | Steps: 2 | Val loss: 0.5762 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.6754 | Steps: 2 | Val loss: 0.5282 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4204 | Steps: 2 | Val loss: 0.3255 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5673 | Steps: 2 | Val loss: 0.4288 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 06:20:16 (running for 00:24:07.19)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.466 |  0.209 |                   62 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.688 |  0.181 |                   31 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.624 |  0.179 |                    7 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.475 |  0.176 |                    3 |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.20907023549079895
[2m[36m(func pid=180788)[0m mae:  0.11524351686239243
[2m[36m(func pid=180788)[0m rmse_per_class: [0.37, 0.292, 0.043, 0.331, 0.088, 0.214, 0.256, 0.166, 0.188, 0.144]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18100716173648834
[2m[36m(func pid=187627)[0m mae:  0.1325463503599167
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.102, 0.194, 0.307, 0.153, 0.139, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.17463421821594238
[2m[36m(func pid=6491)[0m mae:  0.12635526061058044
[2m[36m(func pid=6491)[0m rmse_per_class: [0.108, 0.273, 0.093, 0.34, 0.078, 0.192, 0.276, 0.135, 0.152, 0.1]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.17923185229301453
[2m[36m(func pid=5093)[0m mae:  0.1308450847864151
[2m[36m(func pid=5093)[0m rmse_per_class: [0.106, 0.269, 0.092, 0.326, 0.099, 0.193, 0.3, 0.153, 0.14, 0.114]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4248 | Steps: 2 | Val loss: 0.5798 | Batch size: 32 | lr: 0.1 | Duration: 2.66s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.6671 | Steps: 2 | Val loss: 0.5210 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4423 | Steps: 2 | Val loss: 0.3439 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 06:20:21 (running for 00:24:12.31)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.425 |  0.2   |                   63 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.675 |  0.181 |                   32 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.567 |  0.179 |                    8 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.42  |  0.175 |                    4 |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.19971327483654022
[2m[36m(func pid=180788)[0m mae:  0.1068095937371254
[2m[36m(func pid=180788)[0m rmse_per_class: [0.211, 0.279, 0.042, 0.334, 0.113, 0.212, 0.326, 0.138, 0.236, 0.106]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5250 | Steps: 2 | Val loss: 0.3957 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=187627)[0m rmse: 0.18090203404426575
[2m[36m(func pid=187627)[0m mae:  0.1324600726366043
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.103, 0.194, 0.307, 0.153, 0.139, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.1738145351409912
[2m[36m(func pid=6491)[0m mae:  0.12446039915084839
[2m[36m(func pid=6491)[0m rmse_per_class: [0.108, 0.274, 0.087, 0.344, 0.07, 0.192, 0.276, 0.133, 0.157, 0.096]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3879 | Steps: 2 | Val loss: 0.6206 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=5093)[0m rmse: 0.17902997136116028
[2m[36m(func pid=5093)[0m mae:  0.13058561086654663
[2m[36m(func pid=5093)[0m rmse_per_class: [0.106, 0.269, 0.094, 0.327, 0.097, 0.193, 0.297, 0.151, 0.141, 0.114]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.6580 | Steps: 2 | Val loss: 0.5152 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4801 | Steps: 2 | Val loss: 0.3633 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 06:20:26 (running for 00:24:17.57)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.388 |  0.198 |                   64 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.667 |  0.181 |                   33 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.525 |  0.179 |                    9 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.442 |  0.174 |                    5 |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.19779014587402344
[2m[36m(func pid=180788)[0m mae:  0.10902927070856094
[2m[36m(func pid=180788)[0m rmse_per_class: [0.121, 0.289, 0.041, 0.34, 0.105, 0.206, 0.414, 0.137, 0.236, 0.088]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18086647987365723
[2m[36m(func pid=187627)[0m mae:  0.13241341710090637
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.269, 0.09, 0.324, 0.102, 0.194, 0.307, 0.152, 0.139, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4924 | Steps: 2 | Val loss: 0.3724 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=6491)[0m rmse: 0.173511803150177
[2m[36m(func pid=6491)[0m mae:  0.12285389751195908
[2m[36m(func pid=6491)[0m rmse_per_class: [0.108, 0.274, 0.079, 0.348, 0.064, 0.191, 0.282, 0.134, 0.16, 0.094]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3914 | Steps: 2 | Val loss: 0.6777 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=5093)[0m rmse: 0.1788593828678131
[2m[36m(func pid=5093)[0m mae:  0.1303410530090332
[2m[36m(func pid=5093)[0m rmse_per_class: [0.107, 0.27, 0.095, 0.329, 0.096, 0.193, 0.295, 0.149, 0.141, 0.114]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.6535 | Steps: 2 | Val loss: 0.5096 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 06:20:32 (running for 00:24:23.13)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.391 |  0.2   |                   65 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.658 |  0.181 |                   34 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.492 |  0.179 |                   10 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.48  |  0.174 |                    6 |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)

[2m[36m(func pid=180788)[0m rmse: 0.1997150033712387

[2m[36m(func pid=180788)[0m mae:  0.11240728944540024
[2m[36m(func pid=180788)[0m rmse_per_class: [0.11, 0.316, 0.041, 0.36, 0.087, 0.207, 0.431, 0.144, 0.213, 0.087]
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.5034 | Steps: 2 | Val loss: 0.3744 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18087130784988403
[2m[36m(func pid=187627)[0m mae:  0.1324269324541092
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.325, 0.102, 0.194, 0.307, 0.153, 0.139, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4665 | Steps: 2 | Val loss: 0.3552 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=6491)[0m rmse: 0.173122838139534
[2m[36m(func pid=6491)[0m mae:  0.12119551002979279
[2m[36m(func pid=6491)[0m rmse_per_class: [0.107, 0.273, 0.071, 0.349, 0.06, 0.191, 0.291, 0.136, 0.161, 0.093]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4658 | Steps: 2 | Val loss: 0.7327 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.6429 | Steps: 2 | Val loss: 0.5047 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=5093)[0m rmse: 0.17851053178310394
[2m[36m(func pid=5093)[0m mae:  0.12997280061244965
[2m[36m(func pid=5093)[0m rmse_per_class: [0.107, 0.27, 0.095, 0.329, 0.094, 0.193, 0.293, 0.147, 0.142, 0.114]
[2m[36m(func pid=5093)[0m 
== Status ==
Current time: 2024-01-07 06:20:37 (running for 00:24:28.35)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.466 |  0.202 |                   66 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.653 |  0.181 |                   35 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.467 |  0.179 |                   11 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.503 |  0.173 |                    7 |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.20160198211669922
[2m[36m(func pid=180788)[0m mae:  0.11310170590877533
[2m[36m(func pid=180788)[0m rmse_per_class: [0.18, 0.305, 0.043, 0.372, 0.075, 0.252, 0.371, 0.14, 0.191, 0.087]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.1808585375547409
[2m[36m(func pid=187627)[0m mae:  0.13240602612495422
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.102, 0.194, 0.307, 0.152, 0.139, 0.122]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5098 | Steps: 2 | Val loss: 0.3750 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4444 | Steps: 2 | Val loss: 0.3435 | Batch size: 32 | lr: 0.001 | Duration: 3.15s
[2m[36m(func pid=6491)[0m rmse: 0.17253321409225464
[2m[36m(func pid=6491)[0m mae:  0.11948327720165253
[2m[36m(func pid=6491)[0m rmse_per_class: [0.106, 0.271, 0.062, 0.349, 0.057, 0.191, 0.3, 0.138, 0.16, 0.092]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4380 | Steps: 2 | Val loss: 0.7804 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.6338 | Steps: 2 | Val loss: 0.4982 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=5093)[0m rmse: 0.17822279036045074
[2m[36m(func pid=5093)[0m mae:  0.12966135144233704
[2m[36m(func pid=5093)[0m rmse_per_class: [0.108, 0.271, 0.095, 0.33, 0.092, 0.193, 0.291, 0.145, 0.143, 0.114]
[2m[36m(func pid=5093)[0m 
== Status ==
Current time: 2024-01-07 06:20:42 (running for 00:24:33.59)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.438 |  0.21  |                   67 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.643 |  0.181 |                   36 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.444 |  0.178 |                   12 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.51  |  0.173 |                    8 |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.2099514901638031
[2m[36m(func pid=180788)[0m mae:  0.12136121839284897
[2m[36m(func pid=180788)[0m rmse_per_class: [0.366, 0.287, 0.044, 0.374, 0.063, 0.294, 0.29, 0.132, 0.163, 0.087]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.1808871030807495
[2m[36m(func pid=187627)[0m mae:  0.13240158557891846
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.325, 0.102, 0.194, 0.307, 0.152, 0.139, 0.123]
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5050 | Steps: 2 | Val loss: 0.3673 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4334 | Steps: 2 | Val loss: 0.3351 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4827 | Steps: 2 | Val loss: 0.7943 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=6491)[0m rmse: 0.17197397351264954
[2m[36m(func pid=6491)[0m mae:  0.11819092929363251
[2m[36m(func pid=6491)[0m rmse_per_class: [0.105, 0.27, 0.056, 0.348, 0.056, 0.19, 0.304, 0.139, 0.159, 0.092]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.6316 | Steps: 2 | Val loss: 0.4929 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=5093)[0m rmse: 0.1778402328491211
[2m[36m(func pid=5093)[0m mae:  0.12926208972930908
[2m[36m(func pid=5093)[0m rmse_per_class: [0.109, 0.271, 0.095, 0.33, 0.092, 0.194, 0.289, 0.143, 0.143, 0.113]
[2m[36m(func pid=5093)[0m 
== Status ==
Current time: 2024-01-07 06:20:47 (running for 00:24:38.91)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.483 |  0.217 |                   68 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.634 |  0.181 |                   37 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.433 |  0.178 |                   13 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.505 |  0.172 |                    9 |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.216700479388237
[2m[36m(func pid=180788)[0m mae:  0.1272248923778534
[2m[36m(func pid=180788)[0m rmse_per_class: [0.446, 0.29, 0.047, 0.37, 0.058, 0.277, 0.282, 0.157, 0.153, 0.088]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18089114129543304
[2m[36m(func pid=187627)[0m mae:  0.13240036368370056
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.325, 0.102, 0.194, 0.307, 0.152, 0.14, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4944 | Steps: 2 | Val loss: 0.3523 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4273 | Steps: 2 | Val loss: 0.3296 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4561 | Steps: 2 | Val loss: 0.7342 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=6491)[0m rmse: 0.17050689458847046
[2m[36m(func pid=6491)[0m mae:  0.11695907264947891
[2m[36m(func pid=6491)[0m rmse_per_class: [0.104, 0.267, 0.052, 0.346, 0.056, 0.189, 0.298, 0.14, 0.161, 0.092]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.6203 | Steps: 2 | Val loss: 0.4878 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=5093)[0m rmse: 0.17744331061840057
[2m[36m(func pid=5093)[0m mae:  0.12887248396873474
[2m[36m(func pid=5093)[0m rmse_per_class: [0.109, 0.271, 0.093, 0.331, 0.091, 0.194, 0.287, 0.141, 0.144, 0.113]
[2m[36m(func pid=5093)[0m 
== Status ==
Current time: 2024-01-07 06:20:53 (running for 00:24:44.11)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.456 |  0.211 |                   69 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.632 |  0.181 |                   38 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.427 |  0.177 |                   14 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.494 |  0.171 |                   10 |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.2113698273897171
[2m[36m(func pid=180788)[0m mae:  0.12039320170879364
[2m[36m(func pid=180788)[0m rmse_per_class: [0.321, 0.289, 0.048, 0.359, 0.057, 0.228, 0.372, 0.186, 0.163, 0.091]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18087486922740936
[2m[36m(func pid=187627)[0m mae:  0.13236390054225922
[2m[36m(func pid=187627)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.102, 0.194, 0.306, 0.152, 0.14, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4703 | Steps: 2 | Val loss: 0.3347 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4211 | Steps: 2 | Val loss: 0.3266 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4369 | Steps: 2 | Val loss: 0.6425 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.6146 | Steps: 2 | Val loss: 0.4826 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=6491)[0m rmse: 0.16826799511909485
[2m[36m(func pid=6491)[0m mae:  0.11568576097488403
[2m[36m(func pid=6491)[0m rmse_per_class: [0.104, 0.264, 0.05, 0.341, 0.055, 0.189, 0.284, 0.14, 0.164, 0.092]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.17719818651676178
[2m[36m(func pid=5093)[0m mae:  0.12868395447731018
[2m[36m(func pid=5093)[0m rmse_per_class: [0.11, 0.271, 0.092, 0.331, 0.089, 0.194, 0.286, 0.14, 0.145, 0.113]
[2m[36m(func pid=5093)[0m 
== Status ==
Current time: 2024-01-07 06:20:58 (running for 00:24:49.35)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.437 |  0.202 |                   70 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.62  |  0.181 |                   39 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.421 |  0.177 |                   15 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.47  |  0.168 |                   11 |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.2019730508327484
[2m[36m(func pid=180788)[0m mae:  0.11541358381509781
[2m[36m(func pid=180788)[0m rmse_per_class: [0.143, 0.284, 0.049, 0.344, 0.056, 0.204, 0.493, 0.161, 0.185, 0.101]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18087153136730194
[2m[36m(func pid=187627)[0m mae:  0.13234104216098785
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.325, 0.102, 0.194, 0.306, 0.152, 0.14, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4434 | Steps: 2 | Val loss: 0.3172 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3963 | Steps: 2 | Val loss: 0.5716 | Batch size: 32 | lr: 0.1 | Duration: 2.68s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.4160 | Steps: 2 | Val loss: 0.3244 | Batch size: 32 | lr: 0.001 | Duration: 3.22s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.6080 | Steps: 2 | Val loss: 0.4777 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=6491)[0m rmse: 0.165536031126976
[2m[36m(func pid=6491)[0m mae:  0.11450368165969849
[2m[36m(func pid=6491)[0m rmse_per_class: [0.104, 0.261, 0.049, 0.334, 0.055, 0.188, 0.268, 0.139, 0.165, 0.092]
[2m[36m(func pid=6491)[0m 
== Status ==
Current time: 2024-01-07 06:21:03 (running for 00:24:54.44)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.396 |  0.195 |                   71 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.615 |  0.181 |                   40 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.421 |  0.177 |                   15 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.443 |  0.166 |                   12 |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.195216566324234
[2m[36m(func pid=180788)[0m mae:  0.1096881628036499
[2m[36m(func pid=180788)[0m rmse_per_class: [0.091, 0.28, 0.049, 0.334, 0.055, 0.209, 0.443, 0.15, 0.198, 0.144]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.17685185372829437
[2m[36m(func pid=5093)[0m mae:  0.12838247418403625
[2m[36m(func pid=5093)[0m rmse_per_class: [0.11, 0.271, 0.091, 0.331, 0.088, 0.193, 0.285, 0.139, 0.146, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.1807635873556137
[2m[36m(func pid=187627)[0m mae:  0.1322437822818756
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.325, 0.102, 0.194, 0.306, 0.151, 0.14, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4143 | Steps: 2 | Val loss: 0.3038 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4220 | Steps: 2 | Val loss: 0.5659 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.6009 | Steps: 2 | Val loss: 0.4725 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4163 | Steps: 2 | Val loss: 0.3232 | Batch size: 32 | lr: 0.001 | Duration: 3.20s
[2m[36m(func pid=6491)[0m rmse: 0.16324588656425476
[2m[36m(func pid=6491)[0m mae:  0.11373970657587051
[2m[36m(func pid=6491)[0m rmse_per_class: [0.107, 0.259, 0.048, 0.326, 0.055, 0.188, 0.255, 0.137, 0.166, 0.092]
[2m[36m(func pid=6491)[0m 
== Status ==
Current time: 2024-01-07 06:21:08 (running for 00:24:59.72)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.422 |  0.2   |                   72 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.608 |  0.181 |                   41 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.416 |  0.177 |                   16 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.414 |  0.163 |                   13 |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.20044879615306854
[2m[36m(func pid=180788)[0m mae:  0.10884195566177368
[2m[36m(func pid=180788)[0m rmse_per_class: [0.091, 0.292, 0.047, 0.334, 0.056, 0.265, 0.304, 0.145, 0.21, 0.259]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18066366016864777
[2m[36m(func pid=187627)[0m mae:  0.1321745067834854
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.269, 0.09, 0.325, 0.102, 0.194, 0.305, 0.151, 0.14, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.17667493224143982
[2m[36m(func pid=5093)[0m mae:  0.12822088599205017
[2m[36m(func pid=5093)[0m rmse_per_class: [0.111, 0.271, 0.091, 0.332, 0.087, 0.194, 0.285, 0.139, 0.147, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.3942 | Steps: 2 | Val loss: 0.2952 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4118 | Steps: 2 | Val loss: 0.6024 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.5989 | Steps: 2 | Val loss: 0.4680 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=6491)[0m rmse: 0.16161678731441498
[2m[36m(func pid=6491)[0m mae:  0.11344848573207855
[2m[36m(func pid=6491)[0m rmse_per_class: [0.107, 0.257, 0.048, 0.317, 0.055, 0.187, 0.253, 0.134, 0.163, 0.094]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4133 | Steps: 2 | Val loss: 0.3223 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 06:21:13 (running for 00:25:04.84)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.412 |  0.217 |                   73 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.601 |  0.181 |                   42 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.416 |  0.177 |                   17 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.394 |  0.162 |                   14 |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.21674779057502747
[2m[36m(func pid=180788)[0m mae:  0.120582714676857
[2m[36m(func pid=180788)[0m rmse_per_class: [0.115, 0.297, 0.046, 0.338, 0.06, 0.294, 0.286, 0.139, 0.208, 0.384]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18062403798103333
[2m[36m(func pid=187627)[0m mae:  0.13214023411273956
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.269, 0.09, 0.325, 0.101, 0.194, 0.305, 0.151, 0.14, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.1763906180858612
[2m[36m(func pid=5093)[0m mae:  0.12799641489982605
[2m[36m(func pid=5093)[0m rmse_per_class: [0.111, 0.271, 0.09, 0.332, 0.086, 0.194, 0.284, 0.138, 0.147, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.3783 | Steps: 2 | Val loss: 0.2918 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4181 | Steps: 2 | Val loss: 0.6299 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.5882 | Steps: 2 | Val loss: 0.4640 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=6491)[0m rmse: 0.1605808138847351
[2m[36m(func pid=6491)[0m mae:  0.11331586539745331
[2m[36m(func pid=6491)[0m rmse_per_class: [0.107, 0.257, 0.048, 0.307, 0.055, 0.185, 0.258, 0.131, 0.161, 0.096]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.4119 | Steps: 2 | Val loss: 0.3219 | Batch size: 32 | lr: 0.001 | Duration: 3.13s
== Status ==
Current time: 2024-01-07 06:21:18 (running for 00:25:09.94)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.17099999636411667
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00011 | RUNNING    | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.418 |  0.223 |                   74 |
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.599 |  0.181 |                   43 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.413 |  0.176 |                   18 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.378 |  0.161 |                   15 |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.22263522446155548
[2m[36m(func pid=180788)[0m mae:  0.12506845593452454
[2m[36m(func pid=180788)[0m rmse_per_class: [0.208, 0.278, 0.045, 0.342, 0.07, 0.247, 0.282, 0.144, 0.193, 0.417]
[2m[36m(func pid=180788)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.180645152926445
[2m[36m(func pid=187627)[0m mae:  0.1321398913860321
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.269, 0.09, 0.325, 0.101, 0.194, 0.305, 0.151, 0.14, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3778 | Steps: 2 | Val loss: 0.2919 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=5093)[0m rmse: 0.17617307603359222
[2m[36m(func pid=5093)[0m mae:  0.12780214846134186
[2m[36m(func pid=5093)[0m rmse_per_class: [0.111, 0.271, 0.089, 0.332, 0.085, 0.194, 0.283, 0.138, 0.147, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=180788)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4003 | Steps: 2 | Val loss: 0.6464 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.5862 | Steps: 2 | Val loss: 0.4602 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=6491)[0m rmse: 0.15965315699577332
[2m[36m(func pid=6491)[0m mae:  0.11315862834453583
[2m[36m(func pid=6491)[0m rmse_per_class: [0.105, 0.255, 0.047, 0.3, 0.055, 0.184, 0.265, 0.127, 0.156, 0.103]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4119 | Steps: 2 | Val loss: 0.3210 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 06:21:24 (running for 00:25:15.23)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 3 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.588 |  0.181 |                   44 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.412 |  0.176 |                   19 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.378 |  0.16  |                   16 |
| train_12613_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 TERMINATED)


[2m[36m(func pid=180788)[0m rmse: 0.218331977725029
[2m[36m(func pid=180788)[0m mae:  0.1231193095445633
[2m[36m(func pid=180788)[0m rmse_per_class: [0.259, 0.28, 0.044, 0.351, 0.069, 0.205, 0.33, 0.149, 0.174, 0.321]
[2m[36m(func pid=187627)[0m rmse: 0.18059740960597992
[2m[36m(func pid=187627)[0m mae:  0.13209563493728638
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.269, 0.09, 0.325, 0.101, 0.194, 0.305, 0.151, 0.14, 0.122]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3683 | Steps: 2 | Val loss: 0.2930 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=5093)[0m rmse: 0.17565903067588806
[2m[36m(func pid=5093)[0m mae:  0.1273907572031021
[2m[36m(func pid=5093)[0m rmse_per_class: [0.111, 0.271, 0.088, 0.331, 0.083, 0.193, 0.282, 0.137, 0.147, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.5819 | Steps: 2 | Val loss: 0.4560 | Batch size: 32 | lr: 0.0001 | Duration: 2.73s
[2m[36m(func pid=6491)[0m rmse: 0.159336656332016
[2m[36m(func pid=6491)[0m mae:  0.11327533423900604
[2m[36m(func pid=6491)[0m rmse_per_class: [0.103, 0.253, 0.047, 0.295, 0.055, 0.183, 0.271, 0.125, 0.149, 0.111]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4131 | Steps: 2 | Val loss: 0.3208 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=187627)[0m rmse: 0.1805497258901596
[2m[36m(func pid=187627)[0m mae:  0.13203558325767517
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.269, 0.09, 0.325, 0.101, 0.194, 0.305, 0.151, 0.14, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3552 | Steps: 2 | Val loss: 0.2939 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=5093)[0m rmse: 0.17542019486427307
[2m[36m(func pid=5093)[0m mae:  0.1272220015525818
[2m[36m(func pid=5093)[0m rmse_per_class: [0.111, 0.271, 0.088, 0.331, 0.082, 0.193, 0.282, 0.137, 0.148, 0.112]
== Status ==
Current time: 2024-01-07 06:21:30 (running for 00:25:21.43)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.582 |  0.181 |                   46 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.412 |  0.176 |                   20 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.368 |  0.159 |                   17 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=10475)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=10475)[0m Configuration completed!
[2m[36m(func pid=10475)[0m New optimizer parameters:
[2m[36m(func pid=10475)[0m SGD (
[2m[36m(func pid=10475)[0m Parameter Group 0
[2m[36m(func pid=10475)[0m     dampening: 0
[2m[36m(func pid=10475)[0m     differentiable: False
[2m[36m(func pid=10475)[0m     foreach: None
[2m[36m(func pid=10475)[0m     lr: 0.1
[2m[36m(func pid=10475)[0m     maximize: False
[2m[36m(func pid=10475)[0m     momentum: 0.9
[2m[36m(func pid=10475)[0m     nesterov: False
[2m[36m(func pid=10475)[0m     weight_decay: 0.0001
[2m[36m(func pid=10475)[0m )
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.5792 | Steps: 2 | Val loss: 0.4521 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=6491)[0m rmse: 0.15971210598945618
[2m[36m(func pid=6491)[0m mae:  0.11362919956445694
[2m[36m(func pid=6491)[0m rmse_per_class: [0.1, 0.253, 0.047, 0.291, 0.055, 0.182, 0.276, 0.128, 0.144, 0.121]
[2m[36m(func pid=6491)[0m 
== Status ==
Current time: 2024-01-07 06:21:35 (running for 00:25:26.68)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.579 |  0.181 |                   47 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.413 |  0.175 |                   21 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.355 |  0.16  |                   18 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.1805098056793213
[2m[36m(func pid=187627)[0m mae:  0.1319805085659027
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.326, 0.101, 0.194, 0.304, 0.151, 0.14, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4101 | Steps: 2 | Val loss: 0.3203 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3591 | Steps: 2 | Val loss: 0.2942 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.7691 | Steps: 2 | Val loss: 0.3247 | Batch size: 32 | lr: 0.1 | Duration: 4.23s
[2m[36m(func pid=5093)[0m rmse: 0.1750599890947342
[2m[36m(func pid=5093)[0m mae:  0.12695108354091644
[2m[36m(func pid=5093)[0m rmse_per_class: [0.111, 0.27, 0.086, 0.331, 0.081, 0.193, 0.282, 0.137, 0.148, 0.112]
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.5726 | Steps: 2 | Val loss: 0.4482 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.17222502827644348
[2m[36m(func pid=10475)[0m mae:  0.12401727586984634
[2m[36m(func pid=10475)[0m rmse_per_class: [0.105, 0.274, 0.085, 0.342, 0.072, 0.192, 0.276, 0.132, 0.147, 0.097]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.16038981080055237
[2m[36m(func pid=6491)[0m mae:  0.11402305215597153
[2m[36m(func pid=6491)[0m rmse_per_class: [0.095, 0.254, 0.049, 0.288, 0.055, 0.181, 0.277, 0.135, 0.142, 0.128]
[2m[36m(func pid=6491)[0m 
== Status ==
Current time: 2024-01-07 06:21:41 (running for 00:25:32.09)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.573 |  0.18  |                   48 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.41  |  0.175 |                   22 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.359 |  0.16  |                   19 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.769 |  0.172 |                    1 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.18045927584171295
[2m[36m(func pid=187627)[0m mae:  0.13196326792240143
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.326, 0.1, 0.194, 0.304, 0.151, 0.14, 0.123]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4108 | Steps: 2 | Val loss: 0.3197 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.5521 | Steps: 2 | Val loss: 0.4338 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3578 | Steps: 2 | Val loss: 0.2946 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.5656 | Steps: 2 | Val loss: 0.4439 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=5093)[0m rmse: 0.17467142641544342
[2m[36m(func pid=5093)[0m mae:  0.12664088606834412
[2m[36m(func pid=5093)[0m rmse_per_class: [0.111, 0.27, 0.085, 0.331, 0.08, 0.193, 0.281, 0.137, 0.148, 0.111]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.182514950633049
[2m[36m(func pid=10475)[0m mae:  0.12153388559818268
[2m[36m(func pid=10475)[0m rmse_per_class: [0.098, 0.281, 0.055, 0.367, 0.056, 0.192, 0.397, 0.144, 0.142, 0.094]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.16169126331806183
[2m[36m(func pid=6491)[0m mae:  0.1147007942199707
[2m[36m(func pid=6491)[0m rmse_per_class: [0.091, 0.256, 0.051, 0.289, 0.056, 0.181, 0.275, 0.143, 0.139, 0.134]
[2m[36m(func pid=6491)[0m 
== Status ==
Current time: 2024-01-07 06:21:46 (running for 00:25:37.48)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.566 |  0.18  |                   49 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.411 |  0.175 |                   23 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.358 |  0.162 |                   20 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.552 |  0.183 |                    2 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.1804029494524002
[2m[36m(func pid=187627)[0m mae:  0.13190792500972748
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.269, 0.09, 0.326, 0.1, 0.194, 0.304, 0.15, 0.14, 0.122]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4077 | Steps: 2 | Val loss: 0.3194 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.7363 | Steps: 2 | Val loss: 0.4604 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3413 | Steps: 2 | Val loss: 0.2948 | Batch size: 32 | lr: 0.01 | Duration: 3.15s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.5642 | Steps: 2 | Val loss: 0.4408 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=5093)[0m rmse: 0.17445071041584015
[2m[36m(func pid=5093)[0m mae:  0.12642744183540344
[2m[36m(func pid=5093)[0m rmse_per_class: [0.111, 0.27, 0.084, 0.331, 0.079, 0.193, 0.28, 0.137, 0.148, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.19145330786705017
[2m[36m(func pid=10475)[0m mae:  0.1231863871216774
[2m[36m(func pid=10475)[0m rmse_per_class: [0.096, 0.279, 0.048, 0.378, 0.056, 0.187, 0.485, 0.153, 0.137, 0.096]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.1623217761516571
[2m[36m(func pid=6491)[0m mae:  0.1149771437048912
[2m[36m(func pid=6491)[0m rmse_per_class: [0.089, 0.257, 0.055, 0.292, 0.059, 0.181, 0.272, 0.148, 0.141, 0.13]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18038839101791382
[2m[36m(func pid=187627)[0m mae:  0.1318710893392563
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.269, 0.09, 0.325, 0.1, 0.194, 0.304, 0.151, 0.14, 0.122]
[2m[36m(func pid=187627)[0m 
== Status ==
Current time: 2024-01-07 06:21:51 (running for 00:25:42.92)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.564 |  0.18  |                   50 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.408 |  0.174 |                   24 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.341 |  0.162 |                   21 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.736 |  0.191 |                    3 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.7184 | Steps: 2 | Val loss: 0.3905 | Batch size: 32 | lr: 0.1 | Duration: 2.66s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4078 | Steps: 2 | Val loss: 0.3188 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3365 | Steps: 2 | Val loss: 0.2946 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.5591 | Steps: 2 | Val loss: 0.4376 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
[2m[36m(func pid=10475)[0m rmse: 0.18211160600185394
[2m[36m(func pid=10475)[0m mae:  0.11793993413448334
[2m[36m(func pid=10475)[0m rmse_per_class: [0.088, 0.262, 0.049, 0.373, 0.056, 0.189, 0.413, 0.155, 0.14, 0.097]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.17408111691474915
[2m[36m(func pid=5093)[0m mae:  0.12615889310836792
[2m[36m(func pid=5093)[0m rmse_per_class: [0.111, 0.27, 0.083, 0.33, 0.078, 0.193, 0.28, 0.136, 0.148, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.16214004158973694
[2m[36m(func pid=6491)[0m mae:  0.1145949736237526
[2m[36m(func pid=6491)[0m rmse_per_class: [0.088, 0.257, 0.058, 0.293, 0.064, 0.181, 0.267, 0.148, 0.142, 0.123]
[2m[36m(func pid=6491)[0m 
== Status ==
Current time: 2024-01-07 06:21:57 (running for 00:25:48.08)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.559 |  0.181 |                   51 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.408 |  0.174 |                   25 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.336 |  0.162 |                   22 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.718 |  0.182 |                    4 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.18052121996879578
[2m[36m(func pid=187627)[0m mae:  0.13193434476852417
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.326, 0.101, 0.194, 0.304, 0.151, 0.14, 0.121]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.5659 | Steps: 2 | Val loss: 0.3506 | Batch size: 32 | lr: 0.1 | Duration: 2.61s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4091 | Steps: 2 | Val loss: 0.3182 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3397 | Steps: 2 | Val loss: 0.2940 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.5574 | Steps: 2 | Val loss: 0.4344 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=10475)[0m rmse: 0.16755300760269165
[2m[36m(func pid=10475)[0m mae:  0.11552281677722931
[2m[36m(func pid=10475)[0m rmse_per_class: [0.09, 0.259, 0.049, 0.334, 0.056, 0.205, 0.239, 0.155, 0.192, 0.097]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.1737472116947174
[2m[36m(func pid=5093)[0m mae:  0.1259227842092514
[2m[36m(func pid=5093)[0m rmse_per_class: [0.111, 0.269, 0.082, 0.329, 0.077, 0.193, 0.28, 0.136, 0.148, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.1612946093082428
[2m[36m(func pid=6491)[0m mae:  0.11377173662185669
[2m[36m(func pid=6491)[0m rmse_per_class: [0.087, 0.257, 0.062, 0.294, 0.071, 0.18, 0.261, 0.141, 0.144, 0.115]
[2m[36m(func pid=6491)[0m 
== Status ==
Current time: 2024-01-07 06:22:02 (running for 00:25:53.49)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.557 |  0.18  |                   52 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.409 |  0.174 |                   26 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.34  |  0.161 |                   23 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.566 |  0.168 |                    5 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.18046294152736664
[2m[36m(func pid=187627)[0m mae:  0.13187450170516968
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.1, 0.194, 0.303, 0.15, 0.14, 0.122]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.5350 | Steps: 2 | Val loss: 0.3350 | Batch size: 32 | lr: 0.1 | Duration: 2.64s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4080 | Steps: 2 | Val loss: 0.3176 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3300 | Steps: 2 | Val loss: 0.2928 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=10475)[0m rmse: 0.16152718663215637
[2m[36m(func pid=10475)[0m mae:  0.10983222723007202
[2m[36m(func pid=10475)[0m rmse_per_class: [0.107, 0.244, 0.047, 0.288, 0.056, 0.173, 0.287, 0.15, 0.17, 0.093]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.5497 | Steps: 2 | Val loss: 0.4313 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=6491)[0m rmse: 0.1601850390434265
[2m[36m(func pid=6491)[0m mae:  0.11272597312927246
[2m[36m(func pid=6491)[0m rmse_per_class: [0.085, 0.256, 0.063, 0.295, 0.08, 0.179, 0.255, 0.134, 0.145, 0.109]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.17345896363258362
[2m[36m(func pid=5093)[0m mae:  0.1256885826587677
[2m[36m(func pid=5093)[0m rmse_per_class: [0.111, 0.269, 0.081, 0.328, 0.077, 0.193, 0.28, 0.136, 0.148, 0.111]
[2m[36m(func pid=5093)[0m 
== Status ==
Current time: 2024-01-07 06:22:07 (running for 00:25:58.79)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.55  |  0.18  |                   53 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.408 |  0.173 |                   27 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.33  |  0.16  |                   24 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.535 |  0.162 |                    6 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.18042103946208954
[2m[36m(func pid=187627)[0m mae:  0.13183313608169556
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.1, 0.194, 0.303, 0.15, 0.14, 0.122]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4098 | Steps: 2 | Val loss: 0.2895 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3294 | Steps: 2 | Val loss: 0.2912 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4120 | Steps: 2 | Val loss: 0.3171 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
[2m[36m(func pid=10475)[0m rmse: 0.15788540244102478
[2m[36m(func pid=10475)[0m mae:  0.10387341678142548
[2m[36m(func pid=10475)[0m rmse_per_class: [0.068, 0.263, 0.029, 0.276, 0.056, 0.177, 0.26, 0.113, 0.131, 0.206]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.5470 | Steps: 2 | Val loss: 0.4286 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=6491)[0m rmse: 0.15901567041873932
[2m[36m(func pid=6491)[0m mae:  0.11170194298028946
[2m[36m(func pid=6491)[0m rmse_per_class: [0.084, 0.255, 0.061, 0.296, 0.088, 0.178, 0.252, 0.128, 0.145, 0.104]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.17315492033958435
[2m[36m(func pid=5093)[0m mae:  0.12542937695980072
[2m[36m(func pid=5093)[0m rmse_per_class: [0.11, 0.269, 0.08, 0.328, 0.076, 0.193, 0.279, 0.136, 0.148, 0.111]
[2m[36m(func pid=5093)[0m 
== Status ==
Current time: 2024-01-07 06:22:12 (running for 00:26:03.87)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.547 |  0.18  |                   54 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.412 |  0.173 |                   28 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.329 |  0.159 |                   25 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.41  |  0.158 |                    7 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.18046636879444122
[2m[36m(func pid=187627)[0m mae:  0.1318652331829071
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.1, 0.194, 0.303, 0.15, 0.14, 0.122]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.3576 | Steps: 2 | Val loss: 0.3438 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3246 | Steps: 2 | Val loss: 0.2898 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=10475)[0m rmse: 0.18931417167186737
[2m[36m(func pid=10475)[0m mae:  0.12405461072921753
[2m[36m(func pid=10475)[0m rmse_per_class: [0.09, 0.27, 0.082, 0.307, 0.055, 0.193, 0.239, 0.332, 0.132, 0.193]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.5416 | Steps: 2 | Val loss: 0.4265 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4065 | Steps: 2 | Val loss: 0.3168 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=6491)[0m rmse: 0.15805268287658691
[2m[36m(func pid=6491)[0m mae:  0.11093229055404663
[2m[36m(func pid=6491)[0m rmse_per_class: [0.084, 0.252, 0.058, 0.297, 0.092, 0.178, 0.249, 0.124, 0.145, 0.102]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.3857 | Steps: 2 | Val loss: 0.3087 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 06:22:18 (running for 00:26:09.26)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.542 |  0.18  |                   55 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.412 |  0.173 |                   28 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.325 |  0.158 |                   26 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.358 |  0.189 |                    8 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.18042190372943878
[2m[36m(func pid=187627)[0m mae:  0.13182318210601807
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.1, 0.194, 0.303, 0.15, 0.141, 0.122]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.17296066880226135
[2m[36m(func pid=5093)[0m mae:  0.1253199279308319
[2m[36m(func pid=5093)[0m rmse_per_class: [0.11, 0.269, 0.079, 0.328, 0.076, 0.193, 0.279, 0.136, 0.149, 0.111]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3242 | Steps: 2 | Val loss: 0.2873 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=10475)[0m rmse: 0.16593506932258606
[2m[36m(func pid=10475)[0m mae:  0.10648074001073837
[2m[36m(func pid=10475)[0m rmse_per_class: [0.085, 0.229, 0.127, 0.319, 0.056, 0.169, 0.232, 0.224, 0.133, 0.086]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.5417 | Steps: 2 | Val loss: 0.4231 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4050 | Steps: 2 | Val loss: 0.3162 | Batch size: 32 | lr: 0.001 | Duration: 3.16s
[2m[36m(func pid=6491)[0m rmse: 0.15656879544258118
[2m[36m(func pid=6491)[0m mae:  0.1097681075334549
[2m[36m(func pid=6491)[0m rmse_per_class: [0.084, 0.25, 0.055, 0.297, 0.091, 0.177, 0.247, 0.122, 0.143, 0.101]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3284 | Steps: 2 | Val loss: 0.2853 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 06:22:23 (running for 00:26:14.58)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.542 |  0.18  |                   56 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.407 |  0.173 |                   29 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.324 |  0.157 |                   27 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.386 |  0.166 |                    9 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.180371955037117
[2m[36m(func pid=187627)[0m mae:  0.13179194927215576
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.1, 0.194, 0.303, 0.15, 0.141, 0.122]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.17265459895133972
[2m[36m(func pid=5093)[0m mae:  0.12506677210330963
[2m[36m(func pid=5093)[0m rmse_per_class: [0.11, 0.269, 0.078, 0.327, 0.075, 0.193, 0.279, 0.136, 0.149, 0.111]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.1548749953508377
[2m[36m(func pid=10475)[0m mae:  0.10073164850473404
[2m[36m(func pid=10475)[0m rmse_per_class: [0.067, 0.226, 0.047, 0.286, 0.155, 0.196, 0.219, 0.121, 0.142, 0.09]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3171 | Steps: 2 | Val loss: 0.2851 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.5388 | Steps: 2 | Val loss: 0.4212 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4052 | Steps: 2 | Val loss: 0.3155 | Batch size: 32 | lr: 0.001 | Duration: 3.23s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3031 | Steps: 2 | Val loss: 0.3063 | Batch size: 32 | lr: 0.1 | Duration: 2.65s
[2m[36m(func pid=6491)[0m rmse: 0.15531091392040253
[2m[36m(func pid=6491)[0m mae:  0.1087317019701004
[2m[36m(func pid=6491)[0m rmse_per_class: [0.083, 0.248, 0.051, 0.295, 0.09, 0.176, 0.245, 0.121, 0.144, 0.099]
[2m[36m(func pid=6491)[0m 
== Status ==
Current time: 2024-01-07 06:22:28 (running for 00:26:19.91)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.539 |  0.18  |                   57 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.405 |  0.173 |                   30 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.317 |  0.155 |                   28 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.328 |  0.155 |                   10 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.1803537756204605
[2m[36m(func pid=187627)[0m mae:  0.1317710131406784
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.1, 0.194, 0.303, 0.15, 0.141, 0.122]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.17227935791015625
[2m[36m(func pid=5093)[0m mae:  0.1247984766960144
[2m[36m(func pid=5093)[0m rmse_per_class: [0.11, 0.268, 0.076, 0.326, 0.074, 0.193, 0.279, 0.136, 0.149, 0.111]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.1656845062971115
[2m[36m(func pid=10475)[0m mae:  0.10863256454467773
[2m[36m(func pid=10475)[0m rmse_per_class: [0.069, 0.23, 0.031, 0.266, 0.202, 0.185, 0.256, 0.143, 0.185, 0.091]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3175 | Steps: 2 | Val loss: 0.2826 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.5348 | Steps: 2 | Val loss: 0.4180 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4052 | Steps: 2 | Val loss: 0.3151 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.3121 | Steps: 2 | Val loss: 0.3007 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=6491)[0m rmse: 0.15401522815227509
[2m[36m(func pid=6491)[0m mae:  0.10775840282440186
[2m[36m(func pid=6491)[0m rmse_per_class: [0.083, 0.246, 0.048, 0.292, 0.086, 0.175, 0.246, 0.12, 0.145, 0.099]
[2m[36m(func pid=6491)[0m 
== Status ==
Current time: 2024-01-07 06:22:34 (running for 00:26:25.23)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.535 |  0.18  |                   58 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.405 |  0.172 |                   31 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.317 |  0.154 |                   29 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.303 |  0.166 |                   11 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.18031153082847595
[2m[36m(func pid=187627)[0m mae:  0.13174819946289062
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.099, 0.194, 0.303, 0.15, 0.141, 0.122]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.17210347950458527
[2m[36m(func pid=5093)[0m mae:  0.12470775842666626
[2m[36m(func pid=5093)[0m rmse_per_class: [0.11, 0.268, 0.075, 0.326, 0.073, 0.193, 0.279, 0.137, 0.149, 0.111]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.16156336665153503
[2m[36m(func pid=10475)[0m mae:  0.10243703424930573
[2m[36m(func pid=10475)[0m rmse_per_class: [0.095, 0.248, 0.04, 0.26, 0.1, 0.167, 0.228, 0.142, 0.251, 0.084]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3211 | Steps: 2 | Val loss: 0.2807 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.5344 | Steps: 2 | Val loss: 0.4150 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.2880 | Steps: 2 | Val loss: 0.2830 | Batch size: 32 | lr: 0.1 | Duration: 2.66s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4002 | Steps: 2 | Val loss: 0.3148 | Batch size: 32 | lr: 0.001 | Duration: 3.14s
== Status ==
Current time: 2024-01-07 06:22:39 (running for 00:26:30.32)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.535 |  0.18  |                   58 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.405 |  0.172 |                   32 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.321 |  0.153 |                   30 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.312 |  0.162 |                   12 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m rmse: 0.15307994186878204
[2m[36m(func pid=6491)[0m mae:  0.10703225433826447
[2m[36m(func pid=6491)[0m rmse_per_class: [0.083, 0.246, 0.046, 0.288, 0.081, 0.175, 0.246, 0.12, 0.147, 0.1]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18023458123207092
[2m[36m(func pid=187627)[0m mae:  0.13166388869285583
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.099, 0.194, 0.302, 0.15, 0.141, 0.121]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14912475645542145
[2m[36m(func pid=10475)[0m mae:  0.09067770093679428
[2m[36m(func pid=10475)[0m rmse_per_class: [0.072, 0.25, 0.04, 0.251, 0.055, 0.166, 0.198, 0.128, 0.214, 0.116]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.1719527691602707
[2m[36m(func pid=5093)[0m mae:  0.12461688369512558
[2m[36m(func pid=5093)[0m rmse_per_class: [0.11, 0.268, 0.075, 0.326, 0.073, 0.193, 0.279, 0.136, 0.149, 0.111]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3103 | Steps: 2 | Val loss: 0.2791 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.5243 | Steps: 2 | Val loss: 0.4129 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.2728 | Steps: 2 | Val loss: 0.2824 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
== Status ==
Current time: 2024-01-07 06:22:44 (running for 00:26:35.73)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.534 |  0.18  |                   59 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.4   |  0.172 |                   33 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.31  |  0.152 |                   31 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.288 |  0.149 |                   13 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m rmse: 0.15220028162002563
[2m[36m(func pid=6491)[0m mae:  0.10629782825708389
[2m[36m(func pid=6491)[0m rmse_per_class: [0.082, 0.245, 0.044, 0.285, 0.077, 0.174, 0.247, 0.119, 0.149, 0.1]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18029473721981049
[2m[36m(func pid=187627)[0m mae:  0.13169090449810028
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.327, 0.099, 0.194, 0.302, 0.15, 0.141, 0.122]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3998 | Steps: 2 | Val loss: 0.3142 | Batch size: 32 | lr: 0.001 | Duration: 3.17s
[2m[36m(func pid=10475)[0m rmse: 0.1470402032136917
[2m[36m(func pid=10475)[0m mae:  0.08930037915706635
[2m[36m(func pid=10475)[0m rmse_per_class: [0.06, 0.241, 0.038, 0.25, 0.052, 0.162, 0.214, 0.111, 0.164, 0.179]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.17163947224617004
[2m[36m(func pid=5093)[0m mae:  0.1243661493062973
[2m[36m(func pid=5093)[0m rmse_per_class: [0.109, 0.268, 0.074, 0.325, 0.072, 0.192, 0.279, 0.137, 0.149, 0.111]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.5252 | Steps: 2 | Val loss: 0.4108 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3146 | Steps: 2 | Val loss: 0.2777 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.2794 | Steps: 2 | Val loss: 0.2896 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 06:22:49 (running for 00:26:40.95)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.525 |  0.18  |                   61 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.4   |  0.172 |                   34 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.31  |  0.152 |                   31 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.273 |  0.147 |                   14 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.18029917776584625
[2m[36m(func pid=187627)[0m mae:  0.1317058950662613
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.327, 0.099, 0.194, 0.302, 0.15, 0.141, 0.121]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.1514916718006134
[2m[36m(func pid=6491)[0m mae:  0.10561767965555191
[2m[36m(func pid=6491)[0m rmse_per_class: [0.082, 0.245, 0.043, 0.28, 0.073, 0.174, 0.247, 0.119, 0.15, 0.101]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4022 | Steps: 2 | Val loss: 0.3138 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=10475)[0m rmse: 0.15044836699962616
[2m[36m(func pid=10475)[0m mae:  0.09244342148303986
[2m[36m(func pid=10475)[0m rmse_per_class: [0.061, 0.228, 0.032, 0.268, 0.053, 0.162, 0.229, 0.18, 0.152, 0.14]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.5231 | Steps: 2 | Val loss: 0.4087 | Batch size: 32 | lr: 0.0001 | Duration: 3.08s
[2m[36m(func pid=5093)[0m rmse: 0.17144858837127686
[2m[36m(func pid=5093)[0m mae:  0.12426779419183731
[2m[36m(func pid=5093)[0m rmse_per_class: [0.109, 0.267, 0.073, 0.325, 0.071, 0.193, 0.279, 0.137, 0.149, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3116 | Steps: 2 | Val loss: 0.2771 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.2775 | Steps: 2 | Val loss: 0.2919 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 06:22:55 (running for 00:26:46.41)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.523 |  0.18  |                   62 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.402 |  0.171 |                   35 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.315 |  0.151 |                   32 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.279 |  0.15  |                   15 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.1802050620317459
[2m[36m(func pid=187627)[0m mae:  0.1316128820180893
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.327, 0.099, 0.194, 0.302, 0.15, 0.141, 0.121]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.15115946531295776
[2m[36m(func pid=6491)[0m mae:  0.1052185520529747
[2m[36m(func pid=6491)[0m rmse_per_class: [0.081, 0.246, 0.043, 0.278, 0.07, 0.173, 0.247, 0.12, 0.151, 0.104]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.15367619693279266
[2m[36m(func pid=10475)[0m mae:  0.09527449309825897
[2m[36m(func pid=10475)[0m rmse_per_class: [0.061, 0.23, 0.029, 0.283, 0.053, 0.185, 0.248, 0.204, 0.157, 0.087]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3993 | Steps: 2 | Val loss: 0.3133 | Batch size: 32 | lr: 0.001 | Duration: 3.18s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.5184 | Steps: 2 | Val loss: 0.4068 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3061 | Steps: 2 | Val loss: 0.2777 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.2733 | Steps: 2 | Val loss: 0.2804 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=5093)[0m rmse: 0.17123660445213318
[2m[36m(func pid=5093)[0m mae:  0.1240759938955307
[2m[36m(func pid=5093)[0m rmse_per_class: [0.109, 0.267, 0.072, 0.324, 0.071, 0.192, 0.279, 0.137, 0.149, 0.111]
[2m[36m(func pid=5093)[0m 
== Status ==
Current time: 2024-01-07 06:23:00 (running for 00:26:51.76)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.518 |  0.18  |                   63 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.399 |  0.171 |                   36 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.312 |  0.151 |                   33 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.277 |  0.154 |                   16 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)

[2m[36m(func pid=187627)[0m rmse: 0.18014684319496155

[2m[36m(func pid=187627)[0m mae:  0.1315556913614273
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.092, 0.327, 0.099, 0.194, 0.301, 0.149, 0.141, 0.121]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.15152938663959503
[2m[36m(func pid=6491)[0m mae:  0.10542519390583038
[2m[36m(func pid=6491)[0m rmse_per_class: [0.081, 0.246, 0.042, 0.279, 0.068, 0.173, 0.247, 0.12, 0.152, 0.108]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14726640284061432
[2m[36m(func pid=10475)[0m mae:  0.09061284363269806
[2m[36m(func pid=10475)[0m rmse_per_class: [0.085, 0.228, 0.027, 0.274, 0.053, 0.182, 0.226, 0.138, 0.178, 0.081]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4027 | Steps: 2 | Val loss: 0.3129 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.5166 | Steps: 2 | Val loss: 0.4048 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.2632 | Steps: 2 | Val loss: 0.2776 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3059 | Steps: 2 | Val loss: 0.2778 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=5093)[0m rmse: 0.1710568517446518
[2m[36m(func pid=5093)[0m mae:  0.1239442378282547
[2m[36m(func pid=5093)[0m rmse_per_class: [0.109, 0.267, 0.072, 0.324, 0.071, 0.192, 0.279, 0.137, 0.149, 0.112]
[2m[36m(func pid=5093)[0m 
== Status ==
Current time: 2024-01-07 06:23:06 (running for 00:26:57.14)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.518 |  0.18  |                   63 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.403 |  0.171 |                   37 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.306 |  0.152 |                   34 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.263 |  0.145 |                   18 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.1800805628299713
[2m[36m(func pid=187627)[0m mae:  0.131501704454422
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.327, 0.099, 0.194, 0.301, 0.149, 0.141, 0.121]
[2m[36m(func pid=10475)[0m rmse: 0.14499947428703308
[2m[36m(func pid=10475)[0m mae:  0.08885513246059418
[2m[36m(func pid=10475)[0m rmse_per_class: [0.097, 0.233, 0.027, 0.262, 0.07, 0.162, 0.199, 0.11, 0.208, 0.082]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.15157285332679749
[2m[36m(func pid=6491)[0m mae:  0.10534019768238068
[2m[36m(func pid=6491)[0m rmse_per_class: [0.08, 0.246, 0.042, 0.279, 0.067, 0.173, 0.246, 0.121, 0.149, 0.113]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3966 | Steps: 2 | Val loss: 0.3123 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.5112 | Steps: 2 | Val loss: 0.4023 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.2585 | Steps: 2 | Val loss: 0.2848 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3009 | Steps: 2 | Val loss: 0.2780 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=5093)[0m rmse: 0.17074254155158997
[2m[36m(func pid=5093)[0m mae:  0.12366217374801636
[2m[36m(func pid=5093)[0m rmse_per_class: [0.109, 0.267, 0.071, 0.323, 0.071, 0.192, 0.278, 0.137, 0.149, 0.112]
[2m[36m(func pid=5093)[0m 
== Status ==
Current time: 2024-01-07 06:23:11 (running for 00:27:02.20)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.517 |  0.18  |                   64 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.397 |  0.171 |                   38 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.306 |  0.152 |                   35 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.258 |  0.15  |                   19 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.14977966248989105
[2m[36m(func pid=10475)[0m mae:  0.09126287698745728
[2m[36m(func pid=10475)[0m rmse_per_class: [0.067, 0.245, 0.027, 0.256, 0.107, 0.166, 0.204, 0.112, 0.23, 0.084]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18002595007419586
[2m[36m(func pid=187627)[0m mae:  0.13144218921661377
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.099, 0.194, 0.301, 0.148, 0.141, 0.121]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.151556596159935
[2m[36m(func pid=6491)[0m mae:  0.10515264421701431
[2m[36m(func pid=6491)[0m rmse_per_class: [0.08, 0.246, 0.041, 0.279, 0.066, 0.172, 0.246, 0.122, 0.15, 0.114]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3984 | Steps: 2 | Val loss: 0.3120 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.2622 | Steps: 2 | Val loss: 0.2878 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.5128 | Steps: 2 | Val loss: 0.4003 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3017 | Steps: 2 | Val loss: 0.2778 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=5093)[0m rmse: 0.17063000798225403
[2m[36m(func pid=5093)[0m mae:  0.12358073890209198
[2m[36m(func pid=5093)[0m rmse_per_class: [0.109, 0.267, 0.071, 0.322, 0.07, 0.192, 0.278, 0.136, 0.148, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.15080715715885162
[2m[36m(func pid=10475)[0m mae:  0.09201257675886154
[2m[36m(func pid=10475)[0m rmse_per_class: [0.062, 0.238, 0.026, 0.256, 0.134, 0.165, 0.211, 0.11, 0.211, 0.095]
[2m[36m(func pid=10475)[0m 
== Status ==
Current time: 2024-01-07 06:23:16 (running for 00:27:07.36)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.511 |  0.18  |                   65 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.398 |  0.171 |                   39 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.301 |  0.152 |                   36 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.262 |  0.151 |                   20 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.18007591366767883
[2m[36m(func pid=187627)[0m mae:  0.13147452473640442
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.092, 0.326, 0.099, 0.194, 0.301, 0.149, 0.141, 0.121]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.15133224427700043
[2m[36m(func pid=6491)[0m mae:  0.1048356294631958
[2m[36m(func pid=6491)[0m rmse_per_class: [0.08, 0.245, 0.041, 0.278, 0.065, 0.172, 0.244, 0.123, 0.148, 0.116]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3972 | Steps: 2 | Val loss: 0.3117 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.2599 | Steps: 2 | Val loss: 0.2841 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.5110 | Steps: 2 | Val loss: 0.3977 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2961 | Steps: 2 | Val loss: 0.2775 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 06:23:21 (running for 00:27:12.37)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.513 |  0.18  |                   66 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.397 |  0.171 |                   40 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.302 |  0.151 |                   37 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.262 |  0.151 |                   20 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=5093)[0m rmse: 0.1705404818058014
[2m[36m(func pid=5093)[0m mae:  0.12352333217859268
[2m[36m(func pid=5093)[0m rmse_per_class: [0.109, 0.267, 0.07, 0.322, 0.07, 0.192, 0.278, 0.136, 0.148, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.1485411375761032
[2m[36m(func pid=10475)[0m mae:  0.09092982113361359
[2m[36m(func pid=10475)[0m rmse_per_class: [0.06, 0.23, 0.027, 0.258, 0.098, 0.17, 0.234, 0.118, 0.179, 0.112]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.18001171946525574
[2m[36m(func pid=187627)[0m mae:  0.1314219981431961
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.092, 0.326, 0.099, 0.194, 0.3, 0.148, 0.142, 0.121]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.15091587603092194
[2m[36m(func pid=6491)[0m mae:  0.10439473390579224
[2m[36m(func pid=6491)[0m rmse_per_class: [0.079, 0.244, 0.041, 0.279, 0.065, 0.172, 0.243, 0.123, 0.147, 0.116]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.2420 | Steps: 2 | Val loss: 0.2763 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3967 | Steps: 2 | Val loss: 0.3114 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.5052 | Steps: 2 | Val loss: 0.3961 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2908 | Steps: 2 | Val loss: 0.2769 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 06:23:26 (running for 00:27:17.71)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.511 |  0.18  |                   67 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.397 |  0.171 |                   40 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.296 |  0.151 |                   38 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.242 |  0.144 |                   22 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.14407499134540558
[2m[36m(func pid=10475)[0m mae:  0.08874258399009705
[2m[36m(func pid=10475)[0m rmse_per_class: [0.066, 0.228, 0.032, 0.27, 0.062, 0.173, 0.221, 0.128, 0.154, 0.107]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.17991694808006287
[2m[36m(func pid=187627)[0m mae:  0.1313394010066986
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.098, 0.194, 0.3, 0.148, 0.142, 0.121]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.170421302318573
[2m[36m(func pid=5093)[0m mae:  0.12343938648700714
[2m[36m(func pid=5093)[0m rmse_per_class: [0.109, 0.267, 0.07, 0.322, 0.07, 0.192, 0.278, 0.136, 0.149, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.15027639269828796
[2m[36m(func pid=6491)[0m mae:  0.10384539514780045
[2m[36m(func pid=6491)[0m rmse_per_class: [0.078, 0.243, 0.04, 0.279, 0.065, 0.171, 0.243, 0.124, 0.148, 0.112]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.2533 | Steps: 2 | Val loss: 0.2768 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.5076 | Steps: 2 | Val loss: 0.3951 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3961 | Steps: 2 | Val loss: 0.3110 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2961 | Steps: 2 | Val loss: 0.2765 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 06:23:31 (running for 00:27:22.83)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.505 |  0.18  |                   68 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.397 |  0.17  |                   41 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.291 |  0.15  |                   39 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.253 |  0.144 |                   23 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.1439656764268875
[2m[36m(func pid=10475)[0m mae:  0.08811486512422562
[2m[36m(func pid=10475)[0m rmse_per_class: [0.091, 0.228, 0.037, 0.28, 0.053, 0.162, 0.212, 0.127, 0.152, 0.098]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=187627)[0m rmse: 0.17995840311050415
[2m[36m(func pid=187627)[0m mae:  0.13136455416679382
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.271, 0.092, 0.326, 0.099, 0.194, 0.3, 0.148, 0.142, 0.121]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.17023763060569763
[2m[36m(func pid=5093)[0m mae:  0.12326614558696747
[2m[36m(func pid=5093)[0m rmse_per_class: [0.108, 0.266, 0.07, 0.321, 0.07, 0.192, 0.278, 0.136, 0.148, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.14985699951648712
[2m[36m(func pid=6491)[0m mae:  0.10335010290145874
[2m[36m(func pid=6491)[0m rmse_per_class: [0.077, 0.242, 0.04, 0.279, 0.066, 0.171, 0.241, 0.124, 0.149, 0.11]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.2513 | Steps: 2 | Val loss: 0.2822 | Batch size: 32 | lr: 0.1 | Duration: 2.58s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.5026 | Steps: 2 | Val loss: 0.3935 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3972 | Steps: 2 | Val loss: 0.3107 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2936 | Steps: 2 | Val loss: 0.2763 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=10475)[0m rmse: 0.1454211175441742
[2m[36m(func pid=10475)[0m mae:  0.08821795880794525
[2m[36m(func pid=10475)[0m rmse_per_class: [0.112, 0.233, 0.036, 0.27, 0.053, 0.159, 0.208, 0.122, 0.169, 0.092]
[2m[36m(func pid=10475)[0m 
== Status ==
Current time: 2024-01-07 06:23:37 (running for 00:27:28.85)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.503 |  0.18  |                   70 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.396 |  0.17  |                   42 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.296 |  0.15  |                   40 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.251 |  0.145 |                   24 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.17991173267364502
[2m[36m(func pid=187627)[0m mae:  0.1313362717628479
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.327, 0.098, 0.194, 0.3, 0.148, 0.142, 0.121]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.170098215341568
[2m[36m(func pid=5093)[0m mae:  0.12316860258579254
[2m[36m(func pid=5093)[0m rmse_per_class: [0.108, 0.266, 0.07, 0.321, 0.07, 0.191, 0.278, 0.136, 0.148, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.1496274471282959
[2m[36m(func pid=6491)[0m mae:  0.10311470925807953
[2m[36m(func pid=6491)[0m rmse_per_class: [0.077, 0.241, 0.04, 0.281, 0.066, 0.171, 0.24, 0.123, 0.151, 0.108]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.2545 | Steps: 2 | Val loss: 0.2881 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.5015 | Steps: 2 | Val loss: 0.3916 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=10475)[0m rmse: 0.1449558436870575
[2m[36m(func pid=10475)[0m mae:  0.08789103478193283
[2m[36m(func pid=10475)[0m rmse_per_class: [0.092, 0.237, 0.032, 0.257, 0.058, 0.161, 0.206, 0.115, 0.199, 0.093]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3975 | Steps: 2 | Val loss: 0.3103 | Batch size: 32 | lr: 0.001 | Duration: 3.22s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2974 | Steps: 2 | Val loss: 0.2757 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 06:23:43 (running for 00:27:34.29)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.502 |  0.18  |                   71 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.397 |  0.17  |                   43 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.294 |  0.15  |                   41 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.255 |  0.145 |                   25 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.17991401255130768
[2m[36m(func pid=187627)[0m mae:  0.1313416063785553
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.327, 0.099, 0.194, 0.3, 0.148, 0.142, 0.121]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.1491169035434723
[2m[36m(func pid=6491)[0m mae:  0.10263367742300034
[2m[36m(func pid=6491)[0m rmse_per_class: [0.076, 0.241, 0.039, 0.28, 0.066, 0.17, 0.239, 0.123, 0.15, 0.106]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.2438 | Steps: 2 | Val loss: 0.2841 | Batch size: 32 | lr: 0.1 | Duration: 2.61s
[2m[36m(func pid=5093)[0m rmse: 0.1698964685201645
[2m[36m(func pid=5093)[0m mae:  0.12300515174865723
[2m[36m(func pid=5093)[0m rmse_per_class: [0.108, 0.266, 0.069, 0.32, 0.069, 0.191, 0.278, 0.136, 0.148, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4996 | Steps: 2 | Val loss: 0.3893 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=10475)[0m rmse: 0.14400960505008698
[2m[36m(func pid=10475)[0m mae:  0.08794350922107697
[2m[36m(func pid=10475)[0m rmse_per_class: [0.07, 0.236, 0.027, 0.257, 0.064, 0.163, 0.207, 0.112, 0.21, 0.094]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2938 | Steps: 2 | Val loss: 0.2757 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3988 | Steps: 2 | Val loss: 0.3100 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
== Status ==
Current time: 2024-01-07 06:23:48 (running for 00:27:39.52)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.5   |  0.18  |                   72 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.398 |  0.17  |                   44 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.297 |  0.149 |                   42 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.244 |  0.144 |                   26 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.17971237003803253
[2m[36m(func pid=187627)[0m mae:  0.13116590678691864
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.098, 0.194, 0.299, 0.148, 0.142, 0.121]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.2412 | Steps: 2 | Val loss: 0.2737 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=6491)[0m rmse: 0.14907190203666687
[2m[36m(func pid=6491)[0m mae:  0.10250800848007202
[2m[36m(func pid=6491)[0m rmse_per_class: [0.077, 0.241, 0.039, 0.28, 0.067, 0.17, 0.239, 0.122, 0.154, 0.104]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16973882913589478
[2m[36m(func pid=5093)[0m mae:  0.12291915714740753
[2m[36m(func pid=5093)[0m rmse_per_class: [0.108, 0.266, 0.069, 0.32, 0.069, 0.191, 0.278, 0.136, 0.148, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4940 | Steps: 2 | Val loss: 0.3875 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=10475)[0m rmse: 0.14234329760074615
[2m[36m(func pid=10475)[0m mae:  0.0876396968960762
[2m[36m(func pid=10475)[0m rmse_per_class: [0.063, 0.233, 0.026, 0.257, 0.07, 0.166, 0.207, 0.112, 0.198, 0.091]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2894 | Steps: 2 | Val loss: 0.2750 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4008 | Steps: 2 | Val loss: 0.3094 | Batch size: 32 | lr: 0.001 | Duration: 3.16s
== Status ==
Current time: 2024-01-07 06:23:53 (running for 00:27:44.75)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.494 |  0.18  |                   73 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.399 |  0.17  |                   45 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.294 |  0.149 |                   43 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.241 |  0.142 |                   27 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.1797301322221756
[2m[36m(func pid=187627)[0m mae:  0.1311647742986679
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.098, 0.194, 0.299, 0.148, 0.142, 0.121]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.2426 | Steps: 2 | Val loss: 0.2712 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=6491)[0m rmse: 0.14869673550128937
[2m[36m(func pid=6491)[0m mae:  0.10208486020565033
[2m[36m(func pid=6491)[0m rmse_per_class: [0.076, 0.241, 0.039, 0.279, 0.068, 0.17, 0.237, 0.122, 0.154, 0.102]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16944769024848938
[2m[36m(func pid=5093)[0m mae:  0.1226750984787941
[2m[36m(func pid=5093)[0m rmse_per_class: [0.108, 0.266, 0.068, 0.319, 0.069, 0.191, 0.278, 0.136, 0.148, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14246782660484314
[2m[36m(func pid=10475)[0m mae:  0.08812375366687775
[2m[36m(func pid=10475)[0m rmse_per_class: [0.064, 0.23, 0.025, 0.261, 0.079, 0.164, 0.209, 0.112, 0.183, 0.096]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4903 | Steps: 2 | Val loss: 0.3859 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2850 | Steps: 2 | Val loss: 0.2746 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=187627)[0m rmse: 0.17970938980579376
[2m[36m(func pid=187627)[0m mae:  0.13113224506378174
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.09, 0.326, 0.098, 0.194, 0.299, 0.148, 0.142, 0.121]
[2m[36m(func pid=187627)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3916 | Steps: 2 | Val loss: 0.3093 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 06:23:58 (running for 00:27:49.98)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.17299999669194221
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00012 | RUNNING    | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.49  |  0.18  |                   74 |
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.401 |  0.169 |                   46 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.289 |  0.149 |                   44 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.243 |  0.142 |                   28 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.2415 | Steps: 2 | Val loss: 0.2759 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=6491)[0m rmse: 0.14837034046649933
[2m[36m(func pid=6491)[0m mae:  0.10174472630023956
[2m[36m(func pid=6491)[0m rmse_per_class: [0.077, 0.24, 0.038, 0.278, 0.069, 0.169, 0.237, 0.121, 0.154, 0.101]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16943272948265076
[2m[36m(func pid=5093)[0m mae:  0.12268546968698502
[2m[36m(func pid=5093)[0m rmse_per_class: [0.108, 0.266, 0.068, 0.319, 0.069, 0.191, 0.278, 0.136, 0.148, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14572229981422424
[2m[36m(func pid=10475)[0m mae:  0.08995391428470612
[2m[36m(func pid=10475)[0m rmse_per_class: [0.079, 0.23, 0.026, 0.264, 0.087, 0.163, 0.217, 0.119, 0.164, 0.108]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=187627)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4925 | Steps: 2 | Val loss: 0.3851 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2840 | Steps: 2 | Val loss: 0.2742 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 06:24:04 (running for 00:27:55.26)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 3 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.392 |  0.169 |                   47 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.285 |  0.148 |                   45 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.242 |  0.146 |                   29 |
| train_12613_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=187627)[0m rmse: 0.1796582043170929
[2m[36m(func pid=187627)[0m mae:  0.13111260533332825
[2m[36m(func pid=187627)[0m rmse_per_class: [0.108, 0.27, 0.09, 0.326, 0.098, 0.194, 0.299, 0.148, 0.142, 0.121]
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.2430 | Steps: 2 | Val loss: 0.2783 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3935 | Steps: 2 | Val loss: 0.3091 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=6491)[0m rmse: 0.14804819226264954
[2m[36m(func pid=6491)[0m mae:  0.10138378292322159
[2m[36m(func pid=6491)[0m rmse_per_class: [0.076, 0.24, 0.038, 0.277, 0.069, 0.169, 0.236, 0.12, 0.154, 0.101]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.1453796923160553
[2m[36m(func pid=10475)[0m mae:  0.0890219509601593
[2m[36m(func pid=10475)[0m rmse_per_class: [0.094, 0.229, 0.029, 0.259, 0.08, 0.163, 0.214, 0.117, 0.157, 0.112]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16933047771453857
[2m[36m(func pid=5093)[0m mae:  0.12257920205593109
[2m[36m(func pid=5093)[0m rmse_per_class: [0.108, 0.265, 0.068, 0.319, 0.069, 0.191, 0.277, 0.135, 0.148, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2877 | Steps: 2 | Val loss: 0.2738 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.2467 | Steps: 2 | Val loss: 0.2797 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3903 | Steps: 2 | Val loss: 0.3088 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
[2m[36m(func pid=6491)[0m rmse: 0.14785513281822205
[2m[36m(func pid=6491)[0m mae:  0.10110777616500854
[2m[36m(func pid=6491)[0m rmse_per_class: [0.076, 0.24, 0.038, 0.275, 0.07, 0.169, 0.236, 0.12, 0.154, 0.101]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14307451248168945
[2m[36m(func pid=10475)[0m mae:  0.08676783740520477
[2m[36m(func pid=10475)[0m rmse_per_class: [0.087, 0.237, 0.032, 0.257, 0.062, 0.161, 0.206, 0.114, 0.165, 0.109]
== Status ==
Current time: 2024-01-07 06:24:11 (running for 00:28:02.65)
Memory usage on this node: 23.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.394 |  0.169 |                   48 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.288 |  0.148 |                   47 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.243 |  0.145 |                   30 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=5093)[0m rmse: 0.16920354962348938
[2m[36m(func pid=5093)[0m mae:  0.12243644148111343
[2m[36m(func pid=5093)[0m rmse_per_class: [0.108, 0.265, 0.068, 0.318, 0.068, 0.191, 0.277, 0.135, 0.149, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=17062)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=17062)[0m Configuration completed!
[2m[36m(func pid=17062)[0m New optimizer parameters:
[2m[36m(func pid=17062)[0m SGD (
[2m[36m(func pid=17062)[0m Parameter Group 0
[2m[36m(func pid=17062)[0m     dampening: 0
[2m[36m(func pid=17062)[0m     differentiable: False
[2m[36m(func pid=17062)[0m     foreach: None
[2m[36m(func pid=17062)[0m     lr: 0.0001
[2m[36m(func pid=17062)[0m     maximize: False
[2m[36m(func pid=17062)[0m     momentum: 0.99
[2m[36m(func pid=17062)[0m     nesterov: False
[2m[36m(func pid=17062)[0m     weight_decay: 1e-05
[2m[36m(func pid=17062)[0m )
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2787 | Steps: 2 | Val loss: 0.2727 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.2389 | Steps: 2 | Val loss: 0.2799 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3912 | Steps: 2 | Val loss: 0.3087 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 06:24:17 (running for 00:28:08.24)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.39  |  0.169 |                   49 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.279 |  0.147 |                   48 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.247 |  0.143 |                   31 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m rmse: 0.14726395905017853
[2m[36m(func pid=6491)[0m mae:  0.10054626315832138
[2m[36m(func pid=6491)[0m rmse_per_class: [0.075, 0.24, 0.038, 0.271, 0.07, 0.169, 0.235, 0.119, 0.154, 0.101]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0834 | Steps: 2 | Val loss: 0.8099 | Batch size: 32 | lr: 0.0001 | Duration: 4.35s
[2m[36m(func pid=10475)[0m rmse: 0.14340974390506744
[2m[36m(func pid=10475)[0m mae:  0.08733763545751572
[2m[36m(func pid=10475)[0m rmse_per_class: [0.077, 0.241, 0.035, 0.26, 0.054, 0.167, 0.207, 0.11, 0.182, 0.1]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16913069784641266
[2m[36m(func pid=5093)[0m mae:  0.12238208949565887
[2m[36m(func pid=5093)[0m rmse_per_class: [0.107, 0.265, 0.067, 0.318, 0.068, 0.191, 0.277, 0.135, 0.15, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.17875149846076965
[2m[36m(func pid=17062)[0m mae:  0.13125547766685486
[2m[36m(func pid=17062)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.325, 0.101, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2809 | Steps: 2 | Val loss: 0.2726 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.2566 | Steps: 2 | Val loss: 0.2787 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3898 | Steps: 2 | Val loss: 0.3085 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0753 | Steps: 2 | Val loss: 0.8104 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=6491)[0m rmse: 0.14715099334716797
[2m[36m(func pid=6491)[0m mae:  0.10036051273345947
[2m[36m(func pid=6491)[0m rmse_per_class: [0.075, 0.241, 0.037, 0.27, 0.071, 0.168, 0.235, 0.118, 0.155, 0.101]
[2m[36m(func pid=6491)[0m 
== Status ==
Current time: 2024-01-07 06:24:22 (running for 00:28:13.46)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.391 |  0.169 |                   50 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.281 |  0.147 |                   49 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.143 |                   32 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  1.083 |  0.179 |                    1 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.14502325654029846
[2m[36m(func pid=10475)[0m mae:  0.08901078999042511
[2m[36m(func pid=10475)[0m rmse_per_class: [0.067, 0.238, 0.035, 0.263, 0.054, 0.188, 0.211, 0.111, 0.187, 0.098]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16902494430541992
[2m[36m(func pid=5093)[0m mae:  0.1223076581954956
[2m[36m(func pid=5093)[0m rmse_per_class: [0.107, 0.265, 0.067, 0.318, 0.068, 0.191, 0.277, 0.135, 0.15, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.17922310531139374
[2m[36m(func pid=17062)[0m mae:  0.13162818551063538
[2m[36m(func pid=17062)[0m rmse_per_class: [0.105, 0.266, 0.088, 0.325, 0.102, 0.193, 0.306, 0.153, 0.139, 0.116]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2910 | Steps: 2 | Val loss: 0.2724 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2404 | Steps: 2 | Val loss: 0.2704 | Batch size: 32 | lr: 0.1 | Duration: 2.68s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3888 | Steps: 2 | Val loss: 0.3084 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 1.0702 | Steps: 2 | Val loss: 0.8117 | Batch size: 32 | lr: 0.0001 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 06:24:27 (running for 00:28:18.82)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.39  |  0.169 |                   51 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.291 |  0.147 |                   50 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.257 |  0.145 |                   33 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  1.075 |  0.179 |                    2 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m rmse: 0.14711888134479523
[2m[36m(func pid=6491)[0m mae:  0.10022125393152237
[2m[36m(func pid=6491)[0m rmse_per_class: [0.075, 0.241, 0.037, 0.268, 0.07, 0.168, 0.236, 0.118, 0.156, 0.103]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14081551134586334
[2m[36m(func pid=10475)[0m mae:  0.08680947124958038
[2m[36m(func pid=10475)[0m rmse_per_class: [0.07, 0.228, 0.032, 0.256, 0.056, 0.167, 0.218, 0.112, 0.172, 0.096]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16900108754634857
[2m[36m(func pid=5093)[0m mae:  0.12228796631097794
[2m[36m(func pid=5093)[0m rmse_per_class: [0.107, 0.265, 0.067, 0.318, 0.068, 0.191, 0.277, 0.135, 0.15, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.17971530556678772
[2m[36m(func pid=17062)[0m mae:  0.13199271261692047
[2m[36m(func pid=17062)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.103, 0.193, 0.307, 0.154, 0.139, 0.117]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2800 | Steps: 2 | Val loss: 0.2714 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2621 | Steps: 2 | Val loss: 0.2699 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 1.0568 | Steps: 2 | Val loss: 0.8086 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3880 | Steps: 2 | Val loss: 0.3084 | Batch size: 32 | lr: 0.001 | Duration: 3.13s
[2m[36m(func pid=6491)[0m rmse: 0.14635321497917175
[2m[36m(func pid=6491)[0m mae:  0.09955136477947235
[2m[36m(func pid=6491)[0m rmse_per_class: [0.074, 0.24, 0.037, 0.268, 0.069, 0.168, 0.234, 0.118, 0.155, 0.101]
[2m[36m(func pid=10475)[0m rmse: 0.14164233207702637
[2m[36m(func pid=10475)[0m mae:  0.08734247088432312
[2m[36m(func pid=10475)[0m rmse_per_class: [0.085, 0.228, 0.029, 0.258, 0.065, 0.162, 0.212, 0.114, 0.163, 0.1]
[2m[36m(func pid=10475)[0m 
== Status ==
Current time: 2024-01-07 06:24:33 (running for 00:28:24.29)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.389 |  0.169 |                   52 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.291 |  0.147 |                   50 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.262 |  0.142 |                   35 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  1.07  |  0.18  |                    3 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.18012139201164246
[2m[36m(func pid=17062)[0m mae:  0.13230521976947784
[2m[36m(func pid=17062)[0m rmse_per_class: [0.105, 0.266, 0.091, 0.325, 0.104, 0.193, 0.308, 0.154, 0.139, 0.117]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.1689770519733429
[2m[36m(func pid=5093)[0m mae:  0.12224962562322617
[2m[36m(func pid=5093)[0m rmse_per_class: [0.107, 0.265, 0.067, 0.318, 0.069, 0.19, 0.277, 0.135, 0.15, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2369 | Steps: 2 | Val loss: 0.2786 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2834 | Steps: 2 | Val loss: 0.2713 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 1.0350 | Steps: 2 | Val loss: 0.7996 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 06:24:38 (running for 00:28:29.39)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.388 |  0.169 |                   53 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.28  |  0.146 |                   51 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.237 |  0.146 |                   36 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  1.057 |  0.18  |                    4 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.14609402418136597
[2m[36m(func pid=10475)[0m mae:  0.0899147018790245
[2m[36m(func pid=10475)[0m rmse_per_class: [0.086, 0.236, 0.027, 0.272, 0.074, 0.164, 0.208, 0.126, 0.163, 0.105]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3884 | Steps: 2 | Val loss: 0.3081 | Batch size: 32 | lr: 0.001 | Duration: 3.21s
[2m[36m(func pid=6491)[0m rmse: 0.1463301181793213
[2m[36m(func pid=6491)[0m mae:  0.09950299561023712
[2m[36m(func pid=6491)[0m rmse_per_class: [0.073, 0.239, 0.037, 0.269, 0.069, 0.168, 0.233, 0.118, 0.154, 0.102]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.1803922951221466
[2m[36m(func pid=17062)[0m mae:  0.13251183927059174
[2m[36m(func pid=17062)[0m rmse_per_class: [0.105, 0.266, 0.091, 0.325, 0.105, 0.194, 0.309, 0.154, 0.138, 0.118]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2499 | Steps: 2 | Val loss: 0.2894 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=5093)[0m rmse: 0.1688726544380188
[2m[36m(func pid=5093)[0m mae:  0.12213542312383652
[2m[36m(func pid=5093)[0m rmse_per_class: [0.107, 0.265, 0.067, 0.318, 0.068, 0.19, 0.276, 0.135, 0.15, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2752 | Steps: 2 | Val loss: 0.2710 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 06:24:43 (running for 00:28:34.61)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.388 |  0.169 |                   54 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.283 |  0.146 |                   52 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.25  |  0.149 |                   37 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  1.035 |  0.18  |                    5 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.14948023855686188
[2m[36m(func pid=10475)[0m mae:  0.09226571023464203
[2m[36m(func pid=10475)[0m rmse_per_class: [0.072, 0.245, 0.026, 0.279, 0.077, 0.165, 0.213, 0.127, 0.17, 0.12]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 1.0158 | Steps: 2 | Val loss: 0.7886 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=6491)[0m rmse: 0.14610828459262848
[2m[36m(func pid=6491)[0m mae:  0.09931784868240356
[2m[36m(func pid=6491)[0m rmse_per_class: [0.073, 0.239, 0.036, 0.271, 0.07, 0.167, 0.232, 0.118, 0.152, 0.102]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3922 | Steps: 2 | Val loss: 0.3076 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=17062)[0m rmse: 0.1805374175310135
[2m[36m(func pid=17062)[0m mae:  0.13259509205818176
[2m[36m(func pid=17062)[0m rmse_per_class: [0.105, 0.266, 0.091, 0.325, 0.105, 0.194, 0.309, 0.154, 0.138, 0.118]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2417 | Steps: 2 | Val loss: 0.2858 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=5093)[0m rmse: 0.16857337951660156
[2m[36m(func pid=5093)[0m mae:  0.121925950050354
[2m[36m(func pid=5093)[0m rmse_per_class: [0.107, 0.265, 0.066, 0.317, 0.068, 0.19, 0.276, 0.135, 0.149, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2736 | Steps: 2 | Val loss: 0.2715 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 06:24:48 (running for 00:28:39.80)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.392 |  0.169 |                   55 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.275 |  0.146 |                   53 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.242 |  0.146 |                   38 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  1.016 |  0.181 |                    6 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.14636504650115967
[2m[36m(func pid=10475)[0m mae:  0.09045793116092682
[2m[36m(func pid=10475)[0m rmse_per_class: [0.069, 0.236, 0.026, 0.274, 0.074, 0.172, 0.211, 0.116, 0.172, 0.115]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.9950 | Steps: 2 | Val loss: 0.7714 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=6491)[0m rmse: 0.14620687067508698
[2m[36m(func pid=6491)[0m mae:  0.09924359619617462
[2m[36m(func pid=6491)[0m rmse_per_class: [0.073, 0.239, 0.036, 0.272, 0.07, 0.167, 0.232, 0.118, 0.152, 0.103]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3902 | Steps: 2 | Val loss: 0.3074 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=17062)[0m rmse: 0.18073853850364685
[2m[36m(func pid=17062)[0m mae:  0.13274262845516205
[2m[36m(func pid=17062)[0m rmse_per_class: [0.105, 0.266, 0.091, 0.325, 0.105, 0.194, 0.309, 0.154, 0.138, 0.119]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2385 | Steps: 2 | Val loss: 0.2836 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2833 | Steps: 2 | Val loss: 0.2715 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=5093)[0m rmse: 0.16846312582492828
[2m[36m(func pid=5093)[0m mae:  0.12182068824768066
[2m[36m(func pid=5093)[0m rmse_per_class: [0.107, 0.264, 0.066, 0.317, 0.068, 0.19, 0.276, 0.135, 0.15, 0.112]
[2m[36m(func pid=5093)[0m 
== Status ==
Current time: 2024-01-07 06:24:53 (running for 00:28:44.96)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.39  |  0.168 |                   56 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.274 |  0.146 |                   54 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.238 |  0.144 |                   39 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.995 |  0.181 |                    7 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.1440104991197586
[2m[36m(func pid=10475)[0m mae:  0.08909685909748077
[2m[36m(func pid=10475)[0m rmse_per_class: [0.071, 0.232, 0.028, 0.27, 0.063, 0.168, 0.214, 0.113, 0.17, 0.112]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.9640 | Steps: 2 | Val loss: 0.7529 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=6491)[0m rmse: 0.14614729583263397
[2m[36m(func pid=6491)[0m mae:  0.09905292838811874
[2m[36m(func pid=6491)[0m rmse_per_class: [0.073, 0.238, 0.036, 0.272, 0.071, 0.167, 0.23, 0.119, 0.153, 0.101]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3933 | Steps: 2 | Val loss: 0.3072 | Batch size: 32 | lr: 0.001 | Duration: 3.15s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2387 | Steps: 2 | Val loss: 0.2791 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=17062)[0m rmse: 0.18088354170322418
[2m[36m(func pid=17062)[0m mae:  0.13283182680606842
[2m[36m(func pid=17062)[0m rmse_per_class: [0.106, 0.267, 0.091, 0.325, 0.105, 0.194, 0.31, 0.155, 0.138, 0.119]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2741 | Steps: 2 | Val loss: 0.2712 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=5093)[0m rmse: 0.16834700107574463
[2m[36m(func pid=5093)[0m mae:  0.12173692137002945
[2m[36m(func pid=5093)[0m rmse_per_class: [0.107, 0.264, 0.066, 0.317, 0.068, 0.19, 0.276, 0.135, 0.15, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14236220717430115
[2m[36m(func pid=10475)[0m mae:  0.0878775492310524
[2m[36m(func pid=10475)[0m rmse_per_class: [0.077, 0.233, 0.032, 0.27, 0.056, 0.163, 0.209, 0.112, 0.171, 0.1]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.9378 | Steps: 2 | Val loss: 0.7311 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 06:25:00 (running for 00:28:51.17)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.393 |  0.168 |                   57 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.274 |  0.146 |                   56 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.142 |                   40 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.964 |  0.181 |                    8 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m rmse: 0.1459135115146637
[2m[36m(func pid=6491)[0m mae:  0.09869159013032913
[2m[36m(func pid=6491)[0m rmse_per_class: [0.072, 0.238, 0.036, 0.271, 0.07, 0.167, 0.231, 0.12, 0.153, 0.102]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3865 | Steps: 2 | Val loss: 0.3069 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2461 | Steps: 2 | Val loss: 0.2752 | Batch size: 32 | lr: 0.1 | Duration: 2.67s
[2m[36m(func pid=17062)[0m rmse: 0.18096163868904114
[2m[36m(func pid=17062)[0m mae:  0.13286815583705902
[2m[36m(func pid=17062)[0m rmse_per_class: [0.106, 0.267, 0.091, 0.325, 0.105, 0.194, 0.31, 0.155, 0.138, 0.12]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2798 | Steps: 2 | Val loss: 0.2712 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=10475)[0m rmse: 0.14183956384658813
[2m[36m(func pid=10475)[0m mae:  0.08719690144062042
[2m[36m(func pid=10475)[0m rmse_per_class: [0.078, 0.231, 0.035, 0.268, 0.053, 0.164, 0.207, 0.11, 0.175, 0.097]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16820280253887177
[2m[36m(func pid=5093)[0m mae:  0.12160569429397583
[2m[36m(func pid=5093)[0m rmse_per_class: [0.107, 0.264, 0.066, 0.317, 0.068, 0.19, 0.276, 0.135, 0.149, 0.111]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.9064 | Steps: 2 | Val loss: 0.7067 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 06:25:05 (running for 00:28:56.59)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.386 |  0.168 |                   58 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.28  |  0.146 |                   57 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.246 |  0.142 |                   41 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.938 |  0.181 |                    9 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m rmse: 0.1458984762430191
[2m[36m(func pid=6491)[0m mae:  0.0986512154340744
[2m[36m(func pid=6491)[0m rmse_per_class: [0.072, 0.238, 0.036, 0.27, 0.07, 0.167, 0.231, 0.119, 0.155, 0.102]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2342 | Steps: 2 | Val loss: 0.2760 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3864 | Steps: 2 | Val loss: 0.3067 | Batch size: 32 | lr: 0.001 | Duration: 3.18s
[2m[36m(func pid=17062)[0m rmse: 0.18102498352527618
[2m[36m(func pid=17062)[0m mae:  0.13288699090480804
[2m[36m(func pid=17062)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.31, 0.155, 0.138, 0.121]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2778 | Steps: 2 | Val loss: 0.2709 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=10475)[0m rmse: 0.14322742819786072
[2m[36m(func pid=10475)[0m mae:  0.08793071657419205
[2m[36m(func pid=10475)[0m rmse_per_class: [0.073, 0.234, 0.036, 0.267, 0.056, 0.167, 0.209, 0.117, 0.176, 0.097]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16812649369239807
[2m[36m(func pid=5093)[0m mae:  0.12150689214468002
[2m[36m(func pid=5093)[0m rmse_per_class: [0.107, 0.264, 0.065, 0.317, 0.068, 0.19, 0.275, 0.135, 0.149, 0.111]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.8771 | Steps: 2 | Val loss: 0.6792 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 06:25:10 (running for 00:29:01.92)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.386 |  0.168 |                   59 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.278 |  0.146 |                   58 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.234 |  0.143 |                   42 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.906 |  0.181 |                   10 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m rmse: 0.1456512212753296
[2m[36m(func pid=6491)[0m mae:  0.09840638935565948
[2m[36m(func pid=6491)[0m rmse_per_class: [0.071, 0.237, 0.035, 0.269, 0.07, 0.167, 0.231, 0.12, 0.155, 0.102]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2456 | Steps: 2 | Val loss: 0.2794 | Batch size: 32 | lr: 0.1 | Duration: 2.70s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3889 | Steps: 2 | Val loss: 0.3064 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=17062)[0m rmse: 0.18107140064239502
[2m[36m(func pid=17062)[0m mae:  0.1328829824924469
[2m[36m(func pid=17062)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.104, 0.194, 0.31, 0.155, 0.138, 0.121]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14647726714611053
[2m[36m(func pid=10475)[0m mae:  0.08990542590618134
[2m[36m(func pid=10475)[0m rmse_per_class: [0.069, 0.236, 0.034, 0.266, 0.07, 0.166, 0.212, 0.132, 0.179, 0.1]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2707 | Steps: 2 | Val loss: 0.2707 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=5093)[0m rmse: 0.16795304417610168
[2m[36m(func pid=5093)[0m mae:  0.12135990709066391
[2m[36m(func pid=5093)[0m rmse_per_class: [0.107, 0.264, 0.065, 0.317, 0.067, 0.19, 0.275, 0.135, 0.149, 0.111]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.8399 | Steps: 2 | Val loss: 0.6507 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 06:25:16 (running for 00:29:07.28)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.389 |  0.168 |                   60 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.271 |  0.146 |                   59 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.246 |  0.146 |                   43 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.877 |  0.181 |                   11 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m rmse: 0.14556385576725006
[2m[36m(func pid=6491)[0m mae:  0.09830202162265778
[2m[36m(func pid=6491)[0m rmse_per_class: [0.07, 0.238, 0.035, 0.268, 0.07, 0.166, 0.231, 0.119, 0.155, 0.102]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2401 | Steps: 2 | Val loss: 0.2874 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=17062)[0m rmse: 0.18103723227977753
[2m[36m(func pid=17062)[0m mae:  0.13281969726085663
[2m[36m(func pid=17062)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.104, 0.194, 0.309, 0.155, 0.138, 0.122]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3880 | Steps: 2 | Val loss: 0.3060 | Batch size: 32 | lr: 0.001 | Duration: 3.16s
[2m[36m(func pid=10475)[0m rmse: 0.15162286162376404
[2m[36m(func pid=10475)[0m mae:  0.09293433278799057
[2m[36m(func pid=10475)[0m rmse_per_class: [0.078, 0.24, 0.031, 0.265, 0.083, 0.165, 0.219, 0.124, 0.194, 0.117]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2749 | Steps: 2 | Val loss: 0.2710 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.8017 | Steps: 2 | Val loss: 0.6227 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=5093)[0m rmse: 0.16769389808177948
[2m[36m(func pid=5093)[0m mae:  0.12110395729541779
[2m[36m(func pid=5093)[0m rmse_per_class: [0.107, 0.264, 0.065, 0.316, 0.067, 0.19, 0.274, 0.135, 0.148, 0.111]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2430 | Steps: 2 | Val loss: 0.2867 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
== Status ==
Current time: 2024-01-07 06:25:21 (running for 00:29:12.61)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.388 |  0.168 |                   61 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.275 |  0.146 |                   60 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.24  |  0.152 |                   44 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.84  |  0.181 |                   12 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m rmse: 0.14567552506923676
[2m[36m(func pid=6491)[0m mae:  0.0982392355799675
[2m[36m(func pid=6491)[0m rmse_per_class: [0.07, 0.239, 0.035, 0.267, 0.069, 0.166, 0.23, 0.12, 0.157, 0.102]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.18106424808502197
[2m[36m(func pid=17062)[0m mae:  0.13278701901435852
[2m[36m(func pid=17062)[0m rmse_per_class: [0.106, 0.268, 0.09, 0.324, 0.104, 0.194, 0.309, 0.155, 0.138, 0.122]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3867 | Steps: 2 | Val loss: 0.3057 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=10475)[0m rmse: 0.15053895115852356
[2m[36m(func pid=10475)[0m mae:  0.09255410730838776
[2m[36m(func pid=10475)[0m rmse_per_class: [0.086, 0.237, 0.029, 0.268, 0.09, 0.165, 0.213, 0.11, 0.189, 0.117]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2719 | Steps: 2 | Val loss: 0.2709 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7699 | Steps: 2 | Val loss: 0.5945 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=5093)[0m rmse: 0.16756854951381683
[2m[36m(func pid=5093)[0m mae:  0.12097841501235962
[2m[36m(func pid=5093)[0m rmse_per_class: [0.106, 0.264, 0.065, 0.316, 0.067, 0.19, 0.274, 0.135, 0.147, 0.111]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2441 | Steps: 2 | Val loss: 0.2795 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 06:25:27 (running for 00:29:18.06)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.387 |  0.168 |                   62 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.272 |  0.146 |                   61 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.243 |  0.151 |                   45 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.802 |  0.181 |                   13 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m rmse: 0.14572486281394958
[2m[36m(func pid=6491)[0m mae:  0.09819136559963226
[2m[36m(func pid=6491)[0m rmse_per_class: [0.07, 0.239, 0.035, 0.266, 0.069, 0.166, 0.231, 0.119, 0.158, 0.104]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.18099525570869446
[2m[36m(func pid=17062)[0m mae:  0.13266916573047638
[2m[36m(func pid=17062)[0m rmse_per_class: [0.106, 0.268, 0.09, 0.324, 0.103, 0.194, 0.308, 0.155, 0.138, 0.122]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14524051547050476
[2m[36m(func pid=10475)[0m mae:  0.08925057202577591
[2m[36m(func pid=10475)[0m rmse_per_class: [0.08, 0.234, 0.029, 0.275, 0.076, 0.165, 0.204, 0.108, 0.171, 0.109]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3857 | Steps: 2 | Val loss: 0.3054 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2735 | Steps: 2 | Val loss: 0.2708 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.7391 | Steps: 2 | Val loss: 0.5672 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2416 | Steps: 2 | Val loss: 0.2757 | Batch size: 32 | lr: 0.1 | Duration: 2.68s
== Status ==
Current time: 2024-01-07 06:25:32 (running for 00:29:23.20)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.386 |  0.167 |                   63 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.272 |  0.146 |                   61 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.244 |  0.145 |                   46 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.77  |  0.181 |                   14 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=5093)[0m rmse: 0.16741669178009033
[2m[36m(func pid=5093)[0m mae:  0.12083474546670914
[2m[36m(func pid=5093)[0m rmse_per_class: [0.106, 0.264, 0.065, 0.316, 0.067, 0.189, 0.273, 0.135, 0.147, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.14568600058555603
[2m[36m(func pid=6491)[0m mae:  0.09814394265413284
[2m[36m(func pid=6491)[0m rmse_per_class: [0.07, 0.238, 0.035, 0.265, 0.069, 0.166, 0.232, 0.119, 0.159, 0.103]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.18094177544116974
[2m[36m(func pid=17062)[0m mae:  0.13255828619003296
[2m[36m(func pid=17062)[0m rmse_per_class: [0.106, 0.268, 0.091, 0.324, 0.103, 0.194, 0.308, 0.155, 0.139, 0.122]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.1424461454153061
[2m[36m(func pid=10475)[0m mae:  0.08771193027496338
[2m[36m(func pid=10475)[0m rmse_per_class: [0.08, 0.233, 0.029, 0.273, 0.06, 0.173, 0.207, 0.109, 0.16, 0.1]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3831 | Steps: 2 | Val loss: 0.3053 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2692 | Steps: 2 | Val loss: 0.2705 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.7007 | Steps: 2 | Val loss: 0.5400 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2342 | Steps: 2 | Val loss: 0.2761 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 06:25:37 (running for 00:29:28.76)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.386 |  0.167 |                   63 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.269 |  0.145 |                   63 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.242 |  0.142 |                   47 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.739 |  0.181 |                   15 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m rmse: 0.14526964724063873
[2m[36m(func pid=6491)[0m mae:  0.09774492681026459
[2m[36m(func pid=6491)[0m rmse_per_class: [0.07, 0.237, 0.035, 0.265, 0.068, 0.166, 0.232, 0.119, 0.159, 0.102]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.1673627346754074
[2m[36m(func pid=5093)[0m mae:  0.12079942226409912
[2m[36m(func pid=5093)[0m rmse_per_class: [0.106, 0.264, 0.065, 0.316, 0.067, 0.189, 0.274, 0.135, 0.146, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.18082508444786072
[2m[36m(func pid=17062)[0m mae:  0.13240590691566467
[2m[36m(func pid=17062)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.324, 0.102, 0.194, 0.307, 0.155, 0.139, 0.122]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14123550057411194
[2m[36m(func pid=10475)[0m mae:  0.08682811260223389
[2m[36m(func pid=10475)[0m rmse_per_class: [0.076, 0.231, 0.027, 0.261, 0.055, 0.17, 0.212, 0.123, 0.157, 0.101]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2768 | Steps: 2 | Val loss: 0.2703 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3855 | Steps: 2 | Val loss: 0.3051 | Batch size: 32 | lr: 0.001 | Duration: 3.22s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.6714 | Steps: 2 | Val loss: 0.5147 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2358 | Steps: 2 | Val loss: 0.2839 | Batch size: 32 | lr: 0.1 | Duration: 2.66s
[2m[36m(func pid=6491)[0m rmse: 0.1450042426586151
[2m[36m(func pid=6491)[0m mae:  0.09756183624267578
[2m[36m(func pid=6491)[0m rmse_per_class: [0.07, 0.236, 0.034, 0.266, 0.069, 0.166, 0.231, 0.118, 0.159, 0.1]
== Status ==
Current time: 2024-01-07 06:25:43 (running for 00:29:34.22)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.383 |  0.167 |                   64 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.277 |  0.145 |                   64 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.234 |  0.141 |                   48 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.701 |  0.181 |                   16 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16727755963802338
[2m[36m(func pid=5093)[0m mae:  0.12071345001459122
[2m[36m(func pid=5093)[0m rmse_per_class: [0.106, 0.264, 0.065, 0.316, 0.067, 0.189, 0.273, 0.135, 0.146, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.18075206875801086
[2m[36m(func pid=17062)[0m mae:  0.13228987157344818
[2m[36m(func pid=17062)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.101, 0.194, 0.306, 0.154, 0.139, 0.121]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.1442089080810547
[2m[36m(func pid=10475)[0m mae:  0.08842696249485016
[2m[36m(func pid=10475)[0m rmse_per_class: [0.073, 0.231, 0.028, 0.259, 0.055, 0.162, 0.222, 0.136, 0.169, 0.107]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2771 | Steps: 2 | Val loss: 0.2701 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.6410 | Steps: 2 | Val loss: 0.4904 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3857 | Steps: 2 | Val loss: 0.3051 | Batch size: 32 | lr: 0.001 | Duration: 3.22s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2389 | Steps: 2 | Val loss: 0.2873 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 06:25:48 (running for 00:29:39.60)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.386 |  0.167 |                   65 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.277 |  0.145 |                   65 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.236 |  0.144 |                   49 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.671 |  0.181 |                   17 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m rmse: 0.14477157592773438
[2m[36m(func pid=6491)[0m mae:  0.09734885394573212
[2m[36m(func pid=6491)[0m rmse_per_class: [0.07, 0.236, 0.034, 0.267, 0.069, 0.166, 0.231, 0.118, 0.156, 0.1]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14643530547618866
[2m[36m(func pid=10475)[0m mae:  0.08955465257167816
[2m[36m(func pid=10475)[0m rmse_per_class: [0.074, 0.234, 0.031, 0.264, 0.056, 0.163, 0.213, 0.128, 0.187, 0.113]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.18065181374549866
[2m[36m(func pid=17062)[0m mae:  0.13217636942863464
[2m[36m(func pid=17062)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.101, 0.194, 0.306, 0.154, 0.14, 0.121]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.167194664478302
[2m[36m(func pid=5093)[0m mae:  0.12065516412258148
[2m[36m(func pid=5093)[0m rmse_per_class: [0.105, 0.263, 0.065, 0.316, 0.067, 0.189, 0.273, 0.135, 0.146, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2662 | Steps: 2 | Val loss: 0.2700 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2345 | Steps: 2 | Val loss: 0.2851 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.6144 | Steps: 2 | Val loss: 0.4668 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3858 | Steps: 2 | Val loss: 0.3053 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 06:25:53 (running for 00:29:44.89)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.386 |  0.167 |                   66 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.266 |  0.145 |                   66 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                   50 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.641 |  0.181 |                   18 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m rmse: 0.14457455277442932
[2m[36m(func pid=6491)[0m mae:  0.09722689539194107
[2m[36m(func pid=6491)[0m rmse_per_class: [0.071, 0.235, 0.034, 0.27, 0.069, 0.166, 0.23, 0.118, 0.155, 0.099]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.1471969336271286
[2m[36m(func pid=10475)[0m mae:  0.09000205248594284
[2m[36m(func pid=10475)[0m rmse_per_class: [0.083, 0.237, 0.035, 0.278, 0.058, 0.163, 0.205, 0.11, 0.191, 0.114]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.18058516085147858
[2m[36m(func pid=17062)[0m mae:  0.13205702602863312
[2m[36m(func pid=17062)[0m rmse_per_class: [0.107, 0.27, 0.092, 0.325, 0.1, 0.194, 0.304, 0.153, 0.14, 0.121]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16734039783477783
[2m[36m(func pid=5093)[0m mae:  0.12078621238470078
[2m[36m(func pid=5093)[0m rmse_per_class: [0.105, 0.263, 0.065, 0.316, 0.068, 0.189, 0.273, 0.134, 0.146, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2733 | Steps: 2 | Val loss: 0.2701 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2354 | Steps: 2 | Val loss: 0.2828 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.5861 | Steps: 2 | Val loss: 0.4458 | Batch size: 32 | lr: 0.0001 | Duration: 2.73s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3852 | Steps: 2 | Val loss: 0.3050 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
[2m[36m(func pid=6491)[0m rmse: 0.14440181851387024
[2m[36m(func pid=6491)[0m mae:  0.0969962552189827
[2m[36m(func pid=6491)[0m rmse_per_class: [0.071, 0.234, 0.034, 0.272, 0.07, 0.166, 0.229, 0.117, 0.154, 0.098]
[2m[36m(func pid=6491)[0m 
== Status ==
Current time: 2024-01-07 06:25:59 (running for 00:29:50.35)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.386 |  0.167 |                   67 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.273 |  0.144 |                   67 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.235 |  0.147 |                   51 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.614 |  0.181 |                   19 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.14772923290729523
[2m[36m(func pid=10475)[0m mae:  0.0901929959654808
[2m[36m(func pid=10475)[0m rmse_per_class: [0.085, 0.239, 0.035, 0.281, 0.059, 0.166, 0.207, 0.108, 0.188, 0.11]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.18044112622737885
[2m[36m(func pid=17062)[0m mae:  0.13187986612319946
[2m[36m(func pid=17062)[0m rmse_per_class: [0.107, 0.27, 0.092, 0.326, 0.099, 0.194, 0.303, 0.153, 0.14, 0.121]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.167184516787529
[2m[36m(func pid=5093)[0m mae:  0.12063910812139511
[2m[36m(func pid=5093)[0m rmse_per_class: [0.105, 0.263, 0.065, 0.316, 0.068, 0.189, 0.273, 0.135, 0.146, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2393 | Steps: 2 | Val loss: 0.2823 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2771 | Steps: 2 | Val loss: 0.2698 | Batch size: 32 | lr: 0.01 | Duration: 3.14s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.5607 | Steps: 2 | Val loss: 0.4273 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3869 | Steps: 2 | Val loss: 0.3047 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
== Status ==
Current time: 2024-01-07 06:26:04 (running for 00:29:55.63)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.385 |  0.167 |                   68 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.273 |  0.144 |                   67 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.147 |                   53 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.586 |  0.18  |                   20 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.14694729447364807
[2m[36m(func pid=10475)[0m mae:  0.08983037620782852
[2m[36m(func pid=10475)[0m rmse_per_class: [0.079, 0.239, 0.033, 0.271, 0.063, 0.174, 0.208, 0.109, 0.186, 0.107]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.14428260922431946
[2m[36m(func pid=6491)[0m mae:  0.09678985178470612
[2m[36m(func pid=6491)[0m rmse_per_class: [0.071, 0.235, 0.034, 0.271, 0.069, 0.166, 0.228, 0.117, 0.155, 0.097]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.18027591705322266
[2m[36m(func pid=17062)[0m mae:  0.13169288635253906
[2m[36m(func pid=17062)[0m rmse_per_class: [0.108, 0.27, 0.092, 0.326, 0.098, 0.194, 0.302, 0.151, 0.141, 0.121]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16702142357826233
[2m[36m(func pid=5093)[0m mae:  0.12047891318798065
[2m[36m(func pid=5093)[0m rmse_per_class: [0.104, 0.263, 0.065, 0.316, 0.068, 0.189, 0.273, 0.135, 0.145, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2373 | Steps: 2 | Val loss: 0.2840 | Batch size: 32 | lr: 0.1 | Duration: 2.65s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2655 | Steps: 2 | Val loss: 0.2703 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.5367 | Steps: 2 | Val loss: 0.4104 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=10475)[0m rmse: 0.14661547541618347
[2m[36m(func pid=10475)[0m mae:  0.08944904804229736
[2m[36m(func pid=10475)[0m rmse_per_class: [0.071, 0.238, 0.03, 0.263, 0.066, 0.169, 0.214, 0.12, 0.183, 0.112]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3796 | Steps: 2 | Val loss: 0.3045 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 06:26:10 (running for 00:30:01.09)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.387 |  0.167 |                   69 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.265 |  0.145 |                   69 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.237 |  0.147 |                   54 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.561 |  0.18  |                   21 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m rmse: 0.14472398161888123
[2m[36m(func pid=6491)[0m mae:  0.0970471054315567
[2m[36m(func pid=6491)[0m rmse_per_class: [0.072, 0.235, 0.034, 0.272, 0.071, 0.166, 0.227, 0.117, 0.159, 0.095]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.18021906912326813
[2m[36m(func pid=17062)[0m mae:  0.13160541653633118
[2m[36m(func pid=17062)[0m rmse_per_class: [0.108, 0.27, 0.093, 0.327, 0.098, 0.194, 0.301, 0.15, 0.141, 0.121]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2404 | Steps: 2 | Val loss: 0.2808 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=5093)[0m rmse: 0.16692082583904266
[2m[36m(func pid=5093)[0m mae:  0.12039513885974884
[2m[36m(func pid=5093)[0m rmse_per_class: [0.104, 0.263, 0.065, 0.316, 0.068, 0.189, 0.273, 0.134, 0.145, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2660 | Steps: 2 | Val loss: 0.2706 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.5149 | Steps: 2 | Val loss: 0.3943 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=10475)[0m rmse: 0.14468763768672943
[2m[36m(func pid=10475)[0m mae:  0.08830317854881287
[2m[36m(func pid=10475)[0m rmse_per_class: [0.074, 0.235, 0.028, 0.262, 0.065, 0.164, 0.211, 0.12, 0.172, 0.115]
[2m[36m(func pid=10475)[0m 
== Status ==
Current time: 2024-01-07 06:26:15 (running for 00:30:06.32)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.38  |  0.167 |                   70 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.266 |  0.145 |                   70 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.24  |  0.145 |                   55 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.537 |  0.18  |                   22 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m rmse: 0.14487169682979584
[2m[36m(func pid=6491)[0m mae:  0.09707622230052948
[2m[36m(func pid=6491)[0m rmse_per_class: [0.073, 0.236, 0.034, 0.271, 0.071, 0.165, 0.226, 0.117, 0.16, 0.095]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3833 | Steps: 2 | Val loss: 0.3044 | Batch size: 32 | lr: 0.001 | Duration: 3.26s
[2m[36m(func pid=17062)[0m rmse: 0.18006959557533264
[2m[36m(func pid=17062)[0m mae:  0.1314367949962616
[2m[36m(func pid=17062)[0m rmse_per_class: [0.108, 0.27, 0.093, 0.328, 0.097, 0.194, 0.3, 0.149, 0.142, 0.12]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2393 | Steps: 2 | Val loss: 0.2760 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=5093)[0m rmse: 0.16690783202648163
[2m[36m(func pid=5093)[0m mae:  0.12032462656497955
[2m[36m(func pid=5093)[0m rmse_per_class: [0.104, 0.263, 0.065, 0.315, 0.068, 0.189, 0.272, 0.134, 0.145, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2717 | Steps: 2 | Val loss: 0.2720 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4958 | Steps: 2 | Val loss: 0.3808 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=10475)[0m rmse: 0.14400994777679443
[2m[36m(func pid=10475)[0m mae:  0.08820881694555283
[2m[36m(func pid=10475)[0m rmse_per_class: [0.093, 0.235, 0.028, 0.263, 0.06, 0.164, 0.209, 0.113, 0.166, 0.111]
[2m[36m(func pid=10475)[0m 
== Status ==
Current time: 2024-01-07 06:26:20 (running for 00:30:11.87)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.383 |  0.167 |                   71 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.272 |  0.146 |                   71 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.144 |                   56 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.18  |                   23 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m rmse: 0.1457713544368744
[2m[36m(func pid=6491)[0m mae:  0.09755633771419525
[2m[36m(func pid=6491)[0m rmse_per_class: [0.074, 0.237, 0.034, 0.272, 0.072, 0.166, 0.225, 0.117, 0.164, 0.096]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.17998002469539642
[2m[36m(func pid=17062)[0m mae:  0.13131053745746613
[2m[36m(func pid=17062)[0m rmse_per_class: [0.108, 0.271, 0.093, 0.328, 0.097, 0.194, 0.298, 0.148, 0.143, 0.12]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3820 | Steps: 2 | Val loss: 0.3043 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2367 | Steps: 2 | Val loss: 0.2750 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2727 | Steps: 2 | Val loss: 0.2720 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4833 | Steps: 2 | Val loss: 0.3694 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=5093)[0m rmse: 0.16686153411865234
[2m[36m(func pid=5093)[0m mae:  0.12027551233768463
[2m[36m(func pid=5093)[0m rmse_per_class: [0.104, 0.263, 0.065, 0.315, 0.068, 0.189, 0.272, 0.134, 0.145, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14326594769954681
[2m[36m(func pid=10475)[0m mae:  0.0877303034067154
[2m[36m(func pid=10475)[0m rmse_per_class: [0.087, 0.236, 0.028, 0.26, 0.057, 0.163, 0.207, 0.111, 0.172, 0.11]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.14570824801921844
[2m[36m(func pid=6491)[0m mae:  0.09737002849578857
[2m[36m(func pid=6491)[0m rmse_per_class: [0.074, 0.237, 0.034, 0.272, 0.072, 0.166, 0.224, 0.117, 0.164, 0.098]
== Status ==
Current time: 2024-01-07 06:26:26 (running for 00:30:17.39)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.382 |  0.167 |                   72 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.273 |  0.146 |                   72 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.237 |  0.143 |                   57 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.496 |  0.18  |                   24 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.17976394295692444
[2m[36m(func pid=17062)[0m mae:  0.13109976053237915
[2m[36m(func pid=17062)[0m rmse_per_class: [0.109, 0.271, 0.094, 0.329, 0.096, 0.194, 0.297, 0.147, 0.143, 0.119]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3787 | Steps: 2 | Val loss: 0.3041 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2332 | Steps: 2 | Val loss: 0.2815 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4689 | Steps: 2 | Val loss: 0.3586 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2651 | Steps: 2 | Val loss: 0.2714 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=5093)[0m rmse: 0.16674849390983582
[2m[36m(func pid=5093)[0m mae:  0.1201561912894249
[2m[36m(func pid=5093)[0m rmse_per_class: [0.104, 0.263, 0.065, 0.315, 0.068, 0.189, 0.272, 0.134, 0.145, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14396068453788757
[2m[36m(func pid=10475)[0m mae:  0.08823847025632858
[2m[36m(func pid=10475)[0m rmse_per_class: [0.078, 0.236, 0.027, 0.266, 0.057, 0.165, 0.208, 0.113, 0.191, 0.1]
[2m[36m(func pid=10475)[0m 
== Status ==
Current time: 2024-01-07 06:26:31 (running for 00:30:22.62)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.379 |  0.167 |                   73 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.273 |  0.146 |                   72 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.233 |  0.144 |                   58 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.469 |  0.179 |                   26 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.17949217557907104
[2m[36m(func pid=17062)[0m mae:  0.13081760704517365
[2m[36m(func pid=17062)[0m rmse_per_class: [0.109, 0.271, 0.094, 0.33, 0.095, 0.194, 0.295, 0.145, 0.144, 0.118]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.1453799456357956
[2m[36m(func pid=6491)[0m mae:  0.09701614081859589
[2m[36m(func pid=6491)[0m rmse_per_class: [0.074, 0.238, 0.033, 0.269, 0.071, 0.165, 0.224, 0.117, 0.164, 0.098]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3789 | Steps: 2 | Val loss: 0.3037 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2414 | Steps: 2 | Val loss: 0.2841 | Batch size: 32 | lr: 0.1 | Duration: 2.68s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4569 | Steps: 2 | Val loss: 0.3504 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2703 | Steps: 2 | Val loss: 0.2709 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=10475)[0m rmse: 0.14427296817302704
[2m[36m(func pid=10475)[0m mae:  0.08864463865756989
[2m[36m(func pid=10475)[0m rmse_per_class: [0.071, 0.236, 0.028, 0.271, 0.057, 0.167, 0.21, 0.116, 0.193, 0.093]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.166591614484787
[2m[36m(func pid=5093)[0m mae:  0.11999784409999847
[2m[36m(func pid=5093)[0m rmse_per_class: [0.104, 0.263, 0.065, 0.314, 0.068, 0.189, 0.271, 0.134, 0.145, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.17931967973709106
[2m[36m(func pid=17062)[0m mae:  0.13063809275627136
[2m[36m(func pid=17062)[0m rmse_per_class: [0.109, 0.271, 0.094, 0.331, 0.094, 0.194, 0.293, 0.144, 0.145, 0.118]
[2m[36m(func pid=17062)[0m == Status ==
Current time: 2024-01-07 06:26:36 (running for 00:30:27.88)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.17499999701976776
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.379 |  0.167 |                   74 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.265 |  0.145 |                   73 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.241 |  0.144 |                   59 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.457 |  0.179 |                   27 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)



[2m[36m(func pid=6491)[0m rmse: 0.14496247470378876
[2m[36m(func pid=6491)[0m mae:  0.09651482105255127
[2m[36m(func pid=6491)[0m rmse_per_class: [0.073, 0.238, 0.033, 0.266, 0.07, 0.165, 0.224, 0.118, 0.163, 0.1]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2316 | Steps: 2 | Val loss: 0.2827 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3815 | Steps: 2 | Val loss: 0.3035 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4438 | Steps: 2 | Val loss: 0.3431 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=10475)[0m rmse: 0.14429451525211334
[2m[36m(func pid=10475)[0m mae:  0.08879702538251877
[2m[36m(func pid=10475)[0m rmse_per_class: [0.069, 0.234, 0.029, 0.279, 0.058, 0.169, 0.211, 0.124, 0.179, 0.091]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2631 | Steps: 2 | Val loss: 0.2691 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=5093)[0m rmse: 0.1665196269750595
[2m[36m(func pid=5093)[0m mae:  0.11993495374917984
[2m[36m(func pid=5093)[0m rmse_per_class: [0.104, 0.263, 0.065, 0.314, 0.068, 0.188, 0.271, 0.134, 0.145, 0.114]
[2m[36m(func pid=5093)[0m 
== Status ==
Current time: 2024-01-07 06:26:42 (running for 00:30:33.11)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16899999603629112
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.382 |  0.167 |                   75 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.27  |  0.145 |                   74 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.232 |  0.144 |                   60 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.444 |  0.179 |                   28 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.1791350245475769
[2m[36m(func pid=17062)[0m mae:  0.13040170073509216
[2m[36m(func pid=17062)[0m rmse_per_class: [0.11, 0.271, 0.095, 0.332, 0.093, 0.194, 0.292, 0.143, 0.145, 0.117]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.1438264548778534
[2m[36m(func pid=6491)[0m mae:  0.09564922749996185
[2m[36m(func pid=6491)[0m rmse_per_class: [0.072, 0.237, 0.033, 0.262, 0.069, 0.165, 0.224, 0.117, 0.159, 0.1]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2421 | Steps: 2 | Val loss: 0.2793 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.3810 | Steps: 2 | Val loss: 0.3035 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4373 | Steps: 2 | Val loss: 0.3373 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=10475)[0m rmse: 0.1437056064605713
[2m[36m(func pid=10475)[0m mae:  0.08817316591739655
[2m[36m(func pid=10475)[0m rmse_per_class: [0.072, 0.233, 0.031, 0.272, 0.062, 0.169, 0.209, 0.12, 0.174, 0.094]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2705 | Steps: 2 | Val loss: 0.2681 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=5093)[0m rmse: 0.16648314893245697
[2m[36m(func pid=5093)[0m mae:  0.11991812288761139
[2m[36m(func pid=5093)[0m rmse_per_class: [0.103, 0.263, 0.064, 0.314, 0.068, 0.188, 0.271, 0.134, 0.145, 0.114]
[2m[36m(func pid=5093)[0m 
== Status ==
Current time: 2024-01-07 06:26:47 (running for 00:30:38.29)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.381 |  0.166 |                   76 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.263 |  0.144 |                   75 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.242 |  0.144 |                   61 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.437 |  0.179 |                   29 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.1788933128118515
[2m[36m(func pid=17062)[0m mae:  0.1301163285970688
[2m[36m(func pid=17062)[0m rmse_per_class: [0.11, 0.272, 0.094, 0.332, 0.093, 0.194, 0.29, 0.142, 0.146, 0.116]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2402 | Steps: 2 | Val loss: 0.2765 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=6491)[0m rmse: 0.14313744008541107
[2m[36m(func pid=6491)[0m mae:  0.09504862129688263
[2m[36m(func pid=6491)[0m rmse_per_class: [0.07, 0.237, 0.033, 0.259, 0.068, 0.165, 0.223, 0.118, 0.157, 0.101]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.3788 | Steps: 2 | Val loss: 0.3030 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4292 | Steps: 2 | Val loss: 0.3327 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=10475)[0m rmse: 0.14303556084632874
[2m[36m(func pid=10475)[0m mae:  0.08699877560138702
[2m[36m(func pid=10475)[0m rmse_per_class: [0.084, 0.234, 0.032, 0.263, 0.066, 0.165, 0.206, 0.114, 0.166, 0.1]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2612 | Steps: 2 | Val loss: 0.2681 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 06:26:52 (running for 00:30:43.52)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.381 |  0.166 |                   76 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.27  |  0.143 |                   76 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.24  |  0.143 |                   62 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.429 |  0.179 |                   30 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=5093)[0m rmse: 0.1662444770336151
[2m[36m(func pid=5093)[0m mae:  0.11972503364086151
[2m[36m(func pid=5093)[0m rmse_per_class: [0.103, 0.263, 0.064, 0.313, 0.068, 0.188, 0.271, 0.134, 0.145, 0.114]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.17862387001514435
[2m[36m(func pid=17062)[0m mae:  0.12982192635536194
[2m[36m(func pid=17062)[0m rmse_per_class: [0.111, 0.272, 0.094, 0.333, 0.091, 0.194, 0.288, 0.141, 0.147, 0.115]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2379 | Steps: 2 | Val loss: 0.2762 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=6491)[0m rmse: 0.14304442703723907
[2m[36m(func pid=6491)[0m mae:  0.09500057995319366
[2m[36m(func pid=6491)[0m rmse_per_class: [0.07, 0.237, 0.033, 0.259, 0.068, 0.165, 0.223, 0.117, 0.158, 0.1]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14387640357017517
[2m[36m(func pid=10475)[0m mae:  0.08730850368738174
[2m[36m(func pid=10475)[0m rmse_per_class: [0.087, 0.235, 0.031, 0.258, 0.074, 0.165, 0.205, 0.11, 0.163, 0.111]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4247 | Steps: 2 | Val loss: 0.3297 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.3783 | Steps: 2 | Val loss: 0.3029 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2605 | Steps: 2 | Val loss: 0.2678 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 06:26:57 (running for 00:30:48.88)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.379 |  0.166 |                   77 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.261 |  0.143 |                   77 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.238 |  0.144 |                   63 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.425 |  0.178 |                   31 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.17848341166973114
[2m[36m(func pid=17062)[0m mae:  0.12964528799057007
[2m[36m(func pid=17062)[0m rmse_per_class: [0.111, 0.272, 0.095, 0.334, 0.09, 0.194, 0.286, 0.141, 0.147, 0.115]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16617664694786072
[2m[36m(func pid=5093)[0m mae:  0.11968196928501129
[2m[36m(func pid=5093)[0m rmse_per_class: [0.103, 0.262, 0.064, 0.313, 0.068, 0.188, 0.271, 0.133, 0.145, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2393 | Steps: 2 | Val loss: 0.2767 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=6491)[0m rmse: 0.14285260438919067
[2m[36m(func pid=6491)[0m mae:  0.09484048187732697
[2m[36m(func pid=6491)[0m rmse_per_class: [0.07, 0.236, 0.032, 0.26, 0.069, 0.165, 0.224, 0.117, 0.158, 0.098]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4215 | Steps: 2 | Val loss: 0.3275 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=10475)[0m rmse: 0.14437109231948853
[2m[36m(func pid=10475)[0m mae:  0.08799681812524796
[2m[36m(func pid=10475)[0m rmse_per_class: [0.074, 0.233, 0.031, 0.261, 0.077, 0.165, 0.207, 0.111, 0.173, 0.112]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.3739 | Steps: 2 | Val loss: 0.3027 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2553 | Steps: 2 | Val loss: 0.2677 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 06:27:03 (running for 00:30:54.16)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.378 |  0.166 |                   78 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.261 |  0.143 |                   78 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.144 |                   64 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.422 |  0.178 |                   32 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.1782766878604889
[2m[36m(func pid=17062)[0m mae:  0.12940604984760284
[2m[36m(func pid=17062)[0m rmse_per_class: [0.111, 0.272, 0.095, 0.335, 0.089, 0.194, 0.285, 0.139, 0.148, 0.114]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2331 | Steps: 2 | Val loss: 0.2845 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=5093)[0m rmse: 0.16606783866882324
[2m[36m(func pid=5093)[0m mae:  0.1195741519331932
[2m[36m(func pid=5093)[0m rmse_per_class: [0.103, 0.262, 0.064, 0.313, 0.068, 0.188, 0.271, 0.133, 0.144, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.1425953209400177
[2m[36m(func pid=6491)[0m mae:  0.09459488093852997
[2m[36m(func pid=6491)[0m rmse_per_class: [0.07, 0.236, 0.032, 0.259, 0.067, 0.164, 0.224, 0.117, 0.156, 0.101]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14862754940986633
[2m[36m(func pid=10475)[0m mae:  0.09095786511898041
[2m[36m(func pid=10475)[0m rmse_per_class: [0.071, 0.237, 0.031, 0.271, 0.083, 0.168, 0.21, 0.114, 0.196, 0.106]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4190 | Steps: 2 | Val loss: 0.3264 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.3818 | Steps: 2 | Val loss: 0.3024 | Batch size: 32 | lr: 0.001 | Duration: 3.22s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2619 | Steps: 2 | Val loss: 0.2675 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 06:27:08 (running for 00:30:59.55)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.374 |  0.166 |                   79 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.255 |  0.143 |                   79 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.233 |  0.149 |                   65 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.419 |  0.178 |                   33 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.1781539022922516
[2m[36m(func pid=17062)[0m mae:  0.12924431264400482
[2m[36m(func pid=17062)[0m rmse_per_class: [0.112, 0.272, 0.096, 0.336, 0.088, 0.194, 0.284, 0.139, 0.149, 0.113]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2346 | Steps: 2 | Val loss: 0.2910 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=5093)[0m rmse: 0.16591204702854156
[2m[36m(func pid=5093)[0m mae:  0.1194477528333664
[2m[36m(func pid=5093)[0m rmse_per_class: [0.103, 0.262, 0.064, 0.312, 0.068, 0.188, 0.271, 0.133, 0.145, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.1423751264810562
[2m[36m(func pid=6491)[0m mae:  0.09441210329532623
[2m[36m(func pid=6491)[0m rmse_per_class: [0.069, 0.235, 0.032, 0.259, 0.067, 0.164, 0.224, 0.117, 0.156, 0.101]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.15095160901546478
[2m[36m(func pid=10475)[0m mae:  0.0928439050912857
[2m[36m(func pid=10475)[0m rmse_per_class: [0.071, 0.239, 0.03, 0.283, 0.077, 0.171, 0.21, 0.116, 0.211, 0.101]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4177 | Steps: 2 | Val loss: 0.3256 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.3748 | Steps: 2 | Val loss: 0.3022 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2686 | Steps: 2 | Val loss: 0.2677 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 06:27:13 (running for 00:31:04.84)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.382 |  0.166 |                   80 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.262 |  0.142 |                   80 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.235 |  0.151 |                   66 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.418 |  0.178 |                   34 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.17795690894126892
[2m[36m(func pid=17062)[0m mae:  0.12898989021778107
[2m[36m(func pid=17062)[0m rmse_per_class: [0.112, 0.272, 0.096, 0.337, 0.087, 0.194, 0.282, 0.138, 0.149, 0.112]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2368 | Steps: 2 | Val loss: 0.2877 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=6491)[0m rmse: 0.14255012571811676
[2m[36m(func pid=6491)[0m mae:  0.0944942906498909
[2m[36m(func pid=6491)[0m rmse_per_class: [0.069, 0.234, 0.032, 0.26, 0.067, 0.164, 0.225, 0.117, 0.158, 0.101]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16577544808387756
[2m[36m(func pid=5093)[0m mae:  0.1193229928612709
[2m[36m(func pid=5093)[0m rmse_per_class: [0.103, 0.262, 0.064, 0.312, 0.068, 0.188, 0.271, 0.134, 0.144, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14699696004390717
[2m[36m(func pid=10475)[0m mae:  0.08996021747589111
[2m[36m(func pid=10475)[0m rmse_per_class: [0.081, 0.237, 0.03, 0.278, 0.06, 0.165, 0.206, 0.12, 0.192, 0.101]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4148 | Steps: 2 | Val loss: 0.3254 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2642 | Steps: 2 | Val loss: 0.2679 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.3803 | Steps: 2 | Val loss: 0.3021 | Batch size: 32 | lr: 0.001 | Duration: 3.17s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2410 | Steps: 2 | Val loss: 0.2832 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 06:27:19 (running for 00:31:10.41)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.375 |  0.166 |                   81 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.269 |  0.143 |                   81 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.237 |  0.147 |                   67 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.415 |  0.178 |                   35 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.1777220070362091
[2m[36m(func pid=17062)[0m mae:  0.1286909431219101
[2m[36m(func pid=17062)[0m rmse_per_class: [0.112, 0.273, 0.097, 0.338, 0.085, 0.194, 0.281, 0.137, 0.15, 0.111]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.1426418572664261
[2m[36m(func pid=6491)[0m mae:  0.09453980624675751
[2m[36m(func pid=6491)[0m rmse_per_class: [0.068, 0.234, 0.032, 0.261, 0.067, 0.164, 0.225, 0.118, 0.159, 0.1]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16577289998531342
[2m[36m(func pid=5093)[0m mae:  0.11930842697620392
[2m[36m(func pid=5093)[0m rmse_per_class: [0.103, 0.262, 0.064, 0.312, 0.068, 0.188, 0.271, 0.133, 0.145, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14391298592090607
[2m[36m(func pid=10475)[0m mae:  0.0876290574669838
[2m[36m(func pid=10475)[0m rmse_per_class: [0.09, 0.234, 0.031, 0.272, 0.052, 0.163, 0.207, 0.123, 0.169, 0.098]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4133 | Steps: 2 | Val loss: 0.3261 | Batch size: 32 | lr: 0.0001 | Duration: 2.64s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2598 | Steps: 2 | Val loss: 0.2686 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.3775 | Steps: 2 | Val loss: 0.3020 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 06:27:24 (running for 00:31:15.47)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.38  |  0.166 |                   82 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.264 |  0.143 |                   82 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.241 |  0.144 |                   68 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.413 |  0.178 |                   36 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2404 | Steps: 2 | Val loss: 0.2799 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=17062)[0m rmse: 0.17754104733467102
[2m[36m(func pid=17062)[0m mae:  0.12849806249141693
[2m[36m(func pid=17062)[0m rmse_per_class: [0.112, 0.273, 0.097, 0.339, 0.084, 0.194, 0.28, 0.137, 0.151, 0.11]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.14301487803459167
[2m[36m(func pid=6491)[0m mae:  0.09481566399335861
[2m[36m(func pid=6491)[0m rmse_per_class: [0.068, 0.234, 0.032, 0.263, 0.066, 0.164, 0.225, 0.118, 0.159, 0.101]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16569708287715912
[2m[36m(func pid=5093)[0m mae:  0.119259774684906
[2m[36m(func pid=5093)[0m rmse_per_class: [0.103, 0.262, 0.064, 0.311, 0.068, 0.188, 0.271, 0.134, 0.145, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.1426534354686737
[2m[36m(func pid=10475)[0m mae:  0.08676804602146149
[2m[36m(func pid=10475)[0m rmse_per_class: [0.102, 0.233, 0.032, 0.267, 0.051, 0.164, 0.205, 0.117, 0.156, 0.1]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4181 | Steps: 2 | Val loss: 0.3271 | Batch size: 32 | lr: 0.0001 | Duration: 2.68s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2598 | Steps: 2 | Val loss: 0.2696 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 06:27:29 (running for 00:31:20.50)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.377 |  0.166 |                   83 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.26  |  0.143 |                   83 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.24  |  0.143 |                   69 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.418 |  0.177 |                   37 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2383 | Steps: 2 | Val loss: 0.2768 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=17062)[0m rmse: 0.17737966775894165
[2m[36m(func pid=17062)[0m mae:  0.12828901410102844
[2m[36m(func pid=17062)[0m rmse_per_class: [0.112, 0.273, 0.097, 0.34, 0.083, 0.194, 0.279, 0.136, 0.151, 0.11]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.3734 | Steps: 2 | Val loss: 0.3018 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
[2m[36m(func pid=10475)[0m rmse: 0.14092174172401428
[2m[36m(func pid=10475)[0m mae:  0.08578689396381378
[2m[36m(func pid=10475)[0m rmse_per_class: [0.085, 0.232, 0.033, 0.262, 0.053, 0.167, 0.206, 0.114, 0.156, 0.103]
[2m[36m(func pid=6491)[0m rmse: 0.14363786578178406
[2m[36m(func pid=6491)[0m mae:  0.0952952429652214
[2m[36m(func pid=6491)[0m rmse_per_class: [0.068, 0.234, 0.032, 0.266, 0.066, 0.164, 0.225, 0.119, 0.16, 0.103]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16555307805538177
[2m[36m(func pid=5093)[0m mae:  0.11913353204727173
[2m[36m(func pid=5093)[0m rmse_per_class: [0.102, 0.262, 0.064, 0.311, 0.068, 0.187, 0.271, 0.133, 0.145, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4181 | Steps: 2 | Val loss: 0.3284 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2319 | Steps: 2 | Val loss: 0.2765 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2568 | Steps: 2 | Val loss: 0.2711 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 06:27:34 (running for 00:31:25.95)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.373 |  0.166 |                   84 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.26  |  0.144 |                   84 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.238 |  0.141 |                   70 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.418 |  0.177 |                   38 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.17719896137714386
[2m[36m(func pid=17062)[0m mae:  0.1280921846628189
[2m[36m(func pid=17062)[0m rmse_per_class: [0.112, 0.273, 0.097, 0.34, 0.081, 0.194, 0.278, 0.136, 0.152, 0.109]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.3718 | Steps: 2 | Val loss: 0.3016 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=10475)[0m rmse: 0.14157769083976746
[2m[36m(func pid=10475)[0m mae:  0.08633747696876526
[2m[36m(func pid=10475)[0m rmse_per_class: [0.071, 0.233, 0.031, 0.261, 0.057, 0.167, 0.207, 0.113, 0.163, 0.113]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.14448262751102448
[2m[36m(func pid=6491)[0m mae:  0.09588810801506042
[2m[36m(func pid=6491)[0m rmse_per_class: [0.069, 0.235, 0.032, 0.269, 0.066, 0.164, 0.225, 0.12, 0.162, 0.103]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4203 | Steps: 2 | Val loss: 0.3308 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=5093)[0m rmse: 0.16548855602741241
[2m[36m(func pid=5093)[0m mae:  0.11907372623682022
[2m[36m(func pid=5093)[0m rmse_per_class: [0.103, 0.262, 0.063, 0.31, 0.068, 0.187, 0.271, 0.133, 0.145, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2339 | Steps: 2 | Val loss: 0.2818 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 06:27:40 (running for 00:31:31.23)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.372 |  0.165 |                   85 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.257 |  0.144 |                   85 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.232 |  0.142 |                   71 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.42  |  0.177 |                   39 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.17713840305805206
[2m[36m(func pid=17062)[0m mae:  0.12790453433990479
[2m[36m(func pid=17062)[0m rmse_per_class: [0.113, 0.273, 0.097, 0.341, 0.081, 0.194, 0.277, 0.136, 0.152, 0.108]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2774 | Steps: 2 | Val loss: 0.2713 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.3733 | Steps: 2 | Val loss: 0.3017 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=10475)[0m rmse: 0.14523710310459137
[2m[36m(func pid=10475)[0m mae:  0.08884783089160919
[2m[36m(func pid=10475)[0m rmse_per_class: [0.068, 0.236, 0.03, 0.266, 0.062, 0.171, 0.211, 0.115, 0.179, 0.115]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.14472241699695587
[2m[36m(func pid=6491)[0m mae:  0.0959784984588623
[2m[36m(func pid=6491)[0m rmse_per_class: [0.069, 0.235, 0.032, 0.27, 0.066, 0.164, 0.225, 0.121, 0.163, 0.103]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4232 | Steps: 2 | Val loss: 0.3330 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=5093)[0m rmse: 0.16551974415779114
[2m[36m(func pid=5093)[0m mae:  0.11908233165740967
[2m[36m(func pid=5093)[0m rmse_per_class: [0.103, 0.262, 0.063, 0.31, 0.068, 0.188, 0.271, 0.133, 0.146, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2375 | Steps: 2 | Val loss: 0.2886 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 06:27:45 (running for 00:31:36.50)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.373 |  0.166 |                   86 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.277 |  0.145 |                   86 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.234 |  0.145 |                   72 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.423 |  0.177 |                   40 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.17699885368347168
[2m[36m(func pid=17062)[0m mae:  0.12768161296844482
[2m[36m(func pid=17062)[0m rmse_per_class: [0.113, 0.273, 0.097, 0.342, 0.08, 0.194, 0.276, 0.135, 0.153, 0.107]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2642 | Steps: 2 | Val loss: 0.2714 | Batch size: 32 | lr: 0.01 | Duration: 3.13s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.3726 | Steps: 2 | Val loss: 0.3014 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=10475)[0m rmse: 0.14914026856422424
[2m[36m(func pid=10475)[0m mae:  0.09146799147129059
[2m[36m(func pid=10475)[0m rmse_per_class: [0.073, 0.238, 0.03, 0.278, 0.069, 0.167, 0.209, 0.12, 0.195, 0.113]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.14464649558067322
[2m[36m(func pid=6491)[0m mae:  0.09584452956914902
[2m[36m(func pid=6491)[0m rmse_per_class: [0.07, 0.235, 0.032, 0.271, 0.066, 0.164, 0.224, 0.12, 0.161, 0.103]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4233 | Steps: 2 | Val loss: 0.3356 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=5093)[0m rmse: 0.16538622975349426
[2m[36m(func pid=5093)[0m mae:  0.1189471110701561
[2m[36m(func pid=5093)[0m rmse_per_class: [0.103, 0.262, 0.063, 0.31, 0.068, 0.187, 0.271, 0.133, 0.146, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2354 | Steps: 2 | Val loss: 0.2926 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 06:27:50 (running for 00:31:41.90)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.373 |  0.165 |                   87 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.264 |  0.145 |                   87 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.238 |  0.149 |                   73 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.423 |  0.177 |                   41 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.1768828183412552
[2m[36m(func pid=17062)[0m mae:  0.12746332585811615
[2m[36m(func pid=17062)[0m rmse_per_class: [0.113, 0.273, 0.097, 0.342, 0.079, 0.194, 0.275, 0.135, 0.154, 0.106]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2615 | Steps: 2 | Val loss: 0.2714 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=10475)[0m rmse: 0.15093500912189484
[2m[36m(func pid=10475)[0m mae:  0.09280072152614594
[2m[36m(func pid=10475)[0m rmse_per_class: [0.093, 0.24, 0.03, 0.289, 0.066, 0.166, 0.205, 0.118, 0.197, 0.105]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.3757 | Steps: 2 | Val loss: 0.3014 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4237 | Steps: 2 | Val loss: 0.3386 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=6491)[0m rmse: 0.1445697396993637
[2m[36m(func pid=6491)[0m mae:  0.09576089680194855
[2m[36m(func pid=6491)[0m rmse_per_class: [0.071, 0.235, 0.032, 0.272, 0.066, 0.164, 0.222, 0.12, 0.161, 0.103]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2329 | Steps: 2 | Val loss: 0.2904 | Batch size: 32 | lr: 0.1 | Duration: 2.54s
[2m[36m(func pid=5093)[0m rmse: 0.16538134217262268
[2m[36m(func pid=5093)[0m mae:  0.11893594264984131
[2m[36m(func pid=5093)[0m rmse_per_class: [0.102, 0.262, 0.063, 0.31, 0.067, 0.187, 0.271, 0.133, 0.146, 0.112]
[2m[36m(func pid=5093)[0m 
== Status ==
Current time: 2024-01-07 06:27:56 (running for 00:31:47.13)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.376 |  0.165 |                   88 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.262 |  0.145 |                   88 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.235 |  0.151 |                   74 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.424 |  0.177 |                   42 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.17677870392799377
[2m[36m(func pid=17062)[0m mae:  0.12725171446800232
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.274, 0.096, 0.343, 0.078, 0.194, 0.274, 0.135, 0.155, 0.106]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2631 | Steps: 2 | Val loss: 0.2699 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=10475)[0m rmse: 0.14853695034980774
[2m[36m(func pid=10475)[0m mae:  0.09115241467952728
[2m[36m(func pid=10475)[0m rmse_per_class: [0.092, 0.238, 0.031, 0.288, 0.059, 0.166, 0.206, 0.116, 0.187, 0.102]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.3701 | Steps: 2 | Val loss: 0.3012 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4284 | Steps: 2 | Val loss: 0.3413 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=6491)[0m rmse: 0.14365063607692719
[2m[36m(func pid=6491)[0m mae:  0.09506204724311829
[2m[36m(func pid=6491)[0m rmse_per_class: [0.072, 0.234, 0.032, 0.269, 0.066, 0.164, 0.221, 0.118, 0.159, 0.1]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2377 | Steps: 2 | Val loss: 0.2868 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=5093)[0m rmse: 0.16527003049850464
[2m[36m(func pid=5093)[0m mae:  0.11883985996246338
[2m[36m(func pid=5093)[0m rmse_per_class: [0.102, 0.262, 0.063, 0.309, 0.067, 0.187, 0.271, 0.133, 0.146, 0.112]
[2m[36m(func pid=5093)[0m 
== Status ==
Current time: 2024-01-07 06:28:01 (running for 00:31:52.22)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.37  |  0.165 |                   89 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.263 |  0.144 |                   89 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.233 |  0.149 |                   75 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.428 |  0.177 |                   43 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.1767122596502304
[2m[36m(func pid=17062)[0m mae:  0.12707825005054474
[2m[36m(func pid=17062)[0m rmse_per_class: [0.113, 0.274, 0.096, 0.344, 0.077, 0.194, 0.274, 0.135, 0.156, 0.105]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2611 | Steps: 2 | Val loss: 0.2689 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=10475)[0m rmse: 0.14579293131828308
[2m[36m(func pid=10475)[0m mae:  0.0892338678240776
[2m[36m(func pid=10475)[0m rmse_per_class: [0.075, 0.236, 0.03, 0.276, 0.057, 0.171, 0.208, 0.116, 0.177, 0.112]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4342 | Steps: 2 | Val loss: 0.3438 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.3751 | Steps: 2 | Val loss: 0.3011 | Batch size: 32 | lr: 0.001 | Duration: 3.14s
[2m[36m(func pid=6491)[0m rmse: 0.1430164873600006
[2m[36m(func pid=6491)[0m mae:  0.09458398073911667
[2m[36m(func pid=6491)[0m rmse_per_class: [0.072, 0.234, 0.032, 0.268, 0.066, 0.164, 0.22, 0.118, 0.159, 0.097]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2403 | Steps: 2 | Val loss: 0.2808 | Batch size: 32 | lr: 0.1 | Duration: 2.58s
== Status ==
Current time: 2024-01-07 06:28:06 (running for 00:31:57.62)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.37  |  0.165 |                   89 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.261 |  0.143 |                   90 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.238 |  0.146 |                   76 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.434 |  0.177 |                   44 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.17653098702430725
[2m[36m(func pid=17062)[0m mae:  0.126827210187912
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.274, 0.095, 0.344, 0.076, 0.194, 0.273, 0.135, 0.156, 0.104]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16528023779392242
[2m[36m(func pid=5093)[0m mae:  0.11886809021234512
[2m[36m(func pid=5093)[0m rmse_per_class: [0.102, 0.262, 0.063, 0.309, 0.067, 0.187, 0.271, 0.133, 0.147, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2579 | Steps: 2 | Val loss: 0.2685 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=10475)[0m rmse: 0.14346466958522797
[2m[36m(func pid=10475)[0m mae:  0.08777065575122833
[2m[36m(func pid=10475)[0m rmse_per_class: [0.066, 0.233, 0.03, 0.265, 0.057, 0.172, 0.211, 0.115, 0.165, 0.119]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4442 | Steps: 2 | Val loss: 0.3468 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.3680 | Steps: 2 | Val loss: 0.3011 | Batch size: 32 | lr: 0.001 | Duration: 3.17s
[2m[36m(func pid=6491)[0m rmse: 0.1427631974220276
[2m[36m(func pid=6491)[0m mae:  0.09439561516046524
[2m[36m(func pid=6491)[0m rmse_per_class: [0.073, 0.234, 0.032, 0.267, 0.066, 0.164, 0.221, 0.117, 0.159, 0.095]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2369 | Steps: 2 | Val loss: 0.2733 | Batch size: 32 | lr: 0.1 | Duration: 2.65s
== Status ==
Current time: 2024-01-07 06:28:11 (running for 00:32:02.92)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.375 |  0.165 |                   90 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.143 |                   91 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.24  |  0.143 |                   77 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.444 |  0.176 |                   45 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.17642712593078613
[2m[36m(func pid=17062)[0m mae:  0.1266200989484787
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.274, 0.095, 0.345, 0.075, 0.194, 0.273, 0.135, 0.157, 0.104]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16523894667625427
[2m[36m(func pid=5093)[0m mae:  0.1188240796327591
[2m[36m(func pid=5093)[0m rmse_per_class: [0.102, 0.262, 0.063, 0.31, 0.068, 0.187, 0.27, 0.133, 0.147, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14031478762626648
[2m[36m(func pid=10475)[0m mae:  0.08562364429235458
[2m[36m(func pid=10475)[0m rmse_per_class: [0.067, 0.23, 0.031, 0.256, 0.061, 0.166, 0.212, 0.112, 0.157, 0.112]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2598 | Steps: 2 | Val loss: 0.2683 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4374 | Steps: 2 | Val loss: 0.3500 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2381 | Steps: 2 | Val loss: 0.2751 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=6491)[0m rmse: 0.14264313876628876
[2m[36m(func pid=6491)[0m mae:  0.09420839697122574
[2m[36m(func pid=6491)[0m rmse_per_class: [0.073, 0.234, 0.032, 0.265, 0.067, 0.164, 0.221, 0.116, 0.159, 0.095]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.3711 | Steps: 2 | Val loss: 0.3008 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 06:28:17 (running for 00:32:08.21)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.368 |  0.165 |                   91 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.26  |  0.143 |                   92 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.237 |  0.14  |                   78 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.437 |  0.176 |                   46 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.1763296276330948
[2m[36m(func pid=17062)[0m mae:  0.1264231950044632
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.274, 0.094, 0.346, 0.074, 0.194, 0.273, 0.135, 0.157, 0.103]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.141954705119133
[2m[36m(func pid=10475)[0m mae:  0.08633046597242355
[2m[36m(func pid=10475)[0m rmse_per_class: [0.083, 0.231, 0.031, 0.258, 0.066, 0.166, 0.208, 0.114, 0.162, 0.102]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16509506106376648
[2m[36m(func pid=5093)[0m mae:  0.11868475377559662
[2m[36m(func pid=5093)[0m rmse_per_class: [0.102, 0.261, 0.063, 0.309, 0.068, 0.187, 0.27, 0.133, 0.146, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2613 | Steps: 2 | Val loss: 0.2682 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4444 | Steps: 2 | Val loss: 0.3539 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2362 | Steps: 2 | Val loss: 0.2863 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=6491)[0m rmse: 0.1425144523382187
[2m[36m(func pid=6491)[0m mae:  0.0940510630607605
[2m[36m(func pid=6491)[0m rmse_per_class: [0.073, 0.234, 0.032, 0.264, 0.066, 0.164, 0.222, 0.116, 0.159, 0.095]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.3744 | Steps: 2 | Val loss: 0.3008 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
== Status ==
Current time: 2024-01-07 06:28:22 (running for 00:32:13.51)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.371 |  0.165 |                   92 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.261 |  0.143 |                   93 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.238 |  0.142 |                   79 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.444 |  0.176 |                   47 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.1762811541557312
[2m[36m(func pid=17062)[0m mae:  0.12624213099479675
[2m[36m(func pid=17062)[0m rmse_per_class: [0.115, 0.274, 0.093, 0.347, 0.073, 0.194, 0.273, 0.135, 0.158, 0.102]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14784245193004608
[2m[36m(func pid=10475)[0m mae:  0.09011876583099365
[2m[36m(func pid=10475)[0m rmse_per_class: [0.1, 0.237, 0.031, 0.277, 0.066, 0.166, 0.206, 0.12, 0.175, 0.1]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m rmse: 0.16511142253875732
[2m[36m(func pid=5093)[0m mae:  0.11869879066944122
[2m[36m(func pid=5093)[0m rmse_per_class: [0.102, 0.261, 0.062, 0.31, 0.067, 0.187, 0.27, 0.133, 0.147, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2577 | Steps: 2 | Val loss: 0.2683 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4521 | Steps: 2 | Val loss: 0.3567 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2339 | Steps: 2 | Val loss: 0.2966 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=6491)[0m rmse: 0.1424953192472458
[2m[36m(func pid=6491)[0m mae:  0.09394516050815582
[2m[36m(func pid=6491)[0m rmse_per_class: [0.071, 0.234, 0.032, 0.263, 0.067, 0.164, 0.221, 0.117, 0.159, 0.097]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.3717 | Steps: 2 | Val loss: 0.3009 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 06:28:27 (running for 00:32:18.78)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.374 |  0.165 |                   93 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                   94 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.236 |  0.148 |                   80 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.452 |  0.176 |                   48 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.17611020803451538
[2m[36m(func pid=17062)[0m mae:  0.12596413493156433
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.274, 0.093, 0.347, 0.072, 0.194, 0.273, 0.135, 0.157, 0.102]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.1511642038822174
[2m[36m(func pid=10475)[0m mae:  0.09275130927562714
[2m[36m(func pid=10475)[0m rmse_per_class: [0.092, 0.24, 0.03, 0.294, 0.062, 0.169, 0.209, 0.121, 0.188, 0.105]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2623 | Steps: 2 | Val loss: 0.2684 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=5093)[0m rmse: 0.16514094173908234
[2m[36m(func pid=5093)[0m mae:  0.11872317641973495
[2m[36m(func pid=5093)[0m rmse_per_class: [0.102, 0.261, 0.063, 0.31, 0.068, 0.187, 0.27, 0.133, 0.147, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4510 | Steps: 2 | Val loss: 0.3592 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2458 | Steps: 2 | Val loss: 0.2933 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=6491)[0m rmse: 0.1425660103559494
[2m[36m(func pid=6491)[0m mae:  0.09386052191257477
[2m[36m(func pid=6491)[0m rmse_per_class: [0.07, 0.234, 0.032, 0.263, 0.067, 0.164, 0.22, 0.118, 0.161, 0.096]
[2m[36m(func pid=6491)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.3693 | Steps: 2 | Val loss: 0.3007 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 06:28:32 (running for 00:32:24.03)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.372 |  0.165 |                   94 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.262 |  0.143 |                   95 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.234 |  0.151 |                   81 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.451 |  0.176 |                   49 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.1759146749973297
[2m[36m(func pid=17062)[0m mae:  0.12572981417179108
[2m[36m(func pid=17062)[0m rmse_per_class: [0.115, 0.274, 0.091, 0.347, 0.071, 0.194, 0.273, 0.135, 0.157, 0.101]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.1489725410938263
[2m[36m(func pid=10475)[0m mae:  0.09161177277565002
[2m[36m(func pid=10475)[0m rmse_per_class: [0.073, 0.239, 0.03, 0.291, 0.057, 0.169, 0.208, 0.117, 0.2, 0.105]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2674 | Steps: 2 | Val loss: 0.2680 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=5093)[0m rmse: 0.16500553488731384
[2m[36m(func pid=5093)[0m mae:  0.1185881644487381
[2m[36m(func pid=5093)[0m rmse_per_class: [0.101, 0.261, 0.063, 0.309, 0.068, 0.187, 0.269, 0.133, 0.147, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4570 | Steps: 2 | Val loss: 0.3621 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2365 | Steps: 2 | Val loss: 0.2775 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=6491)[0m rmse: 0.14237745106220245
[2m[36m(func pid=6491)[0m mae:  0.09368814527988434
[2m[36m(func pid=6491)[0m rmse_per_class: [0.069, 0.234, 0.032, 0.263, 0.067, 0.164, 0.221, 0.118, 0.16, 0.097]
[2m[36m(func pid=6491)[0m 
== Status ==
Current time: 2024-01-07 06:28:38 (running for 00:32:29.27)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.369 |  0.165 |                   95 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.267 |  0.142 |                   96 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.246 |  0.149 |                   82 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.457 |  0.176 |                   50 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.17579993605613708
[2m[36m(func pid=17062)[0m mae:  0.12552011013031006
[2m[36m(func pid=17062)[0m rmse_per_class: [0.115, 0.274, 0.09, 0.347, 0.071, 0.194, 0.273, 0.135, 0.158, 0.101]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.3672 | Steps: 2 | Val loss: 0.3005 | Batch size: 32 | lr: 0.001 | Duration: 3.13s
[2m[36m(func pid=10475)[0m rmse: 0.14238891005516052
[2m[36m(func pid=10475)[0m mae:  0.08700702339410782
[2m[36m(func pid=10475)[0m rmse_per_class: [0.066, 0.234, 0.031, 0.267, 0.057, 0.167, 0.206, 0.111, 0.188, 0.097]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2515 | Steps: 2 | Val loss: 0.2678 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=5093)[0m rmse: 0.16495905816555023
[2m[36m(func pid=5093)[0m mae:  0.11852633953094482
[2m[36m(func pid=5093)[0m rmse_per_class: [0.101, 0.261, 0.063, 0.309, 0.068, 0.187, 0.269, 0.133, 0.146, 0.113]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4631 | Steps: 2 | Val loss: 0.3653 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2414 | Steps: 2 | Val loss: 0.2717 | Batch size: 32 | lr: 0.1 | Duration: 2.65s
[2m[36m(func pid=6491)[0m rmse: 0.1421840339899063
[2m[36m(func pid=6491)[0m mae:  0.09345714747905731
[2m[36m(func pid=6491)[0m rmse_per_class: [0.07, 0.233, 0.032, 0.263, 0.067, 0.163, 0.22, 0.118, 0.159, 0.097]
[2m[36m(func pid=6491)[0m 
== Status ==
Current time: 2024-01-07 06:28:43 (running for 00:32:34.65)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.367 |  0.165 |                   96 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.252 |  0.142 |                   97 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.236 |  0.142 |                   83 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.463 |  0.176 |                   51 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.17575602233409882
[2m[36m(func pid=17062)[0m mae:  0.1253580003976822
[2m[36m(func pid=17062)[0m rmse_per_class: [0.115, 0.274, 0.089, 0.347, 0.07, 0.194, 0.273, 0.136, 0.158, 0.1]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14005491137504578
[2m[36m(func pid=10475)[0m mae:  0.08508623391389847
[2m[36m(func pid=10475)[0m rmse_per_class: [0.072, 0.232, 0.032, 0.256, 0.06, 0.166, 0.207, 0.111, 0.171, 0.095]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.3691 | Steps: 2 | Val loss: 0.3003 | Batch size: 32 | lr: 0.001 | Duration: 3.13s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2598 | Steps: 2 | Val loss: 0.2679 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2376 | Steps: 2 | Val loss: 0.2778 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4599 | Steps: 2 | Val loss: 0.3683 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=5093)[0m rmse: 0.16480329632759094
[2m[36m(func pid=5093)[0m mae:  0.11839994043111801
[2m[36m(func pid=5093)[0m rmse_per_class: [0.101, 0.261, 0.062, 0.309, 0.068, 0.187, 0.269, 0.133, 0.146, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.14216826856136322
[2m[36m(func pid=6491)[0m mae:  0.09340086579322815
[2m[36m(func pid=6491)[0m rmse_per_class: [0.07, 0.233, 0.032, 0.261, 0.066, 0.163, 0.221, 0.117, 0.162, 0.097]
[2m[36m(func pid=6491)[0m 
== Status ==
Current time: 2024-01-07 06:28:48 (running for 00:32:39.93)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.369 |  0.165 |                   97 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.26  |  0.142 |                   98 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.238 |  0.144 |                   85 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.463 |  0.176 |                   51 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.14380942285060883
[2m[36m(func pid=10475)[0m mae:  0.08711730688810349
[2m[36m(func pid=10475)[0m rmse_per_class: [0.085, 0.236, 0.032, 0.257, 0.068, 0.17, 0.21, 0.114, 0.165, 0.101]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.17577150464057922
[2m[36m(func pid=17062)[0m mae:  0.12524858117103577
[2m[36m(func pid=17062)[0m rmse_per_class: [0.115, 0.274, 0.088, 0.348, 0.069, 0.194, 0.274, 0.136, 0.159, 0.1]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.3660 | Steps: 2 | Val loss: 0.3001 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2616 | Steps: 2 | Val loss: 0.2678 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2358 | Steps: 2 | Val loss: 0.2837 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4664 | Steps: 2 | Val loss: 0.3718 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=5093)[0m rmse: 0.16468320786952972
[2m[36m(func pid=5093)[0m mae:  0.11830317974090576
[2m[36m(func pid=5093)[0m rmse_per_class: [0.101, 0.261, 0.062, 0.309, 0.068, 0.187, 0.269, 0.133, 0.147, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.1421118676662445
[2m[36m(func pid=6491)[0m mae:  0.09330199658870697
[2m[36m(func pid=6491)[0m rmse_per_class: [0.069, 0.233, 0.032, 0.262, 0.066, 0.163, 0.22, 0.118, 0.161, 0.097]
[2m[36m(func pid=6491)[0m 
== Status ==
Current time: 2024-01-07 06:28:53 (running for 00:32:45.01)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.366 |  0.165 |                   98 |
| train_12613_00014 | RUNNING    | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.262 |  0.142 |                   99 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.236 |  0.147 |                   86 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.46  |  0.176 |                   52 |
| train_12613_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.14695729315280914
[2m[36m(func pid=10475)[0m mae:  0.08907092362642288
[2m[36m(func pid=10475)[0m rmse_per_class: [0.099, 0.237, 0.031, 0.262, 0.074, 0.169, 0.212, 0.118, 0.163, 0.105]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.17570841312408447
[2m[36m(func pid=17062)[0m mae:  0.12503233551979065
[2m[36m(func pid=17062)[0m rmse_per_class: [0.115, 0.274, 0.087, 0.349, 0.068, 0.194, 0.274, 0.136, 0.16, 0.099]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.3670 | Steps: 2 | Val loss: 0.3001 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=6491)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2584 | Steps: 2 | Val loss: 0.2678 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2384 | Steps: 2 | Val loss: 0.2877 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4707 | Steps: 2 | Val loss: 0.3743 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=5093)[0m rmse: 0.16468946635723114
[2m[36m(func pid=5093)[0m mae:  0.11833331733942032
[2m[36m(func pid=5093)[0m rmse_per_class: [0.101, 0.26, 0.062, 0.31, 0.068, 0.187, 0.269, 0.133, 0.147, 0.112]
[2m[36m(func pid=5093)[0m 
[2m[36m(func pid=6491)[0m rmse: 0.1421256959438324
[2m[36m(func pid=6491)[0m mae:  0.09332527965307236
[2m[36m(func pid=6491)[0m rmse_per_class: [0.07, 0.234, 0.032, 0.262, 0.065, 0.163, 0.22, 0.117, 0.161, 0.097]
[2m[36m(func pid=10475)[0m rmse: 0.1486678421497345
[2m[36m(func pid=10475)[0m mae:  0.09031649678945541
[2m[36m(func pid=10475)[0m rmse_per_class: [0.09, 0.238, 0.03, 0.271, 0.073, 0.166, 0.208, 0.125, 0.176, 0.11]
[2m[36m(func pid=17062)[0m rmse: 0.17571505904197693
[2m[36m(func pid=17062)[0m mae:  0.1248571127653122
[2m[36m(func pid=17062)[0m rmse_per_class: [0.115, 0.274, 0.087, 0.349, 0.068, 0.194, 0.275, 0.136, 0.16, 0.099]
[2m[36m(func pid=5093)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.3646 | Steps: 2 | Val loss: 0.3000 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=5093)[0m rmse: 0.16463737189769745
[2m[36m(func pid=5093)[0m mae:  0.11831273138523102
[2m[36m(func pid=5093)[0m rmse_per_class: [0.1, 0.26, 0.062, 0.31, 0.068, 0.186, 0.269, 0.132, 0.147, 0.112]
== Status ==
Current time: 2024-01-07 06:28:59 (running for 00:32:50.30)
Memory usage on this node: 22.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00013 | RUNNING    | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.367 |  0.165 |                   99 |
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.236 |  0.147 |                   86 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.466 |  0.176 |                   53 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


== Status ==
Current time: 2024-01-07 06:29:07 (running for 00:32:58.96)
Memory usage on this node: 23.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 3 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.236 |  0.147 |                   86 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.466 |  0.176 |                   53 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29192)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29192)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=29192)[0m Configuration completed!
[2m[36m(func pid=29192)[0m New optimizer parameters:
[2m[36m(func pid=29192)[0m SGD (
[2m[36m(func pid=29192)[0m Parameter Group 0
[2m[36m(func pid=29192)[0m     dampening: 0
[2m[36m(func pid=29192)[0m     differentiable: False
[2m[36m(func pid=29192)[0m     foreach: None
[2m[36m(func pid=29192)[0m     lr: 0.001
[2m[36m(func pid=29192)[0m     maximize: False
[2m[36m(func pid=29192)[0m     momentum: 0.99
[2m[36m(func pid=29192)[0m     nesterov: False
[2m[36m(func pid=29192)[0m     weight_decay: 1e-05
[2m[36m(func pid=29192)[0m )
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2326 | Steps: 2 | Val loss: 0.2849 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4760 | Steps: 2 | Val loss: 0.3762 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0760 | Steps: 2 | Val loss: 0.7929 | Batch size: 32 | lr: 0.001 | Duration: 4.69s
[2m[36m(func pid=10475)[0m rmse: 0.14643380045890808
[2m[36m(func pid=10475)[0m mae:  0.08941106498241425
[2m[36m(func pid=10475)[0m rmse_per_class: [0.073, 0.237, 0.029, 0.276, 0.061, 0.164, 0.209, 0.12, 0.183, 0.109]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.17561550438404083
[2m[36m(func pid=17062)[0m mae:  0.12467099726200104
[2m[36m(func pid=17062)[0m rmse_per_class: [0.115, 0.274, 0.086, 0.35, 0.067, 0.194, 0.276, 0.136, 0.16, 0.099]
[2m[36m(func pid=29192)[0m rmse: 0.17864646017551422
[2m[36m(func pid=29192)[0m mae:  0.13116218149662018
[2m[36m(func pid=29192)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.325, 0.1, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2433 | Steps: 2 | Val loss: 0.2812 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 06:29:13 (running for 00:33:04.16)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.233 |  0.146 |                   88 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.471 |  0.176 |                   54 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29667)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=29667)[0m Configuration completed!
[2m[36m(func pid=29667)[0m New optimizer parameters:
[2m[36m(func pid=29667)[0m SGD (
[2m[36m(func pid=29667)[0m Parameter Group 0
[2m[36m(func pid=29667)[0m     dampening: 0
[2m[36m(func pid=29667)[0m     differentiable: False
[2m[36m(func pid=29667)[0m     foreach: None
[2m[36m(func pid=29667)[0m     lr: 0.01
[2m[36m(func pid=29667)[0m     maximize: False
[2m[36m(func pid=29667)[0m     momentum: 0.99
[2m[36m(func pid=29667)[0m     nesterov: False
[2m[36m(func pid=29667)[0m     weight_decay: 1e-05
[2m[36m(func pid=29667)[0m )
[2m[36m(func pid=29667)[0m 
== Status ==
Current time: 2024-01-07 06:29:18 (running for 00:33:09.53)
Memory usage on this node: 24.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.243 |  0.145 |                   89 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.476 |  0.176 |                   55 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  1.076 |  0.179 |                    1 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)

[2m[36m(func pid=10475)[0m rmse: 0.1450742930173874

[2m[36m(func pid=10475)[0m mae:  0.08888911455869675
[2m[36m(func pid=10475)[0m rmse_per_class: [0.066, 0.236, 0.029, 0.271, 0.058, 0.165, 0.209, 0.114, 0.193, 0.11]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4786 | Steps: 2 | Val loss: 0.3785 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0326 | Steps: 2 | Val loss: 0.7531 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2358 | Steps: 2 | Val loss: 0.2877 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0308 | Steps: 2 | Val loss: 0.6454 | Batch size: 32 | lr: 0.01 | Duration: 4.59s
[2m[36m(func pid=17062)[0m rmse: 0.17536380887031555
[2m[36m(func pid=17062)[0m mae:  0.12425319850444794
[2m[36m(func pid=17062)[0m rmse_per_class: [0.115, 0.274, 0.085, 0.35, 0.066, 0.194, 0.277, 0.137, 0.16, 0.098]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.1789940744638443
[2m[36m(func pid=29192)[0m mae:  0.13139081001281738
[2m[36m(func pid=29192)[0m rmse_per_class: [0.104, 0.266, 0.088, 0.325, 0.101, 0.192, 0.305, 0.154, 0.139, 0.115]
[2m[36m(func pid=29192)[0m 
== Status ==
Current time: 2024-01-07 06:29:23 (running for 00:33:14.91)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.236 |  0.151 |                   90 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.479 |  0.175 |                   56 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  1.033 |  0.179 |                    2 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.15122005343437195
[2m[36m(func pid=10475)[0m mae:  0.09306491911411285
[2m[36m(func pid=10475)[0m rmse_per_class: [0.071, 0.239, 0.031, 0.27, 0.062, 0.178, 0.225, 0.112, 0.218, 0.107]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.17809224128723145
[2m[36m(func pid=29667)[0m mae:  0.13052000105381012
[2m[36m(func pid=29667)[0m rmse_per_class: [0.104, 0.267, 0.086, 0.325, 0.097, 0.192, 0.301, 0.155, 0.139, 0.114]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4819 | Steps: 2 | Val loss: 0.3812 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.9510 | Steps: 2 | Val loss: 0.6916 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2493 | Steps: 2 | Val loss: 0.2898 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.7031 | Steps: 2 | Val loss: 0.4206 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=17062)[0m rmse: 0.17523647844791412
[2m[36m(func pid=17062)[0m mae:  0.12405663728713989
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.274, 0.083, 0.35, 0.065, 0.194, 0.278, 0.137, 0.16, 0.098]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.1792726367712021
[2m[36m(func pid=29192)[0m mae:  0.13151106238365173
[2m[36m(func pid=29192)[0m rmse_per_class: [0.104, 0.266, 0.089, 0.325, 0.101, 0.193, 0.305, 0.156, 0.139, 0.115]
[2m[36m(func pid=29192)[0m 
== Status ==
Current time: 2024-01-07 06:29:29 (running for 00:33:20.07)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.249 |  0.153 |                   91 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.482 |  0.175 |                   57 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.951 |  0.179 |                    3 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  1.031 |  0.178 |                    1 |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.15333831310272217
[2m[36m(func pid=10475)[0m mae:  0.09457851946353912
[2m[36m(func pid=10475)[0m rmse_per_class: [0.093, 0.24, 0.033, 0.272, 0.065, 0.171, 0.224, 0.111, 0.219, 0.104]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.17700669169425964
[2m[36m(func pid=29667)[0m mae:  0.1293073147535324
[2m[36m(func pid=29667)[0m rmse_per_class: [0.104, 0.269, 0.088, 0.328, 0.092, 0.192, 0.293, 0.153, 0.141, 0.109]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4825 | Steps: 2 | Val loss: 0.3845 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8460 | Steps: 2 | Val loss: 0.6132 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2356 | Steps: 2 | Val loss: 0.2795 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.4525 | Steps: 2 | Val loss: 0.3256 | Batch size: 32 | lr: 0.01 | Duration: 2.71s
[2m[36m(func pid=17062)[0m rmse: 0.1752125769853592
[2m[36m(func pid=17062)[0m mae:  0.12383786588907242
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.274, 0.082, 0.351, 0.065, 0.194, 0.278, 0.137, 0.16, 0.097]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.1794750988483429
[2m[36m(func pid=29192)[0m mae:  0.1315390169620514
[2m[36m(func pid=29192)[0m rmse_per_class: [0.104, 0.267, 0.09, 0.325, 0.101, 0.193, 0.304, 0.157, 0.139, 0.115]
[2m[36m(func pid=29192)[0m 
== Status ==
Current time: 2024-01-07 06:29:34 (running for 00:33:25.13)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.236 |  0.146 |                   92 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.482 |  0.175 |                   58 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.846 |  0.179 |                    4 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.703 |  0.177 |                    2 |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.14607228338718414
[2m[36m(func pid=10475)[0m mae:  0.08932966738939285
[2m[36m(func pid=10475)[0m rmse_per_class: [0.087, 0.234, 0.033, 0.276, 0.067, 0.165, 0.205, 0.115, 0.181, 0.097]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.17478734254837036
[2m[36m(func pid=29667)[0m mae:  0.12701578438282013
[2m[36m(func pid=29667)[0m rmse_per_class: [0.104, 0.272, 0.092, 0.337, 0.082, 0.192, 0.279, 0.139, 0.148, 0.102]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4848 | Steps: 2 | Val loss: 0.3863 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7277 | Steps: 2 | Val loss: 0.5290 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2347 | Steps: 2 | Val loss: 0.2779 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4339 | Steps: 2 | Val loss: 0.3480 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=17062)[0m rmse: 0.1751764416694641
[2m[36m(func pid=17062)[0m mae:  0.12368106842041016
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.274, 0.082, 0.351, 0.064, 0.194, 0.279, 0.137, 0.16, 0.097]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.17949683964252472
[2m[36m(func pid=29192)[0m mae:  0.13139909505844116
[2m[36m(func pid=29192)[0m rmse_per_class: [0.104, 0.268, 0.09, 0.326, 0.1, 0.193, 0.303, 0.156, 0.139, 0.115]
[2m[36m(func pid=29192)[0m 
== Status ==
Current time: 2024-01-07 06:29:39 (running for 00:33:30.37)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.236 |  0.146 |                   92 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.485 |  0.175 |                   59 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.728 |  0.179 |                    5 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.434 |  0.175 |                    4 |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.14313603937625885
[2m[36m(func pid=10475)[0m mae:  0.08723364770412445
[2m[36m(func pid=10475)[0m rmse_per_class: [0.076, 0.231, 0.03, 0.269, 0.064, 0.165, 0.21, 0.125, 0.161, 0.099]
[2m[36m(func pid=29667)[0m rmse: 0.17452296614646912
[2m[36m(func pid=29667)[0m mae:  0.12461032718420029
[2m[36m(func pid=29667)[0m rmse_per_class: [0.105, 0.274, 0.088, 0.35, 0.07, 0.192, 0.283, 0.132, 0.154, 0.096]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4937 | Steps: 2 | Val loss: 0.3884 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.6221 | Steps: 2 | Val loss: 0.4527 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2383 | Steps: 2 | Val loss: 0.2826 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.5137 | Steps: 2 | Val loss: 0.4138 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=17062)[0m rmse: 0.1752258986234665
[2m[36m(func pid=17062)[0m mae:  0.12362468242645264
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.274, 0.081, 0.351, 0.064, 0.194, 0.28, 0.137, 0.161, 0.097]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.1793760359287262
[2m[36m(func pid=29192)[0m mae:  0.1310988962650299
[2m[36m(func pid=29192)[0m rmse_per_class: [0.105, 0.269, 0.092, 0.327, 0.098, 0.193, 0.3, 0.155, 0.14, 0.114]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.1784115731716156
[2m[36m(func pid=29667)[0m mae:  0.12342499196529388
[2m[36m(func pid=29667)[0m rmse_per_class: [0.105, 0.277, 0.077, 0.362, 0.061, 0.191, 0.323, 0.137, 0.159, 0.093]
== Status ==
Current time: 2024-01-07 06:29:44 (running for 00:33:35.55)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.235 |  0.143 |                   93 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.494 |  0.175 |                   60 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.622 |  0.179 |                    6 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.514 |  0.178 |                    5 |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.14309270679950714
[2m[36m(func pid=10475)[0m mae:  0.08711518347263336
[2m[36m(func pid=10475)[0m rmse_per_class: [0.072, 0.232, 0.027, 0.258, 0.061, 0.165, 0.213, 0.128, 0.155, 0.121]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4909 | Steps: 2 | Val loss: 0.3907 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.5274 | Steps: 2 | Val loss: 0.3919 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.6086 | Steps: 2 | Val loss: 0.4822 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2461 | Steps: 2 | Val loss: 0.2844 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=17062)[0m rmse: 0.175205260515213
[2m[36m(func pid=17062)[0m mae:  0.1234695091843605
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.274, 0.08, 0.352, 0.063, 0.194, 0.281, 0.137, 0.161, 0.096]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.1789725124835968
[2m[36m(func pid=29192)[0m mae:  0.13058942556381226
[2m[36m(func pid=29192)[0m rmse_per_class: [0.106, 0.27, 0.093, 0.329, 0.096, 0.193, 0.296, 0.151, 0.141, 0.113]
[2m[36m(func pid=29192)[0m 
== Status ==
Current time: 2024-01-07 06:29:49 (running for 00:33:40.67)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.238 |  0.143 |                   94 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.491 |  0.175 |                   61 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.527 |  0.179 |                    7 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.609 |  0.185 |                    6 |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29667)[0m rmse: 0.1849903166294098
[2m[36m(func pid=29667)[0m mae:  0.12394286692142487
[2m[36m(func pid=29667)[0m rmse_per_class: [0.103, 0.28, 0.063, 0.37, 0.056, 0.19, 0.389, 0.144, 0.16, 0.093]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14498470723628998
[2m[36m(func pid=10475)[0m mae:  0.08843415230512619
[2m[36m(func pid=10475)[0m rmse_per_class: [0.084, 0.233, 0.027, 0.26, 0.057, 0.167, 0.219, 0.118, 0.153, 0.134]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4962 | Steps: 2 | Val loss: 0.3916 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4737 | Steps: 2 | Val loss: 0.3511 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.6894 | Steps: 2 | Val loss: 0.5411 | Batch size: 32 | lr: 0.01 | Duration: 2.65s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2384 | Steps: 2 | Val loss: 0.2808 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=17062)[0m rmse: 0.17516084015369415
[2m[36m(func pid=17062)[0m mae:  0.1233108639717102
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.274, 0.079, 0.352, 0.063, 0.194, 0.282, 0.138, 0.161, 0.096]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.17838893830776215
[2m[36m(func pid=29192)[0m mae:  0.12988749146461487
[2m[36m(func pid=29192)[0m rmse_per_class: [0.107, 0.271, 0.095, 0.332, 0.094, 0.194, 0.29, 0.147, 0.143, 0.112]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.19254252314567566
[2m[36m(func pid=29667)[0m mae:  0.1259438395500183
[2m[36m(func pid=29667)[0m rmse_per_class: [0.101, 0.284, 0.053, 0.377, 0.055, 0.191, 0.465, 0.15, 0.156, 0.094]
[2m[36m(func pid=29667)[0m 
== Status ==
Current time: 2024-01-07 06:29:55 (running for 00:33:46.14)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.238 |  0.145 |                   96 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.496 |  0.175 |                   62 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.474 |  0.178 |                    8 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.689 |  0.193 |                    7 |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.1453736424446106
[2m[36m(func pid=10475)[0m mae:  0.08885672688484192
[2m[36m(func pid=10475)[0m rmse_per_class: [0.09, 0.236, 0.028, 0.27, 0.054, 0.171, 0.209, 0.113, 0.161, 0.122]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4947 | Steps: 2 | Val loss: 0.3944 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.4367 | Steps: 2 | Val loss: 0.3305 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.7678 | Steps: 2 | Val loss: 0.5867 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2485 | Steps: 2 | Val loss: 0.2771 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=17062)[0m rmse: 0.17506864666938782
[2m[36m(func pid=17062)[0m mae:  0.1230500116944313
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.273, 0.078, 0.352, 0.062, 0.194, 0.283, 0.138, 0.161, 0.096]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.1778354048728943
[2m[36m(func pid=29192)[0m mae:  0.1292131245136261
[2m[36m(func pid=29192)[0m rmse_per_class: [0.108, 0.272, 0.097, 0.335, 0.091, 0.194, 0.285, 0.142, 0.146, 0.11]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.19974717497825623
[2m[36m(func pid=29667)[0m mae:  0.1288033425807953
[2m[36m(func pid=29667)[0m rmse_per_class: [0.099, 0.286, 0.049, 0.382, 0.056, 0.195, 0.533, 0.153, 0.15, 0.095]
[2m[36m(func pid=29667)[0m 
== Status ==
Current time: 2024-01-07 06:30:00 (running for 00:33:51.17)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.249 |  0.145 |                   97 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.495 |  0.175 |                   63 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.437 |  0.178 |                    9 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.768 |  0.2   |                    8 |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.14502814412117004
[2m[36m(func pid=10475)[0m mae:  0.08874298632144928
[2m[36m(func pid=10475)[0m rmse_per_class: [0.085, 0.238, 0.027, 0.266, 0.056, 0.166, 0.207, 0.113, 0.179, 0.114]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4955 | Steps: 2 | Val loss: 0.3960 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4205 | Steps: 2 | Val loss: 0.3248 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.8123 | Steps: 2 | Val loss: 0.6166 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2330 | Steps: 2 | Val loss: 0.2837 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=17062)[0m rmse: 0.17501038312911987
[2m[36m(func pid=17062)[0m mae:  0.12288074195384979
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.273, 0.077, 0.352, 0.062, 0.193, 0.283, 0.138, 0.161, 0.096]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.17713528871536255
[2m[36m(func pid=29192)[0m mae:  0.12831683456897736
[2m[36m(func pid=29192)[0m rmse_per_class: [0.109, 0.273, 0.098, 0.338, 0.087, 0.193, 0.28, 0.137, 0.149, 0.107]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.20580847561359406
[2m[36m(func pid=29667)[0m mae:  0.13179852068424225
[2m[36m(func pid=29667)[0m rmse_per_class: [0.099, 0.289, 0.048, 0.384, 0.056, 0.199, 0.587, 0.154, 0.145, 0.096]
[2m[36m(func pid=29667)[0m 
== Status ==
Current time: 2024-01-07 06:30:05 (running for 00:33:56.24)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.233 |  0.148 |                   98 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.495 |  0.175 |                   64 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.42  |  0.177 |                   10 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.812 |  0.206 |                    9 |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.147772878408432
[2m[36m(func pid=10475)[0m mae:  0.09062902629375458
[2m[36m(func pid=10475)[0m rmse_per_class: [0.076, 0.239, 0.027, 0.269, 0.066, 0.166, 0.206, 0.115, 0.21, 0.104]
[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.5020 | Steps: 2 | Val loss: 0.3972 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4143 | Steps: 2 | Val loss: 0.3305 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.8211 | Steps: 2 | Val loss: 0.6262 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2405 | Steps: 2 | Val loss: 0.2906 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=17062)[0m rmse: 0.17510046064853668
[2m[36m(func pid=17062)[0m mae:  0.12282849848270416
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.273, 0.076, 0.353, 0.061, 0.193, 0.285, 0.138, 0.161, 0.096]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.21055540442466736
[2m[36m(func pid=29667)[0m mae:  0.13461649417877197
[2m[36m(func pid=29667)[0m rmse_per_class: [0.1, 0.291, 0.048, 0.386, 0.056, 0.203, 0.627, 0.155, 0.141, 0.097]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.1766810268163681
[2m[36m(func pid=29192)[0m mae:  0.12751272320747375
[2m[36m(func pid=29192)[0m rmse_per_class: [0.111, 0.273, 0.098, 0.342, 0.082, 0.193, 0.276, 0.135, 0.151, 0.104]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=10475)[0m rmse: 0.14996978640556335
[2m[36m(func pid=10475)[0m mae:  0.0919012725353241
[2m[36m(func pid=10475)[0m rmse_per_class: [0.071, 0.238, 0.027, 0.273, 0.078, 0.168, 0.209, 0.119, 0.218, 0.098]
== Status ==
Current time: 2024-01-07 06:30:10 (running for 00:34:01.36)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.241 |  0.15  |                   99 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.502 |  0.175 |                   65 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.414 |  0.177 |                   11 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.821 |  0.211 |                   10 |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.5037 | Steps: 2 | Val loss: 0.3981 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.8361 | Steps: 2 | Val loss: 0.6229 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4297 | Steps: 2 | Val loss: 0.3436 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=10475)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2390 | Steps: 2 | Val loss: 0.2848 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=17062)[0m rmse: 0.17509129643440247
[2m[36m(func pid=17062)[0m mae:  0.12274859845638275
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.273, 0.076, 0.353, 0.061, 0.193, 0.285, 0.138, 0.162, 0.095]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.21341054141521454
[2m[36m(func pid=29667)[0m mae:  0.13654780387878418
[2m[36m(func pid=29667)[0m rmse_per_class: [0.1, 0.293, 0.049, 0.387, 0.056, 0.206, 0.649, 0.156, 0.141, 0.097]
[2m[36m(func pid=29667)[0m 
== Status ==
Current time: 2024-01-07 06:30:15 (running for 00:34:06.51)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00015 | RUNNING    | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.241 |  0.15  |                   99 |
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.504 |  0.175 |                   66 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.43  |  0.176 |                   12 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.836 |  0.213 |                   11 |
| train_12613_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=10475)[0m rmse: 0.14573828876018524
[2m[36m(func pid=10475)[0m mae:  0.08900391310453415
[2m[36m(func pid=10475)[0m rmse_per_class: [0.075, 0.235, 0.027, 0.273, 0.073, 0.167, 0.206, 0.121, 0.186, 0.095]
[2m[36m(func pid=29192)[0m rmse: 0.17641137540340424
[2m[36m(func pid=29192)[0m mae:  0.12669137120246887
[2m[36m(func pid=29192)[0m rmse_per_class: [0.111, 0.274, 0.096, 0.346, 0.078, 0.193, 0.275, 0.135, 0.155, 0.102]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.8343 | Steps: 2 | Val loss: 0.6059 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.5036 | Steps: 2 | Val loss: 0.3991 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4468 | Steps: 2 | Val loss: 0.3612 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=29667)[0m rmse: 0.21455498039722443
[2m[36m(func pid=29667)[0m mae:  0.13738664984703064
[2m[36m(func pid=29667)[0m rmse_per_class: [0.101, 0.293, 0.049, 0.388, 0.056, 0.207, 0.656, 0.156, 0.143, 0.097]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.17497596144676208
[2m[36m(func pid=17062)[0m mae:  0.1224977970123291
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.273, 0.074, 0.353, 0.06, 0.193, 0.287, 0.139, 0.161, 0.095]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.17641225457191467
[2m[36m(func pid=29192)[0m mae:  0.12591545283794403
[2m[36m(func pid=29192)[0m rmse_per_class: [0.112, 0.274, 0.093, 0.349, 0.074, 0.193, 0.276, 0.135, 0.157, 0.099]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.5072 | Steps: 2 | Val loss: 0.4004 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.8052 | Steps: 2 | Val loss: 0.5761 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4766 | Steps: 2 | Val loss: 0.3816 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 06:30:20 (running for 00:34:11.79)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.504 |  0.175 |                   67 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.447 |  0.176 |                   13 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.834 |  0.215 |                   12 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=32597)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=32597)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=32597)[0m Configuration completed!
[2m[36m(func pid=32597)[0m New optimizer parameters:
[2m[36m(func pid=32597)[0m SGD (
[2m[36m(func pid=32597)[0m Parameter Group 0
[2m[36m(func pid=32597)[0m     dampening: 0
[2m[36m(func pid=32597)[0m     differentiable: False
[2m[36m(func pid=32597)[0m     foreach: None
[2m[36m(func pid=32597)[0m     lr: 0.1
[2m[36m(func pid=32597)[0m     maximize: False
[2m[36m(func pid=32597)[0m     momentum: 0.99
[2m[36m(func pid=32597)[0m     nesterov: False
[2m[36m(func pid=32597)[0m     weight_decay: 1e-05
[2m[36m(func pid=32597)[0m )
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.1749986708164215
[2m[36m(func pid=17062)[0m mae:  0.12237952649593353
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.273, 0.073, 0.353, 0.06, 0.193, 0.288, 0.139, 0.161, 0.095]
[2m[36m(func pid=29667)[0m rmse: 0.21303386986255646
[2m[36m(func pid=29667)[0m mae:  0.13627707958221436
[2m[36m(func pid=29667)[0m rmse_per_class: [0.099, 0.291, 0.049, 0.388, 0.056, 0.204, 0.64, 0.156, 0.15, 0.097]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=17062)[0m 
== Status ==
Current time: 2024-01-07 06:30:26 (running for 00:34:17.05)
Memory usage on this node: 24.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.507 |  0.175 |                   68 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.477 |  0.177 |                   14 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.805 |  0.213 |                   13 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29192)[0m rmse: 0.176716148853302
[2m[36m(func pid=29192)[0m mae:  0.1252184510231018
[2m[36m(func pid=29192)[0m rmse_per_class: [0.112, 0.275, 0.09, 0.353, 0.07, 0.193, 0.28, 0.136, 0.16, 0.097]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7760 | Steps: 2 | Val loss: 0.5407 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.5133 | Steps: 2 | Val loss: 0.4020 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.7711 | Steps: 2 | Val loss: 0.3288 | Batch size: 32 | lr: 0.1 | Duration: 4.45s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4958 | Steps: 2 | Val loss: 0.4020 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=29667)[0m rmse: 0.2078210413455963
[2m[36m(func pid=29667)[0m mae:  0.1324770599603653
[2m[36m(func pid=29667)[0m rmse_per_class: [0.094, 0.286, 0.049, 0.388, 0.056, 0.197, 0.58, 0.156, 0.175, 0.097]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.174960657954216
[2m[36m(func pid=17062)[0m mae:  0.1222168430685997
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.273, 0.073, 0.353, 0.06, 0.193, 0.289, 0.139, 0.162, 0.095]
[2m[36m(func pid=17062)[0m 
== Status ==
Current time: 2024-01-07 06:30:31 (running for 00:34:22.12)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.513 |  0.175 |                   69 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.477 |  0.177 |                   14 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.776 |  0.208 |                   14 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.771 |  0.173 |                    1 |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=32597)[0m rmse: 0.17286279797554016
[2m[36m(func pid=32597)[0m mae:  0.12447971105575562
[2m[36m(func pid=32597)[0m rmse_per_class: [0.106, 0.275, 0.086, 0.344, 0.071, 0.191, 0.277, 0.131, 0.15, 0.097]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.17715921998023987
[2m[36m(func pid=29192)[0m mae:  0.1245311051607132
[2m[36m(func pid=29192)[0m rmse_per_class: [0.112, 0.276, 0.086, 0.356, 0.066, 0.193, 0.287, 0.138, 0.162, 0.095]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.7100 | Steps: 2 | Val loss: 0.4974 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.5123 | Steps: 2 | Val loss: 0.4031 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.5761 | Steps: 2 | Val loss: 0.5004 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.5202 | Steps: 2 | Val loss: 0.4222 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=29667)[0m rmse: 0.19758287072181702
[2m[36m(func pid=29667)[0m mae:  0.1257764995098114
[2m[36m(func pid=29667)[0m rmse_per_class: [0.087, 0.273, 0.049, 0.387, 0.056, 0.183, 0.467, 0.156, 0.219, 0.097]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.17493747174739838
[2m[36m(func pid=17062)[0m mae:  0.12215230613946915
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.273, 0.072, 0.353, 0.059, 0.193, 0.289, 0.139, 0.162, 0.095]
[2m[36m(func pid=17062)[0m 
== Status ==
Current time: 2024-01-07 06:30:36 (running for 00:34:27.18)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.512 |  0.175 |                   70 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.496 |  0.177 |                   15 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.71  |  0.198 |                   15 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.576 |  0.189 |                    2 |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=32597)[0m rmse: 0.1894039511680603
[2m[36m(func pid=32597)[0m mae:  0.125034362077713
[2m[36m(func pid=32597)[0m rmse_per_class: [0.1, 0.287, 0.052, 0.377, 0.056, 0.187, 0.443, 0.145, 0.153, 0.095]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.17793689668178558
[2m[36m(func pid=29192)[0m mae:  0.12399798631668091
[2m[36m(func pid=29192)[0m rmse_per_class: [0.112, 0.276, 0.081, 0.359, 0.063, 0.193, 0.298, 0.14, 0.163, 0.094]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.6483 | Steps: 2 | Val loss: 0.4568 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.5084 | Steps: 2 | Val loss: 0.4035 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.8851 | Steps: 2 | Val loss: 0.6166 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.5399 | Steps: 2 | Val loss: 0.4420 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=29667)[0m rmse: 0.18308702111244202
[2m[36m(func pid=29667)[0m mae:  0.11870966106653214
[2m[36m(func pid=29667)[0m rmse_per_class: [0.082, 0.254, 0.049, 0.386, 0.056, 0.174, 0.311, 0.156, 0.265, 0.097]
[2m[36m(func pid=29667)[0m 
== Status ==
Current time: 2024-01-07 06:30:41 (running for 00:34:32.35)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.508 |  0.175 |                   71 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.52  |  0.178 |                   16 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.648 |  0.183 |                   16 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.576 |  0.189 |                    2 |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=17062)[0m rmse: 0.17484764754772186
[2m[36m(func pid=17062)[0m mae:  0.12190993130207062
[2m[36m(func pid=17062)[0m rmse_per_class: [0.113, 0.273, 0.071, 0.353, 0.059, 0.193, 0.29, 0.139, 0.162, 0.095]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.2100844830274582
[2m[36m(func pid=32597)[0m mae:  0.1345714032649994
[2m[36m(func pid=32597)[0m rmse_per_class: [0.098, 0.296, 0.049, 0.388, 0.056, 0.198, 0.622, 0.154, 0.143, 0.097]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.17886877059936523
[2m[36m(func pid=29192)[0m mae:  0.12350878864526749
[2m[36m(func pid=29192)[0m rmse_per_class: [0.111, 0.277, 0.076, 0.362, 0.061, 0.193, 0.311, 0.141, 0.164, 0.093]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.6168 | Steps: 2 | Val loss: 0.4319 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.5053 | Steps: 2 | Val loss: 0.4037 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.9708 | Steps: 2 | Val loss: 0.6159 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.5650 | Steps: 2 | Val loss: 0.4597 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 06:30:46 (running for 00:34:37.37)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.508 |  0.175 |                   71 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.54  |  0.179 |                   17 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.617 |  0.175 |                   17 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.885 |  0.21  |                    3 |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29667)[0m rmse: 0.1753578633069992
[2m[36m(func pid=29667)[0m mae:  0.11808870732784271
[2m[36m(func pid=29667)[0m rmse_per_class: [0.093, 0.245, 0.049, 0.383, 0.056, 0.191, 0.214, 0.156, 0.27, 0.097]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.17481906712055206
[2m[36m(func pid=17062)[0m mae:  0.12174457311630249
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.273, 0.07, 0.354, 0.059, 0.193, 0.29, 0.14, 0.162, 0.094]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.21622514724731445
[2m[36m(func pid=32597)[0m mae:  0.13889971375465393
[2m[36m(func pid=32597)[0m rmse_per_class: [0.102, 0.298, 0.049, 0.389, 0.056, 0.205, 0.663, 0.156, 0.147, 0.097]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.18011713027954102
[2m[36m(func pid=29192)[0m mae:  0.12331534922122955
[2m[36m(func pid=29192)[0m rmse_per_class: [0.11, 0.278, 0.072, 0.364, 0.059, 0.193, 0.326, 0.143, 0.165, 0.093]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.5902 | Steps: 2 | Val loss: 0.4314 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.5121 | Steps: 2 | Val loss: 0.4046 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.9187 | Steps: 2 | Val loss: 0.5389 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.5866 | Steps: 2 | Val loss: 0.4760 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 06:30:51 (running for 00:34:42.54)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.505 |  0.175 |                   72 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.565 |  0.18  |                   18 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.59  |  0.18  |                   18 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.971 |  0.216 |                    4 |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29667)[0m rmse: 0.17965012788772583
[2m[36m(func pid=29667)[0m mae:  0.12293875217437744
[2m[36m(func pid=29667)[0m rmse_per_class: [0.116, 0.258, 0.049, 0.375, 0.056, 0.215, 0.243, 0.156, 0.232, 0.097]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.1747984141111374
[2m[36m(func pid=17062)[0m mae:  0.12159955501556396
[2m[36m(func pid=17062)[0m rmse_per_class: [0.113, 0.273, 0.069, 0.353, 0.059, 0.193, 0.291, 0.14, 0.163, 0.094]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.194783553481102
[2m[36m(func pid=32597)[0m mae:  0.12491466104984283
[2m[36m(func pid=32597)[0m rmse_per_class: [0.08, 0.279, 0.049, 0.389, 0.056, 0.175, 0.364, 0.156, 0.303, 0.097]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.18126030266284943
[2m[36m(func pid=29192)[0m mae:  0.12307647615671158
[2m[36m(func pid=29192)[0m rmse_per_class: [0.108, 0.278, 0.067, 0.366, 0.058, 0.192, 0.341, 0.145, 0.165, 0.092]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.6134 | Steps: 2 | Val loss: 0.4333 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.7747 | Steps: 2 | Val loss: 0.5029 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.5082 | Steps: 2 | Val loss: 0.4059 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.6178 | Steps: 2 | Val loss: 0.4916 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 06:30:56 (running for 00:34:47.72)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.512 |  0.175 |                   73 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.587 |  0.181 |                   19 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.613 |  0.181 |                   19 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.919 |  0.195 |                    5 |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29667)[0m rmse: 0.18114528059959412
[2m[36m(func pid=29667)[0m mae:  0.12465499341487885
[2m[36m(func pid=29667)[0m rmse_per_class: [0.133, 0.27, 0.049, 0.353, 0.056, 0.228, 0.279, 0.156, 0.192, 0.096]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.18820786476135254
[2m[36m(func pid=32597)[0m mae:  0.12876684963703156
[2m[36m(func pid=32597)[0m rmse_per_class: [0.114, 0.263, 0.049, 0.382, 0.056, 0.279, 0.277, 0.156, 0.208, 0.097]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.17475034296512604
[2m[36m(func pid=17062)[0m mae:  0.12135807424783707
[2m[36m(func pid=17062)[0m rmse_per_class: [0.113, 0.272, 0.068, 0.354, 0.058, 0.193, 0.293, 0.14, 0.163, 0.094]
[2m[36m(func pid=17062)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.1826845109462738
[2m[36m(func pid=29192)[0m mae:  0.12300197035074234
[2m[36m(func pid=29192)[0m rmse_per_class: [0.107, 0.279, 0.063, 0.368, 0.057, 0.192, 0.359, 0.146, 0.164, 0.092]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.5703 | Steps: 2 | Val loss: 0.4051 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.7180 | Steps: 2 | Val loss: 0.3709 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=17062)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.5148 | Steps: 2 | Val loss: 0.4060 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.6327 | Steps: 2 | Val loss: 0.5065 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 06:31:01 (running for 00:34:52.74)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.16249999776482582
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00016 | RUNNING    | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.508 |  0.175 |                   74 |
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.618 |  0.183 |                   20 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.57  |  0.174 |                   20 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.775 |  0.188 |                    6 |
| train_12613_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29667)[0m rmse: 0.1743956208229065
[2m[36m(func pid=29667)[0m mae:  0.11923233419656754
[2m[36m(func pid=29667)[0m rmse_per_class: [0.134, 0.265, 0.049, 0.307, 0.056, 0.223, 0.299, 0.155, 0.162, 0.094]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.16345269978046417
[2m[36m(func pid=32597)[0m mae:  0.1074276715517044
[2m[36m(func pid=32597)[0m rmse_per_class: [0.097, 0.252, 0.049, 0.285, 0.056, 0.194, 0.313, 0.154, 0.137, 0.096]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=17062)[0m rmse: 0.174761563539505
[2m[36m(func pid=17062)[0m mae:  0.12128444015979767
[2m[36m(func pid=17062)[0m rmse_per_class: [0.114, 0.272, 0.067, 0.354, 0.058, 0.193, 0.293, 0.14, 0.163, 0.094]
[2m[36m(func pid=29192)[0m rmse: 0.18439564108848572
[2m[36m(func pid=29192)[0m mae:  0.12313081324100494
[2m[36m(func pid=29192)[0m rmse_per_class: [0.106, 0.279, 0.06, 0.37, 0.056, 0.192, 0.377, 0.148, 0.164, 0.092]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.5360 | Steps: 2 | Val loss: 0.3645 | Batch size: 32 | lr: 0.01 | Duration: 2.68s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5400 | Steps: 2 | Val loss: 0.4247 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.6469 | Steps: 2 | Val loss: 0.5202 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=29667)[0m rmse: 0.16336451470851898
[2m[36m(func pid=29667)[0m mae:  0.11021806299686432
[2m[36m(func pid=29667)[0m rmse_per_class: [0.119, 0.246, 0.049, 0.272, 0.056, 0.197, 0.308, 0.155, 0.144, 0.087]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.18875916302204132
[2m[36m(func pid=32597)[0m mae:  0.11916421353816986
[2m[36m(func pid=32597)[0m rmse_per_class: [0.081, 0.28, 0.047, 0.539, 0.056, 0.198, 0.293, 0.121, 0.135, 0.137]
[2m[36m(func pid=29192)[0m rmse: 0.18613344430923462
[2m[36m(func pid=29192)[0m mae:  0.12344087660312653
[2m[36m(func pid=29192)[0m rmse_per_class: [0.105, 0.28, 0.056, 0.371, 0.056, 0.192, 0.395, 0.149, 0.164, 0.092]
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4812 | Steps: 2 | Val loss: 0.3461 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
== Status ==
Current time: 2024-01-07 06:31:06 (running for 00:34:57.78)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.633 |  0.184 |                   21 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.536 |  0.163 |                   21 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.718 |  0.163 |                    7 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=34793)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=34793)[0m Configuration completed!
[2m[36m(func pid=34793)[0m New optimizer parameters:
[2m[36m(func pid=34793)[0m SGD (
[2m[36m(func pid=34793)[0m Parameter Group 0
[2m[36m(func pid=34793)[0m     dampening: 0
[2m[36m(func pid=34793)[0m     differentiable: False
[2m[36m(func pid=34793)[0m     foreach: None
[2m[36m(func pid=34793)[0m     lr: 0.0001
[2m[36m(func pid=34793)[0m     maximize: False
[2m[36m(func pid=34793)[0m     momentum: 0.9
[2m[36m(func pid=34793)[0m     nesterov: False
[2m[36m(func pid=34793)[0m     weight_decay: 1e-05
[2m[36m(func pid=34793)[0m )
[2m[36m(func pid=34793)[0m 
== Status ==
Current time: 2024-01-07 06:31:11 (running for 00:35:02.96)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.647 |  0.186 |                   22 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.481 |  0.161 |                   22 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.54  |  0.189 |                    8 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29667)[0m rmse: 0.16054171323776245
[2m[36m(func pid=29667)[0m mae:  0.10596871376037598
[2m[36m(func pid=29667)[0m rmse_per_class: [0.09, 0.232, 0.048, 0.315, 0.056, 0.166, 0.311, 0.152, 0.136, 0.099]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5290 | Steps: 2 | Val loss: 0.4819 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.6693 | Steps: 2 | Val loss: 0.5301 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4423 | Steps: 2 | Val loss: 0.3564 | Batch size: 32 | lr: 0.01 | Duration: 2.63s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0812 | Steps: 2 | Val loss: 0.8113 | Batch size: 32 | lr: 0.0001 | Duration: 4.35s
[2m[36m(func pid=32597)[0m rmse: 0.20107468962669373
[2m[36m(func pid=32597)[0m mae:  0.128519207239151
[2m[36m(func pid=32597)[0m rmse_per_class: [0.104, 0.3, 0.029, 0.256, 0.056, 0.222, 0.238, 0.247, 0.134, 0.424]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.18774554133415222
[2m[36m(func pid=29192)[0m mae:  0.12375472486019135
[2m[36m(func pid=29192)[0m rmse_per_class: [0.104, 0.281, 0.054, 0.373, 0.056, 0.191, 0.413, 0.15, 0.163, 0.093]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.1737360805273056
[2m[36m(func pid=29667)[0m mae:  0.11216871440410614
[2m[36m(func pid=29667)[0m rmse_per_class: [0.067, 0.249, 0.046, 0.365, 0.056, 0.167, 0.311, 0.144, 0.13, 0.201]
[2m[36m(func pid=29667)[0m 
== Status ==
Current time: 2024-01-07 06:31:17 (running for 00:35:08.24)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.669 |  0.188 |                   23 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.442 |  0.174 |                   23 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.529 |  0.201 |                    9 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  1.081 |  0.179 |                    1 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.17870505154132843
[2m[36m(func pid=34793)[0m mae:  0.13121309876441956
[2m[36m(func pid=34793)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.325, 0.1, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.6778 | Steps: 2 | Val loss: 0.5391 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.5891 | Steps: 2 | Val loss: 0.5544 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4594 | Steps: 2 | Val loss: 0.3793 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0848 | Steps: 2 | Val loss: 0.8133 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=29192)[0m rmse: 0.18943792581558228
[2m[36m(func pid=29192)[0m mae:  0.12416015565395355
[2m[36m(func pid=29192)[0m rmse_per_class: [0.103, 0.281, 0.052, 0.374, 0.055, 0.191, 0.431, 0.151, 0.162, 0.093]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.21102483570575714
[2m[36m(func pid=32597)[0m mae:  0.136153906583786
[2m[36m(func pid=32597)[0m rmse_per_class: [0.097, 0.298, 0.06, 0.36, 0.056, 0.218, 0.278, 0.469, 0.151, 0.125]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.18806204199790955
[2m[36m(func pid=29667)[0m mae:  0.12199632823467255
[2m[36m(func pid=29667)[0m rmse_per_class: [0.073, 0.275, 0.042, 0.353, 0.056, 0.188, 0.309, 0.126, 0.13, 0.328]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.17913207411766052
[2m[36m(func pid=34793)[0m mae:  0.1315334141254425
[2m[36m(func pid=34793)[0m rmse_per_class: [0.104, 0.266, 0.088, 0.325, 0.102, 0.193, 0.306, 0.154, 0.139, 0.116]
== Status ==
Current time: 2024-01-07 06:31:22 (running for 00:35:13.71)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.678 |  0.189 |                   24 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.459 |  0.188 |                   24 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.589 |  0.211 |                   10 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  1.085 |  0.179 |                    2 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.6941 | Steps: 2 | Val loss: 0.5447 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.5910 | Steps: 2 | Val loss: 0.5353 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4471 | Steps: 2 | Val loss: 0.3880 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 1.0698 | Steps: 2 | Val loss: 0.8151 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=29192)[0m rmse: 0.19085615873336792
[2m[36m(func pid=29192)[0m mae:  0.1245424747467041
[2m[36m(func pid=29192)[0m rmse_per_class: [0.102, 0.282, 0.051, 0.375, 0.055, 0.191, 0.446, 0.151, 0.161, 0.093]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.2015300691127777
[2m[36m(func pid=32597)[0m mae:  0.1185649037361145
[2m[36m(func pid=32597)[0m rmse_per_class: [0.087, 0.269, 0.156, 0.379, 0.051, 0.17, 0.371, 0.201, 0.24, 0.092]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.19245555996894836
[2m[36m(func pid=29667)[0m mae:  0.12584616243839264
[2m[36m(func pid=29667)[0m rmse_per_class: [0.084, 0.288, 0.033, 0.309, 0.056, 0.203, 0.301, 0.111, 0.131, 0.409]
[2m[36m(func pid=29667)[0m 
== Status ==
Current time: 2024-01-07 06:31:28 (running for 00:35:19.13)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.694 |  0.191 |                   25 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.447 |  0.192 |                   25 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.591 |  0.202 |                   11 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  1.07  |  0.18  |                    3 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.1796225756406784
[2m[36m(func pid=34793)[0m mae:  0.13191381096839905
[2m[36m(func pid=34793)[0m rmse_per_class: [0.104, 0.266, 0.089, 0.325, 0.103, 0.193, 0.307, 0.154, 0.139, 0.116]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.6992 | Steps: 2 | Val loss: 0.5480 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4620 | Steps: 2 | Val loss: 0.5466 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4321 | Steps: 2 | Val loss: 0.3877 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 1.0597 | Steps: 2 | Val loss: 0.8144 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=29192)[0m rmse: 0.19227094948291779
[2m[36m(func pid=29192)[0m mae:  0.12494808435440063
[2m[36m(func pid=29192)[0m rmse_per_class: [0.101, 0.282, 0.05, 0.376, 0.056, 0.191, 0.462, 0.152, 0.159, 0.094]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.20655164122581482
[2m[36m(func pid=32597)[0m mae:  0.12137849628925323
[2m[36m(func pid=32597)[0m rmse_per_class: [0.075, 0.29, 0.126, 0.385, 0.101, 0.366, 0.232, 0.131, 0.264, 0.097]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.19413940608501434
[2m[36m(func pid=29667)[0m mae:  0.12554140388965607
[2m[36m(func pid=29667)[0m rmse_per_class: [0.089, 0.293, 0.026, 0.264, 0.056, 0.212, 0.285, 0.162, 0.131, 0.423]
[2m[36m(func pid=29667)[0m 
== Status ==
Current time: 2024-01-07 06:31:33 (running for 00:35:24.61)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.699 |  0.192 |                   26 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.432 |  0.194 |                   26 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.462 |  0.207 |                   12 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  1.06  |  0.18  |                    4 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.1799788922071457
[2m[36m(func pid=34793)[0m mae:  0.13217809796333313
[2m[36m(func pid=34793)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.104, 0.193, 0.308, 0.154, 0.138, 0.117]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.5153 | Steps: 2 | Val loss: 0.6238 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.7042 | Steps: 2 | Val loss: 0.5512 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4240 | Steps: 2 | Val loss: 0.4028 | Batch size: 32 | lr: 0.01 | Duration: 2.69s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 1.0440 | Steps: 2 | Val loss: 0.8117 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=32597)[0m rmse: 0.21302494406700134
[2m[36m(func pid=32597)[0m mae:  0.13329800963401794
[2m[36m(func pid=32597)[0m rmse_per_class: [0.074, 0.302, 0.047, 0.385, 0.227, 0.332, 0.296, 0.153, 0.217, 0.097]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.19364140927791595
[2m[36m(func pid=29192)[0m mae:  0.125395730137825
[2m[36m(func pid=29192)[0m rmse_per_class: [0.1, 0.283, 0.049, 0.377, 0.056, 0.192, 0.476, 0.152, 0.158, 0.094]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.20094139873981476
[2m[36m(func pid=29667)[0m mae:  0.12804919481277466
[2m[36m(func pid=29667)[0m rmse_per_class: [0.092, 0.294, 0.038, 0.252, 0.056, 0.217, 0.263, 0.314, 0.131, 0.352]
[2m[36m(func pid=29667)[0m 
== Status ==
Current time: 2024-01-07 06:31:38 (running for 00:35:29.90)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.704 |  0.194 |                   27 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.424 |  0.201 |                   27 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.515 |  0.213 |                   13 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  1.044 |  0.18  |                    5 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18028980493545532
[2m[36m(func pid=34793)[0m mae:  0.1324184089899063
[2m[36m(func pid=34793)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.325, 0.105, 0.194, 0.309, 0.154, 0.138, 0.118]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.7058 | Steps: 2 | Val loss: 0.5523 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.6577 | Steps: 2 | Val loss: 0.6112 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4607 | Steps: 2 | Val loss: 0.4392 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 1.0361 | Steps: 2 | Val loss: 0.8043 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=29192)[0m rmse: 0.1949744075536728
[2m[36m(func pid=29192)[0m mae:  0.12588351964950562
[2m[36m(func pid=29192)[0m rmse_per_class: [0.1, 0.283, 0.048, 0.378, 0.056, 0.192, 0.489, 0.153, 0.157, 0.094]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.2035870999097824
[2m[36m(func pid=32597)[0m mae:  0.1274765580892563
[2m[36m(func pid=32597)[0m rmse_per_class: [0.104, 0.297, 0.029, 0.364, 0.283, 0.224, 0.27, 0.155, 0.211, 0.097]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.2091144323348999
[2m[36m(func pid=29667)[0m mae:  0.134312704205513
[2m[36m(func pid=29667)[0m rmse_per_class: [0.095, 0.294, 0.062, 0.289, 0.056, 0.22, 0.243, 0.47, 0.133, 0.227]
[2m[36m(func pid=29667)[0m 
== Status ==
Current time: 2024-01-07 06:31:44 (running for 00:35:35.30)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.706 |  0.195 |                   28 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.461 |  0.209 |                   28 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.658 |  0.204 |                   14 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  1.036 |  0.181 |                    6 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18050169944763184
[2m[36m(func pid=34793)[0m mae:  0.13256295025348663
[2m[36m(func pid=34793)[0m rmse_per_class: [0.105, 0.266, 0.091, 0.325, 0.105, 0.194, 0.309, 0.154, 0.138, 0.119]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.7026 | Steps: 2 | Val loss: 0.5506 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.6294 | Steps: 2 | Val loss: 0.4751 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4889 | Steps: 2 | Val loss: 0.4778 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 1.0199 | Steps: 2 | Val loss: 0.7964 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=29192)[0m rmse: 0.19606778025627136
[2m[36m(func pid=29192)[0m mae:  0.12626983225345612
[2m[36m(func pid=29192)[0m rmse_per_class: [0.1, 0.283, 0.048, 0.378, 0.056, 0.192, 0.501, 0.153, 0.156, 0.094]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.18456874787807465
[2m[36m(func pid=32597)[0m mae:  0.10314685106277466
[2m[36m(func pid=32597)[0m rmse_per_class: [0.112, 0.259, 0.03, 0.301, 0.196, 0.191, 0.25, 0.155, 0.256, 0.095]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.21359236538410187
[2m[36m(func pid=29667)[0m mae:  0.13928420841693878
[2m[36m(func pid=29667)[0m rmse_per_class: [0.099, 0.294, 0.094, 0.335, 0.056, 0.221, 0.233, 0.544, 0.135, 0.125]
[2m[36m(func pid=29667)[0m 
== Status ==
Current time: 2024-01-07 06:31:49 (running for 00:35:40.62)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.703 |  0.196 |                   29 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.489 |  0.214 |                   29 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.629 |  0.185 |                   15 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  1.02  |  0.181 |                    7 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.1807156652212143
[2m[36m(func pid=34793)[0m mae:  0.13273420929908752
[2m[36m(func pid=34793)[0m rmse_per_class: [0.106, 0.266, 0.091, 0.325, 0.105, 0.194, 0.31, 0.154, 0.138, 0.12]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.7011 | Steps: 2 | Val loss: 0.5489 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.5338 | Steps: 2 | Val loss: 0.4670 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4859 | Steps: 2 | Val loss: 0.4883 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=29192)[0m rmse: 0.1970423310995102
[2m[36m(func pid=29192)[0m mae:  0.12663067877292633
[2m[36m(func pid=29192)[0m rmse_per_class: [0.099, 0.283, 0.048, 0.379, 0.056, 0.192, 0.51, 0.154, 0.155, 0.095]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 1.0035 | Steps: 2 | Val loss: 0.7863 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=32597)[0m rmse: 0.1839539110660553
[2m[36m(func pid=32597)[0m mae:  0.10138449817895889
[2m[36m(func pid=32597)[0m rmse_per_class: [0.095, 0.256, 0.033, 0.3, 0.082, 0.208, 0.357, 0.155, 0.265, 0.089]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.21398775279521942
[2m[36m(func pid=29667)[0m mae:  0.13919766247272491
[2m[36m(func pid=29667)[0m rmse_per_class: [0.099, 0.292, 0.124, 0.356, 0.056, 0.219, 0.25, 0.514, 0.137, 0.092]
[2m[36m(func pid=29667)[0m 
== Status ==
Current time: 2024-01-07 06:31:55 (running for 00:35:46.07)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.701 |  0.197 |                   30 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.486 |  0.214 |                   30 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.534 |  0.184 |                   16 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  1.004 |  0.181 |                    8 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18086108565330505
[2m[36m(func pid=34793)[0m mae:  0.13282844424247742
[2m[36m(func pid=34793)[0m rmse_per_class: [0.106, 0.266, 0.091, 0.324, 0.106, 0.194, 0.31, 0.154, 0.138, 0.12]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.7059 | Steps: 2 | Val loss: 0.5456 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.5013 | Steps: 2 | Val loss: 0.5345 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4945 | Steps: 2 | Val loss: 0.4826 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=29192)[0m rmse: 0.19792336225509644
[2m[36m(func pid=29192)[0m mae:  0.12696127593517303
[2m[36m(func pid=29192)[0m rmse_per_class: [0.099, 0.283, 0.048, 0.379, 0.056, 0.192, 0.519, 0.154, 0.154, 0.095]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.9830 | Steps: 2 | Val loss: 0.7745 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=32597)[0m rmse: 0.1924045979976654
[2m[36m(func pid=32597)[0m mae:  0.10865423828363419
[2m[36m(func pid=32597)[0m rmse_per_class: [0.085, 0.285, 0.033, 0.428, 0.056, 0.212, 0.323, 0.15, 0.244, 0.108]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.21296408772468567
[2m[36m(func pid=29667)[0m mae:  0.1358526051044464
[2m[36m(func pid=29667)[0m rmse_per_class: [0.097, 0.286, 0.158, 0.367, 0.056, 0.215, 0.302, 0.419, 0.141, 0.088]
[2m[36m(func pid=29667)[0m 
== Status ==
Current time: 2024-01-07 06:32:00 (running for 00:35:51.51)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.706 |  0.198 |                   31 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.495 |  0.213 |                   31 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.501 |  0.192 |                   17 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.983 |  0.181 |                    9 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.1809779554605484
[2m[36m(func pid=34793)[0m mae:  0.13291457295417786
[2m[36m(func pid=34793)[0m rmse_per_class: [0.106, 0.266, 0.091, 0.324, 0.106, 0.194, 0.31, 0.154, 0.138, 0.121]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.6999 | Steps: 2 | Val loss: 0.5417 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.5199 | Steps: 2 | Val loss: 0.5805 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4576 | Steps: 2 | Val loss: 0.4637 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=29192)[0m rmse: 0.19872324168682098
[2m[36m(func pid=29192)[0m mae:  0.12726423144340515
[2m[36m(func pid=29192)[0m rmse_per_class: [0.099, 0.283, 0.048, 0.38, 0.056, 0.192, 0.527, 0.154, 0.153, 0.095]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.19971279799938202
[2m[36m(func pid=32597)[0m mae:  0.11335889995098114
[2m[36m(func pid=32597)[0m rmse_per_class: [0.08, 0.297, 0.038, 0.493, 0.054, 0.199, 0.29, 0.133, 0.207, 0.206]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.9672 | Steps: 2 | Val loss: 0.7625 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=29667)[0m rmse: 0.20765402913093567
[2m[36m(func pid=29667)[0m mae:  0.12875555455684662
[2m[36m(func pid=29667)[0m rmse_per_class: [0.094, 0.276, 0.186, 0.371, 0.055, 0.203, 0.367, 0.288, 0.148, 0.089]
[2m[36m(func pid=29667)[0m 
== Status ==
Current time: 2024-01-07 06:32:05 (running for 00:35:56.85)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.7   |  0.199 |                   32 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.458 |  0.208 |                   32 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.52  |  0.2   |                   18 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.967 |  0.181 |                   10 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18104425072669983
[2m[36m(func pid=34793)[0m mae:  0.13297539949417114
[2m[36m(func pid=34793)[0m rmse_per_class: [0.106, 0.266, 0.091, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.121]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.6909 | Steps: 2 | Val loss: 0.5360 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.5875 | Steps: 2 | Val loss: 0.5575 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4585 | Steps: 2 | Val loss: 0.4510 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=29192)[0m rmse: 0.1992858350276947
[2m[36m(func pid=29192)[0m mae:  0.1274789273738861
[2m[36m(func pid=29192)[0m rmse_per_class: [0.098, 0.283, 0.048, 0.38, 0.056, 0.192, 0.533, 0.154, 0.153, 0.095]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.20179101824760437
[2m[36m(func pid=32597)[0m mae:  0.11074292659759521
[2m[36m(func pid=32597)[0m rmse_per_class: [0.082, 0.298, 0.046, 0.406, 0.056, 0.18, 0.286, 0.173, 0.18, 0.311]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.9513 | Steps: 2 | Val loss: 0.7502 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=29667)[0m rmse: 0.1980636864900589
[2m[36m(func pid=29667)[0m mae:  0.12032736837863922
[2m[36m(func pid=29667)[0m rmse_per_class: [0.089, 0.262, 0.198, 0.374, 0.053, 0.182, 0.391, 0.18, 0.16, 0.09]
[2m[36m(func pid=29667)[0m 
== Status ==
Current time: 2024-01-07 06:32:11 (running for 00:36:02.24)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.691 |  0.199 |                   33 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.458 |  0.198 |                   33 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.587 |  0.202 |                   19 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.951 |  0.181 |                   11 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18105784058570862
[2m[36m(func pid=34793)[0m mae:  0.1329752802848816
[2m[36m(func pid=34793)[0m rmse_per_class: [0.106, 0.266, 0.09, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.6938 | Steps: 2 | Val loss: 0.5294 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.5704 | Steps: 2 | Val loss: 0.5554 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4002 | Steps: 2 | Val loss: 0.4370 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=29192)[0m rmse: 0.1996344029903412
[2m[36m(func pid=29192)[0m mae:  0.12757685780525208
[2m[36m(func pid=29192)[0m rmse_per_class: [0.098, 0.283, 0.048, 0.38, 0.056, 0.192, 0.537, 0.155, 0.153, 0.095]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.2000068724155426
[2m[36m(func pid=32597)[0m mae:  0.10991903394460678
[2m[36m(func pid=32597)[0m rmse_per_class: [0.083, 0.295, 0.049, 0.305, 0.056, 0.201, 0.286, 0.227, 0.167, 0.331]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.18529611825942993
[2m[36m(func pid=29667)[0m mae:  0.11103846877813339
[2m[36m(func pid=29667)[0m rmse_per_class: [0.082, 0.25, 0.191, 0.375, 0.053, 0.162, 0.35, 0.121, 0.177, 0.092]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.9322 | Steps: 2 | Val loss: 0.7371 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 06:32:16 (running for 00:36:07.66)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.694 |  0.2   |                   34 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.4   |  0.185 |                   34 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.57  |  0.2   |                   20 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.932 |  0.181 |                   12 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.6869 | Steps: 2 | Val loss: 0.5202 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=34793)[0m rmse: 0.18108399212360382
[2m[36m(func pid=34793)[0m mae:  0.13298091292381287
[2m[36m(func pid=34793)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.324, 0.105, 0.194, 0.31, 0.154, 0.138, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3858 | Steps: 2 | Val loss: 0.4252 | Batch size: 32 | lr: 0.01 | Duration: 2.71s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.6413 | Steps: 2 | Val loss: 0.5841 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=29192)[0m rmse: 0.19963183999061584
[2m[36m(func pid=29192)[0m mae:  0.1275133341550827
[2m[36m(func pid=29192)[0m rmse_per_class: [0.098, 0.282, 0.048, 0.38, 0.056, 0.191, 0.537, 0.155, 0.153, 0.096]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.17762182652950287
[2m[36m(func pid=29667)[0m mae:  0.10536564886569977
[2m[36m(func pid=29667)[0m rmse_per_class: [0.074, 0.258, 0.156, 0.376, 0.068, 0.18, 0.265, 0.115, 0.191, 0.093]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.19966909289360046
[2m[36m(func pid=32597)[0m mae:  0.11230149120092392
[2m[36m(func pid=32597)[0m rmse_per_class: [0.08, 0.284, 0.049, 0.297, 0.056, 0.243, 0.288, 0.245, 0.172, 0.282]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.9173 | Steps: 2 | Val loss: 0.7227 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.6720 | Steps: 2 | Val loss: 0.5117 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3822 | Steps: 2 | Val loss: 0.4241 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 06:32:22 (running for 00:36:13.12)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.687 |  0.2   |                   35 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.386 |  0.178 |                   35 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.641 |  0.2   |                   21 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.917 |  0.181 |                   13 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.1811152994632721
[2m[36m(func pid=34793)[0m mae:  0.13298138976097107
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.105, 0.194, 0.311, 0.154, 0.138, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.6377 | Steps: 2 | Val loss: 0.5557 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=29192)[0m rmse: 0.1998385488986969
[2m[36m(func pid=29192)[0m mae:  0.1275465488433838
[2m[36m(func pid=29192)[0m rmse_per_class: [0.098, 0.281, 0.048, 0.38, 0.056, 0.191, 0.539, 0.155, 0.154, 0.096]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.18135181069374084
[2m[36m(func pid=29667)[0m mae:  0.10871229320764542
[2m[36m(func pid=29667)[0m rmse_per_class: [0.069, 0.275, 0.111, 0.377, 0.102, 0.245, 0.211, 0.129, 0.2, 0.094]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.20378780364990234
[2m[36m(func pid=32597)[0m mae:  0.1116049736738205
[2m[36m(func pid=32597)[0m rmse_per_class: [0.097, 0.271, 0.049, 0.319, 0.056, 0.227, 0.3, 0.273, 0.206, 0.241]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.8975 | Steps: 2 | Val loss: 0.7104 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.6627 | Steps: 2 | Val loss: 0.5022 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3911 | Steps: 2 | Val loss: 0.4308 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 06:32:27 (running for 00:36:18.51)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.672 |  0.2   |                   36 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.382 |  0.181 |                   36 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.638 |  0.204 |                   22 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.898 |  0.181 |                   14 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.5504 | Steps: 2 | Val loss: 0.5753 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=34793)[0m rmse: 0.18121175467967987
[2m[36m(func pid=34793)[0m mae:  0.1330418586730957
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.105, 0.194, 0.311, 0.154, 0.138, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.19951964914798737
[2m[36m(func pid=29192)[0m mae:  0.12729886174201965
[2m[36m(func pid=29192)[0m rmse_per_class: [0.097, 0.28, 0.048, 0.38, 0.056, 0.191, 0.536, 0.155, 0.155, 0.096]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.18980291485786438
[2m[36m(func pid=29667)[0m mae:  0.11659856140613556
[2m[36m(func pid=29667)[0m rmse_per_class: [0.066, 0.29, 0.065, 0.378, 0.151, 0.295, 0.225, 0.14, 0.193, 0.095]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.20667585730552673
[2m[36m(func pid=32597)[0m mae:  0.10980875790119171
[2m[36m(func pid=32597)[0m rmse_per_class: [0.151, 0.317, 0.049, 0.343, 0.056, 0.187, 0.304, 0.241, 0.242, 0.178]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.8827 | Steps: 2 | Val loss: 0.6973 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3961 | Steps: 2 | Val loss: 0.4465 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.6448 | Steps: 2 | Val loss: 0.4908 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 06:32:32 (running for 00:36:23.88)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.663 |  0.2   |                   37 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.391 |  0.19  |                   37 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.55  |  0.207 |                   23 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.883 |  0.181 |                   15 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.5243 | Steps: 2 | Val loss: 0.6688 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=34793)[0m rmse: 0.18123456835746765
[2m[36m(func pid=34793)[0m mae:  0.1330498456954956
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.106, 0.194, 0.311, 0.154, 0.138, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.19893859326839447
[2m[36m(func pid=29192)[0m mae:  0.12688900530338287
[2m[36m(func pid=29192)[0m rmse_per_class: [0.097, 0.28, 0.048, 0.38, 0.056, 0.19, 0.531, 0.155, 0.156, 0.096]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.19563791155815125
[2m[36m(func pid=29667)[0m mae:  0.12327060848474503
[2m[36m(func pid=29667)[0m rmse_per_class: [0.065, 0.292, 0.039, 0.376, 0.202, 0.3, 0.258, 0.147, 0.183, 0.096]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.2089473307132721
[2m[36m(func pid=32597)[0m mae:  0.11442379653453827
[2m[36m(func pid=32597)[0m rmse_per_class: [0.19, 0.374, 0.048, 0.367, 0.061, 0.199, 0.309, 0.165, 0.249, 0.126]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.8683 | Steps: 2 | Val loss: 0.6841 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4263 | Steps: 2 | Val loss: 0.4684 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.6508 | Steps: 2 | Val loss: 0.4778 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.5563 | Steps: 2 | Val loss: 0.7354 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 06:32:38 (running for 00:36:29.28)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.645 |  0.199 |                   38 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.396 |  0.196 |                   38 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.524 |  0.209 |                   24 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.868 |  0.181 |                   16 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.1812526434659958
[2m[36m(func pid=34793)[0m mae:  0.13305452466011047
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.105, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.19828006625175476
[2m[36m(func pid=29667)[0m mae:  0.12760546803474426
[2m[36m(func pid=29667)[0m rmse_per_class: [0.066, 0.284, 0.029, 0.371, 0.244, 0.28, 0.282, 0.151, 0.18, 0.096]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.19784805178642273
[2m[36m(func pid=29192)[0m mae:  0.12621311843395233
[2m[36m(func pid=29192)[0m rmse_per_class: [0.096, 0.278, 0.048, 0.38, 0.056, 0.188, 0.521, 0.155, 0.159, 0.096]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.2073626071214676
[2m[36m(func pid=32597)[0m mae:  0.11662642657756805
[2m[36m(func pid=32597)[0m rmse_per_class: [0.145, 0.369, 0.044, 0.376, 0.071, 0.216, 0.357, 0.138, 0.267, 0.09]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.8503 | Steps: 2 | Val loss: 0.6713 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.6203 | Steps: 2 | Val loss: 0.4642 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4570 | Steps: 2 | Val loss: 0.4759 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 06:32:43 (running for 00:36:34.51)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.651 |  0.198 |                   39 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.426 |  0.198 |                   39 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.556 |  0.207 |                   25 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.85  |  0.181 |                   17 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.5804 | Steps: 2 | Val loss: 0.7603 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=34793)[0m rmse: 0.1812678724527359
[2m[36m(func pid=34793)[0m mae:  0.1330563724040985
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.105, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.19633594155311584
[2m[36m(func pid=29192)[0m mae:  0.12529811263084412
[2m[36m(func pid=29192)[0m rmse_per_class: [0.096, 0.276, 0.049, 0.379, 0.056, 0.187, 0.508, 0.155, 0.162, 0.096]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.1974644958972931
[2m[36m(func pid=29667)[0m mae:  0.12797099351882935
[2m[36m(func pid=29667)[0m rmse_per_class: [0.072, 0.277, 0.027, 0.361, 0.263, 0.256, 0.29, 0.153, 0.182, 0.096]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.20848841965198517
[2m[36m(func pid=32597)[0m mae:  0.11816946417093277
[2m[36m(func pid=32597)[0m rmse_per_class: [0.088, 0.341, 0.042, 0.377, 0.1, 0.218, 0.405, 0.145, 0.287, 0.081]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.8376 | Steps: 2 | Val loss: 0.6603 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.6055 | Steps: 2 | Val loss: 0.4520 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4624 | Steps: 2 | Val loss: 0.4621 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.5912 | Steps: 2 | Val loss: 0.7556 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 06:32:49 (running for 00:36:40.08)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.62  |  0.196 |                   40 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.457 |  0.197 |                   40 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.58  |  0.208 |                   26 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.838 |  0.181 |                   18 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18123787641525269
[2m[36m(func pid=34793)[0m mae:  0.13301971554756165
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.104, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.1947343647480011
[2m[36m(func pid=29667)[0m mae:  0.12552209198474884
[2m[36m(func pid=29667)[0m rmse_per_class: [0.08, 0.267, 0.027, 0.344, 0.267, 0.235, 0.287, 0.153, 0.192, 0.095]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.19474294781684875
[2m[36m(func pid=29192)[0m mae:  0.12434881925582886
[2m[36m(func pid=29192)[0m rmse_per_class: [0.095, 0.274, 0.049, 0.379, 0.056, 0.185, 0.493, 0.155, 0.165, 0.096]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.21031799912452698
[2m[36m(func pid=32597)[0m mae:  0.11808128654956818
[2m[36m(func pid=32597)[0m rmse_per_class: [0.078, 0.311, 0.036, 0.373, 0.141, 0.2, 0.42, 0.15, 0.31, 0.084]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.8218 | Steps: 2 | Val loss: 0.6479 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4679 | Steps: 2 | Val loss: 0.4358 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.5922 | Steps: 2 | Val loss: 0.4391 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.5779 | Steps: 2 | Val loss: 0.7629 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 06:32:54 (running for 00:36:45.54)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.605 |  0.195 |                   41 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.462 |  0.195 |                   41 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.591 |  0.21  |                   27 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.822 |  0.181 |                   19 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18122896552085876
[2m[36m(func pid=34793)[0m mae:  0.13298213481903076
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.104, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.1899658441543579
[2m[36m(func pid=29667)[0m mae:  0.12049989402294159
[2m[36m(func pid=29667)[0m rmse_per_class: [0.088, 0.261, 0.029, 0.322, 0.255, 0.216, 0.276, 0.153, 0.206, 0.093]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.19245833158493042
[2m[36m(func pid=29192)[0m mae:  0.12307599931955338
[2m[36m(func pid=29192)[0m rmse_per_class: [0.094, 0.271, 0.049, 0.378, 0.056, 0.184, 0.472, 0.155, 0.17, 0.096]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.21400852501392365
[2m[36m(func pid=32597)[0m mae:  0.11858481168746948
[2m[36m(func pid=32597)[0m rmse_per_class: [0.081, 0.3, 0.033, 0.363, 0.176, 0.301, 0.336, 0.149, 0.314, 0.088]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.8105 | Steps: 2 | Val loss: 0.6367 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4318 | Steps: 2 | Val loss: 0.3965 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.5729 | Steps: 2 | Val loss: 0.4275 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.6526 | Steps: 2 | Val loss: 0.7819 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 06:33:00 (running for 00:36:51.04)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.592 |  0.192 |                   42 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.468 |  0.19  |                   42 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.578 |  0.214 |                   28 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.811 |  0.181 |                   20 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18128655850887299
[2m[36m(func pid=34793)[0m mae:  0.13300661742687225
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.18121162056922913
[2m[36m(func pid=29667)[0m mae:  0.11122765392065048
[2m[36m(func pid=29667)[0m rmse_per_class: [0.098, 0.25, 0.031, 0.296, 0.225, 0.197, 0.25, 0.153, 0.222, 0.09]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.19008082151412964
[2m[36m(func pid=29192)[0m mae:  0.12175120413303375
[2m[36m(func pid=29192)[0m rmse_per_class: [0.093, 0.268, 0.049, 0.377, 0.056, 0.183, 0.449, 0.155, 0.176, 0.096]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.2220648229122162
[2m[36m(func pid=32597)[0m mae:  0.12924955785274506
[2m[36m(func pid=32597)[0m rmse_per_class: [0.083, 0.284, 0.034, 0.351, 0.166, 0.49, 0.298, 0.148, 0.277, 0.091]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.7942 | Steps: 2 | Val loss: 0.6253 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4069 | Steps: 2 | Val loss: 0.3688 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.6532 | Steps: 2 | Val loss: 0.7370 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.5639 | Steps: 2 | Val loss: 0.4139 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 06:33:05 (running for 00:36:56.29)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.573 |  0.19  |                   43 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.432 |  0.181 |                   43 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.653 |  0.222 |                   29 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.794 |  0.181 |                   21 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.1812533140182495
[2m[36m(func pid=34793)[0m mae:  0.13294921815395355
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.1725817173719406
[2m[36m(func pid=29667)[0m mae:  0.1022331565618515
[2m[36m(func pid=29667)[0m rmse_per_class: [0.101, 0.239, 0.033, 0.282, 0.182, 0.184, 0.228, 0.153, 0.239, 0.086]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.21372362971305847
[2m[36m(func pid=32597)[0m mae:  0.12072713673114777
[2m[36m(func pid=32597)[0m rmse_per_class: [0.084, 0.28, 0.04, 0.335, 0.157, 0.42, 0.319, 0.147, 0.264, 0.091]
[2m[36m(func pid=29192)[0m rmse: 0.1871793270111084
[2m[36m(func pid=29192)[0m mae:  0.12021423876285553
[2m[36m(func pid=29192)[0m rmse_per_class: [0.092, 0.264, 0.049, 0.375, 0.056, 0.181, 0.421, 0.155, 0.182, 0.096]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.7786 | Steps: 2 | Val loss: 0.6149 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3826 | Steps: 2 | Val loss: 0.3536 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.5501 | Steps: 2 | Val loss: 0.3997 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.6302 | Steps: 2 | Val loss: 0.6843 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 06:33:10 (running for 00:37:01.69)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.564 |  0.187 |                   44 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.407 |  0.173 |                   44 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.653 |  0.214 |                   30 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.779 |  0.181 |                   22 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18117214739322662
[2m[36m(func pid=34793)[0m mae:  0.13288211822509766
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.16666169464588165
[2m[36m(func pid=29667)[0m mae:  0.09589871764183044
[2m[36m(func pid=29667)[0m rmse_per_class: [0.098, 0.234, 0.035, 0.287, 0.132, 0.178, 0.217, 0.152, 0.251, 0.082]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.18371649086475372
[2m[36m(func pid=29192)[0m mae:  0.11853267252445221
[2m[36m(func pid=29192)[0m rmse_per_class: [0.091, 0.26, 0.049, 0.373, 0.056, 0.181, 0.387, 0.155, 0.189, 0.096]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.20629815757274628
[2m[36m(func pid=32597)[0m mae:  0.11517296731472015
[2m[36m(func pid=32597)[0m rmse_per_class: [0.099, 0.281, 0.04, 0.322, 0.136, 0.206, 0.491, 0.141, 0.254, 0.092]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.7681 | Steps: 2 | Val loss: 0.6044 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3636 | Steps: 2 | Val loss: 0.3532 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.5184 | Steps: 2 | Val loss: 0.3867 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.5904 | Steps: 2 | Val loss: 0.6578 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 06:33:16 (running for 00:37:07.03)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.55  |  0.184 |                   45 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.383 |  0.167 |                   45 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.63  |  0.206 |                   31 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.768 |  0.181 |                   23 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18113099038600922
[2m[36m(func pid=34793)[0m mae:  0.13284102082252502
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.194, 0.31, 0.154, 0.139, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.16649070382118225
[2m[36m(func pid=29667)[0m mae:  0.09453307092189789
[2m[36m(func pid=29667)[0m rmse_per_class: [0.091, 0.24, 0.037, 0.306, 0.091, 0.184, 0.226, 0.151, 0.253, 0.084]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.18012413382530212
[2m[36m(func pid=29192)[0m mae:  0.11689122021198273
[2m[36m(func pid=29192)[0m rmse_per_class: [0.09, 0.256, 0.049, 0.371, 0.056, 0.181, 0.35, 0.155, 0.197, 0.096]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.20665523409843445
[2m[36m(func pid=32597)[0m mae:  0.11563271284103394
[2m[36m(func pid=32597)[0m rmse_per_class: [0.152, 0.282, 0.034, 0.312, 0.109, 0.21, 0.512, 0.13, 0.237, 0.09]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.7539 | Steps: 2 | Val loss: 0.5942 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3608 | Steps: 2 | Val loss: 0.3614 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.5123 | Steps: 2 | Val loss: 0.3746 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.5375 | Steps: 2 | Val loss: 0.6305 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 06:33:21 (running for 00:37:12.29)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.518 |  0.18  |                   46 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.364 |  0.166 |                   46 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.59  |  0.207 |                   32 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.754 |  0.181 |                   24 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.1810457408428192
[2m[36m(func pid=34793)[0m mae:  0.13276785612106323
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.103, 0.194, 0.31, 0.154, 0.139, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.1693650186061859
[2m[36m(func pid=29667)[0m mae:  0.09570331871509552
[2m[36m(func pid=29667)[0m rmse_per_class: [0.083, 0.253, 0.039, 0.326, 0.065, 0.195, 0.244, 0.15, 0.241, 0.098]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.17675186693668365
[2m[36m(func pid=29192)[0m mae:  0.11548769474029541
[2m[36m(func pid=29192)[0m rmse_per_class: [0.089, 0.253, 0.049, 0.368, 0.056, 0.182, 0.316, 0.155, 0.203, 0.096]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.2026936560869217
[2m[36m(func pid=32597)[0m mae:  0.10766462236642838
[2m[36m(func pid=32597)[0m rmse_per_class: [0.263, 0.275, 0.033, 0.329, 0.087, 0.213, 0.365, 0.166, 0.209, 0.086]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.7478 | Steps: 2 | Val loss: 0.5852 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.5008 | Steps: 2 | Val loss: 0.3636 | Batch size: 32 | lr: 0.001 | Duration: 2.71s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3840 | Steps: 2 | Val loss: 0.3751 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.5586 | Steps: 2 | Val loss: 0.6223 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 06:33:26 (running for 00:37:17.68)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.512 |  0.177 |                   47 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.361 |  0.169 |                   47 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.538 |  0.203 |                   33 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.748 |  0.181 |                   25 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18109887838363647
[2m[36m(func pid=34793)[0m mae:  0.13278897106647491
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.104, 0.194, 0.309, 0.154, 0.139, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.17357973754405975
[2m[36m(func pid=29192)[0m mae:  0.11441642045974731
[2m[36m(func pid=29192)[0m rmse_per_class: [0.089, 0.251, 0.049, 0.365, 0.056, 0.184, 0.283, 0.155, 0.209, 0.096]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.17332780361175537
[2m[36m(func pid=29667)[0m mae:  0.0981903225183487
[2m[36m(func pid=29667)[0m rmse_per_class: [0.076, 0.267, 0.042, 0.34, 0.055, 0.203, 0.259, 0.147, 0.225, 0.119]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.21393458545207977
[2m[36m(func pid=32597)[0m mae:  0.11606162786483765
[2m[36m(func pid=32597)[0m rmse_per_class: [0.304, 0.272, 0.035, 0.362, 0.062, 0.213, 0.283, 0.33, 0.191, 0.088]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.7356 | Steps: 2 | Val loss: 0.5763 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.5005 | Steps: 2 | Val loss: 0.3541 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3853 | Steps: 2 | Val loss: 0.3870 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.5993 | Steps: 2 | Val loss: 0.5822 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 06:33:32 (running for 00:37:23.10)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.501 |  0.174 |                   48 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.384 |  0.173 |                   48 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.559 |  0.214 |                   34 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.736 |  0.181 |                   26 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18113520741462708
[2m[36m(func pid=34793)[0m mae:  0.13278479874134064
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.268, 0.089, 0.324, 0.104, 0.194, 0.309, 0.154, 0.139, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.17091114819049835
[2m[36m(func pid=29192)[0m mae:  0.11366499960422516
[2m[36m(func pid=29192)[0m rmse_per_class: [0.089, 0.249, 0.049, 0.36, 0.056, 0.186, 0.255, 0.155, 0.213, 0.096]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.17666499316692352
[2m[36m(func pid=29667)[0m mae:  0.10000177472829819
[2m[36m(func pid=29667)[0m rmse_per_class: [0.072, 0.278, 0.044, 0.345, 0.053, 0.207, 0.267, 0.144, 0.21, 0.147]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.20990295708179474
[2m[36m(func pid=32597)[0m mae:  0.11431840807199478
[2m[36m(func pid=32597)[0m rmse_per_class: [0.23, 0.266, 0.037, 0.366, 0.058, 0.203, 0.286, 0.358, 0.199, 0.097]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.7223 | Steps: 2 | Val loss: 0.5676 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4001 | Steps: 2 | Val loss: 0.3958 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4659 | Steps: 2 | Val loss: 0.3465 | Batch size: 32 | lr: 0.001 | Duration: 3.14s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.6020 | Steps: 2 | Val loss: 0.5070 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 06:33:37 (running for 00:37:28.32)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.501 |  0.171 |                   49 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.385 |  0.177 |                   49 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.599 |  0.21  |                   35 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.722 |  0.181 |                   27 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18116392195224762
[2m[36m(func pid=34793)[0m mae:  0.13278642296791077
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.324, 0.104, 0.194, 0.309, 0.154, 0.139, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.17973779141902924
[2m[36m(func pid=29667)[0m mae:  0.10162612050771713
[2m[36m(func pid=29667)[0m rmse_per_class: [0.07, 0.284, 0.046, 0.345, 0.053, 0.208, 0.269, 0.14, 0.195, 0.188]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.16895833611488342
[2m[36m(func pid=29192)[0m mae:  0.11331043392419815
[2m[36m(func pid=29192)[0m rmse_per_class: [0.09, 0.249, 0.049, 0.355, 0.056, 0.189, 0.236, 0.155, 0.214, 0.095]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.18119177222251892
[2m[36m(func pid=32597)[0m mae:  0.09647079557180405
[2m[36m(func pid=32597)[0m rmse_per_class: [0.122, 0.26, 0.042, 0.337, 0.056, 0.213, 0.254, 0.207, 0.214, 0.108]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.7153 | Steps: 2 | Val loss: 0.5588 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3977 | Steps: 2 | Val loss: 0.4021 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4707 | Steps: 2 | Val loss: 0.3403 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.5544 | Steps: 2 | Val loss: 0.4998 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
== Status ==
Current time: 2024-01-07 06:33:42 (running for 00:37:33.67)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.466 |  0.169 |                   50 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.4   |  0.18  |                   50 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.602 |  0.181 |                   36 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.715 |  0.181 |                   28 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18111984431743622
[2m[36m(func pid=34793)[0m mae:  0.13275185227394104
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.325, 0.103, 0.194, 0.309, 0.154, 0.139, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.18188032507896423
[2m[36m(func pid=29667)[0m mae:  0.10277412086725235
[2m[36m(func pid=29667)[0m rmse_per_class: [0.07, 0.287, 0.047, 0.344, 0.054, 0.205, 0.266, 0.134, 0.183, 0.228]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.16773410141468048
[2m[36m(func pid=29192)[0m mae:  0.11326734721660614
[2m[36m(func pid=29192)[0m rmse_per_class: [0.092, 0.251, 0.049, 0.349, 0.056, 0.192, 0.226, 0.155, 0.212, 0.095]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.17049118876457214
[2m[36m(func pid=32597)[0m mae:  0.09270035475492477
[2m[36m(func pid=32597)[0m rmse_per_class: [0.081, 0.256, 0.044, 0.307, 0.056, 0.253, 0.247, 0.123, 0.225, 0.112]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.7013 | Steps: 2 | Val loss: 0.5516 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4103 | Steps: 2 | Val loss: 0.4046 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4601 | Steps: 2 | Val loss: 0.3361 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.5669 | Steps: 2 | Val loss: 0.5260 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 06:33:47 (running for 00:37:38.97)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.471 |  0.168 |                   51 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.398 |  0.182 |                   51 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.554 |  0.17  |                   37 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.701 |  0.181 |                   29 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18117298185825348
[2m[36m(func pid=34793)[0m mae:  0.1327485293149948
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.325, 0.104, 0.194, 0.308, 0.153, 0.139, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.18311429023742676
[2m[36m(func pid=29667)[0m mae:  0.10358105599880219
[2m[36m(func pid=29667)[0m rmse_per_class: [0.071, 0.289, 0.047, 0.335, 0.054, 0.2, 0.259, 0.126, 0.173, 0.276]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.16711300611495972
[2m[36m(func pid=29192)[0m mae:  0.11338672786951065
[2m[36m(func pid=29192)[0m rmse_per_class: [0.094, 0.253, 0.049, 0.342, 0.056, 0.195, 0.224, 0.155, 0.209, 0.095]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.18225011229515076
[2m[36m(func pid=32597)[0m mae:  0.09794654697179794
[2m[36m(func pid=32597)[0m rmse_per_class: [0.083, 0.267, 0.046, 0.316, 0.056, 0.238, 0.275, 0.133, 0.27, 0.138]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.6924 | Steps: 2 | Val loss: 0.5440 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4070 | Steps: 2 | Val loss: 0.4076 | Batch size: 32 | lr: 0.01 | Duration: 2.67s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4627 | Steps: 2 | Val loss: 0.3345 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.5456 | Steps: 2 | Val loss: 0.6195 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=34793)[0m rmse: 0.18109700083732605
[2m[36m(func pid=34793)[0m mae:  0.13267089426517487
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.268, 0.09, 0.325, 0.103, 0.194, 0.308, 0.153, 0.139, 0.123]
[2m[36m(func pid=34793)[0m 
== Status ==
Current time: 2024-01-07 06:33:53 (running for 00:37:44.23)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.46  |  0.167 |                   52 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.41  |  0.183 |                   52 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.567 |  0.182 |                   38 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.692 |  0.181 |                   30 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29667)[0m rmse: 0.18362730741500854
[2m[36m(func pid=29667)[0m mae:  0.1040545105934143
[2m[36m(func pid=29667)[0m rmse_per_class: [0.072, 0.29, 0.048, 0.323, 0.055, 0.19, 0.251, 0.122, 0.168, 0.318]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.16703754663467407
[2m[36m(func pid=29192)[0m mae:  0.11377984285354614
[2m[36m(func pid=29192)[0m rmse_per_class: [0.097, 0.255, 0.049, 0.335, 0.056, 0.197, 0.228, 0.155, 0.204, 0.095]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.20158112049102783
[2m[36m(func pid=32597)[0m mae:  0.10801559686660767
[2m[36m(func pid=32597)[0m rmse_per_class: [0.086, 0.286, 0.048, 0.342, 0.057, 0.2, 0.314, 0.146, 0.336, 0.2]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.6837 | Steps: 2 | Val loss: 0.5360 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3936 | Steps: 2 | Val loss: 0.4131 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4632 | Steps: 2 | Val loss: 0.3338 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.5766 | Steps: 2 | Val loss: 0.7324 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 06:33:58 (running for 00:37:49.63)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.463 |  0.167 |                   53 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.407 |  0.184 |                   53 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.546 |  0.202 |                   39 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.684 |  0.181 |                   31 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18111231923103333
[2m[36m(func pid=34793)[0m mae:  0.13264594972133636
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.269, 0.09, 0.324, 0.103, 0.194, 0.308, 0.153, 0.139, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.18509098887443542
[2m[36m(func pid=29667)[0m mae:  0.10509692132472992
[2m[36m(func pid=29667)[0m rmse_per_class: [0.073, 0.289, 0.048, 0.311, 0.055, 0.178, 0.247, 0.132, 0.164, 0.353]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.16670702397823334
[2m[36m(func pid=29192)[0m mae:  0.11381952464580536
[2m[36m(func pid=29192)[0m rmse_per_class: [0.1, 0.257, 0.049, 0.326, 0.056, 0.197, 0.236, 0.154, 0.198, 0.094]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.21650901436805725
[2m[36m(func pid=32597)[0m mae:  0.11650454998016357
[2m[36m(func pid=32597)[0m rmse_per_class: [0.091, 0.289, 0.049, 0.342, 0.06, 0.197, 0.342, 0.153, 0.374, 0.267]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.6743 | Steps: 2 | Val loss: 0.5299 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3980 | Steps: 2 | Val loss: 0.4176 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4478 | Steps: 2 | Val loss: 0.3346 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.5992 | Steps: 2 | Val loss: 0.7891 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 06:34:03 (running for 00:37:54.90)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.463 |  0.167 |                   54 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.394 |  0.185 |                   54 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.577 |  0.217 |                   40 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.674 |  0.181 |                   32 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18115217983722687
[2m[36m(func pid=34793)[0m mae:  0.132672518491745
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.103, 0.194, 0.308, 0.153, 0.139, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.18764452636241913
[2m[36m(func pid=29667)[0m mae:  0.10659779608249664
[2m[36m(func pid=29667)[0m rmse_per_class: [0.074, 0.286, 0.048, 0.297, 0.055, 0.169, 0.25, 0.162, 0.164, 0.372]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.1664133369922638
[2m[36m(func pid=29192)[0m mae:  0.11382689327001572
[2m[36m(func pid=29192)[0m rmse_per_class: [0.103, 0.259, 0.049, 0.316, 0.056, 0.197, 0.246, 0.154, 0.192, 0.094]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.225825697183609
[2m[36m(func pid=32597)[0m mae:  0.1214880719780922
[2m[36m(func pid=32597)[0m rmse_per_class: [0.146, 0.286, 0.049, 0.331, 0.064, 0.206, 0.394, 0.155, 0.34, 0.287]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.6677 | Steps: 2 | Val loss: 0.5228 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4105 | Steps: 2 | Val loss: 0.4254 | Batch size: 32 | lr: 0.01 | Duration: 2.70s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4823 | Steps: 2 | Val loss: 0.3365 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.5908 | Steps: 2 | Val loss: 0.7902 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 06:34:09 (running for 00:38:00.21)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.448 |  0.166 |                   55 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.398 |  0.188 |                   55 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.599 |  0.226 |                   41 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.668 |  0.181 |                   33 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18108417093753815
[2m[36m(func pid=34793)[0m mae:  0.13262136280536652
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.103, 0.194, 0.308, 0.153, 0.139, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.19190016388893127
[2m[36m(func pid=29667)[0m mae:  0.109052874147892
[2m[36m(func pid=29667)[0m rmse_per_class: [0.074, 0.283, 0.048, 0.288, 0.056, 0.168, 0.26, 0.206, 0.166, 0.371]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.16608038544654846
[2m[36m(func pid=29192)[0m mae:  0.11379029601812363
[2m[36m(func pid=29192)[0m rmse_per_class: [0.107, 0.259, 0.049, 0.306, 0.056, 0.195, 0.256, 0.154, 0.187, 0.093]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.23150494694709778
[2m[36m(func pid=32597)[0m mae:  0.12667295336723328
[2m[36m(func pid=32597)[0m rmse_per_class: [0.266, 0.29, 0.049, 0.343, 0.068, 0.212, 0.444, 0.156, 0.243, 0.244]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4147 | Steps: 2 | Val loss: 0.4313 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.6579 | Steps: 2 | Val loss: 0.5161 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4639 | Steps: 2 | Val loss: 0.3381 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.5547 | Steps: 2 | Val loss: 0.7693 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=29667)[0m rmse: 0.1957237720489502
[2m[36m(func pid=29667)[0m mae:  0.11143402010202408
[2m[36m(func pid=29667)[0m rmse_per_class: [0.074, 0.277, 0.048, 0.285, 0.056, 0.177, 0.271, 0.249, 0.165, 0.355]
[2m[36m(func pid=29667)[0m 
== Status ==
Current time: 2024-01-07 06:34:14 (running for 00:38:05.61)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.482 |  0.166 |                   56 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.415 |  0.196 |                   57 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.591 |  0.232 |                   42 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.668 |  0.181 |                   33 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18106083571910858
[2m[36m(func pid=34793)[0m mae:  0.13258711993694305
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.103, 0.194, 0.307, 0.152, 0.139, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.16528335213661194
[2m[36m(func pid=29192)[0m mae:  0.11338068544864655
[2m[36m(func pid=29192)[0m rmse_per_class: [0.11, 0.258, 0.049, 0.296, 0.056, 0.193, 0.265, 0.153, 0.18, 0.092]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.2258208692073822
[2m[36m(func pid=32597)[0m mae:  0.12676522135734558
[2m[36m(func pid=32597)[0m rmse_per_class: [0.348, 0.292, 0.049, 0.36, 0.07, 0.196, 0.428, 0.155, 0.177, 0.186]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4029 | Steps: 2 | Val loss: 0.4347 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.6485 | Steps: 2 | Val loss: 0.5096 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4726 | Steps: 2 | Val loss: 0.3383 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.5593 | Steps: 2 | Val loss: 0.7359 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 06:34:19 (running for 00:38:10.80)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.464 |  0.165 |                   57 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.403 |  0.197 |                   58 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.555 |  0.226 |                   43 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.658 |  0.181 |                   34 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29667)[0m rmse: 0.19722598791122437
[2m[36m(func pid=29667)[0m mae:  0.11229372024536133
[2m[36m(func pid=29667)[0m rmse_per_class: [0.074, 0.271, 0.048, 0.288, 0.056, 0.195, 0.278, 0.286, 0.169, 0.308]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.1810106784105301
[2m[36m(func pid=34793)[0m mae:  0.13253019750118256
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.103, 0.194, 0.307, 0.153, 0.139, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.1641131192445755
[2m[36m(func pid=29192)[0m mae:  0.11262509971857071
[2m[36m(func pid=29192)[0m rmse_per_class: [0.112, 0.256, 0.049, 0.288, 0.056, 0.19, 0.272, 0.153, 0.174, 0.091]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.21827363967895508
[2m[36m(func pid=32597)[0m mae:  0.1210865005850792
[2m[36m(func pid=32597)[0m rmse_per_class: [0.302, 0.281, 0.047, 0.367, 0.079, 0.306, 0.325, 0.147, 0.169, 0.16]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4122 | Steps: 2 | Val loss: 0.4388 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.6449 | Steps: 2 | Val loss: 0.5032 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4584 | Steps: 2 | Val loss: 0.3371 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4808 | Steps: 2 | Val loss: 0.7173 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 06:34:24 (running for 00:38:15.98)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.473 |  0.164 |                   58 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.412 |  0.198 |                   59 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.559 |  0.218 |                   44 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.649 |  0.181 |                   35 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29667)[0m rmse: 0.1976771056652069
[2m[36m(func pid=29667)[0m mae:  0.1130155473947525
[2m[36m(func pid=29667)[0m rmse_per_class: [0.076, 0.264, 0.047, 0.299, 0.056, 0.216, 0.28, 0.302, 0.171, 0.265]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.1809360384941101
[2m[36m(func pid=34793)[0m mae:  0.13247230648994446
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.102, 0.194, 0.307, 0.152, 0.139, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.1629360020160675
[2m[36m(func pid=29192)[0m mae:  0.11185438930988312
[2m[36m(func pid=29192)[0m rmse_per_class: [0.114, 0.253, 0.049, 0.281, 0.056, 0.187, 0.278, 0.152, 0.168, 0.09]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.21263837814331055
[2m[36m(func pid=32597)[0m mae:  0.12146476656198502
[2m[36m(func pid=32597)[0m rmse_per_class: [0.133, 0.287, 0.041, 0.365, 0.096, 0.46, 0.292, 0.131, 0.19, 0.131]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4294 | Steps: 2 | Val loss: 0.4387 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.6378 | Steps: 2 | Val loss: 0.4978 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.5239 | Steps: 2 | Val loss: 0.7343 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4740 | Steps: 2 | Val loss: 0.3364 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 06:34:30 (running for 00:38:21.14)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.458 |  0.163 |                   59 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.429 |  0.196 |                   60 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.481 |  0.213 |                   45 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.645 |  0.181 |                   36 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29667)[0m rmse: 0.19584651291370392
[2m[36m(func pid=29667)[0m mae:  0.1124114990234375
[2m[36m(func pid=29667)[0m rmse_per_class: [0.079, 0.261, 0.047, 0.314, 0.056, 0.239, 0.277, 0.295, 0.174, 0.218]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.16203786432743073
[2m[36m(func pid=29192)[0m mae:  0.11125990003347397
[2m[36m(func pid=29192)[0m rmse_per_class: [0.116, 0.251, 0.048, 0.277, 0.056, 0.184, 0.284, 0.151, 0.163, 0.089]
[2m[36m(func pid=34793)[0m rmse: 0.18095865845680237
[2m[36m(func pid=34793)[0m mae:  0.13246223330497742
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.103, 0.194, 0.307, 0.152, 0.139, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.21924784779548645
[2m[36m(func pid=32597)[0m mae:  0.1217791885137558
[2m[36m(func pid=32597)[0m rmse_per_class: [0.09, 0.334, 0.037, 0.362, 0.12, 0.305, 0.315, 0.313, 0.205, 0.11]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4147 | Steps: 2 | Val loss: 0.4347 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4385 | Steps: 2 | Val loss: 0.3320 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.5753 | Steps: 2 | Val loss: 0.7276 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.6325 | Steps: 2 | Val loss: 0.4928 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 06:34:35 (running for 00:38:26.18)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.474 |  0.162 |                   60 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.415 |  0.192 |                   61 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.524 |  0.219 |                   46 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.638 |  0.181 |                   37 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29667)[0m rmse: 0.19205600023269653
[2m[36m(func pid=29667)[0m mae:  0.11025021225214005
[2m[36m(func pid=29667)[0m rmse_per_class: [0.082, 0.26, 0.046, 0.326, 0.056, 0.252, 0.271, 0.275, 0.18, 0.171]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.16072699427604675
[2m[36m(func pid=29192)[0m mae:  0.11032480001449585
[2m[36m(func pid=29192)[0m rmse_per_class: [0.116, 0.248, 0.048, 0.274, 0.056, 0.181, 0.288, 0.15, 0.158, 0.088]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.18086150288581848
[2m[36m(func pid=34793)[0m mae:  0.13237790763378143
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.102, 0.194, 0.306, 0.152, 0.139, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.22064737975597382
[2m[36m(func pid=32597)[0m mae:  0.12428619712591171
[2m[36m(func pid=32597)[0m rmse_per_class: [0.089, 0.328, 0.035, 0.353, 0.123, 0.217, 0.347, 0.403, 0.218, 0.093]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4037 | Steps: 2 | Val loss: 0.4277 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4356 | Steps: 2 | Val loss: 0.3278 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.6216 | Steps: 2 | Val loss: 0.4881 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.5973 | Steps: 2 | Val loss: 0.6716 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 06:34:40 (running for 00:38:31.39)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.438 |  0.161 |                   61 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.404 |  0.187 |                   62 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.575 |  0.221 |                   47 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.632 |  0.181 |                   38 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29667)[0m rmse: 0.1869613081216812
[2m[36m(func pid=29667)[0m mae:  0.1073988676071167
[2m[36m(func pid=29667)[0m rmse_per_class: [0.085, 0.264, 0.046, 0.34, 0.056, 0.255, 0.264, 0.24, 0.183, 0.137]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.15979337692260742
[2m[36m(func pid=29192)[0m mae:  0.10967258363962173
[2m[36m(func pid=29192)[0m rmse_per_class: [0.115, 0.246, 0.048, 0.273, 0.056, 0.178, 0.291, 0.148, 0.154, 0.089]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.21000850200653076
[2m[36m(func pid=32597)[0m mae:  0.11690745502710342
[2m[36m(func pid=32597)[0m rmse_per_class: [0.1, 0.284, 0.034, 0.343, 0.11, 0.216, 0.455, 0.237, 0.232, 0.089]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.18076637387275696
[2m[36m(func pid=34793)[0m mae:  0.1322997361421585
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.102, 0.194, 0.306, 0.152, 0.139, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4187 | Steps: 2 | Val loss: 0.4229 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4266 | Steps: 2 | Val loss: 0.3231 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.6152 | Steps: 2 | Val loss: 0.4833 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.5332 | Steps: 2 | Val loss: 0.6469 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 06:34:45 (running for 00:38:36.51)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.436 |  0.16  |                   62 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.419 |  0.182 |                   63 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.597 |  0.21  |                   48 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.622 |  0.181 |                   39 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29667)[0m rmse: 0.1816825568675995
[2m[36m(func pid=29667)[0m mae:  0.10420135408639908
[2m[36m(func pid=29667)[0m rmse_per_class: [0.087, 0.27, 0.045, 0.351, 0.056, 0.24, 0.262, 0.208, 0.185, 0.113]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.15899142622947693
[2m[36m(func pid=29192)[0m mae:  0.10896055400371552
[2m[36m(func pid=29192)[0m rmse_per_class: [0.112, 0.244, 0.048, 0.273, 0.056, 0.175, 0.294, 0.145, 0.15, 0.091]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.180763378739357
[2m[36m(func pid=34793)[0m mae:  0.13229626417160034
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.101, 0.194, 0.306, 0.152, 0.14, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.2068672925233841
[2m[36m(func pid=32597)[0m mae:  0.11683537811040878
[2m[36m(func pid=32597)[0m rmse_per_class: [0.192, 0.286, 0.035, 0.325, 0.087, 0.211, 0.489, 0.135, 0.221, 0.089]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4118 | Steps: 2 | Val loss: 0.4173 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4132 | Steps: 2 | Val loss: 0.3183 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4208 | Steps: 2 | Val loss: 0.6683 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.6096 | Steps: 2 | Val loss: 0.4778 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 06:34:50 (running for 00:38:41.73)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.427 |  0.159 |                   63 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.412 |  0.176 |                   64 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.533 |  0.207 |                   49 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.615 |  0.181 |                   40 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29667)[0m rmse: 0.17626456916332245
[2m[36m(func pid=29667)[0m mae:  0.10063783079385757
[2m[36m(func pid=29667)[0m rmse_per_class: [0.091, 0.279, 0.044, 0.358, 0.056, 0.219, 0.264, 0.17, 0.185, 0.097]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.15876194834709167
[2m[36m(func pid=29192)[0m mae:  0.10865096002817154
[2m[36m(func pid=29192)[0m rmse_per_class: [0.111, 0.243, 0.047, 0.275, 0.056, 0.173, 0.295, 0.142, 0.147, 0.097]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.1807829886674881
[2m[36m(func pid=34793)[0m mae:  0.13229186832904816
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.101, 0.194, 0.306, 0.151, 0.14, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.20752942562103271
[2m[36m(func pid=32597)[0m mae:  0.11728918552398682
[2m[36m(func pid=32597)[0m rmse_per_class: [0.381, 0.296, 0.035, 0.326, 0.062, 0.238, 0.298, 0.152, 0.199, 0.089]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3683 | Steps: 2 | Val loss: 0.4179 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4086 | Steps: 2 | Val loss: 0.3131 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.5147 | Steps: 2 | Val loss: 0.6988 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.6052 | Steps: 2 | Val loss: 0.4728 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 06:34:55 (running for 00:38:46.91)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.413 |  0.159 |                   64 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.368 |  0.173 |                   65 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.421 |  0.208 |                   50 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.61  |  0.181 |                   41 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29667)[0m rmse: 0.17303897440433502
[2m[36m(func pid=29667)[0m mae:  0.09874038398265839
[2m[36m(func pid=29667)[0m rmse_per_class: [0.094, 0.289, 0.043, 0.364, 0.056, 0.196, 0.268, 0.146, 0.189, 0.087]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.1585218906402588
[2m[36m(func pid=29192)[0m mae:  0.10815081745386124
[2m[36m(func pid=29192)[0m rmse_per_class: [0.105, 0.243, 0.047, 0.276, 0.056, 0.171, 0.296, 0.138, 0.144, 0.109]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.2160753756761551
[2m[36m(func pid=32597)[0m mae:  0.1239253506064415
[2m[36m(func pid=32597)[0m rmse_per_class: [0.354, 0.297, 0.038, 0.332, 0.054, 0.339, 0.294, 0.156, 0.206, 0.089]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.18075621128082275
[2m[36m(func pid=34793)[0m mae:  0.1322510540485382
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.269, 0.092, 0.325, 0.101, 0.194, 0.305, 0.151, 0.14, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3673 | Steps: 2 | Val loss: 0.4254 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3856 | Steps: 2 | Val loss: 0.3090 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.6455 | Steps: 2 | Val loss: 0.6734 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.5989 | Steps: 2 | Val loss: 0.4678 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 06:35:00 (running for 00:38:52.00)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.409 |  0.159 |                   65 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.367 |  0.172 |                   66 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.515 |  0.216 |                   51 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.605 |  0.181 |                   42 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29667)[0m rmse: 0.17197728157043457
[2m[36m(func pid=29667)[0m mae:  0.09825330972671509
[2m[36m(func pid=29667)[0m rmse_per_class: [0.098, 0.302, 0.041, 0.368, 0.055, 0.179, 0.269, 0.132, 0.194, 0.081]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.15909308195114136
[2m[36m(func pid=29192)[0m mae:  0.10814175754785538
[2m[36m(func pid=29192)[0m rmse_per_class: [0.102, 0.244, 0.046, 0.276, 0.056, 0.169, 0.297, 0.133, 0.141, 0.126]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.2080589234828949
[2m[36m(func pid=32597)[0m mae:  0.11651860177516937
[2m[36m(func pid=32597)[0m rmse_per_class: [0.177, 0.289, 0.04, 0.342, 0.054, 0.375, 0.294, 0.156, 0.264, 0.089]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.18066658079624176
[2m[36m(func pid=34793)[0m mae:  0.13215099275112152
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.269, 0.091, 0.325, 0.101, 0.194, 0.305, 0.151, 0.14, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3591 | Steps: 2 | Val loss: 0.4339 | Batch size: 32 | lr: 0.01 | Duration: 2.66s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3865 | Steps: 2 | Val loss: 0.3060 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.6023 | Steps: 2 | Val loss: 0.6378 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=29667)[0m rmse: 0.1728747934103012
[2m[36m(func pid=29667)[0m mae:  0.09891672432422638
[2m[36m(func pid=29667)[0m rmse_per_class: [0.101, 0.316, 0.039, 0.369, 0.055, 0.17, 0.268, 0.127, 0.203, 0.08]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.5918 | Steps: 2 | Val loss: 0.4632 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=29192)[0m rmse: 0.1601257622241974
[2m[36m(func pid=29192)[0m mae:  0.1084204688668251
[2m[36m(func pid=29192)[0m rmse_per_class: [0.095, 0.247, 0.045, 0.275, 0.056, 0.168, 0.297, 0.128, 0.138, 0.151]
[2m[36m(func pid=29192)[0m 
== Status ==
Current time: 2024-01-07 06:35:07 (running for 00:38:58.65)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.386 |  0.16  |                   67 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.359 |  0.173 |                   67 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.646 |  0.208 |                   52 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.599 |  0.181 |                   43 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=32597)[0m rmse: 0.19369037449359894
[2m[36m(func pid=32597)[0m mae:  0.10695527493953705
[2m[36m(func pid=32597)[0m rmse_per_class: [0.093, 0.285, 0.043, 0.324, 0.054, 0.239, 0.357, 0.156, 0.298, 0.088]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.18071380257606506
[2m[36m(func pid=34793)[0m mae:  0.13218359649181366
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.326, 0.101, 0.194, 0.305, 0.151, 0.14, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3754 | Steps: 2 | Val loss: 0.4421 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3659 | Steps: 2 | Val loss: 0.3038 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=29667)[0m rmse: 0.17475226521492004
[2m[36m(func pid=29667)[0m mae:  0.10022914409637451
[2m[36m(func pid=29667)[0m rmse_per_class: [0.108, 0.33, 0.036, 0.366, 0.055, 0.171, 0.262, 0.124, 0.214, 0.08]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.5757 | Steps: 2 | Val loss: 0.6657 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.5887 | Steps: 2 | Val loss: 0.4590 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 06:35:13 (running for 00:39:04.10)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.366 |  0.161 |                   68 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.375 |  0.175 |                   68 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.602 |  0.194 |                   53 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.592 |  0.181 |                   44 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29192)[0m rmse: 0.1614125519990921
[2m[36m(func pid=29192)[0m mae:  0.10900358855724335
[2m[36m(func pid=29192)[0m rmse_per_class: [0.09, 0.25, 0.044, 0.272, 0.056, 0.169, 0.297, 0.121, 0.137, 0.179]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.20174339413642883
[2m[36m(func pid=32597)[0m mae:  0.11577866971492767
[2m[36m(func pid=32597)[0m rmse_per_class: [0.092, 0.309, 0.046, 0.33, 0.055, 0.204, 0.473, 0.156, 0.267, 0.087]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.18059736490249634
[2m[36m(func pid=34793)[0m mae:  0.13209867477416992
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.326, 0.101, 0.194, 0.305, 0.151, 0.14, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3736 | Steps: 2 | Val loss: 0.4497 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3705 | Steps: 2 | Val loss: 0.3038 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.5581 | Steps: 2 | Val loss: 0.7350 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=29667)[0m rmse: 0.17676863074302673
[2m[36m(func pid=29667)[0m mae:  0.101520836353302
[2m[36m(func pid=29667)[0m rmse_per_class: [0.11, 0.336, 0.035, 0.364, 0.055, 0.172, 0.262, 0.125, 0.228, 0.082]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.5820 | Steps: 2 | Val loss: 0.4547 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 06:35:18 (running for 00:39:09.38)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.371 |  0.163 |                   69 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.374 |  0.177 |                   69 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.576 |  0.202 |                   54 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.589 |  0.181 |                   45 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29192)[0m rmse: 0.1630662977695465
[2m[36m(func pid=29192)[0m mae:  0.10989528894424438
[2m[36m(func pid=29192)[0m rmse_per_class: [0.084, 0.254, 0.042, 0.267, 0.056, 0.17, 0.296, 0.116, 0.135, 0.21]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.20889106392860413
[2m[36m(func pid=32597)[0m mae:  0.11943558603525162
[2m[36m(func pid=32597)[0m rmse_per_class: [0.097, 0.341, 0.049, 0.358, 0.054, 0.206, 0.464, 0.155, 0.257, 0.108]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.18048277497291565
[2m[36m(func pid=34793)[0m mae:  0.13199342787265778
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.325, 0.1, 0.194, 0.304, 0.151, 0.14, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3725 | Steps: 2 | Val loss: 0.4604 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3622 | Steps: 2 | Val loss: 0.3049 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.5090 | Steps: 2 | Val loss: 0.7903 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=29667)[0m rmse: 0.17926235496997833
[2m[36m(func pid=29667)[0m mae:  0.10295496135950089
[2m[36m(func pid=29667)[0m rmse_per_class: [0.112, 0.341, 0.033, 0.361, 0.058, 0.175, 0.258, 0.127, 0.246, 0.083]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.5785 | Steps: 2 | Val loss: 0.4516 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
== Status ==
Current time: 2024-01-07 06:35:23 (running for 00:39:14.60)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.371 |  0.163 |                   69 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.372 |  0.179 |                   70 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.509 |  0.218 |                   56 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.582 |  0.18  |                   46 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=32597)[0m rmse: 0.2176286280155182
[2m[36m(func pid=32597)[0m mae:  0.12042702734470367
[2m[36m(func pid=32597)[0m rmse_per_class: [0.301, 0.32, 0.049, 0.372, 0.055, 0.204, 0.335, 0.143, 0.22, 0.177]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29192)[0m rmse: 0.1648876965045929
[2m[36m(func pid=29192)[0m mae:  0.11085055768489838
[2m[36m(func pid=29192)[0m rmse_per_class: [0.079, 0.258, 0.04, 0.262, 0.056, 0.172, 0.295, 0.114, 0.133, 0.24]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3981 | Steps: 2 | Val loss: 0.4647 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=34793)[0m rmse: 0.18049383163452148
[2m[36m(func pid=34793)[0m mae:  0.13197819888591766
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.325, 0.1, 0.194, 0.304, 0.151, 0.14, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4452 | Steps: 2 | Val loss: 0.8291 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3522 | Steps: 2 | Val loss: 0.3070 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=29667)[0m rmse: 0.18069101870059967
[2m[36m(func pid=29667)[0m mae:  0.10367562621831894
[2m[36m(func pid=29667)[0m rmse_per_class: [0.105, 0.338, 0.031, 0.355, 0.066, 0.179, 0.256, 0.129, 0.266, 0.084]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.5691 | Steps: 2 | Val loss: 0.4483 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 06:35:29 (running for 00:39:20.18)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.352 |  0.167 |                   71 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.398 |  0.181 |                   71 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.509 |  0.218 |                   56 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.578 |  0.18  |                   47 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29192)[0m rmse: 0.1669473946094513
[2m[36m(func pid=29192)[0m mae:  0.11207862943410873
[2m[36m(func pid=29192)[0m rmse_per_class: [0.075, 0.262, 0.038, 0.257, 0.056, 0.175, 0.294, 0.117, 0.131, 0.264]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.23325178027153015
[2m[36m(func pid=32597)[0m mae:  0.13410548865795135
[2m[36m(func pid=32597)[0m rmse_per_class: [0.483, 0.298, 0.049, 0.379, 0.055, 0.214, 0.265, 0.205, 0.168, 0.216]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3769 | Steps: 2 | Val loss: 0.4628 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=34793)[0m rmse: 0.18040569126605988
[2m[36m(func pid=34793)[0m mae:  0.13191507756710052
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.269, 0.09, 0.325, 0.1, 0.194, 0.304, 0.151, 0.14, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3470 | Steps: 2 | Val loss: 0.3106 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=29667)[0m rmse: 0.18163564801216125
[2m[36m(func pid=29667)[0m mae:  0.1036698967218399
[2m[36m(func pid=29667)[0m rmse_per_class: [0.098, 0.325, 0.029, 0.346, 0.084, 0.181, 0.253, 0.131, 0.286, 0.084]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.5105 | Steps: 2 | Val loss: 0.8402 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.5695 | Steps: 2 | Val loss: 0.4452 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 06:35:34 (running for 00:39:25.45)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.347 |  0.17  |                   72 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.377 |  0.182 |                   72 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.445 |  0.233 |                   57 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.569 |  0.18  |                   48 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29192)[0m rmse: 0.1698322892189026
[2m[36m(func pid=29192)[0m mae:  0.11382140219211578
[2m[36m(func pid=29192)[0m rmse_per_class: [0.073, 0.266, 0.036, 0.253, 0.056, 0.178, 0.292, 0.129, 0.13, 0.285]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.226372629404068
[2m[36m(func pid=32597)[0m mae:  0.12822452187538147
[2m[36m(func pid=32597)[0m rmse_per_class: [0.341, 0.298, 0.049, 0.381, 0.055, 0.255, 0.278, 0.231, 0.17, 0.206]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3868 | Steps: 2 | Val loss: 0.4597 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=34793)[0m rmse: 0.1804143488407135
[2m[36m(func pid=34793)[0m mae:  0.13190437853336334
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.325, 0.1, 0.194, 0.304, 0.151, 0.14, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.18252024054527283
[2m[36m(func pid=29667)[0m mae:  0.1034817323088646
[2m[36m(func pid=29667)[0m rmse_per_class: [0.091, 0.308, 0.028, 0.335, 0.107, 0.184, 0.252, 0.133, 0.302, 0.085]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3489 | Steps: 2 | Val loss: 0.3154 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.5907 | Steps: 2 | Val loss: 0.8176 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.5652 | Steps: 2 | Val loss: 0.4417 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 06:35:39 (running for 00:39:30.74)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.349 |  0.173 |                   73 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.387 |  0.183 |                   73 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.511 |  0.226 |                   58 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.569 |  0.18  |                   49 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29192)[0m rmse: 0.1734776794910431
[2m[36m(func pid=29192)[0m mae:  0.11601455509662628
[2m[36m(func pid=29192)[0m rmse_per_class: [0.071, 0.269, 0.033, 0.252, 0.056, 0.181, 0.29, 0.15, 0.13, 0.301]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.21314439177513123
[2m[36m(func pid=32597)[0m mae:  0.1199667900800705
[2m[36m(func pid=32597)[0m rmse_per_class: [0.125, 0.295, 0.049, 0.381, 0.067, 0.265, 0.378, 0.188, 0.207, 0.177]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3733 | Steps: 2 | Val loss: 0.4511 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=34793)[0m rmse: 0.18045422434806824
[2m[36m(func pid=34793)[0m mae:  0.13190987706184387
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.325, 0.1, 0.194, 0.304, 0.15, 0.14, 0.123]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.1822102963924408
[2m[36m(func pid=29667)[0m mae:  0.10222373157739639
[2m[36m(func pid=29667)[0m rmse_per_class: [0.083, 0.282, 0.028, 0.322, 0.133, 0.184, 0.261, 0.133, 0.31, 0.085]
[2m[36m(func pid=29667)[0m 
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3597 | Steps: 2 | Val loss: 0.3210 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.5837 | Steps: 2 | Val loss: 0.7452 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.5629 | Steps: 2 | Val loss: 0.4383 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=29667)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3775 | Steps: 2 | Val loss: 0.4423 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 06:35:44 (running for 00:39:36.01)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00017 | RUNNING    | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.349 |  0.173 |                   73 |
| train_12613_00018 | RUNNING    | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.373 |  0.182 |                   74 |
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.584 |  0.21  |                   60 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.565 |  0.18  |                   50 |
| train_12613_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=29192)[0m rmse: 0.17746855318546295
[2m[36m(func pid=29192)[0m mae:  0.11831687390804291
[2m[36m(func pid=29192)[0m rmse_per_class: [0.071, 0.272, 0.031, 0.254, 0.056, 0.185, 0.288, 0.179, 0.129, 0.308]
[2m[36m(func pid=29192)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.20993570983409882
[2m[36m(func pid=32597)[0m mae:  0.11735738813877106
[2m[36m(func pid=32597)[0m rmse_per_class: [0.09, 0.299, 0.048, 0.373, 0.094, 0.218, 0.435, 0.157, 0.232, 0.153]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.18039186298847198
[2m[36m(func pid=34793)[0m mae:  0.13183282315731049
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.325, 0.101, 0.194, 0.303, 0.15, 0.14, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=29667)[0m rmse: 0.18217292428016663
[2m[36m(func pid=29667)[0m mae:  0.10158424079418182
[2m[36m(func pid=29667)[0m rmse_per_class: [0.076, 0.264, 0.029, 0.31, 0.157, 0.184, 0.269, 0.134, 0.314, 0.085]
[2m[36m(func pid=29192)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3460 | Steps: 2 | Val loss: 0.3266 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4355 | Steps: 2 | Val loss: 0.7062 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.5549 | Steps: 2 | Val loss: 0.4350 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=29192)[0m rmse: 0.18123272061347961
[2m[36m(func pid=29192)[0m mae:  0.12056110054254532
[2m[36m(func pid=29192)[0m rmse_per_class: [0.072, 0.274, 0.031, 0.259, 0.056, 0.188, 0.285, 0.212, 0.129, 0.306]
[2m[36m(func pid=32597)[0m rmse: 0.20512893795967102
[2m[36m(func pid=32597)[0m mae:  0.11172471195459366
[2m[36m(func pid=32597)[0m rmse_per_class: [0.097, 0.379, 0.044, 0.358, 0.11, 0.215, 0.34, 0.142, 0.242, 0.124]
[2m[36m(func pid=34793)[0m rmse: 0.18040241301059723
[2m[36m(func pid=34793)[0m mae:  0.13182036578655243
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.325, 0.101, 0.194, 0.303, 0.15, 0.14, 0.122]
== Status ==
Current time: 2024-01-07 06:35:50 (running for 00:39:41.30)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 3 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.584 |  0.21  |                   60 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.563 |  0.18  |                   51 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


== Status ==
Current time: 2024-01-07 06:35:56 (running for 00:39:47.18)
Memory usage on this node: 20.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 3 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.584 |  0.21  |                   60 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.555 |  0.18  |                   52 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=46501)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46501)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=46501)[0m Configuration completed!
[2m[36m(func pid=46501)[0m New optimizer parameters:
[2m[36m(func pid=46501)[0m SGD (
[2m[36m(func pid=46501)[0m Parameter Group 0
[2m[36m(func pid=46501)[0m     dampening: 0
[2m[36m(func pid=46501)[0m     differentiable: False
[2m[36m(func pid=46501)[0m     foreach: None
[2m[36m(func pid=46501)[0m     lr: 0.001
[2m[36m(func pid=46501)[0m     maximize: False
[2m[36m(func pid=46501)[0m     momentum: 0.9
[2m[36m(func pid=46501)[0m     nesterov: False
[2m[36m(func pid=46501)[0m     weight_decay: 1e-05
[2m[36m(func pid=46501)[0m )
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4202 | Steps: 2 | Val loss: 0.6870 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.5495 | Steps: 2 | Val loss: 0.4324 | Batch size: 32 | lr: 0.0001 | Duration: 3.19s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0773 | Steps: 2 | Val loss: 0.7945 | Batch size: 32 | lr: 0.001 | Duration: 4.43s
[2m[36m(func pid=32597)[0m rmse: 0.20393720269203186
[2m[36m(func pid=32597)[0m mae:  0.11079756915569305
[2m[36m(func pid=32597)[0m rmse_per_class: [0.158, 0.384, 0.042, 0.344, 0.111, 0.213, 0.302, 0.153, 0.235, 0.096]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.18042457103729248
[2m[36m(func pid=34793)[0m mae:  0.1318322718143463
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.101, 0.194, 0.303, 0.15, 0.14, 0.122]
[2m[36m(func pid=46501)[0m rmse: 0.17858317494392395
[2m[36m(func pid=46501)[0m mae:  0.13109411299228668
[2m[36m(func pid=46501)[0m rmse_per_class: [0.105, 0.266, 0.086, 0.325, 0.1, 0.192, 0.304, 0.153, 0.139, 0.116]
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4900 | Steps: 2 | Val loss: 0.6615 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 06:36:01 (running for 00:39:52.57)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.42  |  0.204 |                   62 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.555 |  0.18  |                   52 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46973)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=46973)[0m Configuration completed!
[2m[36m(func pid=46973)[0m New optimizer parameters:
[2m[36m(func pid=46973)[0m SGD (
[2m[36m(func pid=46973)[0m Parameter Group 0
[2m[36m(func pid=46973)[0m     dampening: 0
[2m[36m(func pid=46973)[0m     differentiable: False
[2m[36m(func pid=46973)[0m     foreach: None
[2m[36m(func pid=46973)[0m     lr: 0.01
[2m[36m(func pid=46973)[0m     maximize: False
[2m[36m(func pid=46973)[0m     momentum: 0.9
[2m[36m(func pid=46973)[0m     nesterov: False
[2m[36m(func pid=46973)[0m     weight_decay: 1e-05
[2m[36m(func pid=46973)[0m )
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:36:06 (running for 00:39:57.94)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.49  |  0.204 |                   63 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.55  |  0.18  |                   53 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  1.077 |  0.179 |                    1 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=32597)[0m rmse: 0.2041202336549759
[2m[36m(func pid=32597)[0m mae:  0.1115218997001648
[2m[36m(func pid=32597)[0m rmse_per_class: [0.314, 0.299, 0.043, 0.336, 0.09, 0.207, 0.287, 0.156, 0.22, 0.09]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0393 | Steps: 2 | Val loss: 0.7585 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.5471 | Steps: 2 | Val loss: 0.4290 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0333 | Steps: 2 | Val loss: 0.6491 | Batch size: 32 | lr: 0.01 | Duration: 4.17s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.5215 | Steps: 2 | Val loss: 0.6484 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=46501)[0m rmse: 0.17888960242271423
[2m[36m(func pid=46501)[0m mae:  0.13129805028438568
[2m[36m(func pid=46501)[0m rmse_per_class: [0.104, 0.266, 0.087, 0.325, 0.1, 0.192, 0.305, 0.155, 0.139, 0.116]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.18039527535438538
[2m[36m(func pid=34793)[0m mae:  0.13180764019489288
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.101, 0.194, 0.303, 0.15, 0.14, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.17804017663002014
[2m[36m(func pid=46973)[0m mae:  0.13046914339065552
[2m[36m(func pid=46973)[0m rmse_per_class: [0.104, 0.267, 0.086, 0.325, 0.097, 0.192, 0.301, 0.155, 0.139, 0.115]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:36:12 (running for 00:40:03.07)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.521 |  0.2   |                   64 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.547 |  0.18  |                   54 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  1.039 |  0.179 |                    2 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  1.033 |  0.178 |                    1 |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=32597)[0m rmse: 0.20020928978919983
[2m[36m(func pid=32597)[0m mae:  0.11126990616321564
[2m[36m(func pid=32597)[0m rmse_per_class: [0.325, 0.292, 0.043, 0.321, 0.06, 0.194, 0.314, 0.156, 0.209, 0.089]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.9659 | Steps: 2 | Val loss: 0.7076 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.5433 | Steps: 2 | Val loss: 0.4262 | Batch size: 32 | lr: 0.0001 | Duration: 2.76s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.7151 | Steps: 2 | Val loss: 0.4384 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.5688 | Steps: 2 | Val loss: 0.6464 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=46501)[0m rmse: 0.1791922152042389
[2m[36m(func pid=46501)[0m mae:  0.13145719468593597
[2m[36m(func pid=46501)[0m rmse_per_class: [0.104, 0.266, 0.088, 0.325, 0.101, 0.193, 0.305, 0.156, 0.139, 0.115]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.18031522631645203
[2m[36m(func pid=34793)[0m mae:  0.13174709677696228
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.1, 0.194, 0.303, 0.15, 0.141, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.177047461271286
[2m[36m(func pid=46973)[0m mae:  0.12935969233512878
[2m[36m(func pid=46973)[0m rmse_per_class: [0.104, 0.269, 0.087, 0.327, 0.093, 0.192, 0.294, 0.154, 0.141, 0.109]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:36:17 (running for 00:40:08.31)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.569 |  0.194 |                   65 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.543 |  0.18  |                   55 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.966 |  0.179 |                    3 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.715 |  0.177 |                    2 |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=32597)[0m rmse: 0.19414791464805603
[2m[36m(func pid=32597)[0m mae:  0.1076384037733078
[2m[36m(func pid=32597)[0m rmse_per_class: [0.195, 0.295, 0.043, 0.311, 0.054, 0.216, 0.353, 0.156, 0.229, 0.09]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.8761 | Steps: 2 | Val loss: 0.6474 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.5425 | Steps: 2 | Val loss: 0.4238 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.4715 | Steps: 2 | Val loss: 0.3367 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.5468 | Steps: 2 | Val loss: 0.6355 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=46501)[0m rmse: 0.17943356931209564
[2m[36m(func pid=46501)[0m mae:  0.1315401792526245
[2m[36m(func pid=46501)[0m rmse_per_class: [0.104, 0.267, 0.088, 0.325, 0.101, 0.193, 0.305, 0.157, 0.139, 0.116]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.1803412139415741
[2m[36m(func pid=34793)[0m mae:  0.13176612555980682
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.1, 0.194, 0.303, 0.15, 0.141, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.1755145937204361
[2m[36m(func pid=46973)[0m mae:  0.12780611217021942
[2m[36m(func pid=46973)[0m rmse_per_class: [0.105, 0.272, 0.091, 0.334, 0.086, 0.192, 0.283, 0.143, 0.146, 0.103]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:36:22 (running for 00:40:13.57)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.547 |  0.197 |                   66 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.542 |  0.18  |                   56 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.876 |  0.179 |                    4 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.471 |  0.176 |                    3 |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=32597)[0m rmse: 0.19656579196453094
[2m[36m(func pid=32597)[0m mae:  0.108779177069664
[2m[36m(func pid=32597)[0m rmse_per_class: [0.116, 0.29, 0.043, 0.321, 0.054, 0.291, 0.336, 0.156, 0.268, 0.091]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7830 | Steps: 2 | Val loss: 0.5826 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.5377 | Steps: 2 | Val loss: 0.4211 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4187 | Steps: 2 | Val loss: 0.3252 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4741 | Steps: 2 | Val loss: 0.6549 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=46501)[0m rmse: 0.17953327298164368
[2m[36m(func pid=46501)[0m mae:  0.13148154318332672
[2m[36m(func pid=46501)[0m rmse_per_class: [0.104, 0.267, 0.089, 0.324, 0.101, 0.194, 0.305, 0.157, 0.139, 0.115]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.1803397238254547
[2m[36m(func pid=34793)[0m mae:  0.1317516416311264
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.1, 0.194, 0.303, 0.15, 0.141, 0.121]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.17452655732631683
[2m[36m(func pid=46973)[0m mae:  0.12622973322868347
[2m[36m(func pid=46973)[0m rmse_per_class: [0.106, 0.274, 0.091, 0.341, 0.078, 0.192, 0.276, 0.134, 0.154, 0.098]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:36:27 (running for 00:40:18.69)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.474 |  0.201 |                   67 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.538 |  0.18  |                   57 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.783 |  0.18  |                    5 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.419 |  0.175 |                    4 |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=32597)[0m rmse: 0.20065435767173767
[2m[36m(func pid=32597)[0m mae:  0.10945823043584824
[2m[36m(func pid=32597)[0m rmse_per_class: [0.111, 0.295, 0.043, 0.336, 0.054, 0.286, 0.316, 0.15, 0.274, 0.141]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.6984 | Steps: 2 | Val loss: 0.5223 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.5368 | Steps: 2 | Val loss: 0.4183 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4471 | Steps: 2 | Val loss: 0.3432 | Batch size: 32 | lr: 0.01 | Duration: 2.65s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4467 | Steps: 2 | Val loss: 0.6882 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=46501)[0m rmse: 0.1796565055847168
[2m[36m(func pid=46501)[0m mae:  0.13147267699241638
[2m[36m(func pid=46501)[0m rmse_per_class: [0.105, 0.268, 0.09, 0.325, 0.1, 0.194, 0.304, 0.157, 0.139, 0.115]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.18024833500385284
[2m[36m(func pid=34793)[0m mae:  0.1316613107919693
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.1, 0.194, 0.302, 0.149, 0.141, 0.121]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.17421157658100128
[2m[36m(func pid=46973)[0m mae:  0.12467160075902939
[2m[36m(func pid=46973)[0m rmse_per_class: [0.108, 0.275, 0.087, 0.345, 0.07, 0.192, 0.277, 0.133, 0.161, 0.095]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.20824368298053741
[2m[36m(func pid=32597)[0m mae:  0.11230077594518661
[2m[36m(func pid=32597)[0m rmse_per_class: [0.118, 0.356, 0.046, 0.349, 0.054, 0.202, 0.297, 0.162, 0.25, 0.248]
[2m[36m(func pid=32597)[0m 
== Status ==
Current time: 2024-01-07 06:36:32 (running for 00:40:23.77)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.447 |  0.208 |                   68 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.537 |  0.18  |                   58 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.698 |  0.18  |                    6 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.447 |  0.174 |                    5 |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.6241 | Steps: 2 | Val loss: 0.4700 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4805 | Steps: 2 | Val loss: 0.3637 | Batch size: 32 | lr: 0.01 | Duration: 2.67s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.5295 | Steps: 2 | Val loss: 0.4153 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4417 | Steps: 2 | Val loss: 0.7030 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=46501)[0m rmse: 0.1795782595872879
[2m[36m(func pid=46501)[0m mae:  0.13128599524497986
[2m[36m(func pid=46501)[0m rmse_per_class: [0.105, 0.269, 0.091, 0.326, 0.099, 0.194, 0.302, 0.156, 0.14, 0.115]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.17405395209789276
[2m[36m(func pid=46973)[0m mae:  0.12307083606719971
[2m[36m(func pid=46973)[0m rmse_per_class: [0.108, 0.275, 0.078, 0.347, 0.063, 0.192, 0.283, 0.135, 0.167, 0.093]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.18018236756324768
[2m[36m(func pid=34793)[0m mae:  0.13159289956092834
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.1, 0.194, 0.302, 0.149, 0.141, 0.121]
[2m[36m(func pid=34793)[0m 
== Status ==
Current time: 2024-01-07 06:36:37 (running for 00:40:28.79)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.442 |  0.222 |                   69 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.529 |  0.18  |                   59 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.624 |  0.18  |                    7 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.48  |  0.174 |                    6 |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=32597)[0m rmse: 0.22197887301445007
[2m[36m(func pid=32597)[0m mae:  0.12201879918575287
[2m[36m(func pid=32597)[0m rmse_per_class: [0.145, 0.339, 0.048, 0.364, 0.054, 0.201, 0.309, 0.249, 0.201, 0.309]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5684 | Steps: 2 | Val loss: 0.4278 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.5071 | Steps: 2 | Val loss: 0.3751 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.5282 | Steps: 2 | Val loss: 0.4134 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4918 | Steps: 2 | Val loss: 0.7264 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=46501)[0m rmse: 0.1794152557849884
[2m[36m(func pid=46501)[0m mae:  0.13105076551437378
[2m[36m(func pid=46501)[0m rmse_per_class: [0.106, 0.269, 0.092, 0.326, 0.098, 0.194, 0.3, 0.153, 0.14, 0.115]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.17400477826595306
[2m[36m(func pid=46973)[0m mae:  0.12174497544765472
[2m[36m(func pid=46973)[0m rmse_per_class: [0.108, 0.274, 0.07, 0.348, 0.059, 0.191, 0.29, 0.137, 0.17, 0.093]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.1801951825618744
[2m[36m(func pid=34793)[0m mae:  0.13160817325115204
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.092, 0.326, 0.1, 0.194, 0.302, 0.149, 0.141, 0.121]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.2149372547864914
[2m[36m(func pid=32597)[0m mae:  0.1213550940155983
[2m[36m(func pid=32597)[0m rmse_per_class: [0.193, 0.287, 0.049, 0.372, 0.053, 0.203, 0.329, 0.232, 0.166, 0.266]
[2m[36m(func pid=32597)[0m 
== Status ==
Current time: 2024-01-07 06:36:42 (running for 00:40:33.87)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.492 |  0.215 |                   70 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.528 |  0.18  |                   60 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.568 |  0.179 |                    8 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.507 |  0.174 |                    7 |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5246 | Steps: 2 | Val loss: 0.3954 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5147 | Steps: 2 | Val loss: 0.3764 | Batch size: 32 | lr: 0.01 | Duration: 2.68s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.5247 | Steps: 2 | Val loss: 0.4106 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.5243 | Steps: 2 | Val loss: 0.7320 | Batch size: 32 | lr: 0.1 | Duration: 2.68s
[2m[36m(func pid=46501)[0m rmse: 0.179212749004364
[2m[36m(func pid=46501)[0m mae:  0.130803644657135
[2m[36m(func pid=46501)[0m rmse_per_class: [0.107, 0.27, 0.094, 0.327, 0.097, 0.194, 0.298, 0.15, 0.141, 0.115]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.1735723614692688
[2m[36m(func pid=46973)[0m mae:  0.12054544687271118
[2m[36m(func pid=46973)[0m rmse_per_class: [0.108, 0.273, 0.062, 0.347, 0.057, 0.19, 0.293, 0.139, 0.174, 0.092]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.18015488982200623
[2m[36m(func pid=34793)[0m mae:  0.131565660238266
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.092, 0.326, 0.099, 0.194, 0.302, 0.149, 0.141, 0.121]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.20948052406311035
[2m[36m(func pid=32597)[0m mae:  0.11994515359401703
[2m[36m(func pid=32597)[0m rmse_per_class: [0.226, 0.275, 0.049, 0.373, 0.053, 0.187, 0.339, 0.192, 0.155, 0.248]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4899 | Steps: 2 | Val loss: 0.3725 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5049 | Steps: 2 | Val loss: 0.3696 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.5242 | Steps: 2 | Val loss: 0.4084 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.5378 | Steps: 2 | Val loss: 0.7059 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 06:36:51 (running for 00:40:42.76)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.524 |  0.209 |                   71 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.525 |  0.18  |                   61 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.525 |  0.179 |                    9 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.505 |  0.173 |                    9 |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.17259076237678528
[2m[36m(func pid=46973)[0m mae:  0.11919206380844116
[2m[36m(func pid=46973)[0m rmse_per_class: [0.109, 0.271, 0.057, 0.345, 0.056, 0.19, 0.293, 0.141, 0.173, 0.092]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.17903313040733337
[2m[36m(func pid=46501)[0m mae:  0.13056263327598572
[2m[36m(func pid=46501)[0m rmse_per_class: [0.108, 0.27, 0.094, 0.328, 0.096, 0.194, 0.296, 0.148, 0.142, 0.114]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.22313551604747772
[2m[36m(func pid=32597)[0m mae:  0.12551839649677277
[2m[36m(func pid=32597)[0m rmse_per_class: [0.255, 0.281, 0.048, 0.368, 0.063, 0.307, 0.291, 0.184, 0.165, 0.269]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.18006440997123718
[2m[36m(func pid=34793)[0m mae:  0.1315072476863861
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.099, 0.194, 0.301, 0.149, 0.141, 0.121]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4886 | Steps: 2 | Val loss: 0.3557 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4622 | Steps: 2 | Val loss: 0.3555 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4491 | Steps: 2 | Val loss: 0.7305 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.5171 | Steps: 2 | Val loss: 0.4062 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 06:36:56 (running for 00:40:47.92)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.538 |  0.223 |                   72 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.524 |  0.18  |                   62 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.49  |  0.179 |                   10 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.489 |  0.171 |                   10 |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.1711955964565277
[2m[36m(func pid=46973)[0m mae:  0.11804244667291641
[2m[36m(func pid=46973)[0m rmse_per_class: [0.11, 0.268, 0.053, 0.343, 0.055, 0.189, 0.285, 0.142, 0.174, 0.092]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.17871971428394318
[2m[36m(func pid=46501)[0m mae:  0.1302070915699005
[2m[36m(func pid=46501)[0m rmse_per_class: [0.108, 0.27, 0.095, 0.329, 0.095, 0.193, 0.294, 0.146, 0.143, 0.114]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.23056373000144958
[2m[36m(func pid=32597)[0m mae:  0.12783271074295044
[2m[36m(func pid=32597)[0m rmse_per_class: [0.242, 0.284, 0.047, 0.356, 0.099, 0.4, 0.295, 0.162, 0.189, 0.231]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.17996256053447723
[2m[36m(func pid=34793)[0m mae:  0.1314157247543335
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.098, 0.194, 0.301, 0.149, 0.141, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4688 | Steps: 2 | Val loss: 0.3387 | Batch size: 32 | lr: 0.01 | Duration: 2.71s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4484 | Steps: 2 | Val loss: 0.3442 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4044 | Steps: 2 | Val loss: 0.7537 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.5176 | Steps: 2 | Val loss: 0.4038 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 06:37:01 (running for 00:40:52.93)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.449 |  0.231 |                   73 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.517 |  0.18  |                   63 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.462 |  0.179 |                   11 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.469 |  0.169 |                   11 |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.16942699253559113
[2m[36m(func pid=46973)[0m mae:  0.11702308803796768
[2m[36m(func pid=46973)[0m rmse_per_class: [0.113, 0.265, 0.05, 0.34, 0.055, 0.189, 0.274, 0.142, 0.174, 0.092]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.17843769490718842
[2m[36m(func pid=46501)[0m mae:  0.1299281120300293
[2m[36m(func pid=46501)[0m rmse_per_class: [0.109, 0.271, 0.095, 0.33, 0.093, 0.193, 0.292, 0.144, 0.144, 0.114]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.21791386604309082
[2m[36m(func pid=32597)[0m mae:  0.11683668941259384
[2m[36m(func pid=32597)[0m rmse_per_class: [0.232, 0.281, 0.044, 0.345, 0.142, 0.269, 0.339, 0.141, 0.215, 0.171]
[2m[36m(func pid=32597)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.17994925379753113
[2m[36m(func pid=34793)[0m mae:  0.1313902586698532
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.099, 0.194, 0.301, 0.148, 0.141, 0.121]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4448 | Steps: 2 | Val loss: 0.3212 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4341 | Steps: 2 | Val loss: 0.3360 | Batch size: 32 | lr: 0.001 | Duration: 2.67s
[2m[36m(func pid=32597)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.5009 | Steps: 2 | Val loss: 0.7317 | Batch size: 32 | lr: 0.1 | Duration: 2.64s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.5131 | Steps: 2 | Val loss: 0.4018 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 06:37:06 (running for 00:40:58.01)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00019 | RUNNING    | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.404 |  0.218 |                   74 |
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.518 |  0.18  |                   64 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.448 |  0.178 |                   12 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.445 |  0.167 |                   12 |
| train_12613_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.1671743541955948
[2m[36m(func pid=46973)[0m mae:  0.11579789966344833
[2m[36m(func pid=46973)[0m rmse_per_class: [0.113, 0.263, 0.049, 0.334, 0.055, 0.188, 0.262, 0.141, 0.173, 0.092]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.17812657356262207
[2m[36m(func pid=46501)[0m mae:  0.12959396839141846
[2m[36m(func pid=46501)[0m rmse_per_class: [0.109, 0.271, 0.096, 0.331, 0.092, 0.193, 0.29, 0.142, 0.145, 0.113]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=32597)[0m rmse: 0.21320757269859314
[2m[36m(func pid=32597)[0m mae:  0.11993668973445892
[2m[36m(func pid=32597)[0m rmse_per_class: [0.148, 0.278, 0.044, 0.341, 0.126, 0.21, 0.508, 0.155, 0.217, 0.104]
[2m[36m(func pid=34793)[0m rmse: 0.17998334765434265
[2m[36m(func pid=34793)[0m mae:  0.1314222514629364
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.098, 0.194, 0.301, 0.148, 0.141, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4225 | Steps: 2 | Val loss: 0.3057 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4279 | Steps: 2 | Val loss: 0.3311 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=46973)[0m rmse: 0.16437284648418427
[2m[36m(func pid=46973)[0m mae:  0.11441327631473541
[2m[36m(func pid=46973)[0m rmse_per_class: [0.113, 0.26, 0.048, 0.325, 0.055, 0.188, 0.254, 0.14, 0.168, 0.092]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.5135 | Steps: 2 | Val loss: 0.4002 | Batch size: 32 | lr: 0.0001 | Duration: 3.10s
[2m[36m(func pid=46501)[0m rmse: 0.17786358296871185
[2m[36m(func pid=46501)[0m mae:  0.1293155997991562
[2m[36m(func pid=46501)[0m rmse_per_class: [0.11, 0.271, 0.095, 0.332, 0.091, 0.193, 0.288, 0.141, 0.146, 0.112]
[2m[36m(func pid=34793)[0m rmse: 0.179953932762146
[2m[36m(func pid=34793)[0m mae:  0.13141542673110962
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.098, 0.194, 0.301, 0.148, 0.141, 0.122]
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4012 | Steps: 2 | Val loss: 0.2956 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 06:37:12 (running for 00:41:03.14)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.513 |  0.18  |                   65 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.434 |  0.178 |                   13 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.423 |  0.164 |                   13 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=50346)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=50346)[0m Configuration completed!
[2m[36m(func pid=50346)[0m New optimizer parameters:
[2m[36m(func pid=50346)[0m SGD (
[2m[36m(func pid=50346)[0m Parameter Group 0
[2m[36m(func pid=50346)[0m     dampening: 0
[2m[36m(func pid=50346)[0m     differentiable: False
[2m[36m(func pid=50346)[0m     foreach: None
[2m[36m(func pid=50346)[0m     lr: 0.1
[2m[36m(func pid=50346)[0m     maximize: False
[2m[36m(func pid=50346)[0m     momentum: 0.9
[2m[36m(func pid=50346)[0m     nesterov: False
[2m[36m(func pid=50346)[0m     weight_decay: 1e-05
[2m[36m(func pid=50346)[0m )
[2m[36m(func pid=50346)[0m 
== Status ==
Current time: 2024-01-07 06:37:17 (running for 00:41:08.22)
Memory usage on this node: 23.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.513 |  0.18  |                   66 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.428 |  0.178 |                   14 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.401 |  0.162 |                   14 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.16207191348075867
[2m[36m(func pid=46973)[0m mae:  0.11345405876636505
[2m[36m(func pid=46973)[0m rmse_per_class: [0.114, 0.258, 0.048, 0.314, 0.055, 0.187, 0.251, 0.137, 0.162, 0.094]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4240 | Steps: 2 | Val loss: 0.3276 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.5084 | Steps: 2 | Val loss: 0.3983 | Batch size: 32 | lr: 0.0001 | Duration: 3.22s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.3847 | Steps: 2 | Val loss: 0.2913 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.7631 | Steps: 2 | Val loss: 0.3261 | Batch size: 32 | lr: 0.1 | Duration: 4.45s
[2m[36m(func pid=46501)[0m rmse: 0.17750659584999084
[2m[36m(func pid=46501)[0m mae:  0.12900589406490326
[2m[36m(func pid=46501)[0m rmse_per_class: [0.11, 0.271, 0.094, 0.332, 0.089, 0.193, 0.287, 0.14, 0.146, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.16031409800052643
[2m[36m(func pid=46973)[0m mae:  0.11270491778850555
[2m[36m(func pid=46973)[0m rmse_per_class: [0.11, 0.256, 0.047, 0.305, 0.055, 0.186, 0.255, 0.133, 0.156, 0.097]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:37:22 (running for 00:41:13.29)
Memory usage on this node: 24.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.508 |  0.18  |                   67 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.424 |  0.178 |                   15 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.385 |  0.16  |                   15 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=34793)[0m rmse: 0.18003156781196594
[2m[36m(func pid=34793)[0m mae:  0.13144703209400177
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.092, 0.326, 0.098, 0.194, 0.301, 0.149, 0.141, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.17289727926254272
[2m[36m(func pid=50346)[0m mae:  0.12462686002254486
[2m[36m(func pid=50346)[0m rmse_per_class: [0.105, 0.274, 0.088, 0.342, 0.073, 0.191, 0.276, 0.132, 0.15, 0.098]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3738 | Steps: 2 | Val loss: 0.2914 | Batch size: 32 | lr: 0.01 | Duration: 2.60s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.4175 | Steps: 2 | Val loss: 0.3249 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.5043 | Steps: 2 | Val loss: 0.3963 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.5490 | Steps: 2 | Val loss: 0.4452 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=46973)[0m rmse: 0.1596004068851471
[2m[36m(func pid=46973)[0m mae:  0.11277516931295395
[2m[36m(func pid=46973)[0m rmse_per_class: [0.105, 0.255, 0.047, 0.299, 0.055, 0.185, 0.263, 0.129, 0.153, 0.105]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:37:27 (running for 00:41:18.39)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.508 |  0.18  |                   67 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.418 |  0.177 |                   16 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.374 |  0.16  |                   16 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.763 |  0.173 |                    1 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m rmse: 0.17714473605155945
[2m[36m(func pid=46501)[0m mae:  0.1286318153142929
[2m[36m(func pid=46501)[0m rmse_per_class: [0.11, 0.271, 0.093, 0.332, 0.088, 0.194, 0.286, 0.139, 0.146, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.17993302643299103
[2m[36m(func pid=34793)[0m mae:  0.1313616782426834
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.327, 0.098, 0.194, 0.3, 0.149, 0.141, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.18512274324893951
[2m[36m(func pid=50346)[0m mae:  0.12392548471689224
[2m[36m(func pid=50346)[0m rmse_per_class: [0.098, 0.284, 0.062, 0.368, 0.056, 0.188, 0.399, 0.143, 0.159, 0.094]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3637 | Steps: 2 | Val loss: 0.2930 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4175 | Steps: 2 | Val loss: 0.3235 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4975 | Steps: 2 | Val loss: 0.3933 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.7447 | Steps: 2 | Val loss: 0.4797 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=46973)[0m rmse: 0.1597009003162384
[2m[36m(func pid=46973)[0m mae:  0.11334123462438583
[2m[36m(func pid=46973)[0m rmse_per_class: [0.101, 0.254, 0.047, 0.295, 0.055, 0.183, 0.271, 0.126, 0.149, 0.116]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:37:32 (running for 00:41:23.64)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.504 |  0.18  |                   68 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.418 |  0.177 |                   17 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.364 |  0.16  |                   17 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.549 |  0.185 |                    2 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m rmse: 0.17682167887687683
[2m[36m(func pid=46501)[0m mae:  0.12833422422409058
[2m[36m(func pid=46501)[0m rmse_per_class: [0.111, 0.271, 0.092, 0.332, 0.087, 0.193, 0.285, 0.139, 0.147, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.17988839745521545
[2m[36m(func pid=34793)[0m mae:  0.13127663731575012
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.098, 0.194, 0.3, 0.149, 0.141, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.20097586512565613
[2m[36m(func pid=50346)[0m mae:  0.12969133257865906
[2m[36m(func pid=50346)[0m rmse_per_class: [0.098, 0.291, 0.048, 0.379, 0.056, 0.192, 0.54, 0.152, 0.158, 0.096]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3586 | Steps: 2 | Val loss: 0.2938 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4168 | Steps: 2 | Val loss: 0.3225 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.5020 | Steps: 2 | Val loss: 0.3916 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.7340 | Steps: 2 | Val loss: 0.4258 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=46973)[0m rmse: 0.15997442603111267
[2m[36m(func pid=46973)[0m mae:  0.11370321363210678
[2m[36m(func pid=46973)[0m rmse_per_class: [0.096, 0.254, 0.047, 0.291, 0.055, 0.182, 0.275, 0.127, 0.147, 0.127]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:37:38 (running for 00:41:29.08)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.498 |  0.18  |                   69 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.417 |  0.176 |                   18 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.359 |  0.16  |                   18 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.745 |  0.201 |                    3 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m rmse: 0.176470547914505
[2m[36m(func pid=46501)[0m mae:  0.12803660333156586
[2m[36m(func pid=46501)[0m rmse_per_class: [0.111, 0.271, 0.091, 0.332, 0.085, 0.193, 0.284, 0.138, 0.147, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.17988638579845428
[2m[36m(func pid=34793)[0m mae:  0.13127747178077698
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.091, 0.326, 0.097, 0.194, 0.3, 0.149, 0.141, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.19721496105194092
[2m[36m(func pid=50346)[0m mae:  0.12707141041755676
[2m[36m(func pid=50346)[0m rmse_per_class: [0.094, 0.287, 0.048, 0.38, 0.056, 0.183, 0.479, 0.154, 0.196, 0.097]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3556 | Steps: 2 | Val loss: 0.2951 | Batch size: 32 | lr: 0.01 | Duration: 2.71s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.4128 | Steps: 2 | Val loss: 0.3219 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.5008 | Steps: 2 | Val loss: 0.3906 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.5924 | Steps: 2 | Val loss: 0.3503 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=46973)[0m rmse: 0.16137036681175232
[2m[36m(func pid=46973)[0m mae:  0.11462268978357315
[2m[36m(func pid=46973)[0m rmse_per_class: [0.093, 0.255, 0.048, 0.29, 0.055, 0.181, 0.277, 0.134, 0.146, 0.136]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:37:43 (running for 00:41:34.36)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.502 |  0.18  |                   70 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.413 |  0.176 |                   19 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.356 |  0.161 |                   19 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.734 |  0.197 |                    4 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m rmse: 0.17621977627277374
[2m[36m(func pid=46501)[0m mae:  0.12783664464950562
[2m[36m(func pid=46501)[0m rmse_per_class: [0.111, 0.271, 0.09, 0.332, 0.084, 0.193, 0.283, 0.138, 0.147, 0.113]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.179933100938797
[2m[36m(func pid=34793)[0m mae:  0.13131625950336456
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.27, 0.092, 0.327, 0.097, 0.194, 0.3, 0.149, 0.141, 0.121]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.1753222644329071
[2m[36m(func pid=50346)[0m mae:  0.12022656202316284
[2m[36m(func pid=50346)[0m rmse_per_class: [0.09, 0.25, 0.047, 0.355, 0.056, 0.212, 0.232, 0.154, 0.262, 0.096]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3502 | Steps: 2 | Val loss: 0.2954 | Batch size: 32 | lr: 0.01 | Duration: 2.57s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4122 | Steps: 2 | Val loss: 0.3215 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4983 | Steps: 2 | Val loss: 0.3896 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4762 | Steps: 2 | Val loss: 0.3402 | Batch size: 32 | lr: 0.1 | Duration: 2.69s
[2m[36m(func pid=46973)[0m rmse: 0.16227135062217712
[2m[36m(func pid=46973)[0m mae:  0.1150510311126709
[2m[36m(func pid=46973)[0m rmse_per_class: [0.09, 0.256, 0.049, 0.29, 0.056, 0.181, 0.276, 0.144, 0.145, 0.136]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:37:48 (running for 00:41:39.55)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.501 |  0.18  |                   71 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.412 |  0.176 |                   20 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.35  |  0.162 |                   20 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.592 |  0.175 |                    5 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m rmse: 0.17595461010932922
[2m[36m(func pid=46501)[0m mae:  0.1276242434978485
[2m[36m(func pid=46501)[0m rmse_per_class: [0.111, 0.271, 0.089, 0.332, 0.083, 0.193, 0.283, 0.138, 0.148, 0.113]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.16053646802902222
[2m[36m(func pid=50346)[0m mae:  0.11071109771728516
[2m[36m(func pid=50346)[0m rmse_per_class: [0.113, 0.251, 0.043, 0.277, 0.056, 0.188, 0.303, 0.148, 0.138, 0.089]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.17996473610401154
[2m[36m(func pid=34793)[0m mae:  0.13131335377693176
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.27, 0.093, 0.327, 0.097, 0.194, 0.299, 0.149, 0.141, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3460 | Steps: 2 | Val loss: 0.2957 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4062 | Steps: 2 | Val loss: 0.3210 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4437 | Steps: 2 | Val loss: 0.3123 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4970 | Steps: 2 | Val loss: 0.3877 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=46973)[0m rmse: 0.16290399432182312
[2m[36m(func pid=46973)[0m mae:  0.11528758704662323
[2m[36m(func pid=46973)[0m rmse_per_class: [0.088, 0.258, 0.052, 0.293, 0.058, 0.181, 0.272, 0.152, 0.145, 0.13]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:37:53 (running for 00:41:44.79)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.498 |  0.18  |                   72 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.406 |  0.176 |                   21 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.346 |  0.163 |                   21 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.476 |  0.161 |                    6 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m rmse: 0.17556950449943542
[2m[36m(func pid=46501)[0m mae:  0.1272648274898529
[2m[36m(func pid=46501)[0m rmse_per_class: [0.111, 0.271, 0.088, 0.331, 0.082, 0.193, 0.282, 0.138, 0.148, 0.113]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.16588947176933289
[2m[36m(func pid=50346)[0m mae:  0.11087890714406967
[2m[36m(func pid=50346)[0m rmse_per_class: [0.072, 0.269, 0.033, 0.28, 0.056, 0.175, 0.29, 0.114, 0.13, 0.24]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.179803267121315
[2m[36m(func pid=34793)[0m mae:  0.13119284808635712
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.27, 0.092, 0.327, 0.097, 0.194, 0.299, 0.149, 0.141, 0.121]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3376 | Steps: 2 | Val loss: 0.2948 | Batch size: 32 | lr: 0.01 | Duration: 2.71s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4116 | Steps: 2 | Val loss: 0.3205 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.3726 | Steps: 2 | Val loss: 0.3541 | Batch size: 32 | lr: 0.1 | Duration: 2.62s
[2m[36m(func pid=46973)[0m rmse: 0.16225644946098328
[2m[36m(func pid=46973)[0m mae:  0.11463434994220734
[2m[36m(func pid=46973)[0m rmse_per_class: [0.087, 0.257, 0.056, 0.294, 0.061, 0.181, 0.267, 0.153, 0.146, 0.12]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4944 | Steps: 2 | Val loss: 0.3862 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 06:37:59 (running for 00:41:50.21)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.497 |  0.18  |                   73 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.412 |  0.175 |                   22 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.338 |  0.162 |                   22 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.444 |  0.166 |                    7 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m rmse: 0.17524924874305725
[2m[36m(func pid=46501)[0m mae:  0.12703613936901093
[2m[36m(func pid=46501)[0m rmse_per_class: [0.111, 0.271, 0.087, 0.331, 0.081, 0.193, 0.281, 0.137, 0.148, 0.113]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.18969732522964478
[2m[36m(func pid=50346)[0m mae:  0.12485359609127045
[2m[36m(func pid=50346)[0m rmse_per_class: [0.086, 0.286, 0.086, 0.316, 0.054, 0.192, 0.238, 0.382, 0.137, 0.122]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=34793)[0m rmse: 0.1799110770225525
[2m[36m(func pid=34793)[0m mae:  0.13126443326473236
[2m[36m(func pid=34793)[0m rmse_per_class: [0.107, 0.27, 0.093, 0.327, 0.097, 0.194, 0.299, 0.148, 0.141, 0.122]
[2m[36m(func pid=34793)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3362 | Steps: 2 | Val loss: 0.2939 | Batch size: 32 | lr: 0.01 | Duration: 2.68s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4070 | Steps: 2 | Val loss: 0.3200 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.3903 | Steps: 2 | Val loss: 0.3611 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=46973)[0m rmse: 0.161350280046463
[2m[36m(func pid=46973)[0m mae:  0.11384205520153046
[2m[36m(func pid=46973)[0m rmse_per_class: [0.086, 0.256, 0.059, 0.296, 0.066, 0.18, 0.261, 0.147, 0.147, 0.114]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=34793)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4918 | Steps: 2 | Val loss: 0.3851 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 06:38:04 (running for 00:41:55.59)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00020 | RUNNING    | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.494 |  0.18  |                   74 |
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.412 |  0.175 |                   22 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.336 |  0.161 |                   23 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.39  |  0.185 |                    9 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.18496833741664886
[2m[36m(func pid=50346)[0m mae:  0.11968390643596649
[2m[36m(func pid=50346)[0m rmse_per_class: [0.089, 0.278, 0.076, 0.359, 0.09, 0.179, 0.277, 0.227, 0.184, 0.09]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.17494314908981323
[2m[36m(func pid=46501)[0m mae:  0.12682414054870605
[2m[36m(func pid=46501)[0m rmse_per_class: [0.112, 0.27, 0.085, 0.33, 0.08, 0.193, 0.281, 0.137, 0.148, 0.113]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3356 | Steps: 2 | Val loss: 0.2929 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=34793)[0m rmse: 0.1798795759677887
[2m[36m(func pid=34793)[0m mae:  0.1312408745288849
[2m[36m(func pid=34793)[0m rmse_per_class: [0.108, 0.271, 0.092, 0.327, 0.097, 0.194, 0.299, 0.149, 0.141, 0.121]
[2m[36m(func pid=46973)[0m rmse: 0.16014251112937927
[2m[36m(func pid=46973)[0m mae:  0.11274101585149765
[2m[36m(func pid=46973)[0m rmse_per_class: [0.085, 0.255, 0.06, 0.297, 0.073, 0.18, 0.256, 0.14, 0.149, 0.107]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3476 | Steps: 2 | Val loss: 0.3319 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4092 | Steps: 2 | Val loss: 0.3194 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=50346)[0m rmse: 0.1763240396976471
[2m[36m(func pid=50346)[0m mae:  0.11603488773107529
[2m[36m(func pid=50346)[0m rmse_per_class: [0.074, 0.243, 0.031, 0.342, 0.261, 0.181, 0.214, 0.118, 0.205, 0.094]
[2m[36m(func pid=50346)[0m 
== Status ==
Current time: 2024-01-07 06:38:09 (running for 00:42:00.81)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.407 |  0.175 |                   23 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.336 |  0.16  |                   24 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.348 |  0.176 |                   10 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m rmse: 0.17459186911582947
[2m[36m(func pid=46501)[0m mae:  0.1265423595905304
[2m[36m(func pid=46501)[0m rmse_per_class: [0.112, 0.27, 0.085, 0.33, 0.078, 0.193, 0.281, 0.137, 0.148, 0.113]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3334 | Steps: 2 | Val loss: 0.2921 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=46973)[0m rmse: 0.15933279693126678
[2m[36m(func pid=46973)[0m mae:  0.11204642057418823
[2m[36m(func pid=46973)[0m rmse_per_class: [0.085, 0.254, 0.059, 0.299, 0.079, 0.179, 0.251, 0.132, 0.152, 0.103]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3344 | Steps: 2 | Val loss: 0.3089 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4100 | Steps: 2 | Val loss: 0.3192 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 06:38:15 (running for 00:42:06.05)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.409 |  0.175 |                   24 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.333 |  0.159 |                   25 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.334 |  0.165 |                   11 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.1653769314289093
[2m[36m(func pid=50346)[0m mae:  0.10846853256225586
[2m[36m(func pid=50346)[0m rmse_per_class: [0.064, 0.238, 0.035, 0.295, 0.142, 0.215, 0.255, 0.137, 0.179, 0.094]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.17436069250106812
[2m[36m(func pid=46501)[0m mae:  0.1263757050037384
[2m[36m(func pid=46501)[0m rmse_per_class: [0.111, 0.27, 0.084, 0.329, 0.078, 0.193, 0.281, 0.137, 0.148, 0.113]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3250 | Steps: 2 | Val loss: 0.2900 | Batch size: 32 | lr: 0.01 | Duration: 2.71s
[2m[36m(func pid=46973)[0m rmse: 0.1580282747745514
[2m[36m(func pid=46973)[0m mae:  0.1109880581498146
[2m[36m(func pid=46973)[0m rmse_per_class: [0.085, 0.252, 0.056, 0.299, 0.085, 0.178, 0.247, 0.126, 0.152, 0.1]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.3125 | Steps: 2 | Val loss: 0.2715 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4093 | Steps: 2 | Val loss: 0.3187 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 06:38:20 (running for 00:42:11.44)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.41  |  0.174 |                   25 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.325 |  0.158 |                   26 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.313 |  0.145 |                   12 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14507894217967987
[2m[36m(func pid=50346)[0m mae:  0.09155428409576416
[2m[36m(func pid=50346)[0m rmse_per_class: [0.088, 0.222, 0.039, 0.265, 0.059, 0.17, 0.232, 0.13, 0.162, 0.084]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3232 | Steps: 2 | Val loss: 0.2879 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=46501)[0m rmse: 0.17409132421016693
[2m[36m(func pid=46501)[0m mae:  0.12617187201976776
[2m[36m(func pid=46501)[0m rmse_per_class: [0.112, 0.27, 0.083, 0.329, 0.077, 0.193, 0.281, 0.137, 0.148, 0.113]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.1568722426891327
[2m[36m(func pid=46973)[0m mae:  0.11004819720983505
[2m[36m(func pid=46973)[0m rmse_per_class: [0.084, 0.25, 0.053, 0.299, 0.087, 0.177, 0.245, 0.123, 0.151, 0.099]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.2987 | Steps: 2 | Val loss: 0.2695 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4089 | Steps: 2 | Val loss: 0.3186 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3238 | Steps: 2 | Val loss: 0.2862 | Batch size: 32 | lr: 0.01 | Duration: 2.67s
== Status ==
Current time: 2024-01-07 06:38:25 (running for 00:42:16.83)
Memory usage on this node: 21.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.409 |  0.174 |                   26 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.323 |  0.157 |                   27 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.299 |  0.144 |                   13 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.1439553201198578
[2m[36m(func pid=50346)[0m mae:  0.0877099484205246
[2m[36m(func pid=50346)[0m rmse_per_class: [0.079, 0.24, 0.039, 0.269, 0.052, 0.161, 0.211, 0.112, 0.151, 0.126]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.17399534583091736
[2m[36m(func pid=46501)[0m mae:  0.1261119544506073
[2m[36m(func pid=46501)[0m rmse_per_class: [0.111, 0.269, 0.082, 0.329, 0.076, 0.193, 0.28, 0.136, 0.149, 0.113]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.1559789478778839
[2m[36m(func pid=46973)[0m mae:  0.10936696827411652
[2m[36m(func pid=46973)[0m rmse_per_class: [0.084, 0.248, 0.051, 0.299, 0.086, 0.176, 0.244, 0.121, 0.151, 0.099]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.2793 | Steps: 2 | Val loss: 0.2896 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4063 | Steps: 2 | Val loss: 0.3180 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3195 | Steps: 2 | Val loss: 0.2850 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 06:38:31 (running for 00:42:22.16)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.409 |  0.174 |                   27 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.324 |  0.156 |                   28 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.279 |  0.154 |                   14 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.1538417637348175
[2m[36m(func pid=50346)[0m mae:  0.0942947268486023
[2m[36m(func pid=50346)[0m rmse_per_class: [0.061, 0.256, 0.035, 0.25, 0.051, 0.165, 0.22, 0.146, 0.152, 0.201]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.1736801713705063
[2m[36m(func pid=46501)[0m mae:  0.12588311731815338
[2m[36m(func pid=46501)[0m rmse_per_class: [0.111, 0.269, 0.082, 0.328, 0.075, 0.193, 0.28, 0.137, 0.149, 0.113]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.1554780900478363
[2m[36m(func pid=46973)[0m mae:  0.10900362581014633
[2m[36m(func pid=46973)[0m rmse_per_class: [0.084, 0.247, 0.048, 0.298, 0.084, 0.176, 0.245, 0.12, 0.152, 0.101]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.2837 | Steps: 2 | Val loss: 0.3060 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4076 | Steps: 2 | Val loss: 0.3174 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3169 | Steps: 2 | Val loss: 0.2829 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
== Status ==
Current time: 2024-01-07 06:38:36 (running for 00:42:27.53)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.406 |  0.174 |                   28 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.319 |  0.155 |                   29 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.284 |  0.16  |                   15 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.15987901389598846
[2m[36m(func pid=50346)[0m mae:  0.09890488535165787
[2m[36m(func pid=50346)[0m rmse_per_class: [0.061, 0.244, 0.029, 0.277, 0.052, 0.161, 0.231, 0.214, 0.18, 0.15]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.1733463704586029
[2m[36m(func pid=46501)[0m mae:  0.12561817467212677
[2m[36m(func pid=46501)[0m rmse_per_class: [0.111, 0.269, 0.08, 0.327, 0.075, 0.193, 0.28, 0.137, 0.149, 0.113]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.15437591075897217
[2m[36m(func pid=46973)[0m mae:  0.108087457716465
[2m[36m(func pid=46973)[0m rmse_per_class: [0.083, 0.246, 0.046, 0.295, 0.08, 0.175, 0.245, 0.12, 0.151, 0.102]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.2741 | Steps: 2 | Val loss: 0.3030 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4087 | Steps: 2 | Val loss: 0.3168 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3137 | Steps: 2 | Val loss: 0.2809 | Batch size: 32 | lr: 0.01 | Duration: 2.64s
== Status ==
Current time: 2024-01-07 06:38:41 (running for 00:42:32.92)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.408 |  0.173 |                   29 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.317 |  0.154 |                   30 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.274 |  0.155 |                   16 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.15536710619926453
[2m[36m(func pid=50346)[0m mae:  0.09693915396928787
[2m[36m(func pid=50346)[0m rmse_per_class: [0.061, 0.238, 0.028, 0.305, 0.063, 0.193, 0.228, 0.147, 0.209, 0.082]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.17299377918243408
[2m[36m(func pid=46501)[0m mae:  0.12535396218299866
[2m[36m(func pid=46501)[0m rmse_per_class: [0.111, 0.269, 0.079, 0.327, 0.074, 0.193, 0.28, 0.136, 0.15, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.15332111716270447
[2m[36m(func pid=46973)[0m mae:  0.10720910876989365
[2m[36m(func pid=46973)[0m rmse_per_class: [0.083, 0.245, 0.044, 0.29, 0.076, 0.175, 0.247, 0.12, 0.15, 0.103]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.2638 | Steps: 2 | Val loss: 0.2921 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4054 | Steps: 2 | Val loss: 0.3159 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3065 | Steps: 2 | Val loss: 0.2787 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
== Status ==
Current time: 2024-01-07 06:38:47 (running for 00:42:38.35)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.409 |  0.173 |                   30 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.314 |  0.153 |                   31 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.264 |  0.15  |                   17 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.150375634431839
[2m[36m(func pid=50346)[0m mae:  0.09382151812314987
[2m[36m(func pid=50346)[0m rmse_per_class: [0.068, 0.236, 0.027, 0.301, 0.086, 0.187, 0.206, 0.111, 0.198, 0.083]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.1725693643093109
[2m[36m(func pid=46501)[0m mae:  0.1250367909669876
[2m[36m(func pid=46501)[0m rmse_per_class: [0.11, 0.268, 0.078, 0.325, 0.074, 0.193, 0.279, 0.137, 0.15, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.15203599631786346
[2m[36m(func pid=46973)[0m mae:  0.10613536834716797
[2m[36m(func pid=46973)[0m rmse_per_class: [0.081, 0.244, 0.043, 0.285, 0.074, 0.174, 0.248, 0.12, 0.147, 0.104]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.2590 | Steps: 2 | Val loss: 0.2818 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4018 | Steps: 2 | Val loss: 0.3154 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3033 | Steps: 2 | Val loss: 0.2772 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 06:38:52 (running for 00:42:43.90)
Memory usage on this node: 21.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.405 |  0.173 |                   31 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.306 |  0.152 |                   32 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.259 |  0.147 |                   18 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m rmse: 0.17228592932224274
[2m[36m(func pid=46501)[0m mae:  0.12484381347894669
[2m[36m(func pid=46501)[0m rmse_per_class: [0.11, 0.268, 0.077, 0.325, 0.073, 0.192, 0.279, 0.136, 0.149, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.1471889168024063
[2m[36m(func pid=50346)[0m mae:  0.09055940806865692
[2m[36m(func pid=50346)[0m rmse_per_class: [0.088, 0.227, 0.026, 0.277, 0.111, 0.167, 0.2, 0.115, 0.178, 0.083]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.15112744271755219
[2m[36m(func pid=46973)[0m mae:  0.10530165582895279
[2m[36m(func pid=46973)[0m rmse_per_class: [0.08, 0.243, 0.043, 0.28, 0.071, 0.173, 0.249, 0.119, 0.146, 0.106]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.2621 | Steps: 2 | Val loss: 0.2758 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4004 | Steps: 2 | Val loss: 0.3150 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3045 | Steps: 2 | Val loss: 0.2765 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 06:38:58 (running for 00:42:49.21)
Memory usage on this node: 21.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.402 |  0.172 |                   32 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.303 |  0.151 |                   33 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.262 |  0.144 |                   19 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m rmse: 0.17213986814022064
[2m[36m(func pid=46501)[0m mae:  0.12474153935909271
[2m[36m(func pid=46501)[0m rmse_per_class: [0.11, 0.268, 0.076, 0.324, 0.073, 0.192, 0.28, 0.136, 0.15, 0.113]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.14358744025230408
[2m[36m(func pid=50346)[0m mae:  0.08747506886720657
[2m[36m(func pid=50346)[0m rmse_per_class: [0.077, 0.229, 0.025, 0.259, 0.105, 0.164, 0.204, 0.11, 0.18, 0.081]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.1506725251674652
[2m[36m(func pid=46973)[0m mae:  0.10475331544876099
[2m[36m(func pid=46973)[0m rmse_per_class: [0.079, 0.244, 0.042, 0.277, 0.07, 0.173, 0.249, 0.12, 0.146, 0.107]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.2618 | Steps: 2 | Val loss: 0.2802 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4059 | Steps: 2 | Val loss: 0.3145 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3056 | Steps: 2 | Val loss: 0.2767 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 06:39:03 (running for 00:42:54.67)
Memory usage on this node: 21.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.406 |  0.172 |                   34 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.304 |  0.151 |                   34 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.262 |  0.144 |                   19 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m rmse: 0.17189984023571014
[2m[36m(func pid=46501)[0m mae:  0.12452191114425659
[2m[36m(func pid=46501)[0m rmse_per_class: [0.11, 0.268, 0.075, 0.324, 0.072, 0.192, 0.279, 0.137, 0.15, 0.113]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.14639076590538025
[2m[36m(func pid=50346)[0m mae:  0.08906985819339752
[2m[36m(func pid=50346)[0m rmse_per_class: [0.061, 0.24, 0.025, 0.265, 0.085, 0.162, 0.223, 0.116, 0.188, 0.098]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.150705486536026
[2m[36m(func pid=46973)[0m mae:  0.1046566516160965
[2m[36m(func pid=46973)[0m rmse_per_class: [0.079, 0.244, 0.042, 0.277, 0.068, 0.172, 0.248, 0.121, 0.147, 0.109]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4002 | Steps: 2 | Val loss: 0.3139 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.2558 | Steps: 2 | Val loss: 0.2810 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3070 | Steps: 2 | Val loss: 0.2760 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 06:39:08 (running for 00:42:59.98)
Memory usage on this node: 21.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.4   |  0.172 |                   35 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.306 |  0.151 |                   35 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.262 |  0.146 |                   20 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m rmse: 0.17159578204154968
[2m[36m(func pid=46501)[0m mae:  0.12429724633693695
[2m[36m(func pid=46501)[0m rmse_per_class: [0.109, 0.267, 0.074, 0.324, 0.072, 0.192, 0.279, 0.136, 0.149, 0.113]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.14859680831432343
[2m[36m(func pid=50346)[0m mae:  0.09086308628320694
[2m[36m(func pid=50346)[0m rmse_per_class: [0.061, 0.238, 0.028, 0.255, 0.063, 0.165, 0.23, 0.146, 0.183, 0.117]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.15012073516845703
[2m[36m(func pid=46973)[0m mae:  0.10403533279895782
[2m[36m(func pid=46973)[0m rmse_per_class: [0.078, 0.244, 0.041, 0.275, 0.067, 0.173, 0.246, 0.122, 0.146, 0.109]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3975 | Steps: 2 | Val loss: 0.3133 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.2513 | Steps: 2 | Val loss: 0.2838 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3074 | Steps: 2 | Val loss: 0.2756 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 06:39:14 (running for 00:43:05.26)
Memory usage on this node: 22.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.4   |  0.172 |                   35 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.307 |  0.15  |                   36 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.256 |  0.149 |                   21 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m rmse: 0.17125530540943146
[2m[36m(func pid=46501)[0m mae:  0.12404674291610718
[2m[36m(func pid=46501)[0m rmse_per_class: [0.109, 0.267, 0.073, 0.323, 0.071, 0.192, 0.279, 0.137, 0.15, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.14959506690502167
[2m[36m(func pid=46973)[0m mae:  0.10346727073192596
[2m[36m(func pid=46973)[0m rmse_per_class: [0.077, 0.244, 0.041, 0.274, 0.066, 0.172, 0.245, 0.123, 0.147, 0.108]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.1482071578502655
[2m[36m(func pid=50346)[0m mae:  0.09133732318878174
[2m[36m(func pid=50346)[0m rmse_per_class: [0.061, 0.232, 0.032, 0.277, 0.054, 0.167, 0.217, 0.15, 0.178, 0.114]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2945 | Steps: 2 | Val loss: 0.2749 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4025 | Steps: 2 | Val loss: 0.3126 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.2509 | Steps: 2 | Val loss: 0.2846 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 06:39:19 (running for 00:43:10.51)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.397 |  0.171 |                   36 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.307 |  0.15  |                   37 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.251 |  0.148 |                   22 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.14900337159633636
[2m[36m(func pid=46973)[0m mae:  0.10286007076501846
[2m[36m(func pid=46973)[0m rmse_per_class: [0.077, 0.243, 0.041, 0.272, 0.066, 0.172, 0.243, 0.123, 0.146, 0.107]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.17095503211021423
[2m[36m(func pid=46501)[0m mae:  0.12383417040109634
[2m[36m(func pid=46501)[0m rmse_per_class: [0.108, 0.267, 0.072, 0.323, 0.071, 0.192, 0.279, 0.136, 0.15, 0.112]
[2m[36m(func pid=50346)[0m rmse: 0.14568667113780975
[2m[36m(func pid=50346)[0m mae:  0.08949292451143265
[2m[36m(func pid=50346)[0m rmse_per_class: [0.078, 0.232, 0.036, 0.293, 0.053, 0.162, 0.207, 0.117, 0.177, 0.103]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2912 | Steps: 2 | Val loss: 0.2747 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.2493 | Steps: 2 | Val loss: 0.2911 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4015 | Steps: 2 | Val loss: 0.3122 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
== Status ==
Current time: 2024-01-07 06:39:24 (running for 00:43:15.77)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.403 |  0.171 |                   37 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.291 |  0.149 |                   39 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.251 |  0.146 |                   23 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.14873751997947693
[2m[36m(func pid=46973)[0m mae:  0.10254480689764023
[2m[36m(func pid=46973)[0m rmse_per_class: [0.076, 0.243, 0.041, 0.273, 0.065, 0.171, 0.241, 0.124, 0.147, 0.106]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.14715583622455597
[2m[36m(func pid=50346)[0m mae:  0.09016188234090805
[2m[36m(func pid=50346)[0m rmse_per_class: [0.098, 0.233, 0.036, 0.292, 0.057, 0.162, 0.201, 0.109, 0.187, 0.095]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.17074280977249146
[2m[36m(func pid=46501)[0m mae:  0.12364266812801361
[2m[36m(func pid=46501)[0m rmse_per_class: [0.108, 0.267, 0.072, 0.322, 0.07, 0.192, 0.278, 0.136, 0.15, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2988 | Steps: 2 | Val loss: 0.2743 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.2452 | Steps: 2 | Val loss: 0.2927 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3976 | Steps: 2 | Val loss: 0.3119 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 06:39:29 (running for 00:43:20.84)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.401 |  0.171 |                   38 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.299 |  0.148 |                   40 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.249 |  0.147 |                   24 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.14835579693317413
[2m[36m(func pid=46973)[0m mae:  0.10216846317052841
[2m[36m(func pid=46973)[0m rmse_per_class: [0.075, 0.242, 0.041, 0.273, 0.065, 0.171, 0.24, 0.124, 0.147, 0.105]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.14706522226333618
[2m[36m(func pid=50346)[0m mae:  0.08987922221422195
[2m[36m(func pid=50346)[0m rmse_per_class: [0.083, 0.233, 0.033, 0.274, 0.065, 0.176, 0.208, 0.109, 0.197, 0.094]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.17061667144298553
[2m[36m(func pid=46501)[0m mae:  0.12354687601327896
[2m[36m(func pid=46501)[0m rmse_per_class: [0.108, 0.266, 0.072, 0.322, 0.07, 0.192, 0.278, 0.136, 0.15, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2957 | Steps: 2 | Val loss: 0.2743 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.2535 | Steps: 2 | Val loss: 0.2841 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3969 | Steps: 2 | Val loss: 0.3114 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=46973)[0m rmse: 0.14827696979045868
[2m[36m(func pid=46973)[0m mae:  0.102048359811306
[2m[36m(func pid=46973)[0m rmse_per_class: [0.075, 0.242, 0.041, 0.273, 0.065, 0.171, 0.239, 0.123, 0.149, 0.105]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:39:35 (running for 00:43:26.81)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.398 |  0.171 |                   39 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.296 |  0.148 |                   41 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.253 |  0.144 |                   26 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14368577301502228
[2m[36m(func pid=50346)[0m mae:  0.08756144344806671
[2m[36m(func pid=50346)[0m rmse_per_class: [0.066, 0.234, 0.03, 0.261, 0.072, 0.172, 0.206, 0.109, 0.194, 0.092]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.1703716218471527
[2m[36m(func pid=46501)[0m mae:  0.1233736053109169
[2m[36m(func pid=46501)[0m rmse_per_class: [0.108, 0.266, 0.071, 0.322, 0.07, 0.192, 0.278, 0.136, 0.15, 0.111]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2968 | Steps: 2 | Val loss: 0.2749 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.2551 | Steps: 2 | Val loss: 0.2718 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4015 | Steps: 2 | Val loss: 0.3111 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=46973)[0m rmse: 0.14856521785259247
[2m[36m(func pid=46973)[0m mae:  0.10222487151622772
[2m[36m(func pid=46973)[0m rmse_per_class: [0.076, 0.242, 0.041, 0.275, 0.065, 0.171, 0.239, 0.122, 0.152, 0.104]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.1412300169467926
[2m[36m(func pid=50346)[0m mae:  0.08670111000537872
[2m[36m(func pid=50346)[0m rmse_per_class: [0.061, 0.233, 0.027, 0.258, 0.08, 0.166, 0.209, 0.114, 0.175, 0.09]
== Status ==
Current time: 2024-01-07 06:39:40 (running for 00:43:32.03)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.397 |  0.17  |                   40 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.297 |  0.149 |                   42 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.255 |  0.141 |                   27 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.1702798753976822
[2m[36m(func pid=46501)[0m mae:  0.1233198493719101
[2m[36m(func pid=46501)[0m rmse_per_class: [0.108, 0.266, 0.071, 0.322, 0.069, 0.192, 0.278, 0.136, 0.15, 0.111]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2892 | Steps: 2 | Val loss: 0.2742 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.2427 | Steps: 2 | Val loss: 0.2735 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3946 | Steps: 2 | Val loss: 0.3109 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=46973)[0m rmse: 0.14805707335472107
[2m[36m(func pid=46973)[0m mae:  0.1017228364944458
[2m[36m(func pid=46973)[0m rmse_per_class: [0.076, 0.241, 0.04, 0.276, 0.065, 0.17, 0.237, 0.122, 0.151, 0.103]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.1429634988307953
[2m[36m(func pid=50346)[0m mae:  0.08814363181591034
[2m[36m(func pid=50346)[0m rmse_per_class: [0.067, 0.23, 0.025, 0.262, 0.079, 0.165, 0.209, 0.125, 0.163, 0.105]
[2m[36m(func pid=50346)[0m 
== Status ==
Current time: 2024-01-07 06:39:46 (running for 00:43:37.19)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.401 |  0.17  |                   41 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.289 |  0.148 |                   43 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.243 |  0.143 |                   28 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m rmse: 0.1701575368642807
[2m[36m(func pid=46501)[0m mae:  0.12324543297290802
[2m[36m(func pid=46501)[0m rmse_per_class: [0.108, 0.265, 0.07, 0.322, 0.069, 0.192, 0.279, 0.136, 0.15, 0.111]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2935 | Steps: 2 | Val loss: 0.2743 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.2491 | Steps: 2 | Val loss: 0.2795 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3979 | Steps: 2 | Val loss: 0.3104 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=46973)[0m rmse: 0.1481756865978241
[2m[36m(func pid=46973)[0m mae:  0.10173223912715912
[2m[36m(func pid=46973)[0m rmse_per_class: [0.076, 0.241, 0.039, 0.277, 0.067, 0.17, 0.237, 0.121, 0.152, 0.103]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:39:51 (running for 00:43:42.35)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.395 |  0.17  |                   42 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.294 |  0.148 |                   44 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.249 |  0.147 |                   29 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.1465354859828949
[2m[36m(func pid=50346)[0m mae:  0.0907706543803215
[2m[36m(func pid=50346)[0m rmse_per_class: [0.091, 0.229, 0.025, 0.268, 0.069, 0.167, 0.224, 0.124, 0.16, 0.109]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16989891231060028
[2m[36m(func pid=46501)[0m mae:  0.12301937490701675
[2m[36m(func pid=46501)[0m rmse_per_class: [0.108, 0.265, 0.07, 0.321, 0.069, 0.191, 0.278, 0.136, 0.15, 0.111]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2899 | Steps: 2 | Val loss: 0.2740 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.2485 | Steps: 2 | Val loss: 0.2785 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4031 | Steps: 2 | Val loss: 0.3102 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=46973)[0m rmse: 0.147921621799469
[2m[36m(func pid=46973)[0m mae:  0.10144846141338348
[2m[36m(func pid=46973)[0m rmse_per_class: [0.076, 0.24, 0.039, 0.278, 0.067, 0.169, 0.236, 0.12, 0.153, 0.101]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.14405947923660278
[2m[36m(func pid=50346)[0m mae:  0.0891011655330658
[2m[36m(func pid=50346)[0m rmse_per_class: [0.093, 0.23, 0.025, 0.268, 0.058, 0.175, 0.214, 0.113, 0.163, 0.101]
[2m[36m(func pid=50346)[0m 
== Status ==
Current time: 2024-01-07 06:39:56 (running for 00:43:47.79)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.398 |  0.17  |                   43 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.29  |  0.148 |                   45 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.248 |  0.144 |                   30 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m rmse: 0.16984006762504578
[2m[36m(func pid=46501)[0m mae:  0.1229839101433754
[2m[36m(func pid=46501)[0m rmse_per_class: [0.108, 0.265, 0.07, 0.32, 0.069, 0.191, 0.278, 0.136, 0.15, 0.111]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2818 | Steps: 2 | Val loss: 0.2731 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.2460 | Steps: 2 | Val loss: 0.2757 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=46973)[0m rmse: 0.14727067947387695
[2m[36m(func pid=46973)[0m mae:  0.10087740421295166
[2m[36m(func pid=46973)[0m rmse_per_class: [0.076, 0.239, 0.038, 0.278, 0.068, 0.169, 0.235, 0.12, 0.151, 0.098]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3959 | Steps: 2 | Val loss: 0.3098 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 06:40:01 (running for 00:43:52.97)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.403 |  0.17  |                   44 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.282 |  0.147 |                   46 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.246 |  0.141 |                   31 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14113318920135498
[2m[36m(func pid=50346)[0m mae:  0.0866142064332962
[2m[36m(func pid=50346)[0m rmse_per_class: [0.086, 0.231, 0.028, 0.269, 0.054, 0.167, 0.204, 0.109, 0.168, 0.096]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16963572800159454
[2m[36m(func pid=46501)[0m mae:  0.12278664112091064
[2m[36m(func pid=46501)[0m rmse_per_class: [0.107, 0.265, 0.069, 0.32, 0.069, 0.191, 0.278, 0.136, 0.149, 0.111]
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2834 | Steps: 2 | Val loss: 0.2721 | Batch size: 32 | lr: 0.01 | Duration: 2.62s
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.2371 | Steps: 2 | Val loss: 0.2830 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=46973)[0m rmse: 0.1467258781194687
[2m[36m(func pid=46973)[0m mae:  0.10031671822071075
[2m[36m(func pid=46973)[0m rmse_per_class: [0.075, 0.239, 0.038, 0.275, 0.069, 0.169, 0.235, 0.12, 0.151, 0.098]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3912 | Steps: 2 | Val loss: 0.3091 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 06:40:07 (running for 00:43:58.37)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.396 |  0.17  |                   45 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.283 |  0.147 |                   47 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.237 |  0.144 |                   32 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14356885850429535
[2m[36m(func pid=50346)[0m mae:  0.08747962862253189
[2m[36m(func pid=50346)[0m rmse_per_class: [0.068, 0.237, 0.032, 0.268, 0.058, 0.167, 0.209, 0.111, 0.189, 0.097]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2918 | Steps: 2 | Val loss: 0.2719 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=46501)[0m rmse: 0.16931600868701935
[2m[36m(func pid=46501)[0m mae:  0.12248468399047852
[2m[36m(func pid=46501)[0m rmse_per_class: [0.107, 0.265, 0.069, 0.319, 0.069, 0.191, 0.277, 0.135, 0.149, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.2506 | Steps: 2 | Val loss: 0.2873 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=46973)[0m rmse: 0.14666655659675598
[2m[36m(func pid=46973)[0m mae:  0.10014152526855469
[2m[36m(func pid=46973)[0m rmse_per_class: [0.074, 0.24, 0.038, 0.272, 0.069, 0.169, 0.236, 0.119, 0.15, 0.099]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3995 | Steps: 2 | Val loss: 0.3087 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 06:40:12 (running for 00:44:03.66)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.391 |  0.169 |                   46 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.292 |  0.147 |                   48 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.251 |  0.146 |                   33 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.1461077630519867
[2m[36m(func pid=50346)[0m mae:  0.08886867761611938
[2m[36m(func pid=50346)[0m rmse_per_class: [0.065, 0.238, 0.034, 0.264, 0.064, 0.167, 0.207, 0.118, 0.206, 0.099]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2875 | Steps: 2 | Val loss: 0.2726 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=46501)[0m rmse: 0.16908738017082214
[2m[36m(func pid=46501)[0m mae:  0.12227823585271835
[2m[36m(func pid=46501)[0m rmse_per_class: [0.107, 0.265, 0.069, 0.318, 0.068, 0.191, 0.277, 0.136, 0.148, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2432 | Steps: 2 | Val loss: 0.2821 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=46973)[0m rmse: 0.14704041182994843
[2m[36m(func pid=46973)[0m mae:  0.10031535476446152
[2m[36m(func pid=46973)[0m rmse_per_class: [0.074, 0.24, 0.037, 0.272, 0.069, 0.169, 0.236, 0.119, 0.153, 0.1]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3942 | Steps: 2 | Val loss: 0.3085 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 06:40:17 (running for 00:44:08.91)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.399 |  0.169 |                   47 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.287 |  0.147 |                   49 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.243 |  0.147 |                   34 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14666993916034698
[2m[36m(func pid=50346)[0m mae:  0.08982539921998978
[2m[36m(func pid=50346)[0m rmse_per_class: [0.069, 0.233, 0.036, 0.268, 0.07, 0.169, 0.212, 0.117, 0.198, 0.094]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2805 | Steps: 2 | Val loss: 0.2724 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=46501)[0m rmse: 0.16902218759059906
[2m[36m(func pid=46501)[0m mae:  0.12224242836236954
[2m[36m(func pid=46501)[0m rmse_per_class: [0.107, 0.265, 0.069, 0.318, 0.068, 0.191, 0.277, 0.135, 0.148, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2400 | Steps: 2 | Val loss: 0.2743 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=46973)[0m rmse: 0.14685072004795074
[2m[36m(func pid=46973)[0m mae:  0.100088931620121
[2m[36m(func pid=46973)[0m rmse_per_class: [0.074, 0.24, 0.037, 0.271, 0.07, 0.168, 0.236, 0.119, 0.154, 0.1]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3915 | Steps: 2 | Val loss: 0.3082 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 06:40:23 (running for 00:44:14.04)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.394 |  0.169 |                   48 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.281 |  0.147 |                   50 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.24  |  0.144 |                   35 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14439192414283752
[2m[36m(func pid=50346)[0m mae:  0.0891348347067833
[2m[36m(func pid=50346)[0m rmse_per_class: [0.079, 0.232, 0.035, 0.267, 0.07, 0.168, 0.217, 0.109, 0.176, 0.092]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2843 | Steps: 2 | Val loss: 0.2725 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=46501)[0m rmse: 0.1688685566186905
[2m[36m(func pid=46501)[0m mae:  0.12208584696054459
[2m[36m(func pid=46501)[0m rmse_per_class: [0.106, 0.265, 0.068, 0.318, 0.069, 0.191, 0.276, 0.135, 0.148, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2471 | Steps: 2 | Val loss: 0.2695 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=46973)[0m rmse: 0.1469457447528839
[2m[36m(func pid=46973)[0m mae:  0.10011136531829834
[2m[36m(func pid=46973)[0m rmse_per_class: [0.073, 0.24, 0.037, 0.272, 0.071, 0.168, 0.236, 0.119, 0.154, 0.1]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3935 | Steps: 2 | Val loss: 0.3079 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 06:40:28 (running for 00:44:19.30)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.392 |  0.169 |                   49 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.284 |  0.147 |                   51 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.247 |  0.142 |                   36 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.1419776827096939
[2m[36m(func pid=50346)[0m mae:  0.08729220926761627
[2m[36m(func pid=50346)[0m rmse_per_class: [0.082, 0.228, 0.031, 0.263, 0.074, 0.166, 0.207, 0.108, 0.166, 0.094]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2845 | Steps: 2 | Val loss: 0.2724 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=46501)[0m rmse: 0.1687288135290146
[2m[36m(func pid=46501)[0m mae:  0.12196822464466095
[2m[36m(func pid=46501)[0m rmse_per_class: [0.106, 0.265, 0.068, 0.318, 0.069, 0.191, 0.276, 0.135, 0.148, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2471 | Steps: 2 | Val loss: 0.2767 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=46973)[0m rmse: 0.1467944085597992
[2m[36m(func pid=46973)[0m mae:  0.0999339371919632
[2m[36m(func pid=46973)[0m rmse_per_class: [0.073, 0.24, 0.037, 0.271, 0.071, 0.168, 0.235, 0.119, 0.154, 0.1]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3923 | Steps: 2 | Val loss: 0.3078 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 06:40:33 (running for 00:44:24.74)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.393 |  0.169 |                   50 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.285 |  0.147 |                   52 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.247 |  0.143 |                   37 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14334838092327118
[2m[36m(func pid=50346)[0m mae:  0.08749036490917206
[2m[36m(func pid=50346)[0m rmse_per_class: [0.071, 0.238, 0.027, 0.262, 0.074, 0.165, 0.21, 0.113, 0.171, 0.103]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2823 | Steps: 2 | Val loss: 0.2719 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=46501)[0m rmse: 0.16864636540412903
[2m[36m(func pid=46501)[0m mae:  0.12190362066030502
[2m[36m(func pid=46501)[0m rmse_per_class: [0.106, 0.265, 0.067, 0.318, 0.069, 0.191, 0.276, 0.136, 0.148, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2460 | Steps: 2 | Val loss: 0.2946 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=46973)[0m rmse: 0.1463312804698944
[2m[36m(func pid=46973)[0m mae:  0.09955557435750961
[2m[36m(func pid=46973)[0m rmse_per_class: [0.072, 0.239, 0.037, 0.271, 0.071, 0.168, 0.235, 0.119, 0.152, 0.1]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3914 | Steps: 2 | Val loss: 0.3077 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=50346)[0m rmse: 0.14949098229408264
[2m[36m(func pid=50346)[0m mae:  0.09179304540157318
[2m[36m(func pid=50346)[0m rmse_per_class: [0.067, 0.247, 0.026, 0.272, 0.07, 0.168, 0.216, 0.142, 0.18, 0.108]
[2m[36m(func pid=50346)[0m 
== Status ==
Current time: 2024-01-07 06:40:39 (running for 00:44:30.04)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.392 |  0.169 |                   51 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.282 |  0.146 |                   53 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.246 |  0.149 |                   38 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2752 | Steps: 2 | Val loss: 0.2719 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=46501)[0m rmse: 0.16860249638557434
[2m[36m(func pid=46501)[0m mae:  0.12187401205301285
[2m[36m(func pid=46501)[0m rmse_per_class: [0.106, 0.265, 0.067, 0.318, 0.069, 0.19, 0.276, 0.135, 0.148, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2515 | Steps: 2 | Val loss: 0.2990 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=46973)[0m rmse: 0.1462448388338089
[2m[36m(func pid=46973)[0m mae:  0.09946666657924652
[2m[36m(func pid=46973)[0m rmse_per_class: [0.072, 0.237, 0.036, 0.272, 0.072, 0.168, 0.235, 0.12, 0.151, 0.1]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3935 | Steps: 2 | Val loss: 0.3075 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 06:40:44 (running for 00:44:35.25)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.391 |  0.169 |                   52 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.275 |  0.146 |                   54 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.252 |  0.149 |                   39 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14931324124336243
[2m[36m(func pid=50346)[0m mae:  0.09177020192146301
[2m[36m(func pid=50346)[0m rmse_per_class: [0.077, 0.237, 0.026, 0.278, 0.063, 0.17, 0.214, 0.138, 0.186, 0.104]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2776 | Steps: 2 | Val loss: 0.2724 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=46501)[0m rmse: 0.16855737566947937
[2m[36m(func pid=46501)[0m mae:  0.12182971090078354
[2m[36m(func pid=46501)[0m rmse_per_class: [0.106, 0.265, 0.067, 0.318, 0.069, 0.19, 0.276, 0.135, 0.148, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2382 | Steps: 2 | Val loss: 0.2877 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=46973)[0m rmse: 0.14637675881385803
[2m[36m(func pid=46973)[0m mae:  0.09945641458034515
[2m[36m(func pid=46973)[0m rmse_per_class: [0.072, 0.237, 0.036, 0.274, 0.071, 0.168, 0.233, 0.12, 0.152, 0.101]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3928 | Steps: 2 | Val loss: 0.3075 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 06:40:49 (running for 00:44:40.55)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.394 |  0.169 |                   53 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.278 |  0.146 |                   55 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.238 |  0.146 |                   40 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14635363221168518
[2m[36m(func pid=50346)[0m mae:  0.09051595628261566
[2m[36m(func pid=50346)[0m rmse_per_class: [0.097, 0.236, 0.03, 0.283, 0.057, 0.172, 0.212, 0.11, 0.175, 0.091]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2752 | Steps: 2 | Val loss: 0.2723 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=46501)[0m rmse: 0.16852344572544098
[2m[36m(func pid=46501)[0m mae:  0.12179423868656158
[2m[36m(func pid=46501)[0m rmse_per_class: [0.106, 0.265, 0.067, 0.318, 0.069, 0.19, 0.276, 0.135, 0.148, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2423 | Steps: 2 | Val loss: 0.2770 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=46973)[0m rmse: 0.14628443121910095
[2m[36m(func pid=46973)[0m mae:  0.09935088455677032
[2m[36m(func pid=46973)[0m rmse_per_class: [0.072, 0.237, 0.036, 0.274, 0.07, 0.167, 0.233, 0.119, 0.153, 0.101]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:40:54 (running for 00:44:45.66)
Memory usage on this node: 21.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.393 |  0.169 |                   54 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.275 |  0.146 |                   56 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.242 |  0.143 |                   41 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3871 | Steps: 2 | Val loss: 0.3073 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=50346)[0m rmse: 0.14331719279289246
[2m[36m(func pid=50346)[0m mae:  0.08856064081192017
[2m[36m(func pid=50346)[0m rmse_per_class: [0.087, 0.236, 0.033, 0.28, 0.057, 0.167, 0.205, 0.109, 0.17, 0.091]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2745 | Steps: 2 | Val loss: 0.2726 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=46501)[0m rmse: 0.1683937907218933
[2m[36m(func pid=46501)[0m mae:  0.12165360152721405
[2m[36m(func pid=46501)[0m rmse_per_class: [0.106, 0.265, 0.066, 0.318, 0.069, 0.19, 0.275, 0.135, 0.148, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2419 | Steps: 2 | Val loss: 0.2745 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=46973)[0m rmse: 0.14634601771831512
[2m[36m(func pid=46973)[0m mae:  0.099242202937603
[2m[36m(func pid=46973)[0m rmse_per_class: [0.072, 0.237, 0.036, 0.274, 0.07, 0.167, 0.233, 0.12, 0.153, 0.102]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:40:59 (running for 00:44:50.95)
Memory usage on this node: 21.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.387 |  0.168 |                   55 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.275 |  0.146 |                   57 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.242 |  0.142 |                   42 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3902 | Steps: 2 | Val loss: 0.3069 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=50346)[0m rmse: 0.14237725734710693
[2m[36m(func pid=50346)[0m mae:  0.08712907135486603
[2m[36m(func pid=50346)[0m rmse_per_class: [0.069, 0.232, 0.031, 0.269, 0.06, 0.164, 0.208, 0.109, 0.179, 0.103]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2789 | Steps: 2 | Val loss: 0.2732 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=46501)[0m rmse: 0.16820278763771057
[2m[36m(func pid=46501)[0m mae:  0.12145619094371796
[2m[36m(func pid=46501)[0m rmse_per_class: [0.106, 0.264, 0.066, 0.317, 0.069, 0.19, 0.274, 0.135, 0.148, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2412 | Steps: 2 | Val loss: 0.2824 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=46973)[0m rmse: 0.14668476581573486
[2m[36m(func pid=46973)[0m mae:  0.09934627264738083
[2m[36m(func pid=46973)[0m rmse_per_class: [0.072, 0.237, 0.035, 0.276, 0.07, 0.167, 0.232, 0.12, 0.155, 0.102]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:41:05 (running for 00:44:56.34)
Memory usage on this node: 21.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.39  |  0.168 |                   56 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.279 |  0.147 |                   58 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.241 |  0.147 |                   43 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3889 | Steps: 2 | Val loss: 0.3069 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=50346)[0m rmse: 0.14713987708091736
[2m[36m(func pid=50346)[0m mae:  0.09009470045566559
[2m[36m(func pid=50346)[0m rmse_per_class: [0.066, 0.241, 0.028, 0.263, 0.07, 0.168, 0.212, 0.117, 0.192, 0.115]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2784 | Steps: 2 | Val loss: 0.2730 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=46501)[0m rmse: 0.16816267371177673
[2m[36m(func pid=46501)[0m mae:  0.12143339961767197
[2m[36m(func pid=46501)[0m rmse_per_class: [0.105, 0.264, 0.066, 0.317, 0.069, 0.19, 0.274, 0.135, 0.148, 0.111]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.14668984711170197
[2m[36m(func pid=46973)[0m mae:  0.09924063086509705
[2m[36m(func pid=46973)[0m rmse_per_class: [0.072, 0.237, 0.035, 0.275, 0.069, 0.167, 0.232, 0.12, 0.159, 0.101]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2363 | Steps: 2 | Val loss: 0.2921 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3915 | Steps: 2 | Val loss: 0.3067 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2720 | Steps: 2 | Val loss: 0.2729 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 06:41:11 (running for 00:45:02.10)
Memory usage on this node: 21.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.389 |  0.168 |                   57 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.278 |  0.147 |                   59 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.236 |  0.154 |                   44 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.15362301468849182
[2m[36m(func pid=50346)[0m mae:  0.09396001696586609
[2m[36m(func pid=50346)[0m rmse_per_class: [0.075, 0.246, 0.028, 0.263, 0.077, 0.173, 0.23, 0.131, 0.198, 0.116]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.14668214321136475
[2m[36m(func pid=46973)[0m mae:  0.09914771467447281
[2m[36m(func pid=46973)[0m rmse_per_class: [0.072, 0.237, 0.035, 0.275, 0.069, 0.167, 0.232, 0.119, 0.16, 0.101]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16808775067329407
[2m[36m(func pid=46501)[0m mae:  0.12137766182422638
[2m[36m(func pid=46501)[0m rmse_per_class: [0.105, 0.264, 0.066, 0.317, 0.069, 0.19, 0.274, 0.135, 0.148, 0.111]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2370 | Steps: 2 | Val loss: 0.2864 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2788 | Steps: 2 | Val loss: 0.2719 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3856 | Steps: 2 | Val loss: 0.3065 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 06:41:16 (running for 00:45:07.49)
Memory usage on this node: 21.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.391 |  0.168 |                   58 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.272 |  0.147 |                   60 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.237 |  0.15  |                   45 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14970055222511292
[2m[36m(func pid=50346)[0m mae:  0.09151388704776764
[2m[36m(func pid=50346)[0m rmse_per_class: [0.087, 0.241, 0.03, 0.264, 0.072, 0.167, 0.217, 0.121, 0.192, 0.106]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.14621701836585999
[2m[36m(func pid=46973)[0m mae:  0.09869780391454697
[2m[36m(func pid=46973)[0m rmse_per_class: [0.072, 0.237, 0.035, 0.272, 0.068, 0.167, 0.232, 0.119, 0.161, 0.099]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16798345744609833
[2m[36m(func pid=46501)[0m mae:  0.12129757553339005
[2m[36m(func pid=46501)[0m rmse_per_class: [0.105, 0.264, 0.065, 0.318, 0.069, 0.19, 0.274, 0.135, 0.148, 0.111]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2446 | Steps: 2 | Val loss: 0.2798 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2800 | Steps: 2 | Val loss: 0.2714 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3904 | Steps: 2 | Val loss: 0.3060 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=50346)[0m rmse: 0.14454928040504456
[2m[36m(func pid=50346)[0m mae:  0.08858498930931091
[2m[36m(func pid=50346)[0m rmse_per_class: [0.08, 0.235, 0.032, 0.275, 0.062, 0.164, 0.206, 0.112, 0.181, 0.097]
== Status ==
Current time: 2024-01-07 06:41:21 (running for 00:45:12.66)
Memory usage on this node: 21.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.386 |  0.168 |                   59 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.279 |  0.146 |                   61 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.245 |  0.145 |                   46 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.14586105942726135
[2m[36m(func pid=46973)[0m mae:  0.09840156137943268
[2m[36m(func pid=46973)[0m rmse_per_class: [0.072, 0.237, 0.035, 0.27, 0.068, 0.166, 0.231, 0.119, 0.162, 0.098]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16772088408470154
[2m[36m(func pid=46501)[0m mae:  0.12107408046722412
[2m[36m(func pid=46501)[0m rmse_per_class: [0.105, 0.264, 0.065, 0.317, 0.069, 0.19, 0.274, 0.135, 0.148, 0.111]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2352 | Steps: 2 | Val loss: 0.2787 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2704 | Steps: 2 | Val loss: 0.2708 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3835 | Steps: 2 | Val loss: 0.3058 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 06:41:27 (running for 00:45:18.26)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.39  |  0.168 |                   60 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.28  |  0.146 |                   62 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.235 |  0.143 |                   47 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14338284730911255
[2m[36m(func pid=50346)[0m mae:  0.08857479691505432
[2m[36m(func pid=50346)[0m rmse_per_class: [0.077, 0.239, 0.033, 0.285, 0.056, 0.165, 0.206, 0.109, 0.171, 0.091]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.1454954892396927
[2m[36m(func pid=46973)[0m mae:  0.09812738746404648
[2m[36m(func pid=46973)[0m rmse_per_class: [0.072, 0.237, 0.035, 0.269, 0.069, 0.166, 0.231, 0.119, 0.16, 0.097]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16763001680374146
[2m[36m(func pid=46501)[0m mae:  0.12098175287246704
[2m[36m(func pid=46501)[0m rmse_per_class: [0.105, 0.264, 0.065, 0.316, 0.069, 0.19, 0.273, 0.135, 0.148, 0.111]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2455 | Steps: 2 | Val loss: 0.2809 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2687 | Steps: 2 | Val loss: 0.2703 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3882 | Steps: 2 | Val loss: 0.3056 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 06:41:32 (running for 00:45:23.69)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.384 |  0.168 |                   61 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.27  |  0.145 |                   63 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.245 |  0.144 |                   48 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14447256922721863
[2m[36m(func pid=50346)[0m mae:  0.08917097747325897
[2m[36m(func pid=50346)[0m rmse_per_class: [0.082, 0.236, 0.033, 0.279, 0.056, 0.169, 0.212, 0.112, 0.168, 0.097]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.14501409232616425
[2m[36m(func pid=46973)[0m mae:  0.0976334735751152
[2m[36m(func pid=46973)[0m rmse_per_class: [0.071, 0.237, 0.035, 0.269, 0.069, 0.166, 0.23, 0.119, 0.159, 0.096]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16752275824546814
[2m[36m(func pid=46501)[0m mae:  0.1209128275513649
[2m[36m(func pid=46501)[0m rmse_per_class: [0.105, 0.264, 0.064, 0.316, 0.069, 0.19, 0.273, 0.135, 0.148, 0.111]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2442 | Steps: 2 | Val loss: 0.2839 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2707 | Steps: 2 | Val loss: 0.2700 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3851 | Steps: 2 | Val loss: 0.3056 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 06:41:37 (running for 00:45:28.98)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.388 |  0.168 |                   62 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.269 |  0.145 |                   64 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.244 |  0.147 |                   49 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14671817421913147
[2m[36m(func pid=50346)[0m mae:  0.08996710181236267
[2m[36m(func pid=50346)[0m rmse_per_class: [0.096, 0.236, 0.031, 0.269, 0.06, 0.169, 0.213, 0.115, 0.174, 0.104]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.14470656216144562
[2m[36m(func pid=46973)[0m mae:  0.09735018759965897
[2m[36m(func pid=46973)[0m rmse_per_class: [0.071, 0.237, 0.034, 0.268, 0.068, 0.166, 0.229, 0.119, 0.159, 0.096]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.167520672082901
[2m[36m(func pid=46501)[0m mae:  0.12092308700084686
[2m[36m(func pid=46501)[0m rmse_per_class: [0.105, 0.264, 0.064, 0.317, 0.069, 0.19, 0.273, 0.135, 0.148, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2397 | Steps: 2 | Val loss: 0.2838 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2666 | Steps: 2 | Val loss: 0.2703 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3900 | Steps: 2 | Val loss: 0.3055 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 06:41:43 (running for 00:45:34.27)
Memory usage on this node: 21.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.385 |  0.168 |                   63 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.271 |  0.145 |                   65 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.24  |  0.148 |                   50 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14750179648399353
[2m[36m(func pid=50346)[0m mae:  0.09043008089065552
[2m[36m(func pid=50346)[0m rmse_per_class: [0.09, 0.239, 0.03, 0.273, 0.065, 0.168, 0.209, 0.115, 0.181, 0.105]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.1447795331478119
[2m[36m(func pid=46973)[0m mae:  0.09730739891529083
[2m[36m(func pid=46973)[0m rmse_per_class: [0.071, 0.236, 0.034, 0.27, 0.069, 0.166, 0.229, 0.119, 0.158, 0.096]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.1674632579088211
[2m[36m(func pid=46501)[0m mae:  0.12087388336658478
[2m[36m(func pid=46501)[0m rmse_per_class: [0.105, 0.263, 0.064, 0.317, 0.069, 0.189, 0.273, 0.135, 0.148, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2375 | Steps: 2 | Val loss: 0.2867 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2748 | Steps: 2 | Val loss: 0.2702 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3869 | Steps: 2 | Val loss: 0.3054 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 06:41:48 (running for 00:45:39.65)
Memory usage on this node: 21.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.39  |  0.167 |                   64 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.267 |  0.145 |                   66 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.238 |  0.148 |                   51 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14832696318626404
[2m[36m(func pid=50346)[0m mae:  0.09132891148328781
[2m[36m(func pid=50346)[0m rmse_per_class: [0.071, 0.239, 0.029, 0.283, 0.068, 0.17, 0.209, 0.115, 0.19, 0.109]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.1445702314376831
[2m[36m(func pid=46973)[0m mae:  0.09702788293361664
[2m[36m(func pid=46973)[0m rmse_per_class: [0.07, 0.236, 0.034, 0.269, 0.07, 0.166, 0.228, 0.121, 0.157, 0.095]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.1673891395330429
[2m[36m(func pid=46501)[0m mae:  0.12080259621143341
[2m[36m(func pid=46501)[0m rmse_per_class: [0.105, 0.264, 0.064, 0.316, 0.069, 0.19, 0.273, 0.135, 0.147, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2438 | Steps: 2 | Val loss: 0.2829 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2825 | Steps: 2 | Val loss: 0.2702 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3865 | Steps: 2 | Val loss: 0.3055 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=50346)[0m rmse: 0.14689604938030243
[2m[36m(func pid=50346)[0m mae:  0.09042217582464218
[2m[36m(func pid=50346)[0m rmse_per_class: [0.072, 0.236, 0.028, 0.277, 0.069, 0.168, 0.21, 0.117, 0.185, 0.107]
[2m[36m(func pid=50346)[0m 
== Status ==
Current time: 2024-01-07 06:41:54 (running for 00:45:45.18)
Memory usage on this node: 21.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.387 |  0.167 |                   65 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.275 |  0.145 |                   67 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.244 |  0.147 |                   52 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.14449167251586914
[2m[36m(func pid=46973)[0m mae:  0.0969429686665535
[2m[36m(func pid=46973)[0m rmse_per_class: [0.07, 0.237, 0.034, 0.269, 0.07, 0.166, 0.227, 0.121, 0.154, 0.097]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16743949055671692
[2m[36m(func pid=46501)[0m mae:  0.12086465209722519
[2m[36m(func pid=46501)[0m rmse_per_class: [0.105, 0.264, 0.065, 0.316, 0.069, 0.19, 0.273, 0.135, 0.147, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2412 | Steps: 2 | Val loss: 0.2812 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2683 | Steps: 2 | Val loss: 0.2709 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3854 | Steps: 2 | Val loss: 0.3051 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 06:41:59 (running for 00:45:50.45)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.387 |  0.167 |                   66 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.282 |  0.144 |                   68 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.241 |  0.146 |                   53 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.1456262767314911
[2m[36m(func pid=50346)[0m mae:  0.08972776681184769
[2m[36m(func pid=50346)[0m rmse_per_class: [0.083, 0.235, 0.028, 0.274, 0.065, 0.166, 0.211, 0.116, 0.177, 0.103]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.1448543816804886
[2m[36m(func pid=46973)[0m mae:  0.09726206958293915
[2m[36m(func pid=46973)[0m rmse_per_class: [0.071, 0.237, 0.034, 0.27, 0.07, 0.166, 0.227, 0.12, 0.158, 0.097]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16724327206611633
[2m[36m(func pid=46501)[0m mae:  0.12067679315805435
[2m[36m(func pid=46501)[0m rmse_per_class: [0.104, 0.263, 0.064, 0.316, 0.069, 0.189, 0.273, 0.135, 0.146, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2702 | Steps: 2 | Val loss: 0.2713 | Batch size: 32 | lr: 0.01 | Duration: 2.59s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2372 | Steps: 2 | Val loss: 0.2803 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3852 | Steps: 2 | Val loss: 0.3047 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 06:42:04 (running for 00:45:55.88)
Memory usage on this node: 21.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.385 |  0.167 |                   67 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.27  |  0.145 |                   70 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.241 |  0.146 |                   53 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.14513254165649414
[2m[36m(func pid=46973)[0m mae:  0.09744603931903839
[2m[36m(func pid=46973)[0m rmse_per_class: [0.071, 0.237, 0.034, 0.27, 0.071, 0.166, 0.228, 0.119, 0.16, 0.097]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.14360040426254272
[2m[36m(func pid=50346)[0m mae:  0.0882728323340416
[2m[36m(func pid=50346)[0m rmse_per_class: [0.09, 0.234, 0.029, 0.273, 0.058, 0.164, 0.208, 0.116, 0.166, 0.098]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.1670387089252472
[2m[36m(func pid=46501)[0m mae:  0.12048713862895966
[2m[36m(func pid=46501)[0m rmse_per_class: [0.104, 0.263, 0.064, 0.315, 0.069, 0.189, 0.273, 0.135, 0.146, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2677 | Steps: 2 | Val loss: 0.2712 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2388 | Steps: 2 | Val loss: 0.2813 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3798 | Steps: 2 | Val loss: 0.3045 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 06:42:09 (running for 00:46:00.95)
Memory usage on this node: 21.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.385 |  0.167 |                   68 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.268 |  0.145 |                   71 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.237 |  0.144 |                   54 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.14518378674983978
[2m[36m(func pid=46973)[0m mae:  0.0973941832780838
[2m[36m(func pid=46973)[0m rmse_per_class: [0.071, 0.237, 0.034, 0.269, 0.07, 0.166, 0.227, 0.119, 0.162, 0.097]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.14327162504196167
[2m[36m(func pid=50346)[0m mae:  0.08768731355667114
[2m[36m(func pid=50346)[0m rmse_per_class: [0.088, 0.234, 0.031, 0.275, 0.054, 0.164, 0.207, 0.116, 0.167, 0.097]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16695331037044525
[2m[36m(func pid=46501)[0m mae:  0.1203794926404953
[2m[36m(func pid=46501)[0m rmse_per_class: [0.104, 0.263, 0.063, 0.315, 0.069, 0.189, 0.272, 0.135, 0.146, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2694 | Steps: 2 | Val loss: 0.2708 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2452 | Steps: 2 | Val loss: 0.2798 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=46973)[0m rmse: 0.14487777650356293
[2m[36m(func pid=46973)[0m mae:  0.09702473878860474
[2m[36m(func pid=46973)[0m rmse_per_class: [0.071, 0.238, 0.034, 0.267, 0.07, 0.165, 0.226, 0.119, 0.162, 0.098]
== Status ==
Current time: 2024-01-07 06:42:15 (running for 00:46:06.16)
Memory usage on this node: 21.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.38  |  0.167 |                   69 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.269 |  0.145 |                   72 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.239 |  0.143 |                   55 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3781 | Steps: 2 | Val loss: 0.3044 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.14330731332302094
[2m[36m(func pid=50346)[0m mae:  0.08785657584667206
[2m[36m(func pid=50346)[0m rmse_per_class: [0.074, 0.233, 0.031, 0.271, 0.054, 0.171, 0.21, 0.122, 0.171, 0.096]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16689065098762512
[2m[36m(func pid=46501)[0m mae:  0.12034334987401962
[2m[36m(func pid=46501)[0m rmse_per_class: [0.104, 0.262, 0.063, 0.315, 0.068, 0.189, 0.273, 0.135, 0.146, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2691 | Steps: 2 | Val loss: 0.2698 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2454 | Steps: 2 | Val loss: 0.2780 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3805 | Steps: 2 | Val loss: 0.3042 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=46973)[0m rmse: 0.14438313245773315
[2m[36m(func pid=46973)[0m mae:  0.09658948332071304
[2m[36m(func pid=46973)[0m rmse_per_class: [0.07, 0.237, 0.034, 0.265, 0.069, 0.165, 0.226, 0.118, 0.162, 0.097]
== Status ==
Current time: 2024-01-07 06:42:20 (running for 00:46:11.43)
Memory usage on this node: 21.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.378 |  0.167 |                   70 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.269 |  0.144 |                   73 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.245 |  0.143 |                   56 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.14436721801757812
[2m[36m(func pid=50346)[0m mae:  0.08844710141420364
[2m[36m(func pid=50346)[0m rmse_per_class: [0.067, 0.233, 0.031, 0.264, 0.06, 0.172, 0.215, 0.116, 0.181, 0.106]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16680100560188293
[2m[36m(func pid=46501)[0m mae:  0.1202741414308548
[2m[36m(func pid=46501)[0m rmse_per_class: [0.104, 0.262, 0.063, 0.316, 0.069, 0.189, 0.273, 0.135, 0.146, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2662 | Steps: 2 | Val loss: 0.2693 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2338 | Steps: 2 | Val loss: 0.2822 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=46973)[0m rmse: 0.1439538598060608
[2m[36m(func pid=46973)[0m mae:  0.09614421427249908
[2m[36m(func pid=46973)[0m rmse_per_class: [0.071, 0.236, 0.033, 0.264, 0.069, 0.165, 0.225, 0.117, 0.161, 0.098]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:42:25 (running for 00:46:16.55)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.381 |  0.167 |                   71 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.266 |  0.144 |                   74 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.245 |  0.144 |                   57 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3796 | Steps: 2 | Val loss: 0.3041 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=50346)[0m rmse: 0.14821910858154297
[2m[36m(func pid=50346)[0m mae:  0.09090297669172287
[2m[36m(func pid=50346)[0m rmse_per_class: [0.069, 0.235, 0.031, 0.264, 0.067, 0.165, 0.216, 0.109, 0.183, 0.141]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16676205396652222
[2m[36m(func pid=46501)[0m mae:  0.12024398148059845
[2m[36m(func pid=46501)[0m rmse_per_class: [0.104, 0.262, 0.063, 0.315, 0.069, 0.189, 0.273, 0.135, 0.146, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2737 | Steps: 2 | Val loss: 0.2686 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2450 | Steps: 2 | Val loss: 0.2837 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 06:42:30 (running for 00:46:21.75)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.38  |  0.167 |                   72 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.274 |  0.144 |                   75 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.234 |  0.148 |                   58 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.14360125362873077
[2m[36m(func pid=46973)[0m mae:  0.09583891928195953
[2m[36m(func pid=46973)[0m rmse_per_class: [0.071, 0.235, 0.033, 0.264, 0.068, 0.165, 0.226, 0.117, 0.159, 0.098]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3790 | Steps: 2 | Val loss: 0.3040 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=50346)[0m rmse: 0.14861032366752625
[2m[36m(func pid=50346)[0m mae:  0.09082521498203278
[2m[36m(func pid=50346)[0m rmse_per_class: [0.084, 0.236, 0.032, 0.268, 0.069, 0.164, 0.207, 0.109, 0.184, 0.132]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16668926179409027
[2m[36m(func pid=46501)[0m mae:  0.12016705423593521
[2m[36m(func pid=46501)[0m rmse_per_class: [0.104, 0.262, 0.063, 0.315, 0.069, 0.189, 0.273, 0.135, 0.146, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2624 | Steps: 2 | Val loss: 0.2686 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2381 | Steps: 2 | Val loss: 0.2855 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
== Status ==
Current time: 2024-01-07 06:42:36 (running for 00:46:27.17)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.379 |  0.167 |                   73 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.262 |  0.143 |                   76 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.245 |  0.149 |                   59 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.14345934987068176
[2m[36m(func pid=46973)[0m mae:  0.09576509892940521
[2m[36m(func pid=46973)[0m rmse_per_class: [0.071, 0.235, 0.033, 0.264, 0.067, 0.165, 0.226, 0.117, 0.159, 0.098]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3806 | Steps: 2 | Val loss: 0.3037 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=50346)[0m rmse: 0.14878560602664948
[2m[36m(func pid=50346)[0m mae:  0.09089451283216476
[2m[36m(func pid=50346)[0m rmse_per_class: [0.102, 0.236, 0.033, 0.281, 0.069, 0.165, 0.205, 0.112, 0.184, 0.1]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16652877628803253
[2m[36m(func pid=46501)[0m mae:  0.12004099786281586
[2m[36m(func pid=46501)[0m rmse_per_class: [0.104, 0.262, 0.063, 0.314, 0.068, 0.189, 0.272, 0.134, 0.146, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2655 | Steps: 2 | Val loss: 0.2686 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2346 | Steps: 2 | Val loss: 0.2851 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=46973)[0m rmse: 0.14336943626403809
[2m[36m(func pid=46973)[0m mae:  0.09567949175834656
[2m[36m(func pid=46973)[0m rmse_per_class: [0.072, 0.234, 0.033, 0.265, 0.067, 0.165, 0.226, 0.116, 0.158, 0.098]== Status ==
Current time: 2024-01-07 06:42:41 (running for 00:46:32.44)
Memory usage on this node: 21.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16699999570846558
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.381 |  0.167 |                   74 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.266 |  0.143 |                   77 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.238 |  0.149 |                   60 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)



[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3789 | Steps: 2 | Val loss: 0.3033 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=50346)[0m rmse: 0.1468317210674286
[2m[36m(func pid=50346)[0m mae:  0.08977988362312317
[2m[36m(func pid=50346)[0m rmse_per_class: [0.084, 0.235, 0.032, 0.278, 0.063, 0.167, 0.208, 0.127, 0.186, 0.088]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16637463867664337
[2m[36m(func pid=46501)[0m mae:  0.11988365650177002
[2m[36m(func pid=46501)[0m rmse_per_class: [0.104, 0.262, 0.063, 0.314, 0.069, 0.189, 0.272, 0.134, 0.145, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2738 | Steps: 2 | Val loss: 0.2688 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2307 | Steps: 2 | Val loss: 0.2834 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 06:42:46 (running for 00:46:37.60)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16649999469518661
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.379 |  0.166 |                   75 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.274 |  0.144 |                   78 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.235 |  0.147 |                   61 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.1435297429561615
[2m[36m(func pid=46973)[0m mae:  0.095631904900074
[2m[36m(func pid=46973)[0m rmse_per_class: [0.071, 0.235, 0.033, 0.265, 0.067, 0.165, 0.226, 0.116, 0.16, 0.098]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.3775 | Steps: 2 | Val loss: 0.3030 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=50346)[0m rmse: 0.1449296623468399
[2m[36m(func pid=50346)[0m mae:  0.08876968920230865
[2m[36m(func pid=50346)[0m rmse_per_class: [0.071, 0.233, 0.029, 0.268, 0.06, 0.179, 0.214, 0.125, 0.181, 0.089]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16618412733078003
[2m[36m(func pid=46501)[0m mae:  0.11967943608760834
[2m[36m(func pid=46501)[0m rmse_per_class: [0.104, 0.262, 0.063, 0.313, 0.068, 0.189, 0.272, 0.134, 0.145, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2612 | Steps: 2 | Val loss: 0.2682 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2329 | Steps: 2 | Val loss: 0.2783 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 06:42:51 (running for 00:46:42.92)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16649999469518661
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.377 |  0.166 |                   76 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.261 |  0.143 |                   79 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.231 |  0.145 |                   62 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.14326921105384827
[2m[36m(func pid=46973)[0m mae:  0.0953601524233818
[2m[36m(func pid=46973)[0m rmse_per_class: [0.071, 0.235, 0.033, 0.263, 0.068, 0.165, 0.227, 0.116, 0.159, 0.097]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.3767 | Steps: 2 | Val loss: 0.3031 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=50346)[0m rmse: 0.1412348449230194
[2m[36m(func pid=50346)[0m mae:  0.0862085297703743
[2m[36m(func pid=50346)[0m rmse_per_class: [0.066, 0.232, 0.027, 0.258, 0.058, 0.171, 0.211, 0.114, 0.179, 0.097]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.1662745475769043
[2m[36m(func pid=46501)[0m mae:  0.11978121101856232
[2m[36m(func pid=46501)[0m rmse_per_class: [0.104, 0.262, 0.063, 0.313, 0.068, 0.188, 0.272, 0.134, 0.146, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2669 | Steps: 2 | Val loss: 0.2685 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2389 | Steps: 2 | Val loss: 0.2749 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 06:42:57 (running for 00:46:48.37)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16649999469518661
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.377 |  0.166 |                   77 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.267 |  0.143 |                   80 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.233 |  0.141 |                   63 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.1432819962501526
[2m[36m(func pid=46973)[0m mae:  0.0952906385064125
[2m[36m(func pid=46973)[0m rmse_per_class: [0.07, 0.235, 0.033, 0.263, 0.068, 0.165, 0.226, 0.116, 0.16, 0.098]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.3758 | Steps: 2 | Val loss: 0.3031 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=50346)[0m rmse: 0.14117200672626495
[2m[36m(func pid=50346)[0m mae:  0.08618295192718506
[2m[36m(func pid=50346)[0m rmse_per_class: [0.067, 0.233, 0.027, 0.254, 0.059, 0.166, 0.209, 0.11, 0.175, 0.112]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.166233628988266
[2m[36m(func pid=46501)[0m mae:  0.11973996460437775
[2m[36m(func pid=46501)[0m rmse_per_class: [0.104, 0.262, 0.063, 0.313, 0.069, 0.188, 0.272, 0.134, 0.146, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2621 | Steps: 2 | Val loss: 0.2679 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2394 | Steps: 2 | Val loss: 0.2751 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=46973)[0m rmse: 0.142796590924263
[2m[36m(func pid=46973)[0m mae:  0.09488885849714279
[2m[36m(func pid=46973)[0m rmse_per_class: [0.069, 0.236, 0.032, 0.261, 0.068, 0.164, 0.225, 0.116, 0.158, 0.098]
== Status ==
Current time: 2024-01-07 06:43:02 (running for 00:46:53.39)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16649999469518661
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.376 |  0.166 |                   78 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.262 |  0.143 |                   81 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.239 |  0.141 |                   64 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.3777 | Steps: 2 | Val loss: 0.3027 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=50346)[0m rmse: 0.14296986162662506
[2m[36m(func pid=50346)[0m mae:  0.08730800449848175
[2m[36m(func pid=50346)[0m rmse_per_class: [0.078, 0.235, 0.027, 0.259, 0.06, 0.164, 0.205, 0.11, 0.178, 0.115]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.166070818901062
[2m[36m(func pid=46501)[0m mae:  0.1195814460515976
[2m[36m(func pid=46501)[0m rmse_per_class: [0.104, 0.262, 0.062, 0.313, 0.069, 0.188, 0.272, 0.134, 0.146, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2657 | Steps: 2 | Val loss: 0.2679 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2472 | Steps: 2 | Val loss: 0.2755 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 06:43:07 (running for 00:46:58.62)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16649999469518661
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.378 |  0.166 |                   79 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.266 |  0.143 |                   82 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.239 |  0.143 |                   65 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.14276035130023956
[2m[36m(func pid=46973)[0m mae:  0.09475276619195938
[2m[36m(func pid=46973)[0m rmse_per_class: [0.069, 0.236, 0.032, 0.261, 0.067, 0.164, 0.224, 0.116, 0.158, 0.099]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.3795 | Steps: 2 | Val loss: 0.3026 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=50346)[0m rmse: 0.14352339506149292
[2m[36m(func pid=50346)[0m mae:  0.08837798982858658
[2m[36m(func pid=50346)[0m rmse_per_class: [0.083, 0.233, 0.027, 0.273, 0.061, 0.165, 0.206, 0.111, 0.176, 0.1]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2579 | Steps: 2 | Val loss: 0.2676 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=46501)[0m rmse: 0.16599878668785095
[2m[36m(func pid=46501)[0m mae:  0.11949744075536728
[2m[36m(func pid=46501)[0m rmse_per_class: [0.104, 0.262, 0.063, 0.313, 0.069, 0.188, 0.271, 0.134, 0.146, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2412 | Steps: 2 | Val loss: 0.2790 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 06:43:12 (running for 00:47:03.68)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16649999469518661
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.38  |  0.166 |                   80 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.258 |  0.142 |                   83 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.247 |  0.144 |                   66 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.142498180270195
[2m[36m(func pid=46973)[0m mae:  0.09447460621595383
[2m[36m(func pid=46973)[0m rmse_per_class: [0.069, 0.236, 0.032, 0.26, 0.068, 0.164, 0.223, 0.117, 0.157, 0.099]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.3777 | Steps: 2 | Val loss: 0.3023 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=50346)[0m rmse: 0.1455921083688736
[2m[36m(func pid=50346)[0m mae:  0.0902647078037262
[2m[36m(func pid=50346)[0m rmse_per_class: [0.083, 0.235, 0.028, 0.281, 0.07, 0.17, 0.213, 0.116, 0.168, 0.091]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2597 | Steps: 2 | Val loss: 0.2681 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=46501)[0m rmse: 0.16586609184741974
[2m[36m(func pid=46501)[0m mae:  0.11939193308353424
[2m[36m(func pid=46501)[0m rmse_per_class: [0.103, 0.261, 0.062, 0.312, 0.069, 0.188, 0.271, 0.134, 0.145, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2441 | Steps: 2 | Val loss: 0.2834 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 06:43:17 (running for 00:47:08.89)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16649999469518661
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.378 |  0.166 |                   81 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.26  |  0.143 |                   84 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.241 |  0.146 |                   67 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.1428336799144745
[2m[36m(func pid=46973)[0m mae:  0.09461917728185654
[2m[36m(func pid=46973)[0m rmse_per_class: [0.068, 0.236, 0.032, 0.261, 0.07, 0.164, 0.223, 0.117, 0.157, 0.1]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.14588221907615662
[2m[36m(func pid=50346)[0m mae:  0.08942423015832901
[2m[36m(func pid=50346)[0m rmse_per_class: [0.078, 0.233, 0.028, 0.275, 0.075, 0.169, 0.209, 0.121, 0.178, 0.093]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.3737 | Steps: 2 | Val loss: 0.3021 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2611 | Steps: 2 | Val loss: 0.2677 | Batch size: 32 | lr: 0.01 | Duration: 2.69s
[2m[36m(func pid=46501)[0m rmse: 0.165786474943161
[2m[36m(func pid=46501)[0m mae:  0.11935899406671524
[2m[36m(func pid=46501)[0m rmse_per_class: [0.103, 0.261, 0.062, 0.312, 0.068, 0.188, 0.271, 0.134, 0.145, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2401 | Steps: 2 | Val loss: 0.2864 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 06:43:22 (running for 00:47:14.03)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16649999469518661
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.374 |  0.166 |                   82 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.261 |  0.142 |                   85 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.244 |  0.146 |                   68 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.14241823554039001
[2m[36m(func pid=46973)[0m mae:  0.09421543776988983
[2m[36m(func pid=46973)[0m rmse_per_class: [0.067, 0.236, 0.032, 0.259, 0.071, 0.164, 0.223, 0.117, 0.156, 0.099]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.14616531133651733
[2m[36m(func pid=50346)[0m mae:  0.08876591920852661
[2m[36m(func pid=50346)[0m rmse_per_class: [0.072, 0.239, 0.028, 0.266, 0.074, 0.169, 0.209, 0.117, 0.183, 0.105]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.3813 | Steps: 2 | Val loss: 0.3020 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2583 | Steps: 2 | Val loss: 0.2680 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=46501)[0m rmse: 0.1657358705997467
[2m[36m(func pid=46501)[0m mae:  0.11930447816848755
[2m[36m(func pid=46501)[0m rmse_per_class: [0.103, 0.261, 0.062, 0.312, 0.068, 0.188, 0.271, 0.133, 0.145, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2378 | Steps: 2 | Val loss: 0.2822 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 06:43:28 (running for 00:47:19.15)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16649999469518661
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.381 |  0.166 |                   83 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.258 |  0.143 |                   86 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.24  |  0.146 |                   69 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46973)[0m rmse: 0.14258286356925964
[2m[36m(func pid=46973)[0m mae:  0.09424968808889389
[2m[36m(func pid=46973)[0m rmse_per_class: [0.068, 0.236, 0.032, 0.259, 0.071, 0.164, 0.223, 0.117, 0.158, 0.099]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m rmse: 0.14458957314491272
[2m[36m(func pid=50346)[0m mae:  0.08787897229194641
[2m[36m(func pid=50346)[0m rmse_per_class: [0.068, 0.235, 0.03, 0.262, 0.067, 0.166, 0.209, 0.115, 0.175, 0.119]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.3789 | Steps: 2 | Val loss: 0.3020 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2582 | Steps: 2 | Val loss: 0.2681 | Batch size: 32 | lr: 0.01 | Duration: 2.66s
[2m[36m(func pid=46501)[0m rmse: 0.16568438708782196
[2m[36m(func pid=46501)[0m mae:  0.11926861852407455
[2m[36m(func pid=46501)[0m rmse_per_class: [0.103, 0.261, 0.063, 0.313, 0.068, 0.188, 0.271, 0.133, 0.145, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2422 | Steps: 2 | Val loss: 0.2772 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=46973)[0m rmse: 0.14263421297073364
[2m[36m(func pid=46973)[0m mae:  0.09426885098218918
[2m[36m(func pid=46973)[0m rmse_per_class: [0.068, 0.235, 0.032, 0.26, 0.071, 0.164, 0.223, 0.117, 0.157, 0.099]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:43:34 (running for 00:47:25.87)
Memory usage on this node: 22.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16649999469518661
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.379 |  0.166 |                   84 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.258 |  0.143 |                   87 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.242 |  0.143 |                   71 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14311310648918152
[2m[36m(func pid=50346)[0m mae:  0.08758145570755005
[2m[36m(func pid=50346)[0m rmse_per_class: [0.069, 0.231, 0.029, 0.263, 0.061, 0.165, 0.211, 0.113, 0.164, 0.125]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.3716 | Steps: 2 | Val loss: 0.3019 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2621 | Steps: 2 | Val loss: 0.2688 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=46501)[0m rmse: 0.16565242409706116
[2m[36m(func pid=46501)[0m mae:  0.11924459785223007
[2m[36m(func pid=46501)[0m rmse_per_class: [0.102, 0.261, 0.063, 0.313, 0.069, 0.188, 0.271, 0.133, 0.145, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2358 | Steps: 2 | Val loss: 0.2762 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=46973)[0m rmse: 0.14302301406860352
[2m[36m(func pid=46973)[0m mae:  0.09451733529567719
[2m[36m(func pid=46973)[0m rmse_per_class: [0.068, 0.235, 0.032, 0.262, 0.072, 0.164, 0.223, 0.117, 0.159, 0.098]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:43:40 (running for 00:47:31.23)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16649999469518661
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.372 |  0.166 |                   85 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.262 |  0.143 |                   88 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.236 |  0.144 |                   72 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14364930987358093
[2m[36m(func pid=50346)[0m mae:  0.08832713216543198
[2m[36m(func pid=50346)[0m rmse_per_class: [0.083, 0.233, 0.029, 0.266, 0.061, 0.164, 0.211, 0.111, 0.164, 0.114]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.3717 | Steps: 2 | Val loss: 0.3019 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2624 | Steps: 2 | Val loss: 0.2687 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=46501)[0m rmse: 0.1656349003314972
[2m[36m(func pid=46501)[0m mae:  0.11922184377908707
[2m[36m(func pid=46501)[0m rmse_per_class: [0.103, 0.261, 0.063, 0.313, 0.069, 0.188, 0.271, 0.133, 0.145, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2399 | Steps: 2 | Val loss: 0.2800 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=46973)[0m rmse: 0.14295679330825806
[2m[36m(func pid=46973)[0m mae:  0.0944192185997963
[2m[36m(func pid=46973)[0m rmse_per_class: [0.068, 0.234, 0.032, 0.264, 0.071, 0.164, 0.222, 0.118, 0.16, 0.096]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:43:45 (running for 00:47:36.72)
Memory usage on this node: 21.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16649999469518661
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.372 |  0.166 |                   86 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.262 |  0.143 |                   89 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.24  |  0.145 |                   73 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14461955428123474
[2m[36m(func pid=50346)[0m mae:  0.08834662288427353
[2m[36m(func pid=50346)[0m rmse_per_class: [0.087, 0.234, 0.029, 0.27, 0.061, 0.167, 0.206, 0.113, 0.179, 0.1]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.3744 | Steps: 2 | Val loss: 0.3019 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2656 | Steps: 2 | Val loss: 0.2686 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
[2m[36m(func pid=46501)[0m rmse: 0.16563822329044342
[2m[36m(func pid=46501)[0m mae:  0.11919313669204712
[2m[36m(func pid=46501)[0m rmse_per_class: [0.102, 0.261, 0.063, 0.313, 0.069, 0.188, 0.27, 0.133, 0.145, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2358 | Steps: 2 | Val loss: 0.2818 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=46973)[0m rmse: 0.14279350638389587
[2m[36m(func pid=46973)[0m mae:  0.09432405233383179
[2m[36m(func pid=46973)[0m rmse_per_class: [0.068, 0.233, 0.032, 0.265, 0.07, 0.164, 0.223, 0.117, 0.159, 0.097]
[2m[36m(func pid=46973)[0m 
== Status ==
Current time: 2024-01-07 06:43:51 (running for 00:47:42.03)
Memory usage on this node: 21.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16649999469518661
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.374 |  0.166 |                   87 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.266 |  0.143 |                   90 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.236 |  0.145 |                   74 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.3736 | Steps: 2 | Val loss: 0.3015 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=50346)[0m rmse: 0.14531800150871277
[2m[36m(func pid=50346)[0m mae:  0.08849410712718964
[2m[36m(func pid=50346)[0m rmse_per_class: [0.076, 0.239, 0.029, 0.265, 0.064, 0.175, 0.208, 0.115, 0.187, 0.094]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2667 | Steps: 2 | Val loss: 0.2686 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=46501)[0m rmse: 0.16543546319007874
[2m[36m(func pid=46501)[0m mae:  0.11902519315481186
[2m[36m(func pid=46501)[0m rmse_per_class: [0.102, 0.261, 0.062, 0.312, 0.069, 0.188, 0.27, 0.133, 0.145, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.14301952719688416
[2m[36m(func pid=46973)[0m mae:  0.09451960027217865
[2m[36m(func pid=46973)[0m rmse_per_class: [0.068, 0.233, 0.032, 0.267, 0.07, 0.164, 0.222, 0.117, 0.16, 0.097]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2409 | Steps: 2 | Val loss: 0.2846 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 06:43:56 (running for 00:47:47.51)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.374 |  0.165 |                   88 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.267 |  0.143 |                   91 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.241 |  0.145 |                   75 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14543569087982178
[2m[36m(func pid=50346)[0m mae:  0.08846394717693329
[2m[36m(func pid=50346)[0m rmse_per_class: [0.073, 0.237, 0.027, 0.266, 0.067, 0.17, 0.208, 0.117, 0.191, 0.099]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2586 | Steps: 2 | Val loss: 0.2689 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.3750 | Steps: 2 | Val loss: 0.3012 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=46973)[0m rmse: 0.14323945343494415
[2m[36m(func pid=46973)[0m mae:  0.09465667605400085
[2m[36m(func pid=46973)[0m rmse_per_class: [0.069, 0.233, 0.032, 0.268, 0.068, 0.164, 0.221, 0.117, 0.164, 0.095]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16524073481559753
[2m[36m(func pid=46501)[0m mae:  0.11885236203670502
[2m[36m(func pid=46501)[0m rmse_per_class: [0.102, 0.261, 0.062, 0.312, 0.068, 0.187, 0.27, 0.133, 0.146, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2374 | Steps: 2 | Val loss: 0.2782 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2586 | Steps: 2 | Val loss: 0.2693 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
== Status ==
Current time: 2024-01-07 06:44:01 (running for 00:47:53.01)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.375 |  0.165 |                   89 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.259 |  0.143 |                   92 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.237 |  0.142 |                   76 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14200671017169952
[2m[36m(func pid=50346)[0m mae:  0.08682379126548767
[2m[36m(func pid=50346)[0m rmse_per_class: [0.07, 0.232, 0.027, 0.262, 0.063, 0.165, 0.209, 0.115, 0.177, 0.1]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.3727 | Steps: 2 | Val loss: 0.3011 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=46973)[0m rmse: 0.14361312985420227
[2m[36m(func pid=46973)[0m mae:  0.09488304704427719
[2m[36m(func pid=46973)[0m rmse_per_class: [0.069, 0.234, 0.032, 0.268, 0.069, 0.164, 0.221, 0.117, 0.167, 0.095]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16517755389213562
[2m[36m(func pid=46501)[0m mae:  0.11883733421564102
[2m[36m(func pid=46501)[0m rmse_per_class: [0.102, 0.261, 0.061, 0.311, 0.068, 0.187, 0.27, 0.133, 0.146, 0.112]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2422 | Steps: 2 | Val loss: 0.2739 | Batch size: 32 | lr: 0.1 | Duration: 2.73s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2657 | Steps: 2 | Val loss: 0.2693 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 06:44:07 (running for 00:47:58.23)
Memory usage on this node: 21.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.373 |  0.165 |                   90 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.259 |  0.144 |                   93 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.242 |  0.141 |                   77 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.3732 | Steps: 2 | Val loss: 0.3008 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=50346)[0m rmse: 0.1414014995098114
[2m[36m(func pid=50346)[0m mae:  0.08644799888134003
[2m[36m(func pid=50346)[0m rmse_per_class: [0.073, 0.232, 0.029, 0.259, 0.059, 0.164, 0.208, 0.113, 0.179, 0.099]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.1436244547367096
[2m[36m(func pid=46973)[0m mae:  0.09483133256435394
[2m[36m(func pid=46973)[0m rmse_per_class: [0.07, 0.234, 0.032, 0.267, 0.068, 0.164, 0.222, 0.117, 0.168, 0.095]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16499708592891693
[2m[36m(func pid=46501)[0m mae:  0.11869869381189346
[2m[36m(func pid=46501)[0m rmse_per_class: [0.101, 0.26, 0.062, 0.311, 0.068, 0.187, 0.27, 0.133, 0.146, 0.111]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2381 | Steps: 2 | Val loss: 0.2761 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2534 | Steps: 2 | Val loss: 0.2692 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.3763 | Steps: 2 | Val loss: 0.3006 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 06:44:12 (running for 00:48:03.66)
Memory usage on this node: 21.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.373 |  0.165 |                   91 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.266 |  0.144 |                   94 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.238 |  0.144 |                   78 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14388474822044373
[2m[36m(func pid=50346)[0m mae:  0.08742621541023254
[2m[36m(func pid=50346)[0m rmse_per_class: [0.081, 0.234, 0.031, 0.26, 0.06, 0.166, 0.205, 0.111, 0.194, 0.098]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.1433826982975006
[2m[36m(func pid=46973)[0m mae:  0.09450408816337585
[2m[36m(func pid=46973)[0m rmse_per_class: [0.069, 0.234, 0.032, 0.266, 0.069, 0.164, 0.22, 0.117, 0.168, 0.095]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16495674848556519
[2m[36m(func pid=46501)[0m mae:  0.11864082515239716
[2m[36m(func pid=46501)[0m rmse_per_class: [0.102, 0.26, 0.062, 0.311, 0.068, 0.187, 0.27, 0.133, 0.146, 0.111]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2336 | Steps: 2 | Val loss: 0.2843 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2533 | Steps: 2 | Val loss: 0.2695 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.3695 | Steps: 2 | Val loss: 0.3004 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 06:44:17 (running for 00:48:08.95)
Memory usage on this node: 21.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.376 |  0.165 |                   92 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.253 |  0.143 |                   95 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.234 |  0.148 |                   79 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.1476839780807495
[2m[36m(func pid=50346)[0m mae:  0.08976434916257858
[2m[36m(func pid=50346)[0m rmse_per_class: [0.076, 0.242, 0.033, 0.27, 0.058, 0.177, 0.208, 0.113, 0.198, 0.102]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.14351001381874084
[2m[36m(func pid=46973)[0m mae:  0.0945088341832161
[2m[36m(func pid=46973)[0m rmse_per_class: [0.069, 0.235, 0.032, 0.266, 0.069, 0.164, 0.22, 0.117, 0.167, 0.096]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16482526063919067
[2m[36m(func pid=46501)[0m mae:  0.11850392818450928
[2m[36m(func pid=46501)[0m rmse_per_class: [0.102, 0.26, 0.062, 0.311, 0.068, 0.187, 0.27, 0.133, 0.146, 0.111]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2329 | Steps: 2 | Val loss: 0.2952 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2551 | Steps: 2 | Val loss: 0.2700 | Batch size: 32 | lr: 0.01 | Duration: 2.73s
== Status ==
Current time: 2024-01-07 06:44:23 (running for 00:48:14.18)
Memory usage on this node: 21.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.37  |  0.165 |                   93 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.253 |  0.144 |                   96 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.233 |  0.151 |                   80 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.3744 | Steps: 2 | Val loss: 0.3004 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=50346)[0m rmse: 0.1507674902677536
[2m[36m(func pid=50346)[0m mae:  0.09187144041061401
[2m[36m(func pid=50346)[0m rmse_per_class: [0.071, 0.241, 0.032, 0.279, 0.06, 0.178, 0.212, 0.121, 0.193, 0.12]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.1437004655599594
[2m[36m(func pid=46973)[0m mae:  0.09460204094648361
[2m[36m(func pid=46973)[0m rmse_per_class: [0.07, 0.236, 0.032, 0.265, 0.07, 0.164, 0.22, 0.116, 0.168, 0.097]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.1648605912923813
[2m[36m(func pid=46501)[0m mae:  0.11851586401462555
[2m[36m(func pid=46501)[0m rmse_per_class: [0.102, 0.26, 0.062, 0.311, 0.068, 0.187, 0.27, 0.132, 0.146, 0.111]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2507 | Steps: 2 | Val loss: 0.2918 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2531 | Steps: 2 | Val loss: 0.2701 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.3688 | Steps: 2 | Val loss: 0.3003 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 06:44:28 (running for 00:48:19.53)
Memory usage on this node: 21.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.374 |  0.165 |                   94 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.255 |  0.144 |                   97 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.251 |  0.149 |                   81 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14853909611701965
[2m[36m(func pid=50346)[0m mae:  0.09042619168758392
[2m[36m(func pid=50346)[0m rmse_per_class: [0.071, 0.235, 0.03, 0.275, 0.064, 0.167, 0.213, 0.131, 0.177, 0.124]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.14355093240737915
[2m[36m(func pid=46973)[0m mae:  0.09442329406738281
[2m[36m(func pid=46973)[0m rmse_per_class: [0.07, 0.236, 0.032, 0.264, 0.069, 0.164, 0.22, 0.116, 0.168, 0.097]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.1648070514202118
[2m[36m(func pid=46501)[0m mae:  0.11848100274801254
[2m[36m(func pid=46501)[0m rmse_per_class: [0.102, 0.26, 0.062, 0.311, 0.068, 0.187, 0.27, 0.132, 0.146, 0.11]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2323 | Steps: 2 | Val loss: 0.2808 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2584 | Steps: 2 | Val loss: 0.2699 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 06:44:33 (running for 00:48:24.87)
Memory usage on this node: 21.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.369 |  0.165 |                   95 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.253 |  0.144 |                   98 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.232 |  0.144 |                   82 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.3749 | Steps: 2 | Val loss: 0.2999 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=50346)[0m rmse: 0.14434002339839935
[2m[36m(func pid=50346)[0m mae:  0.08799589425325394
[2m[36m(func pid=50346)[0m rmse_per_class: [0.072, 0.231, 0.029, 0.273, 0.068, 0.166, 0.208, 0.125, 0.161, 0.11]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.14333023130893707
[2m[36m(func pid=46973)[0m mae:  0.09419053792953491
[2m[36m(func pid=46973)[0m rmse_per_class: [0.07, 0.235, 0.032, 0.263, 0.068, 0.163, 0.22, 0.115, 0.167, 0.098]
[2m[36m(func pid=46973)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16457346081733704
[2m[36m(func pid=46501)[0m mae:  0.11830447614192963
[2m[36m(func pid=46501)[0m rmse_per_class: [0.101, 0.26, 0.062, 0.31, 0.069, 0.187, 0.27, 0.132, 0.146, 0.11]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2390 | Steps: 2 | Val loss: 0.2731 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=46973)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2599 | Steps: 2 | Val loss: 0.2697 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.3692 | Steps: 2 | Val loss: 0.3001 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 06:44:39 (running for 00:48:30.32)
Memory usage on this node: 21.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.375 |  0.165 |                   96 |
| train_12613_00022 | RUNNING    | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.258 |  0.143 |                   99 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.239 |  0.141 |                   83 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14073002338409424
[2m[36m(func pid=50346)[0m mae:  0.08602146804332733
[2m[36m(func pid=50346)[0m rmse_per_class: [0.078, 0.229, 0.029, 0.268, 0.066, 0.166, 0.205, 0.114, 0.155, 0.096]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46973)[0m rmse: 0.14305861294269562
[2m[36m(func pid=46973)[0m mae:  0.09395510703325272
[2m[36m(func pid=46973)[0m rmse_per_class: [0.069, 0.235, 0.031, 0.262, 0.07, 0.163, 0.221, 0.115, 0.166, 0.098]
[2m[36m(func pid=46501)[0m rmse: 0.16463910043239594
[2m[36m(func pid=46501)[0m mae:  0.11836475133895874
[2m[36m(func pid=46501)[0m rmse_per_class: [0.101, 0.26, 0.062, 0.31, 0.069, 0.186, 0.27, 0.132, 0.147, 0.109]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2325 | Steps: 2 | Val loss: 0.2734 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.3701 | Steps: 2 | Val loss: 0.2999 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 06:44:44 (running for 00:48:35.73)
Memory usage on this node: 19.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.369 |  0.165 |                   97 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.233 |  0.141 |                   84 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
| train_12613_00017 | TERMINATED | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.181 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.1408490389585495
[2m[36m(func pid=50346)[0m mae:  0.08596822619438171
[2m[36m(func pid=50346)[0m rmse_per_class: [0.086, 0.229, 0.029, 0.26, 0.063, 0.167, 0.207, 0.11, 0.162, 0.094]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16459038853645325
[2m[36m(func pid=46501)[0m mae:  0.11828044801950455
[2m[36m(func pid=46501)[0m rmse_per_class: [0.101, 0.26, 0.062, 0.31, 0.069, 0.186, 0.27, 0.132, 0.146, 0.11]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2363 | Steps: 2 | Val loss: 0.2801 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 06:44:50 (running for 00:48:41.07)
Memory usage on this node: 18.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.37  |  0.165 |                   98 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.236 |  0.143 |                   85 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
| train_12613_00017 | TERMINATED | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.181 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)

[2m[36m(func pid=50346)[0m rmse: 0.14334657788276672

[2m[36m(func pid=50346)[0m mae:  0.08709525316953659
[2m[36m(func pid=50346)[0m rmse_per_class: [0.078, 0.233, 0.029, 0.258, 0.063, 0.167, 0.209, 0.111, 0.192, 0.094]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.3687 | Steps: 2 | Val loss: 0.2998 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=46501)[0m rmse: 0.16453608870506287
[2m[36m(func pid=46501)[0m mae:  0.1182311400771141
[2m[36m(func pid=46501)[0m rmse_per_class: [0.101, 0.26, 0.062, 0.31, 0.069, 0.186, 0.269, 0.132, 0.147, 0.11]
[2m[36m(func pid=46501)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2366 | Steps: 2 | Val loss: 0.2825 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=46501)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.3679 | Steps: 2 | Val loss: 0.2997 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 06:44:55 (running for 00:48:46.63)
Memory usage on this node: 18.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00021 | RUNNING    | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.369 |  0.165 |                   99 |
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.237 |  0.145 |                   86 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
| train_12613_00017 | TERMINATED | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.181 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14498920738697052
[2m[36m(func pid=50346)[0m mae:  0.0875818282365799
[2m[36m(func pid=50346)[0m rmse_per_class: [0.071, 0.24, 0.03, 0.256, 0.061, 0.165, 0.205, 0.111, 0.211, 0.099]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=46501)[0m rmse: 0.16444085538387299
[2m[36m(func pid=46501)[0m mae:  0.1181454285979271
[2m[36m(func pid=46501)[0m rmse_per_class: [0.101, 0.26, 0.061, 0.309, 0.069, 0.186, 0.269, 0.132, 0.147, 0.109]
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2404 | Steps: 2 | Val loss: 0.2851 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 06:45:00 (running for 00:48:51.90)
Memory usage on this node: 16.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.24  |  0.148 |                   87 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
| train_12613_00017 | TERMINATED | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.181 |                   75 |
| train_12613_00018 | TERMINATED | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.378 |  0.182 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14783774316310883
[2m[36m(func pid=50346)[0m mae:  0.08966509252786636
[2m[36m(func pid=50346)[0m rmse_per_class: [0.07, 0.242, 0.032, 0.268, 0.058, 0.165, 0.208, 0.119, 0.206, 0.11]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2404 | Steps: 2 | Val loss: 0.2894 | Batch size: 32 | lr: 0.1 | Duration: 3.23s
== Status ==
Current time: 2024-01-07 06:45:05 (running for 00:48:56.91)
Memory usage on this node: 16.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.24  |  0.148 |                   87 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
| train_12613_00017 | TERMINATED | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.181 |                   75 |
| train_12613_00018 | TERMINATED | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.378 |  0.182 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.1504884660243988
[2m[36m(func pid=50346)[0m mae:  0.09220714867115021
[2m[36m(func pid=50346)[0m rmse_per_class: [0.073, 0.24, 0.033, 0.287, 0.057, 0.166, 0.211, 0.13, 0.187, 0.12]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2398 | Steps: 2 | Val loss: 0.2935 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 06:45:11 (running for 00:49:02.44)
Memory usage on this node: 16.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.24  |  0.15  |                   88 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
| train_12613_00017 | TERMINATED | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.181 |                   75 |
| train_12613_00018 | TERMINATED | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.378 |  0.182 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.15104563534259796
[2m[36m(func pid=50346)[0m mae:  0.09310223162174225
[2m[36m(func pid=50346)[0m rmse_per_class: [0.087, 0.238, 0.031, 0.295, 0.061, 0.169, 0.213, 0.129, 0.174, 0.114]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2358 | Steps: 2 | Val loss: 0.2927 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 06:45:16 (running for 00:49:07.67)
Memory usage on this node: 16.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.24  |  0.151 |                   89 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
| train_12613_00017 | TERMINATED | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.181 |                   75 |
| train_12613_00018 | TERMINATED | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.378 |  0.182 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14899028837680817
[2m[36m(func pid=50346)[0m mae:  0.0919664055109024
[2m[36m(func pid=50346)[0m rmse_per_class: [0.091, 0.242, 0.029, 0.285, 0.069, 0.169, 0.217, 0.116, 0.171, 0.099]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2370 | Steps: 2 | Val loss: 0.2850 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 06:45:22 (running for 00:49:13.15)
Memory usage on this node: 16.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.236 |  0.149 |                   90 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
| train_12613_00017 | TERMINATED | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.181 |                   75 |
| train_12613_00018 | TERMINATED | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.378 |  0.182 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14422932267189026
[2m[36m(func pid=50346)[0m mae:  0.08809366822242737
[2m[36m(func pid=50346)[0m rmse_per_class: [0.081, 0.235, 0.028, 0.27, 0.07, 0.168, 0.206, 0.111, 0.18, 0.094]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2310 | Steps: 2 | Val loss: 0.2798 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
== Status ==
Current time: 2024-01-07 06:45:27 (running for 00:49:18.47)
Memory usage on this node: 16.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.237 |  0.144 |                   91 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
| train_12613_00017 | TERMINATED | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.181 |                   75 |
| train_12613_00018 | TERMINATED | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.378 |  0.182 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14314314723014832
[2m[36m(func pid=50346)[0m mae:  0.08648818731307983
[2m[36m(func pid=50346)[0m rmse_per_class: [0.072, 0.237, 0.029, 0.26, 0.065, 0.168, 0.206, 0.11, 0.193, 0.091]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2360 | Steps: 2 | Val loss: 0.2810 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 06:45:33 (running for 00:49:24.26)
Memory usage on this node: 16.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.231 |  0.143 |                   92 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
| train_12613_00017 | TERMINATED | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.181 |                   75 |
| train_12613_00018 | TERMINATED | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.378 |  0.182 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.1443631947040558
[2m[36m(func pid=50346)[0m mae:  0.08722905814647675
[2m[36m(func pid=50346)[0m rmse_per_class: [0.073, 0.24, 0.031, 0.259, 0.063, 0.165, 0.206, 0.113, 0.197, 0.098]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2320 | Steps: 2 | Val loss: 0.2851 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 06:45:38 (running for 00:49:29.55)
Memory usage on this node: 16.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.236 |  0.144 |                   93 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
| train_12613_00017 | TERMINATED | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.181 |                   75 |
| train_12613_00018 | TERMINATED | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.378 |  0.182 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14860032498836517
[2m[36m(func pid=50346)[0m mae:  0.09037824720144272
[2m[36m(func pid=50346)[0m rmse_per_class: [0.082, 0.238, 0.033, 0.267, 0.058, 0.164, 0.21, 0.128, 0.195, 0.111]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2387 | Steps: 2 | Val loss: 0.2871 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 06:45:44 (running for 00:49:35.15)
Memory usage on this node: 16.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.232 |  0.149 |                   94 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
| train_12613_00017 | TERMINATED | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.181 |                   75 |
| train_12613_00018 | TERMINATED | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.378 |  0.182 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.15035727620124817
[2m[36m(func pid=50346)[0m mae:  0.0921911746263504
[2m[36m(func pid=50346)[0m rmse_per_class: [0.088, 0.237, 0.033, 0.282, 0.055, 0.164, 0.214, 0.134, 0.18, 0.115]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2363 | Steps: 2 | Val loss: 0.2821 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 06:45:49 (running for 00:49:40.54)
Memory usage on this node: 16.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.239 |  0.15  |                   95 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
| train_12613_00017 | TERMINATED | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.181 |                   75 |
| train_12613_00018 | TERMINATED | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.378 |  0.182 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.1458462029695511
[2m[36m(func pid=50346)[0m mae:  0.08937110751867294
[2m[36m(func pid=50346)[0m rmse_per_class: [0.077, 0.235, 0.031, 0.28, 0.054, 0.165, 0.208, 0.12, 0.166, 0.121]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2442 | Steps: 2 | Val loss: 0.2792 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 06:45:54 (running for 00:49:45.87)
Memory usage on this node: 16.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.236 |  0.146 |                   96 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
| train_12613_00017 | TERMINATED | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.181 |                   75 |
| train_12613_00018 | TERMINATED | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.378 |  0.182 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14339956641197205
[2m[36m(func pid=50346)[0m mae:  0.08715171366930008
[2m[36m(func pid=50346)[0m rmse_per_class: [0.075, 0.234, 0.03, 0.268, 0.058, 0.167, 0.206, 0.111, 0.167, 0.118]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2356 | Steps: 2 | Val loss: 0.2793 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 06:46:00 (running for 00:49:51.22)
Memory usage on this node: 16.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.244 |  0.143 |                   97 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
| train_12613_00017 | TERMINATED | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.181 |                   75 |
| train_12613_00018 | TERMINATED | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.378 |  0.182 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14367341995239258
[2m[36m(func pid=50346)[0m mae:  0.0865335762500763
[2m[36m(func pid=50346)[0m rmse_per_class: [0.088, 0.241, 0.029, 0.255, 0.063, 0.166, 0.204, 0.11, 0.178, 0.102]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2390 | Steps: 2 | Val loss: 0.2818 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 06:46:05 (running for 00:49:56.46)
Memory usage on this node: 16.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.236 |  0.144 |                   98 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
| train_12613_00017 | TERMINATED | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.181 |                   75 |
| train_12613_00018 | TERMINATED | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.378 |  0.182 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14524516463279724
[2m[36m(func pid=50346)[0m mae:  0.08753321319818497
[2m[36m(func pid=50346)[0m rmse_per_class: [0.093, 0.242, 0.028, 0.257, 0.069, 0.166, 0.204, 0.113, 0.187, 0.094]
[2m[36m(func pid=50346)[0m 
[2m[36m(func pid=50346)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2463 | Steps: 2 | Val loss: 0.2862 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 06:46:10 (running for 00:50:01.62)
Memory usage on this node: 16.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00023 | RUNNING    | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.239 |  0.145 |                   99 |
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
| train_12613_00017 | TERMINATED | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.181 |                   75 |
| train_12613_00018 | TERMINATED | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.378 |  0.182 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=50346)[0m rmse: 0.14697380363941193
[2m[36m(func pid=50346)[0m mae:  0.08920992910861969
[2m[36m(func pid=50346)[0m rmse_per_class: [0.075, 0.239, 0.028, 0.269, 0.067, 0.167, 0.207, 0.124, 0.197, 0.095]
== Status ==
Current time: 2024-01-07 06:46:11 (running for 00:50:02.15)
Memory usage on this node: 16.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=24
Bracket: Iter 75.000: -0.16174999624490738
Resources requested: 0/72 CPUs, 0/4 GPUs, 0.0/120.12 GiB heap, 0.0/55.47 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (24 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_12613_00000 | TERMINATED | 192.168.7.53:134465 | 0.0001 |       0.99 |         0      |  0.483 |  0.172 |                  100 |
| train_12613_00001 | TERMINATED | 192.168.7.53:134839 | 0.001  |       0.99 |         0      |  0.343 |  0.18  |                   75 |
| train_12613_00002 | TERMINATED | 192.168.7.53:135261 | 0.01   |       0.99 |         0      |  0.403 |  0.187 |                   75 |
| train_12613_00003 | TERMINATED | 192.168.7.53:135687 | 0.1    |       0.99 |         0      |  0.509 |  0.216 |                   75 |
| train_12613_00004 | TERMINATED | 192.168.7.53:151958 | 0.0001 |       0.9  |         0      |  0.49  |  0.18  |                   75 |
| train_12613_00005 | TERMINATED | 192.168.7.53:152019 | 0.001  |       0.9  |         0      |  0.367 |  0.165 |                  100 |
| train_12613_00006 | TERMINATED | 192.168.7.53:153479 | 0.01   |       0.9  |         0      |  0.251 |  0.143 |                  100 |
| train_12613_00007 | TERMINATED | 192.168.7.53:158006 | 0.1    |       0.9  |         0      |  0.241 |  0.143 |                  100 |
| train_12613_00008 | TERMINATED | 192.168.7.53:169589 | 0.0001 |       0.99 |         0.0001 |  0.519 |  0.175 |                   75 |
| train_12613_00009 | TERMINATED | 192.168.7.53:175366 | 0.001  |       0.99 |         0.0001 |  0.376 |  0.183 |                   75 |
| train_12613_00010 | TERMINATED | 192.168.7.53:176440 | 0.01   |       0.99 |         0.0001 |  0.382 |  0.184 |                   75 |
| train_12613_00011 | TERMINATED | 192.168.7.53:180788 | 0.1    |       0.99 |         0.0001 |  0.4   |  0.218 |                   75 |
| train_12613_00012 | TERMINATED | 192.168.7.53:187627 | 0.0001 |       0.9  |         0.0001 |  0.493 |  0.18  |                   75 |
| train_12613_00013 | TERMINATED | 192.168.7.53:5093   | 0.001  |       0.9  |         0.0001 |  0.365 |  0.165 |                  100 |
| train_12613_00014 | TERMINATED | 192.168.7.53:6491   | 0.01   |       0.9  |         0.0001 |  0.258 |  0.142 |                  100 |
| train_12613_00015 | TERMINATED | 192.168.7.53:10475  | 0.1    |       0.9  |         0.0001 |  0.239 |  0.146 |                  100 |
| train_12613_00016 | TERMINATED | 192.168.7.53:17062  | 0.0001 |       0.99 |         1e-05  |  0.515 |  0.175 |                   75 |
| train_12613_00017 | TERMINATED | 192.168.7.53:29192  | 0.001  |       0.99 |         1e-05  |  0.346 |  0.181 |                   75 |
| train_12613_00018 | TERMINATED | 192.168.7.53:29667  | 0.01   |       0.99 |         1e-05  |  0.378 |  0.182 |                   75 |
| train_12613_00019 | TERMINATED | 192.168.7.53:32597  | 0.1    |       0.99 |         1e-05  |  0.501 |  0.213 |                   75 |
| train_12613_00020 | TERMINATED | 192.168.7.53:34793  | 0.0001 |       0.9  |         1e-05  |  0.492 |  0.18  |                   75 |
| train_12613_00021 | TERMINATED | 192.168.7.53:46501  | 0.001  |       0.9  |         1e-05  |  0.368 |  0.164 |                  100 |
| train_12613_00022 | TERMINATED | 192.168.7.53:46973  | 0.01   |       0.9  |         1e-05  |  0.26  |  0.143 |                  100 |
| train_12613_00023 | TERMINATED | 192.168.7.53:50346  | 0.1    |       0.9  |         1e-05  |  0.246 |  0.147 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+


2024-01-07 06:46:11,132	INFO tune.py:798 -- Total run time: 3002.97 seconds (3002.14 seconds for the tuning loop).
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 1341340.1 ON aap04 CANCELLED AT 2024-01-07T06:46:18 ***
srun: error: aap04: task 0: Exited with exit code 1
