IP Head: 192.168.7.53:6379
STARTING HEAD at aap04
2024-01-07 16:23:17,314	INFO usage_lib.py:461 -- Usage stats collection is enabled by default without user confirmation because this terminal is detected to be non-interactive. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.
2024-01-07 16:23:17,314	INFO scripts.py:710 -- Local node IP: 192.168.7.53
2024-01-07 16:23:19,956	SUCC scripts.py:747 -- --------------------
2024-01-07 16:23:19,957	SUCC scripts.py:748 -- Ray runtime started.
2024-01-07 16:23:19,957	SUCC scripts.py:749 -- --------------------
2024-01-07 16:23:19,957	INFO scripts.py:751 -- Next steps
2024-01-07 16:23:19,957	INFO scripts.py:752 -- To connect to this Ray runtime from another node, run
2024-01-07 16:23:19,957	INFO scripts.py:755 --   ray start --address='192.168.7.53:6379'
2024-01-07 16:23:19,957	INFO scripts.py:771 -- Alternatively, use the following Python code:
2024-01-07 16:23:19,957	INFO scripts.py:773 -- import ray
2024-01-07 16:23:19,957	INFO scripts.py:777 -- ray.init(address='auto', _node_ip_address='192.168.7.53')
2024-01-07 16:23:19,957	INFO scripts.py:790 -- To see the status of the cluster, use
2024-01-07 16:23:19,957	INFO scripts.py:791 --   ray status
2024-01-07 16:23:19,958	INFO scripts.py:801 -- If connection fails, check your firewall settings and network configuration.
2024-01-07 16:23:19,958	INFO scripts.py:809 -- To terminate the Ray runtime, run
2024-01-07 16:23:19,958	INFO scripts.py:810 --   ray stop
2024-01-07 16:23:19,958	INFO scripts.py:891 -- --block
2024-01-07 16:23:19,958	INFO scripts.py:892 -- This command will now block forever until terminated by a signal.
2024-01-07 16:23:19,958	INFO scripts.py:895 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.

torch initial seed:              3232100708747318459
torch current seed:              42
torch.cuda.is_available():       True
torch.cuda.device_count():       4
torch.cuda.current_device():     0
torch.cuda.device(0):            <torch.cuda.device object at 0x7f5c87a730a0>
torch.cuda.get_device_name(0):   Tesla V100-PCIE-32GB
torch.backends.cudnn.benchmark:  False
os.sched_getaffinity:            72
os.cpu_count():                  72

model_name:          Supervised
task_name:           multilabel
backbone_name:       resnet18
input_data:          None
dataset_name:        Sentinel2AndaluciaLULC
dataset_level:       Level_N2
train_rate:          10
epochs:              100
learning_rate:       0.01
save_every:          5
batch_size:          32
num_workers:         4
ini_weights:         imagenet
seed:                42
dropout:             None
transfer_learning:   LP
show:                False
verbose:             False
balanced_dataset:    False
torch_compile:       False
distributed:         False
ray_tune:            gridsearch
load_best_hyperparameters: False
grace_period:        75
num_samples_trials:  1
gpus_per_trial:      1

Using ImageNet weights

Supervised model resnet18 with imagenet weights
Old final fully-connected layer: Linear(in_features=512, out_features=1000, bias=True)
No dropout layer
New final fully-connected layer: Linear(in_features=512, out_features=10, bias=True)
Linear probing adjusted
Device: 0

Setting a new configuration using tune.grid_search

2024-01-07 16:24:02,046	INFO worker.py:1364 -- Connecting to existing Ray cluster at address: 192.168.7.53:6379...
2024-01-07 16:24:02,071	INFO worker.py:1553 -- Connected to Ray cluster.
2024-01-07 16:24:25,810	WARNING worker.py:1866 -- Warning: The actor ImplicitFunc is very large (44 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.
== Status ==
Current time: 2024-01-07 16:24:25 (running for 00:00:23.07)
Memory usage on this node: 13.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (23 PENDING, 1 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |
|-------------------+----------+--------------------+--------+------------+----------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |
| train_c9cb4_00001 | PENDING  |                    | 0.001  |       0.99 |         0      |
| train_c9cb4_00002 | PENDING  |                    | 0.01   |       0.99 |         0      |
| train_c9cb4_00003 | PENDING  |                    | 0.1    |       0.99 |         0      |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+--------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77085)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77085)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=77085)[0m Configuration completed!
[2m[36m(func pid=77085)[0m New optimizer parameters:
[2m[36m(func pid=77085)[0m SGD (
[2m[36m(func pid=77085)[0m Parameter Group 0
[2m[36m(func pid=77085)[0m     dampening: 0
[2m[36m(func pid=77085)[0m     differentiable: False
[2m[36m(func pid=77085)[0m     foreach: None
[2m[36m(func pid=77085)[0m     lr: 0.0001
[2m[36m(func pid=77085)[0m     maximize: False
[2m[36m(func pid=77085)[0m     momentum: 0.99
[2m[36m(func pid=77085)[0m     nesterov: False
[2m[36m(func pid=77085)[0m     weight_decay: 0
[2m[36m(func pid=77085)[0m )
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0886 | Steps: 4 | Val loss: 0.8048 | Batch size: 32 | lr: 0.0001 | Duration: 5.06s
[2m[36m(func pid=77085)[0m rmse: 0.17886260151863098
[2m[36m(func pid=77085)[0m mae:  0.1313287615776062
[2m[36m(func pid=77085)[0m rmse_per_class: [0.105, 0.265, 0.087, 0.325, 0.101, 0.192, 0.305, 0.154, 0.139, 0.116]
== Status ==
Current time: 2024-01-07 16:24:36 (running for 00:00:33.47)
Memory usage on this node: 15.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (22 PENDING, 2 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |
|-------------------+----------+--------------------+--------+------------+----------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |
| train_c9cb4_00002 | PENDING  |                    | 0.01   |       0.99 |         0      |
| train_c9cb4_00003 | PENDING  |                    | 0.1    |       0.99 |         0      |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+--------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77465)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=77465)[0m Configuration completed!
[2m[36m(func pid=77465)[0m New optimizer parameters:
[2m[36m(func pid=77465)[0m SGD (
[2m[36m(func pid=77465)[0m Parameter Group 0
[2m[36m(func pid=77465)[0m     dampening: 0
[2m[36m(func pid=77465)[0m     differentiable: False
[2m[36m(func pid=77465)[0m     foreach: None
[2m[36m(func pid=77465)[0m     lr: 0.001
[2m[36m(func pid=77465)[0m     maximize: False
[2m[36m(func pid=77465)[0m     momentum: 0.99
[2m[36m(func pid=77465)[0m     nesterov: False
[2m[36m(func pid=77465)[0m     weight_decay: 0
[2m[36m(func pid=77465)[0m )
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0566 | Steps: 4 | Val loss: 0.7500 | Batch size: 32 | lr: 0.001 | Duration: 4.72s
[2m[36m(func pid=77465)[0m rmse: 0.17851459980010986
[2m[36m(func pid=77465)[0m mae:  0.13097959756851196
[2m[36m(func pid=77465)[0m rmse_per_class: [0.105, 0.265, 0.087, 0.324, 0.099, 0.193, 0.304, 0.154, 0.139, 0.115]
== Status ==
Current time: 2024-01-07 16:24:45 (running for 00:00:42.41)
Memory usage on this node: 18.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (21 PENDING, 3 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |
|-------------------+----------+--------------------+--------+------------+----------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |
| train_c9cb4_00003 | PENDING  |                    | 0.1    |       0.99 |         0      |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+--------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77888)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=77888)[0m Configuration completed!
[2m[36m(func pid=77888)[0m New optimizer parameters:
[2m[36m(func pid=77888)[0m SGD (
[2m[36m(func pid=77888)[0m Parameter Group 0
[2m[36m(func pid=77888)[0m     dampening: 0
[2m[36m(func pid=77888)[0m     differentiable: False
[2m[36m(func pid=77888)[0m     foreach: None
[2m[36m(func pid=77888)[0m     lr: 0.01
[2m[36m(func pid=77888)[0m     maximize: False
[2m[36m(func pid=77888)[0m     momentum: 0.99
[2m[36m(func pid=77888)[0m     nesterov: False
[2m[36m(func pid=77888)[0m     weight_decay: 0
[2m[36m(func pid=77888)[0m )
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8692 | Steps: 4 | Val loss: 0.4161 | Batch size: 32 | lr: 0.01 | Duration: 4.67s
[2m[36m(func pid=77888)[0m rmse: 0.17671939730644226
[2m[36m(func pid=77888)[0m mae:  0.12902183830738068
[2m[36m(func pid=77888)[0m rmse_per_class: [0.104, 0.269, 0.089, 0.329, 0.092, 0.192, 0.292, 0.151, 0.141, 0.109]
== Status ==
Current time: 2024-01-07 16:24:54 (running for 00:00:51.67)
Memory usage on this node: 20.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |
|-------------------+----------+--------------------+--------+------------+----------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |
+-------------------+----------+--------------------+--------+------------+----------------+
... 4 more trials not shown (4 PENDING)


== Status ==
Current time: 2024-01-07 16:25:03 (running for 00:01:00.47)
Memory usage on this node: 22.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |        |        |                      |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |        |        |                      |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.869 |  0.177 |                    1 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |        |        |                      |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=78316)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=78316)[0m Configuration completed!
[2m[36m(func pid=78316)[0m New optimizer parameters:
[2m[36m(func pid=78316)[0m SGD (
[2m[36m(func pid=78316)[0m Parameter Group 0
[2m[36m(func pid=78316)[0m     dampening: 0
[2m[36m(func pid=78316)[0m     differentiable: False
[2m[36m(func pid=78316)[0m     foreach: None
[2m[36m(func pid=78316)[0m     lr: 0.1
[2m[36m(func pid=78316)[0m     maximize: False
[2m[36m(func pid=78316)[0m     momentum: 0.99
[2m[36m(func pid=78316)[0m     nesterov: False
[2m[36m(func pid=78316)[0m     weight_decay: 0
[2m[36m(func pid=78316)[0m )
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.9003 | Steps: 4 | Val loss: 0.6110 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0644 | Steps: 4 | Val loss: 0.7997 | Batch size: 32 | lr: 0.0001 | Duration: 3.20s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.4482 | Steps: 4 | Val loss: 0.3495 | Batch size: 32 | lr: 0.01 | Duration: 3.20s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.6741 | Steps: 4 | Val loss: 0.4991 | Batch size: 32 | lr: 0.1 | Duration: 4.58s
== Status ==
Current time: 2024-01-07 16:25:08 (running for 00:01:05.51)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  1.089 |  0.179 |                    1 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  1.057 |  0.179 |                    1 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.869 |  0.177 |                    1 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |        |        |                      |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.17902059853076935
[2m[36m(func pid=77465)[0m mae:  0.13110925257205963
[2m[36m(func pid=77465)[0m rmse_per_class: [0.105, 0.267, 0.09, 0.324, 0.099, 0.193, 0.302, 0.156, 0.138, 0.115]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.174979105591774
[2m[36m(func pid=77888)[0m mae:  0.12398358434438705
[2m[36m(func pid=77888)[0m rmse_per_class: [0.112, 0.274, 0.091, 0.354, 0.072, 0.192, 0.285, 0.133, 0.145, 0.093]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.1796799600124359
[2m[36m(func pid=77085)[0m mae:  0.1319514960050583
[2m[36m(func pid=77085)[0m rmse_per_class: [0.106, 0.265, 0.088, 0.324, 0.104, 0.193, 0.308, 0.154, 0.138, 0.116]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.19902777671813965
[2m[36m(func pid=78316)[0m mae:  0.1273113489151001
[2m[36m(func pid=78316)[0m rmse_per_class: [0.1, 0.294, 0.052, 0.38, 0.056, 0.187, 0.544, 0.148, 0.134, 0.095]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.6722 | Steps: 4 | Val loss: 0.4512 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.5728 | Steps: 4 | Val loss: 0.4757 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 1.0322 | Steps: 4 | Val loss: 0.7753 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0061 | Steps: 4 | Val loss: 0.6506 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 16:25:13 (running for 00:01:11.01)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  1.064 |  0.18  |                    2 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.672 |  0.179 |                    3 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.448 |  0.175 |                    2 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.674 |  0.199 |                    1 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.17861543595790863
[2m[36m(func pid=77465)[0m mae:  0.13051313161849976
[2m[36m(func pid=77465)[0m rmse_per_class: [0.106, 0.268, 0.093, 0.326, 0.096, 0.194, 0.298, 0.153, 0.139, 0.113]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.18715272843837738
[2m[36m(func pid=77888)[0m mae:  0.12410763651132584
[2m[36m(func pid=77888)[0m rmse_per_class: [0.113, 0.282, 0.068, 0.371, 0.056, 0.192, 0.413, 0.145, 0.138, 0.093]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.18025335669517517
[2m[36m(func pid=77085)[0m mae:  0.13239207863807678
[2m[36m(func pid=77085)[0m rmse_per_class: [0.106, 0.265, 0.09, 0.325, 0.105, 0.193, 0.309, 0.155, 0.138, 0.118]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.20697855949401855
[2m[36m(func pid=78316)[0m mae:  0.131556436419487
[2m[36m(func pid=78316)[0m rmse_per_class: [0.11, 0.302, 0.049, 0.389, 0.056, 0.384, 0.388, 0.156, 0.139, 0.097]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.5048 | Steps: 4 | Val loss: 0.3514 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.7417 | Steps: 4 | Val loss: 0.5783 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.9842 | Steps: 4 | Val loss: 0.7428 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.9387 | Steps: 4 | Val loss: 0.4802 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
== Status ==
Current time: 2024-01-07 16:25:19 (running for 00:01:16.10)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  1.032 |  0.18  |                    3 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.505 |  0.177 |                    4 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.573 |  0.187 |                    3 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  1.006 |  0.207 |                    2 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.17702224850654602
[2m[36m(func pid=77465)[0m mae:  0.12881521880626678
[2m[36m(func pid=77465)[0m rmse_per_class: [0.109, 0.27, 0.098, 0.327, 0.09, 0.193, 0.289, 0.144, 0.14, 0.109]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.20076104998588562
[2m[36m(func pid=77888)[0m mae:  0.12926901876926422
[2m[36m(func pid=77888)[0m rmse_per_class: [0.105, 0.288, 0.051, 0.381, 0.056, 0.199, 0.546, 0.153, 0.134, 0.096]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.18034784495830536
[2m[36m(func pid=77085)[0m mae:  0.13245858252048492
[2m[36m(func pid=77085)[0m rmse_per_class: [0.107, 0.265, 0.088, 0.324, 0.106, 0.193, 0.309, 0.154, 0.138, 0.118]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.22105567157268524
[2m[36m(func pid=78316)[0m mae:  0.14640070497989655
[2m[36m(func pid=78316)[0m rmse_per_class: [0.589, 0.282, 0.049, 0.369, 0.056, 0.212, 0.273, 0.155, 0.128, 0.097]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4253 | Steps: 4 | Val loss: 0.3212 | Batch size: 32 | lr: 0.001 | Duration: 2.62s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.8376 | Steps: 4 | Val loss: 0.6167 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.9215 | Steps: 4 | Val loss: 0.6967 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.9108 | Steps: 4 | Val loss: 0.4742 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=77465)[0m rmse: 0.17554804682731628
[2m[36m(func pid=77465)[0m mae:  0.12698140740394592
[2m[36m(func pid=77465)[0m rmse_per_class: [0.113, 0.271, 0.1, 0.333, 0.084, 0.193, 0.278, 0.136, 0.144, 0.104]
[2m[36m(func pid=77465)[0m 
== Status ==
Current time: 2024-01-07 16:25:25 (running for 00:01:22.49)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.984 |  0.18  |                    4 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.425 |  0.176 |                    5 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.838 |  0.207 |                    5 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.939 |  0.221 |                    3 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.20692101120948792
[2m[36m(func pid=77888)[0m mae:  0.13282354176044464
[2m[36m(func pid=77888)[0m rmse_per_class: [0.098, 0.291, 0.048, 0.385, 0.056, 0.205, 0.601, 0.155, 0.134, 0.097]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.18051090836524963
[2m[36m(func pid=77085)[0m mae:  0.1325567215681076
[2m[36m(func pid=77085)[0m rmse_per_class: [0.107, 0.266, 0.088, 0.324, 0.104, 0.194, 0.309, 0.154, 0.138, 0.12]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.17218509316444397
[2m[36m(func pid=78316)[0m mae:  0.11671240627765656
[2m[36m(func pid=78316)[0m rmse_per_class: [0.104, 0.229, 0.049, 0.28, 0.056, 0.221, 0.222, 0.143, 0.157, 0.26]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4337 | Steps: 4 | Val loss: 0.3386 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.8598 | Steps: 4 | Val loss: 0.5942 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.8650 | Steps: 4 | Val loss: 0.6436 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.6242 | Steps: 4 | Val loss: 0.5973 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=77465)[0m rmse: 0.17520901560783386
[2m[36m(func pid=77465)[0m mae:  0.1254052072763443
[2m[36m(func pid=77465)[0m rmse_per_class: [0.117, 0.273, 0.098, 0.341, 0.075, 0.194, 0.272, 0.135, 0.148, 0.1]
[2m[36m(func pid=77465)[0m 
== Status ==
Current time: 2024-01-07 16:25:30 (running for 00:01:27.72)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.921 |  0.181 |                    5 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.434 |  0.175 |                    6 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.86  |  0.209 |                    6 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.911 |  0.172 |                    4 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.20905449986457825
[2m[36m(func pid=77888)[0m mae:  0.13473932445049286
[2m[36m(func pid=77888)[0m rmse_per_class: [0.09, 0.293, 0.048, 0.387, 0.056, 0.209, 0.615, 0.156, 0.138, 0.097]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.18070974946022034
[2m[36m(func pid=77085)[0m mae:  0.13264216482639313
[2m[36m(func pid=77085)[0m rmse_per_class: [0.107, 0.266, 0.089, 0.325, 0.105, 0.194, 0.309, 0.154, 0.138, 0.12]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.20998480916023254
[2m[36m(func pid=78316)[0m mae:  0.13362672924995422
[2m[36m(func pid=78316)[0m rmse_per_class: [0.109, 0.302, 0.059, 0.372, 0.056, 0.418, 0.246, 0.301, 0.144, 0.092]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4669 | Steps: 4 | Val loss: 0.3742 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.8096 | Steps: 4 | Val loss: 0.5339 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.8633 | Steps: 4 | Val loss: 0.6800 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.7811 | Steps: 4 | Val loss: 0.5860 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=77465)[0m rmse: 0.17560407519340515
[2m[36m(func pid=77465)[0m mae:  0.1239829882979393
[2m[36m(func pid=77465)[0m rmse_per_class: [0.12, 0.273, 0.091, 0.348, 0.068, 0.193, 0.277, 0.138, 0.153, 0.095]
[2m[36m(func pid=77465)[0m 
== Status ==
Current time: 2024-01-07 16:25:35 (running for 00:01:33.09)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.865 |  0.181 |                    6 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.467 |  0.176 |                    7 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.81  |  0.202 |                    7 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.624 |  0.21  |                    5 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.20234496891498566
[2m[36m(func pid=77888)[0m mae:  0.13096538186073303
[2m[36m(func pid=77888)[0m rmse_per_class: [0.094, 0.29, 0.049, 0.387, 0.056, 0.202, 0.515, 0.156, 0.177, 0.097]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.24460986256599426
[2m[36m(func pid=78316)[0m mae:  0.14923609793186188
[2m[36m(func pid=78316)[0m rmse_per_class: [0.11, 0.302, 0.442, 0.352, 0.055, 0.379, 0.328, 0.23, 0.153, 0.095]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.18057957291603088
[2m[36m(func pid=77085)[0m mae:  0.13236287236213684
[2m[36m(func pid=77085)[0m rmse_per_class: [0.108, 0.267, 0.088, 0.324, 0.106, 0.194, 0.308, 0.154, 0.138, 0.12]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5159 | Steps: 4 | Val loss: 0.4121 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.7551 | Steps: 4 | Val loss: 0.4737 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.6823 | Steps: 4 | Val loss: 0.4442 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=77465)[0m rmse: 0.17673087120056152
[2m[36m(func pid=77465)[0m mae:  0.12305182218551636
[2m[36m(func pid=77465)[0m rmse_per_class: [0.118, 0.274, 0.081, 0.355, 0.062, 0.193, 0.292, 0.142, 0.156, 0.094]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.7160 | Steps: 4 | Val loss: 0.5300 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 16:25:41 (running for 00:01:38.49)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.781 |  0.181 |                    7 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.516 |  0.177 |                    8 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.755 |  0.191 |                    8 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.863 |  0.245 |                    6 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.19106803834438324
[2m[36m(func pid=77888)[0m mae:  0.12608255445957184
[2m[36m(func pid=77888)[0m rmse_per_class: [0.149, 0.276, 0.049, 0.385, 0.056, 0.181, 0.281, 0.156, 0.28, 0.097]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.19558565318584442
[2m[36m(func pid=78316)[0m mae:  0.11446783691644669
[2m[36m(func pid=78316)[0m rmse_per_class: [0.073, 0.29, 0.093, 0.269, 0.265, 0.207, 0.221, 0.14, 0.277, 0.121]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.1805492788553238
[2m[36m(func pid=77085)[0m mae:  0.1322435438632965
[2m[36m(func pid=77085)[0m rmse_per_class: [0.109, 0.267, 0.087, 0.324, 0.105, 0.194, 0.307, 0.153, 0.138, 0.121]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5614 | Steps: 4 | Val loss: 0.4534 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.7103 | Steps: 4 | Val loss: 0.4363 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.6337 | Steps: 4 | Val loss: 0.5661 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=77465)[0m rmse: 0.17959658801555634
[2m[36m(func pid=77465)[0m mae:  0.12274432182312012
[2m[36m(func pid=77465)[0m rmse_per_class: [0.117, 0.276, 0.071, 0.362, 0.058, 0.193, 0.323, 0.145, 0.158, 0.093]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.6568 | Steps: 4 | Val loss: 0.4791 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 16:25:46 (running for 00:01:43.85)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.716 |  0.181 |                    8 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.561 |  0.18  |                    9 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.71  |  0.181 |                    9 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.682 |  0.196 |                    7 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.18058595061302185
[2m[36m(func pid=77888)[0m mae:  0.12341785430908203
[2m[36m(func pid=77888)[0m rmse_per_class: [0.155, 0.234, 0.049, 0.373, 0.056, 0.216, 0.227, 0.156, 0.244, 0.097]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.14847157895565033
[2m[36m(func pid=78316)[0m mae:  0.09106066077947617
[2m[36m(func pid=78316)[0m rmse_per_class: [0.098, 0.224, 0.029, 0.253, 0.096, 0.177, 0.205, 0.149, 0.125, 0.129]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.18057191371917725
[2m[36m(func pid=77085)[0m mae:  0.1322210133075714
[2m[36m(func pid=77085)[0m rmse_per_class: [0.11, 0.267, 0.088, 0.325, 0.102, 0.194, 0.306, 0.152, 0.139, 0.122]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.6105 | Steps: 4 | Val loss: 0.4809 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.6655 | Steps: 4 | Val loss: 0.3985 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.6794 | Steps: 4 | Val loss: 0.4881 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=77465)[0m rmse: 0.18201449513435364
[2m[36m(func pid=77465)[0m mae:  0.12275513261556625
[2m[36m(func pid=77465)[0m rmse_per_class: [0.113, 0.276, 0.065, 0.366, 0.056, 0.192, 0.352, 0.148, 0.159, 0.092]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.6011 | Steps: 4 | Val loss: 0.4369 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 16:25:51 (running for 00:01:49.06)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.657 |  0.181 |                    9 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.611 |  0.182 |                   10 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.666 |  0.169 |                   10 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.634 |  0.148 |                    8 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.1692350208759308
[2m[36m(func pid=77888)[0m mae:  0.11500783264636993
[2m[36m(func pid=77888)[0m rmse_per_class: [0.086, 0.251, 0.047, 0.303, 0.056, 0.268, 0.284, 0.156, 0.146, 0.094]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.19492562115192413
[2m[36m(func pid=78316)[0m mae:  0.11073337495326996
[2m[36m(func pid=78316)[0m rmse_per_class: [0.135, 0.236, 0.028, 0.337, 0.053, 0.401, 0.325, 0.141, 0.203, 0.088]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.6567 | Steps: 4 | Val loss: 0.5151 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=77085)[0m rmse: 0.18057017028331757
[2m[36m(func pid=77085)[0m mae:  0.132137268781662
[2m[36m(func pid=77085)[0m rmse_per_class: [0.11, 0.268, 0.09, 0.327, 0.1, 0.194, 0.304, 0.151, 0.14, 0.121]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.5705 | Steps: 4 | Val loss: 0.3513 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=77465)[0m rmse: 0.18594703078269958
[2m[36m(func pid=77465)[0m mae:  0.1234162300825119
[2m[36m(func pid=77465)[0m rmse_per_class: [0.11, 0.278, 0.059, 0.37, 0.056, 0.193, 0.394, 0.15, 0.156, 0.093]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.6346 | Steps: 4 | Val loss: 0.6755 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.5508 | Steps: 4 | Val loss: 0.4059 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 16:25:57 (running for 00:01:54.63)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.601 |  0.181 |                   10 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.657 |  0.186 |                   11 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.571 |  0.155 |                   11 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.679 |  0.195 |                    9 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.15498578548431396
[2m[36m(func pid=77888)[0m mae:  0.10349875688552856
[2m[36m(func pid=77888)[0m rmse_per_class: [0.073, 0.231, 0.034, 0.296, 0.056, 0.181, 0.304, 0.155, 0.128, 0.091]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.20518365502357483
[2m[36m(func pid=78316)[0m mae:  0.11635394394397736
[2m[36m(func pid=78316)[0m rmse_per_class: [0.084, 0.284, 0.034, 0.301, 0.056, 0.195, 0.312, 0.277, 0.42, 0.088]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.6765 | Steps: 4 | Val loss: 0.5350 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=77085)[0m rmse: 0.18021069467067719
[2m[36m(func pid=77085)[0m mae:  0.13173121213912964
[2m[36m(func pid=77085)[0m rmse_per_class: [0.111, 0.269, 0.092, 0.328, 0.098, 0.194, 0.3, 0.148, 0.141, 0.12]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.5516 | Steps: 4 | Val loss: 0.3791 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=77465)[0m rmse: 0.18900084495544434
[2m[36m(func pid=77465)[0m mae:  0.12398089468479156
[2m[36m(func pid=77465)[0m rmse_per_class: [0.105, 0.28, 0.054, 0.373, 0.055, 0.193, 0.433, 0.152, 0.152, 0.093]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.8084 | Steps: 4 | Val loss: 0.6980 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.5123 | Steps: 4 | Val loss: 0.3779 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 16:26:02 (running for 00:01:60.00)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.551 |  0.18  |                   11 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.676 |  0.189 |                   12 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.552 |  0.188 |                   12 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.635 |  0.205 |                   10 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.1876898854970932
[2m[36m(func pid=77888)[0m mae:  0.12363111972808838
[2m[36m(func pid=77888)[0m rmse_per_class: [0.092, 0.251, 0.051, 0.336, 0.056, 0.191, 0.303, 0.146, 0.134, 0.316]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.2102150022983551
[2m[36m(func pid=78316)[0m mae:  0.12508925795555115
[2m[36m(func pid=78316)[0m rmse_per_class: [0.087, 0.288, 0.041, 0.327, 0.056, 0.225, 0.496, 0.172, 0.32, 0.089]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.7215 | Steps: 4 | Val loss: 0.5418 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=77085)[0m rmse: 0.17980772256851196
[2m[36m(func pid=77085)[0m mae:  0.13113269209861755
[2m[36m(func pid=77085)[0m rmse_per_class: [0.111, 0.27, 0.094, 0.329, 0.098, 0.194, 0.296, 0.146, 0.141, 0.118]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.5809 | Steps: 4 | Val loss: 0.3874 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
[2m[36m(func pid=77465)[0m rmse: 0.19215954840183258
[2m[36m(func pid=77465)[0m mae:  0.12510496377944946
[2m[36m(func pid=77465)[0m rmse_per_class: [0.102, 0.282, 0.051, 0.375, 0.056, 0.193, 0.466, 0.152, 0.15, 0.094]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.7006 | Steps: 4 | Val loss: 0.5212 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4805 | Steps: 4 | Val loss: 0.3559 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 16:26:08 (running for 00:02:05.70)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.512 |  0.18  |                   12 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.721 |  0.192 |                   13 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.581 |  0.202 |                   13 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.808 |  0.21  |                   11 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.20204982161521912
[2m[36m(func pid=77888)[0m mae:  0.1321772336959839
[2m[36m(func pid=77888)[0m rmse_per_class: [0.099, 0.288, 0.177, 0.256, 0.056, 0.211, 0.27, 0.108, 0.136, 0.418]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.19998855888843536
[2m[36m(func pid=78316)[0m mae:  0.10885585844516754
[2m[36m(func pid=78316)[0m rmse_per_class: [0.083, 0.273, 0.031, 0.314, 0.056, 0.26, 0.296, 0.221, 0.265, 0.201]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7202 | Steps: 4 | Val loss: 0.5484 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=77085)[0m rmse: 0.17929688096046448
[2m[36m(func pid=77085)[0m mae:  0.1305304765701294
[2m[36m(func pid=77085)[0m rmse_per_class: [0.112, 0.271, 0.096, 0.331, 0.098, 0.194, 0.292, 0.142, 0.142, 0.116]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.19573922455310822
[2m[36m(func pid=77465)[0m mae:  0.12641878426074982
[2m[36m(func pid=77465)[0m rmse_per_class: [0.099, 0.284, 0.049, 0.377, 0.056, 0.194, 0.504, 0.153, 0.146, 0.094]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4895 | Steps: 4 | Val loss: 0.4160 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.6170 | Steps: 4 | Val loss: 0.6120 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4515 | Steps: 4 | Val loss: 0.3415 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 16:26:14 (running for 00:02:11.29)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.481 |  0.179 |                   13 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.72  |  0.196 |                   14 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.489 |  0.214 |                   14 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.701 |  0.2   |                   12 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.7184 | Steps: 4 | Val loss: 0.5536 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=77888)[0m rmse: 0.21393117308616638
[2m[36m(func pid=77888)[0m mae:  0.1336682289838791
[2m[36m(func pid=77888)[0m rmse_per_class: [0.091, 0.292, 0.33, 0.289, 0.056, 0.219, 0.234, 0.308, 0.135, 0.184]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.18109746277332306
[2m[36m(func pid=78316)[0m mae:  0.10533956438302994
[2m[36m(func pid=78316)[0m rmse_per_class: [0.109, 0.261, 0.026, 0.279, 0.056, 0.35, 0.314, 0.154, 0.128, 0.134]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.1787436455488205
[2m[36m(func pid=77085)[0m mae:  0.13008108735084534
[2m[36m(func pid=77085)[0m rmse_per_class: [0.112, 0.27, 0.095, 0.332, 0.095, 0.194, 0.29, 0.141, 0.145, 0.115]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.1986990123987198
[2m[36m(func pid=77465)[0m mae:  0.12769076228141785
[2m[36m(func pid=77465)[0m rmse_per_class: [0.098, 0.286, 0.048, 0.379, 0.056, 0.195, 0.532, 0.154, 0.144, 0.095]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.5224 | Steps: 4 | Val loss: 0.4832 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.6120 | Steps: 4 | Val loss: 0.5229 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4348 | Steps: 4 | Val loss: 0.3323 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 16:26:19 (running for 00:02:16.67)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.451 |  0.179 |                   14 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.718 |  0.199 |                   15 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.522 |  0.221 |                   15 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.617 |  0.181 |                   13 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.7198 | Steps: 4 | Val loss: 0.5430 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=77888)[0m rmse: 0.2206798791885376
[2m[36m(func pid=77888)[0m mae:  0.14157220721244812
[2m[36m(func pid=77888)[0m rmse_per_class: [0.077, 0.292, 0.251, 0.346, 0.056, 0.224, 0.221, 0.517, 0.135, 0.088]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.16872088611125946
[2m[36m(func pid=78316)[0m mae:  0.09212084114551544
[2m[36m(func pid=78316)[0m rmse_per_class: [0.131, 0.242, 0.043, 0.279, 0.056, 0.198, 0.328, 0.134, 0.163, 0.114]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.17848284542560577
[2m[36m(func pid=77085)[0m mae:  0.12982705235481262
[2m[36m(func pid=77085)[0m rmse_per_class: [0.111, 0.27, 0.097, 0.334, 0.091, 0.194, 0.287, 0.141, 0.146, 0.115]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.20040059089660645
[2m[36m(func pid=77465)[0m mae:  0.12829764187335968
[2m[36m(func pid=77465)[0m rmse_per_class: [0.096, 0.287, 0.048, 0.38, 0.056, 0.194, 0.552, 0.154, 0.141, 0.095]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.6620 | Steps: 4 | Val loss: 0.6606 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.5758 | Steps: 4 | Val loss: 0.4900 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.4248 | Steps: 4 | Val loss: 0.3277 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 16:26:24 (running for 00:02:22.03)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.435 |  0.178 |                   15 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.72  |  0.2   |                   16 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.522 |  0.221 |                   15 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.662 |  0.206 |                   15 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.6875 | Steps: 4 | Val loss: 0.5297 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=78316)[0m rmse: 0.20552273094654083
[2m[36m(func pid=78316)[0m mae:  0.11245147138834
[2m[36m(func pid=78316)[0m rmse_per_class: [0.097, 0.269, 0.1, 0.366, 0.084, 0.215, 0.293, 0.154, 0.382, 0.095]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.20751091837882996
[2m[36m(func pid=77888)[0m mae:  0.13494762778282166
[2m[36m(func pid=77888)[0m rmse_per_class: [0.078, 0.288, 0.108, 0.359, 0.055, 0.219, 0.234, 0.509, 0.133, 0.091]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.17824521660804749
[2m[36m(func pid=77085)[0m mae:  0.1296112984418869
[2m[36m(func pid=77085)[0m rmse_per_class: [0.113, 0.27, 0.099, 0.335, 0.087, 0.195, 0.286, 0.139, 0.146, 0.113]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.2013605386018753
[2m[36m(func pid=77465)[0m mae:  0.12864378094673157
[2m[36m(func pid=77465)[0m rmse_per_class: [0.095, 0.287, 0.048, 0.38, 0.056, 0.194, 0.563, 0.155, 0.14, 0.095]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.5117 | Steps: 4 | Val loss: 0.3976 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.6635 | Steps: 4 | Val loss: 0.7159 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4200 | Steps: 4 | Val loss: 0.3256 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.7041 | Steps: 4 | Val loss: 0.5053 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 16:26:30 (running for 00:02:27.42)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.425 |  0.178 |                   16 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.687 |  0.201 |                   17 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.512 |  0.186 |                   17 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.662 |  0.206 |                   15 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.18602624535560608
[2m[36m(func pid=77888)[0m mae:  0.11599405854940414
[2m[36m(func pid=77888)[0m rmse_per_class: [0.125, 0.263, 0.036, 0.336, 0.048, 0.191, 0.291, 0.312, 0.166, 0.093]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.23082351684570312
[2m[36m(func pid=78316)[0m mae:  0.12440784275531769
[2m[36m(func pid=78316)[0m rmse_per_class: [0.085, 0.265, 0.102, 0.344, 0.182, 0.266, 0.317, 0.18, 0.435, 0.131]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.17793691158294678
[2m[36m(func pid=77085)[0m mae:  0.12917587161064148
[2m[36m(func pid=77085)[0m rmse_per_class: [0.114, 0.27, 0.101, 0.337, 0.085, 0.195, 0.283, 0.138, 0.148, 0.11]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.20129330456256866
[2m[36m(func pid=77465)[0m mae:  0.12831658124923706
[2m[36m(func pid=77465)[0m rmse_per_class: [0.095, 0.287, 0.048, 0.381, 0.056, 0.191, 0.566, 0.155, 0.138, 0.095]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4055 | Steps: 4 | Val loss: 0.3076 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.6653 | Steps: 4 | Val loss: 0.6320 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4238 | Steps: 4 | Val loss: 0.3266 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.6881 | Steps: 4 | Val loss: 0.4832 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 16:26:35 (running for 00:02:32.68)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.42  |  0.178 |                   17 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.704 |  0.201 |                   18 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.405 |  0.159 |                   18 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.664 |  0.231 |                   16 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.15850375592708588
[2m[36m(func pid=77888)[0m mae:  0.09443821758031845
[2m[36m(func pid=77888)[0m rmse_per_class: [0.151, 0.223, 0.026, 0.293, 0.088, 0.172, 0.209, 0.122, 0.207, 0.094]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.2158629447221756
[2m[36m(func pid=78316)[0m mae:  0.12162376940250397
[2m[36m(func pid=78316)[0m rmse_per_class: [0.085, 0.27, 0.042, 0.318, 0.137, 0.433, 0.314, 0.146, 0.24, 0.174]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.17778658866882324
[2m[36m(func pid=77085)[0m mae:  0.12900786101818085
[2m[36m(func pid=77085)[0m rmse_per_class: [0.115, 0.271, 0.1, 0.339, 0.083, 0.195, 0.281, 0.137, 0.149, 0.109]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.20009136199951172
[2m[36m(func pid=77465)[0m mae:  0.12750770151615143
[2m[36m(func pid=77465)[0m rmse_per_class: [0.093, 0.286, 0.048, 0.38, 0.056, 0.19, 0.559, 0.155, 0.138, 0.096]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3753 | Steps: 4 | Val loss: 0.3384 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.6063 | Steps: 4 | Val loss: 0.5919 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.6729 | Steps: 4 | Val loss: 0.4585 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.4200 | Steps: 4 | Val loss: 0.3294 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 16:26:40 (running for 00:02:37.78)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.424 |  0.178 |                   18 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.688 |  0.2   |                   19 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.375 |  0.169 |                   19 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.665 |  0.216 |                   17 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.16909031569957733
[2m[36m(func pid=77888)[0m mae:  0.10699363797903061
[2m[36m(func pid=77888)[0m rmse_per_class: [0.106, 0.205, 0.04, 0.282, 0.185, 0.218, 0.247, 0.125, 0.188, 0.094]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.17054735124111176
[2m[36m(func pid=78316)[0m mae:  0.09522426128387451
[2m[36m(func pid=78316)[0m rmse_per_class: [0.085, 0.248, 0.033, 0.299, 0.1, 0.195, 0.273, 0.137, 0.157, 0.178]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.1969059407711029
[2m[36m(func pid=77465)[0m mae:  0.12554681301116943
[2m[36m(func pid=77465)[0m rmse_per_class: [0.091, 0.283, 0.048, 0.378, 0.056, 0.187, 0.535, 0.155, 0.139, 0.096]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.17799720168113708
[2m[36m(func pid=77085)[0m mae:  0.12895363569259644
[2m[36m(func pid=77085)[0m rmse_per_class: [0.115, 0.271, 0.104, 0.34, 0.083, 0.195, 0.279, 0.136, 0.15, 0.108]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4771 | Steps: 4 | Val loss: 0.4187 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.6527 | Steps: 4 | Val loss: 0.6510 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.6060 | Steps: 4 | Val loss: 0.4297 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 16:26:45 (running for 00:02:43.03)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.42  |  0.178 |                   19 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.673 |  0.197 |                   20 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.477 |  0.17  |                   20 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.606 |  0.171 |                   18 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.16950422525405884
[2m[36m(func pid=77888)[0m mae:  0.11125610023736954
[2m[36m(func pid=77888)[0m rmse_per_class: [0.072, 0.202, 0.045, 0.258, 0.214, 0.226, 0.284, 0.142, 0.16, 0.093]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.2127065360546112
[2m[36m(func pid=78316)[0m mae:  0.11946424096822739
[2m[36m(func pid=78316)[0m rmse_per_class: [0.158, 0.251, 0.037, 0.292, 0.117, 0.213, 0.322, 0.418, 0.152, 0.168]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4270 | Steps: 4 | Val loss: 0.3325 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
[2m[36m(func pid=77465)[0m rmse: 0.19129589200019836
[2m[36m(func pid=77465)[0m mae:  0.1223360076546669
[2m[36m(func pid=77465)[0m rmse_per_class: [0.089, 0.278, 0.048, 0.375, 0.056, 0.185, 0.489, 0.155, 0.141, 0.095]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.17747482657432556
[2m[36m(func pid=77085)[0m mae:  0.12829402089118958
[2m[36m(func pid=77085)[0m rmse_per_class: [0.113, 0.272, 0.104, 0.341, 0.08, 0.195, 0.277, 0.135, 0.151, 0.106]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4619 | Steps: 4 | Val loss: 0.3598 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.8242 | Steps: 4 | Val loss: 0.6300 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.5969 | Steps: 4 | Val loss: 0.4028 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
== Status ==
Current time: 2024-01-07 16:26:51 (running for 00:02:48.16)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.427 |  0.177 |                   20 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.606 |  0.191 |                   21 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.462 |  0.157 |                   21 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.653 |  0.213 |                   19 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.15700608491897583
[2m[36m(func pid=77888)[0m mae:  0.09999281913042068
[2m[36m(func pid=77888)[0m rmse_per_class: [0.064, 0.198, 0.045, 0.241, 0.165, 0.216, 0.268, 0.144, 0.15, 0.08]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.20230934023857117
[2m[36m(func pid=78316)[0m mae:  0.10610146820545197
[2m[36m(func pid=78316)[0m rmse_per_class: [0.136, 0.259, 0.038, 0.38, 0.081, 0.219, 0.302, 0.261, 0.179, 0.168]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4382 | Steps: 4 | Val loss: 0.3381 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=77465)[0m rmse: 0.18533268570899963
[2m[36m(func pid=77465)[0m mae:  0.11897680908441544
[2m[36m(func pid=77465)[0m rmse_per_class: [0.088, 0.273, 0.048, 0.371, 0.056, 0.187, 0.437, 0.155, 0.142, 0.095]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.17692889273166656
[2m[36m(func pid=77085)[0m mae:  0.12747056782245636
[2m[36m(func pid=77085)[0m rmse_per_class: [0.114, 0.272, 0.104, 0.342, 0.078, 0.195, 0.275, 0.135, 0.151, 0.104]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3964 | Steps: 4 | Val loss: 0.3253 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.6326 | Steps: 4 | Val loss: 0.6140 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.5654 | Steps: 4 | Val loss: 0.3756 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 16:26:56 (running for 00:02:53.61)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.438 |  0.177 |                   21 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.597 |  0.185 |                   22 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.396 |  0.153 |                   22 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.824 |  0.202 |                   20 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.15293174982070923
[2m[36m(func pid=77888)[0m mae:  0.09140373021364212
[2m[36m(func pid=77888)[0m rmse_per_class: [0.063, 0.204, 0.045, 0.294, 0.084, 0.183, 0.235, 0.147, 0.14, 0.136]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.17723765969276428
[2m[36m(func pid=78316)[0m mae:  0.09688328206539154
[2m[36m(func pid=78316)[0m rmse_per_class: [0.087, 0.264, 0.036, 0.363, 0.056, 0.204, 0.338, 0.144, 0.17, 0.109]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4387 | Steps: 4 | Val loss: 0.3434 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=77465)[0m rmse: 0.1784440129995346
[2m[36m(func pid=77465)[0m mae:  0.11541817337274551
[2m[36m(func pid=77465)[0m rmse_per_class: [0.09, 0.265, 0.048, 0.364, 0.056, 0.196, 0.369, 0.155, 0.146, 0.095]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4424 | Steps: 4 | Val loss: 0.3444 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=77085)[0m rmse: 0.17718598246574402
[2m[36m(func pid=77085)[0m mae:  0.12750288844108582
[2m[36m(func pid=77085)[0m rmse_per_class: [0.114, 0.272, 0.105, 0.345, 0.076, 0.194, 0.274, 0.135, 0.154, 0.103]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.6585 | Steps: 4 | Val loss: 0.6695 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.5524 | Steps: 4 | Val loss: 0.3531 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 16:27:01 (running for 00:02:58.95)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.439 |  0.177 |                   22 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.565 |  0.178 |                   23 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.442 |  0.164 |                   23 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.633 |  0.177 |                   21 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.16402554512023926
[2m[36m(func pid=77888)[0m mae:  0.09657593071460724
[2m[36m(func pid=77888)[0m rmse_per_class: [0.065, 0.243, 0.045, 0.266, 0.048, 0.183, 0.209, 0.145, 0.122, 0.315]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.1916046291589737
[2m[36m(func pid=78316)[0m mae:  0.10905726253986359
[2m[36m(func pid=78316)[0m rmse_per_class: [0.089, 0.276, 0.037, 0.303, 0.056, 0.371, 0.299, 0.142, 0.251, 0.092]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4453 | Steps: 4 | Val loss: 0.3502 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=77465)[0m rmse: 0.17157527804374695
[2m[36m(func pid=77465)[0m mae:  0.11250573396682739
[2m[36m(func pid=77465)[0m rmse_per_class: [0.098, 0.256, 0.049, 0.352, 0.056, 0.209, 0.293, 0.155, 0.151, 0.095]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4583 | Steps: 4 | Val loss: 0.3888 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=77085)[0m rmse: 0.17679893970489502
[2m[36m(func pid=77085)[0m mae:  0.12694242596626282
[2m[36m(func pid=77085)[0m rmse_per_class: [0.113, 0.272, 0.103, 0.346, 0.074, 0.195, 0.273, 0.135, 0.154, 0.103]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.7443 | Steps: 4 | Val loss: 0.8527 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.5472 | Steps: 4 | Val loss: 0.3357 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 16:27:07 (running for 00:03:04.13)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.445 |  0.177 |                   23 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.552 |  0.172 |                   24 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.458 |  0.179 |                   24 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.658 |  0.192 |                   22 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.17946794629096985
[2m[36m(func pid=77888)[0m mae:  0.10604608058929443
[2m[36m(func pid=77888)[0m rmse_per_class: [0.07, 0.265, 0.043, 0.25, 0.051, 0.201, 0.251, 0.147, 0.12, 0.395]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.23939093947410583
[2m[36m(func pid=78316)[0m mae:  0.14505775272846222
[2m[36m(func pid=78316)[0m rmse_per_class: [0.083, 0.277, 0.052, 0.363, 0.056, 0.244, 0.337, 0.452, 0.429, 0.1]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4566 | Steps: 4 | Val loss: 0.3545 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=77465)[0m rmse: 0.16648134589195251
[2m[36m(func pid=77465)[0m mae:  0.11094024032354355
[2m[36m(func pid=77465)[0m rmse_per_class: [0.111, 0.247, 0.049, 0.339, 0.056, 0.216, 0.241, 0.155, 0.156, 0.095]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.5070 | Steps: 4 | Val loss: 0.3997 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.7219 | Steps: 4 | Val loss: 0.7700 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=77085)[0m rmse: 0.17640922963619232
[2m[36m(func pid=77085)[0m mae:  0.126594677567482
[2m[36m(func pid=77085)[0m rmse_per_class: [0.113, 0.271, 0.098, 0.347, 0.074, 0.194, 0.272, 0.135, 0.158, 0.101]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4969 | Steps: 4 | Val loss: 0.3241 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 16:27:12 (running for 00:03:09.36)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.457 |  0.176 |                   24 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.547 |  0.166 |                   25 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.507 |  0.186 |                   25 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.744 |  0.239 |                   23 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.1862594187259674
[2m[36m(func pid=77888)[0m mae:  0.10948795080184937
[2m[36m(func pid=77888)[0m rmse_per_class: [0.072, 0.271, 0.037, 0.257, 0.054, 0.206, 0.387, 0.141, 0.122, 0.314]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.2417534589767456
[2m[36m(func pid=78316)[0m mae:  0.134109228849411
[2m[36m(func pid=78316)[0m rmse_per_class: [0.186, 0.329, 0.072, 0.364, 0.058, 0.224, 0.324, 0.432, 0.263, 0.165]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4649 | Steps: 4 | Val loss: 0.3631 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=77465)[0m rmse: 0.16308699548244476
[2m[36m(func pid=77465)[0m mae:  0.10982058197259903
[2m[36m(func pid=77465)[0m rmse_per_class: [0.118, 0.241, 0.049, 0.323, 0.056, 0.218, 0.223, 0.155, 0.155, 0.094]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4584 | Steps: 4 | Val loss: 0.3989 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.6583 | Steps: 4 | Val loss: 0.6625 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=77085)[0m rmse: 0.17648082971572876
[2m[36m(func pid=77085)[0m mae:  0.12644536793231964
[2m[36m(func pid=77085)[0m rmse_per_class: [0.115, 0.271, 0.097, 0.348, 0.072, 0.194, 0.272, 0.136, 0.16, 0.101]
[2m[36m(func pid=77085)[0m 
== Status ==
Current time: 2024-01-07 16:27:17 (running for 00:03:14.43)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.465 |  0.176 |                   25 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.497 |  0.163 |                   26 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.458 |  0.18  |                   26 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.722 |  0.242 |                   24 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.1797696352005005
[2m[36m(func pid=77888)[0m mae:  0.1058233380317688
[2m[36m(func pid=77888)[0m rmse_per_class: [0.072, 0.254, 0.028, 0.267, 0.056, 0.198, 0.45, 0.135, 0.134, 0.205]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.5039 | Steps: 4 | Val loss: 0.3217 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=78316)[0m rmse: 0.20160774886608124
[2m[36m(func pid=78316)[0m mae:  0.11076752096414566
[2m[36m(func pid=78316)[0m rmse_per_class: [0.298, 0.31, 0.03, 0.335, 0.058, 0.207, 0.324, 0.138, 0.13, 0.187]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4647 | Steps: 4 | Val loss: 0.3702 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=77465)[0m rmse: 0.16100819408893585
[2m[36m(func pid=77465)[0m mae:  0.10924327373504639
[2m[36m(func pid=77465)[0m rmse_per_class: [0.119, 0.239, 0.049, 0.305, 0.056, 0.211, 0.227, 0.154, 0.156, 0.093]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4740 | Steps: 4 | Val loss: 0.3894 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.7565 | Steps: 4 | Val loss: 0.5918 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=77085)[0m rmse: 0.1764306277036667
[2m[36m(func pid=77085)[0m mae:  0.12610721588134766
[2m[36m(func pid=77085)[0m rmse_per_class: [0.114, 0.271, 0.098, 0.35, 0.07, 0.194, 0.271, 0.136, 0.161, 0.1]
[2m[36m(func pid=77085)[0m 
== Status ==
Current time: 2024-01-07 16:27:22 (running for 00:03:19.92)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.465 |  0.176 |                   26 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.504 |  0.161 |                   27 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.474 |  0.164 |                   27 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.658 |  0.202 |                   25 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.16358566284179688
[2m[36m(func pid=77888)[0m mae:  0.0934448391199112
[2m[36m(func pid=77888)[0m rmse_per_class: [0.082, 0.229, 0.03, 0.271, 0.056, 0.172, 0.368, 0.126, 0.178, 0.124]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4862 | Steps: 4 | Val loss: 0.3263 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=78316)[0m rmse: 0.18788295984268188
[2m[36m(func pid=78316)[0m mae:  0.10404697805643082
[2m[36m(func pid=78316)[0m rmse_per_class: [0.113, 0.252, 0.042, 0.309, 0.059, 0.363, 0.28, 0.148, 0.127, 0.187]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4746 | Steps: 4 | Val loss: 0.3762 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=77465)[0m rmse: 0.1599365621805191
[2m[36m(func pid=77465)[0m mae:  0.10921543836593628
[2m[36m(func pid=77465)[0m rmse_per_class: [0.115, 0.24, 0.048, 0.289, 0.056, 0.203, 0.245, 0.154, 0.157, 0.091]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4147 | Steps: 4 | Val loss: 0.3699 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.6907 | Steps: 4 | Val loss: 0.8228 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=77085)[0m rmse: 0.17607776820659637
[2m[36m(func pid=77085)[0m mae:  0.12538360059261322
[2m[36m(func pid=77085)[0m rmse_per_class: [0.113, 0.271, 0.097, 0.35, 0.069, 0.194, 0.27, 0.137, 0.16, 0.099]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4733 | Steps: 4 | Val loss: 0.3298 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=77888)[0m rmse: 0.16107839345932007
[2m[36m(func pid=77888)[0m mae:  0.09098586440086365
[2m[36m(func pid=77888)[0m rmse_per_class: [0.087, 0.225, 0.035, 0.281, 0.056, 0.228, 0.254, 0.141, 0.225, 0.079]
[2m[36m(func pid=77888)[0m 
== Status ==
Current time: 2024-01-07 16:27:28 (running for 00:03:25.32)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.475 |  0.176 |                   27 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.486 |  0.16  |                   28 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.415 |  0.161 |                   28 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.757 |  0.188 |                   26 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=78316)[0m rmse: 0.21190638840198517
[2m[36m(func pid=78316)[0m mae:  0.12322696298360825
[2m[36m(func pid=78316)[0m rmse_per_class: [0.09, 0.263, 0.034, 0.516, 0.103, 0.296, 0.351, 0.141, 0.15, 0.176]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4823 | Steps: 4 | Val loss: 0.3848 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=77465)[0m rmse: 0.15845805406570435
[2m[36m(func pid=77465)[0m mae:  0.10875805467367172
[2m[36m(func pid=77465)[0m rmse_per_class: [0.11, 0.242, 0.048, 0.277, 0.056, 0.192, 0.26, 0.153, 0.157, 0.089]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3792 | Steps: 4 | Val loss: 0.3673 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.7739 | Steps: 4 | Val loss: 0.8511 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=77085)[0m rmse: 0.17615775763988495
[2m[36m(func pid=77085)[0m mae:  0.1251431703567505
[2m[36m(func pid=77085)[0m rmse_per_class: [0.115, 0.271, 0.096, 0.351, 0.066, 0.193, 0.272, 0.138, 0.161, 0.099]
[2m[36m(func pid=77085)[0m 
== Status ==
Current time: 2024-01-07 16:27:33 (running for 00:03:30.78)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.482 |  0.176 |                   28 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.473 |  0.158 |                   29 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.379 |  0.176 |                   29 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.691 |  0.212 |                   27 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.5037 | Steps: 4 | Val loss: 0.3339 | Batch size: 32 | lr: 0.001 | Duration: 3.17s
[2m[36m(func pid=77888)[0m rmse: 0.17644868791103363
[2m[36m(func pid=77888)[0m mae:  0.10322315990924835
[2m[36m(func pid=77888)[0m rmse_per_class: [0.08, 0.225, 0.035, 0.289, 0.056, 0.317, 0.274, 0.148, 0.257, 0.083]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.24507367610931396
[2m[36m(func pid=78316)[0m mae:  0.14157554507255554
[2m[36m(func pid=78316)[0m rmse_per_class: [0.087, 0.271, 0.035, 0.32, 0.177, 0.228, 0.352, 0.465, 0.364, 0.152]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4863 | Steps: 4 | Val loss: 0.3875 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=77465)[0m rmse: 0.15775419771671295
[2m[36m(func pid=77465)[0m mae:  0.10898818075656891
[2m[36m(func pid=77465)[0m rmse_per_class: [0.108, 0.243, 0.048, 0.271, 0.056, 0.182, 0.274, 0.15, 0.156, 0.089]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4419 | Steps: 4 | Val loss: 0.3824 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.7312 | Steps: 4 | Val loss: 0.7789 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=77085)[0m rmse: 0.17636342346668243
[2m[36m(func pid=77085)[0m mae:  0.1252051293849945
[2m[36m(func pid=77085)[0m rmse_per_class: [0.115, 0.271, 0.097, 0.351, 0.065, 0.194, 0.272, 0.138, 0.162, 0.099]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4626 | Steps: 4 | Val loss: 0.3275 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 16:27:39 (running for 00:03:36.32)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.486 |  0.176 |                   29 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.504 |  0.158 |                   30 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.442 |  0.176 |                   30 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.774 |  0.245 |                   28 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.17556798458099365
[2m[36m(func pid=77888)[0m mae:  0.10655070841312408
[2m[36m(func pid=77888)[0m rmse_per_class: [0.072, 0.21, 0.032, 0.287, 0.056, 0.322, 0.296, 0.148, 0.243, 0.09]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.23427614569664001
[2m[36m(func pid=78316)[0m mae:  0.13110551238059998
[2m[36m(func pid=78316)[0m rmse_per_class: [0.123, 0.298, 0.035, 0.377, 0.155, 0.227, 0.289, 0.307, 0.35, 0.181]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.15671870112419128
[2m[36m(func pid=77465)[0m mae:  0.1087869256734848
[2m[36m(func pid=77465)[0m rmse_per_class: [0.1, 0.242, 0.048, 0.268, 0.056, 0.177, 0.281, 0.145, 0.156, 0.093]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4968 | Steps: 4 | Val loss: 0.3892 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4655 | Steps: 4 | Val loss: 0.3747 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.7502 | Steps: 4 | Val loss: 0.8993 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=77085)[0m rmse: 0.1765802800655365
[2m[36m(func pid=77085)[0m mae:  0.12508639693260193
[2m[36m(func pid=77085)[0m rmse_per_class: [0.114, 0.271, 0.099, 0.352, 0.063, 0.193, 0.276, 0.139, 0.162, 0.098]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4543 | Steps: 4 | Val loss: 0.3154 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 16:27:44 (running for 00:03:41.64)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.497 |  0.177 |                   30 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.463 |  0.157 |                   31 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.466 |  0.163 |                   31 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.731 |  0.234 |                   29 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.16332247853279114
[2m[36m(func pid=77888)[0m mae:  0.0987817794084549
[2m[36m(func pid=77888)[0m rmse_per_class: [0.072, 0.2, 0.035, 0.266, 0.056, 0.277, 0.281, 0.149, 0.208, 0.09]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.2080385386943817
[2m[36m(func pid=78316)[0m mae:  0.11920769512653351
[2m[36m(func pid=78316)[0m rmse_per_class: [0.264, 0.282, 0.037, 0.386, 0.093, 0.241, 0.324, 0.146, 0.15, 0.158]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.15574732422828674
[2m[36m(func pid=77465)[0m mae:  0.10835341364145279
[2m[36m(func pid=77465)[0m rmse_per_class: [0.093, 0.238, 0.047, 0.265, 0.056, 0.175, 0.285, 0.135, 0.152, 0.111]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.5106 | Steps: 4 | Val loss: 0.3915 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4605 | Steps: 4 | Val loss: 0.3431 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.7257 | Steps: 4 | Val loss: 0.8550 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4229 | Steps: 4 | Val loss: 0.3079 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=77085)[0m rmse: 0.17589715123176575
[2m[36m(func pid=77085)[0m mae:  0.12439026683568954
[2m[36m(func pid=77085)[0m rmse_per_class: [0.115, 0.271, 0.096, 0.352, 0.062, 0.193, 0.275, 0.139, 0.159, 0.097]
[2m[36m(func pid=77085)[0m 
== Status ==
Current time: 2024-01-07 16:27:49 (running for 00:03:46.68)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.511 |  0.176 |                   31 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.454 |  0.156 |                   32 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.466 |  0.163 |                   31 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.75  |  0.208 |                   30 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.14946690201759338
[2m[36m(func pid=77888)[0m mae:  0.08720336109399796
[2m[36m(func pid=77888)[0m rmse_per_class: [0.076, 0.196, 0.04, 0.245, 0.056, 0.188, 0.251, 0.191, 0.171, 0.081]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.24329033493995667
[2m[36m(func pid=78316)[0m mae:  0.1274750977754593
[2m[36m(func pid=78316)[0m rmse_per_class: [0.128, 0.389, 0.125, 0.362, 0.167, 0.36, 0.321, 0.143, 0.146, 0.291]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.15700848400592804
[2m[36m(func pid=77465)[0m mae:  0.10907068103551865
[2m[36m(func pid=77465)[0m rmse_per_class: [0.085, 0.236, 0.046, 0.263, 0.056, 0.175, 0.29, 0.125, 0.147, 0.147]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4996 | Steps: 4 | Val loss: 0.3979 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3890 | Steps: 4 | Val loss: 0.3345 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.8430 | Steps: 4 | Val loss: 0.8475 | Batch size: 32 | lr: 0.1 | Duration: 2.84s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4067 | Steps: 4 | Val loss: 0.3031 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=77085)[0m rmse: 0.1761361062526703
[2m[36m(func pid=77085)[0m mae:  0.1244078278541565
[2m[36m(func pid=77085)[0m rmse_per_class: [0.114, 0.271, 0.094, 0.353, 0.062, 0.193, 0.277, 0.14, 0.162, 0.097]
[2m[36m(func pid=77085)[0m 
== Status ==
Current time: 2024-01-07 16:27:55 (running for 00:03:52.25)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.5   |  0.176 |                   32 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.423 |  0.157 |                   33 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.46  |  0.149 |                   32 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.726 |  0.243 |                   31 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.14779289066791534
[2m[36m(func pid=77888)[0m mae:  0.08453916013240814
[2m[36m(func pid=77888)[0m rmse_per_class: [0.086, 0.198, 0.051, 0.233, 0.054, 0.16, 0.24, 0.225, 0.145, 0.085]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.23312833905220032
[2m[36m(func pid=78316)[0m mae:  0.12470944970846176
[2m[36m(func pid=78316)[0m rmse_per_class: [0.11, 0.297, 0.155, 0.446, 0.114, 0.341, 0.344, 0.211, 0.13, 0.184]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.15965552628040314
[2m[36m(func pid=77465)[0m mae:  0.11031095683574677
[2m[36m(func pid=77465)[0m rmse_per_class: [0.078, 0.238, 0.043, 0.258, 0.056, 0.177, 0.292, 0.115, 0.14, 0.199]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3887 | Steps: 4 | Val loss: 0.3412 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.5157 | Steps: 4 | Val loss: 0.4030 | Batch size: 32 | lr: 0.0001 | Duration: 3.11s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.8465 | Steps: 4 | Val loss: 0.7984 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3793 | Steps: 4 | Val loss: 0.3048 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=77888)[0m rmse: 0.1565026342868805
[2m[36m(func pid=77888)[0m mae:  0.08742260932922363
[2m[36m(func pid=77888)[0m rmse_per_class: [0.081, 0.209, 0.064, 0.242, 0.051, 0.188, 0.239, 0.228, 0.128, 0.136]
== Status ==
Current time: 2024-01-07 16:28:00 (running for 00:03:57.71)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.5   |  0.176 |                   32 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.407 |  0.16  |                   34 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.389 |  0.157 |                   34 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.843 |  0.233 |                   32 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.17642895877361298
[2m[36m(func pid=77085)[0m mae:  0.12438760697841644
[2m[36m(func pid=77085)[0m rmse_per_class: [0.114, 0.27, 0.093, 0.354, 0.061, 0.193, 0.277, 0.14, 0.165, 0.096]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.20391809940338135
[2m[36m(func pid=78316)[0m mae:  0.11746440827846527
[2m[36m(func pid=78316)[0m rmse_per_class: [0.111, 0.266, 0.078, 0.41, 0.062, 0.349, 0.331, 0.199, 0.129, 0.103]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.1642971783876419
[2m[36m(func pid=77465)[0m mae:  0.11289854347705841
[2m[36m(func pid=77465)[0m rmse_per_class: [0.072, 0.243, 0.04, 0.254, 0.056, 0.182, 0.293, 0.111, 0.136, 0.258]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3926 | Steps: 4 | Val loss: 0.3527 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.5179 | Steps: 4 | Val loss: 0.4054 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.9564 | Steps: 4 | Val loss: 0.7502 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3868 | Steps: 4 | Val loss: 0.3101 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 16:28:05 (running for 00:04:02.85)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.516 |  0.176 |                   33 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.379 |  0.164 |                   35 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.393 |  0.168 |                   35 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.846 |  0.204 |                   33 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.16828161478042603
[2m[36m(func pid=77888)[0m mae:  0.09253992140293121
[2m[36m(func pid=77888)[0m rmse_per_class: [0.071, 0.229, 0.073, 0.268, 0.059, 0.201, 0.242, 0.211, 0.122, 0.207]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.17604434490203857
[2m[36m(func pid=77085)[0m mae:  0.12376533448696136
[2m[36m(func pid=77085)[0m rmse_per_class: [0.114, 0.27, 0.088, 0.355, 0.061, 0.193, 0.278, 0.141, 0.165, 0.096]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.19061066210269928
[2m[36m(func pid=78316)[0m mae:  0.11086700856685638
[2m[36m(func pid=78316)[0m rmse_per_class: [0.099, 0.269, 0.036, 0.293, 0.06, 0.223, 0.376, 0.284, 0.146, 0.118]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.17051847279071808
[2m[36m(func pid=77465)[0m mae:  0.11589027941226959
[2m[36m(func pid=77465)[0m rmse_per_class: [0.07, 0.247, 0.037, 0.256, 0.056, 0.186, 0.29, 0.138, 0.131, 0.293]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4398 | Steps: 4 | Val loss: 0.3763 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.5291 | Steps: 4 | Val loss: 0.4052 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.6871 | Steps: 4 | Val loss: 0.8954 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3862 | Steps: 4 | Val loss: 0.3199 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=77888)[0m rmse: 0.18027250468730927
[2m[36m(func pid=77888)[0m mae:  0.09989489614963531
[2m[36m(func pid=77888)[0m rmse_per_class: [0.067, 0.237, 0.079, 0.283, 0.087, 0.208, 0.242, 0.17, 0.12, 0.31]
[2m[36m(func pid=77888)[0m == Status ==
Current time: 2024-01-07 16:28:11 (running for 00:04:08.23)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.518 |  0.176 |                   34 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.387 |  0.171 |                   36 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.44  |  0.18  |                   36 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.956 |  0.191 |                   34 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)



[2m[36m(func pid=77085)[0m rmse: 0.17569507658481598
[2m[36m(func pid=77085)[0m mae:  0.12353517860174179
[2m[36m(func pid=77085)[0m rmse_per_class: [0.114, 0.269, 0.087, 0.356, 0.061, 0.193, 0.278, 0.141, 0.163, 0.096]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.17884103953838348
[2m[36m(func pid=77465)[0m mae:  0.12015391886234283
[2m[36m(func pid=77465)[0m rmse_per_class: [0.07, 0.253, 0.038, 0.264, 0.056, 0.191, 0.291, 0.193, 0.127, 0.305]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.2539904713630676
[2m[36m(func pid=78316)[0m mae:  0.14448757469654083
[2m[36m(func pid=78316)[0m rmse_per_class: [0.217, 0.311, 0.036, 0.367, 0.068, 0.246, 0.327, 0.183, 0.49, 0.294]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4226 | Steps: 4 | Val loss: 0.3879 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.5308 | Steps: 4 | Val loss: 0.4077 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4113 | Steps: 4 | Val loss: 0.3306 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.8787 | Steps: 4 | Val loss: 1.1523 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=77888)[0m rmse: 0.18944497406482697== Status ==
Current time: 2024-01-07 16:28:16 (running for 00:04:13.39)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.529 |  0.176 |                   35 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.386 |  0.179 |                   37 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.423 |  0.189 |                   37 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.687 |  0.254 |                   35 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)



[2m[36m(func pid=77888)[0m mae:  0.10376932471990585
[2m[36m(func pid=77888)[0m rmse_per_class: [0.07, 0.239, 0.085, 0.271, 0.139, 0.209, 0.245, 0.17, 0.121, 0.347]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.18659937381744385
[2m[36m(func pid=77465)[0m mae:  0.12426415830850601
[2m[36m(func pid=77465)[0m rmse_per_class: [0.072, 0.258, 0.045, 0.277, 0.056, 0.195, 0.288, 0.263, 0.127, 0.284]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.265158474445343
[2m[36m(func pid=78316)[0m mae:  0.15198953449726105
[2m[36m(func pid=78316)[0m rmse_per_class: [0.332, 0.302, 0.036, 0.384, 0.06, 0.374, 0.349, 0.145, 0.31, 0.358]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.1759369671344757
[2m[36m(func pid=77085)[0m mae:  0.12344984710216522
[2m[36m(func pid=77085)[0m rmse_per_class: [0.112, 0.27, 0.086, 0.356, 0.059, 0.193, 0.281, 0.141, 0.165, 0.096]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4085 | Steps: 4 | Val loss: 0.3773 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4327 | Steps: 4 | Val loss: 0.3439 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.8571 | Steps: 4 | Val loss: 0.9931 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.5228 | Steps: 4 | Val loss: 0.4105 | Batch size: 32 | lr: 0.0001 | Duration: 3.18s
== Status ==
Current time: 2024-01-07 16:28:21 (running for 00:04:18.59)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.531 |  0.176 |                   36 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.411 |  0.187 |                   38 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.408 |  0.186 |                   38 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.879 |  0.265 |                   36 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.18583880364894867
[2m[36m(func pid=77888)[0m mae:  0.09955151379108429
[2m[36m(func pid=77888)[0m rmse_per_class: [0.07, 0.24, 0.077, 0.257, 0.179, 0.203, 0.259, 0.158, 0.125, 0.29]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.1943264901638031
[2m[36m(func pid=77465)[0m mae:  0.12888355553150177
[2m[36m(func pid=77465)[0m rmse_per_class: [0.075, 0.263, 0.069, 0.296, 0.056, 0.198, 0.283, 0.332, 0.127, 0.243]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.24212951958179474
[2m[36m(func pid=78316)[0m mae:  0.14155106246471405
[2m[36m(func pid=78316)[0m rmse_per_class: [0.094, 0.357, 0.06, 0.363, 0.066, 0.575, 0.344, 0.152, 0.152, 0.259]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.17595872282981873
[2m[36m(func pid=77085)[0m mae:  0.12349724769592285
[2m[36m(func pid=77085)[0m rmse_per_class: [0.112, 0.269, 0.084, 0.357, 0.059, 0.193, 0.281, 0.141, 0.169, 0.095]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3850 | Steps: 4 | Val loss: 0.3690 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3952 | Steps: 4 | Val loss: 0.3552 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.9075 | Steps: 4 | Val loss: 0.7654 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.5325 | Steps: 4 | Val loss: 0.4094 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 16:28:26 (running for 00:04:24.06)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.523 |  0.176 |                   37 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.433 |  0.194 |                   39 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.385 |  0.18  |                   39 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.857 |  0.242 |                   37 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.18030403554439545
[2m[36m(func pid=77888)[0m mae:  0.0977594405412674
[2m[36m(func pid=77888)[0m rmse_per_class: [0.072, 0.236, 0.07, 0.274, 0.199, 0.195, 0.284, 0.139, 0.149, 0.186]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.20032565295696259
[2m[36m(func pid=77465)[0m mae:  0.1321643888950348
[2m[36m(func pid=77465)[0m rmse_per_class: [0.078, 0.267, 0.111, 0.309, 0.056, 0.199, 0.28, 0.384, 0.128, 0.19]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.20152127742767334
[2m[36m(func pid=78316)[0m mae:  0.10899905860424042
[2m[36m(func pid=78316)[0m rmse_per_class: [0.1, 0.29, 0.067, 0.323, 0.099, 0.27, 0.435, 0.154, 0.132, 0.144]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.1754622757434845
[2m[36m(func pid=77085)[0m mae:  0.12293199449777603
[2m[36m(func pid=77085)[0m rmse_per_class: [0.113, 0.268, 0.082, 0.357, 0.058, 0.193, 0.281, 0.142, 0.166, 0.095]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3854 | Steps: 4 | Val loss: 0.3633 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4005 | Steps: 4 | Val loss: 0.3593 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.8699 | Steps: 4 | Val loss: 0.8398 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.5333 | Steps: 4 | Val loss: 0.4100 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 16:28:32 (running for 00:04:29.63)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.533 |  0.175 |                   38 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.395 |  0.2   |                   40 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.385 |  0.173 |                   40 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.907 |  0.202 |                   38 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.17324599623680115
[2m[36m(func pid=77888)[0m mae:  0.09800238907337189
[2m[36m(func pid=77888)[0m rmse_per_class: [0.071, 0.235, 0.048, 0.298, 0.162, 0.204, 0.281, 0.127, 0.192, 0.115]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.20056211948394775
[2m[36m(func pid=77465)[0m mae:  0.13213272392749786
[2m[36m(func pid=77465)[0m rmse_per_class: [0.079, 0.266, 0.134, 0.319, 0.056, 0.198, 0.269, 0.419, 0.129, 0.136]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.18899130821228027
[2m[36m(func pid=78316)[0m mae:  0.10478770732879639
[2m[36m(func pid=78316)[0m rmse_per_class: [0.109, 0.268, 0.047, 0.384, 0.122, 0.239, 0.346, 0.147, 0.129, 0.098]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.17530333995819092
[2m[36m(func pid=77085)[0m mae:  0.12245198339223862
[2m[36m(func pid=77085)[0m rmse_per_class: [0.113, 0.268, 0.078, 0.356, 0.058, 0.193, 0.284, 0.142, 0.165, 0.095]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3633 | Steps: 4 | Val loss: 0.3624 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4187 | Steps: 4 | Val loss: 0.3600 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.9009 | Steps: 4 | Val loss: 0.8370 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.5219 | Steps: 4 | Val loss: 0.4111 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 16:28:38 (running for 00:04:35.13)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.533 |  0.175 |                   39 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.401 |  0.201 |                   41 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.363 |  0.168 |                   41 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.87  |  0.189 |                   39 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.16778124868869781
[2m[36m(func pid=77888)[0m mae:  0.09902004897594452
[2m[36m(func pid=77888)[0m rmse_per_class: [0.07, 0.226, 0.033, 0.3, 0.114, 0.247, 0.253, 0.129, 0.223, 0.082]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.20098423957824707
[2m[36m(func pid=77465)[0m mae:  0.13175560534000397
[2m[36m(func pid=77465)[0m rmse_per_class: [0.08, 0.265, 0.182, 0.329, 0.056, 0.197, 0.257, 0.403, 0.129, 0.112]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.21748892962932587
[2m[36m(func pid=78316)[0m mae:  0.11995210498571396
[2m[36m(func pid=78316)[0m rmse_per_class: [0.094, 0.28, 0.045, 0.347, 0.177, 0.4, 0.343, 0.189, 0.14, 0.16]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.17526699602603912
[2m[36m(func pid=77085)[0m mae:  0.12209463119506836
[2m[36m(func pid=77085)[0m rmse_per_class: [0.112, 0.268, 0.075, 0.357, 0.057, 0.193, 0.287, 0.142, 0.164, 0.096]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4204 | Steps: 4 | Val loss: 0.3607 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3910 | Steps: 4 | Val loss: 0.3739 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.7722 | Steps: 4 | Val loss: 1.0071 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.5241 | Steps: 4 | Val loss: 0.4087 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 16:28:43 (running for 00:04:40.26)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.522 |  0.175 |                   40 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.42  |  0.199 |                   43 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.363 |  0.168 |                   41 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.901 |  0.217 |                   40 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.19946005940437317
[2m[36m(func pid=77465)[0m mae:  0.12979331612586975
[2m[36m(func pid=77465)[0m rmse_per_class: [0.081, 0.265, 0.216, 0.337, 0.055, 0.193, 0.242, 0.38, 0.13, 0.095]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.16685490310192108
[2m[36m(func pid=77888)[0m mae:  0.10041560232639313
[2m[36m(func pid=77888)[0m rmse_per_class: [0.069, 0.219, 0.028, 0.296, 0.093, 0.268, 0.24, 0.131, 0.242, 0.082]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.24082835018634796
[2m[36m(func pid=78316)[0m mae:  0.13383379578590393
[2m[36m(func pid=78316)[0m rmse_per_class: [0.105, 0.31, 0.035, 0.322, 0.178, 0.264, 0.352, 0.333, 0.257, 0.252]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.1752498894929886
[2m[36m(func pid=77085)[0m mae:  0.12208320200443268
[2m[36m(func pid=77085)[0m rmse_per_class: [0.111, 0.268, 0.075, 0.356, 0.057, 0.192, 0.288, 0.142, 0.167, 0.096]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4113 | Steps: 4 | Val loss: 0.3502 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3709 | Steps: 4 | Val loss: 0.3749 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.8772 | Steps: 4 | Val loss: 0.9158 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.5223 | Steps: 4 | Val loss: 0.4049 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=77465)[0m rmse: 0.19342848658561707
[2m[36m(func pid=77465)[0m mae:  0.12514367699623108
[2m[36m(func pid=77465)[0m rmse_per_class: [0.081, 0.258, 0.241, 0.339, 0.055, 0.188, 0.231, 0.325, 0.13, 0.088]
== Status ==
Current time: 2024-01-07 16:28:48 (running for 00:04:45.38)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.524 |  0.175 |                   41 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.411 |  0.193 |                   44 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.391 |  0.167 |                   42 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.772 |  0.241 |                   41 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.16603432595729828
[2m[36m(func pid=77888)[0m mae:  0.10040821135044098
[2m[36m(func pid=77888)[0m rmse_per_class: [0.071, 0.212, 0.028, 0.285, 0.08, 0.298, 0.243, 0.13, 0.229, 0.085]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.25467076897621155
[2m[36m(func pid=78316)[0m mae:  0.13901153206825256
[2m[36m(func pid=78316)[0m rmse_per_class: [0.228, 0.326, 0.038, 0.341, 0.155, 0.247, 0.331, 0.255, 0.322, 0.303]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.17478778958320618
[2m[36m(func pid=77085)[0m mae:  0.12164785712957382
[2m[36m(func pid=77085)[0m rmse_per_class: [0.111, 0.267, 0.074, 0.356, 0.057, 0.192, 0.288, 0.142, 0.165, 0.095]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4049 | Steps: 4 | Val loss: 0.3364 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3832 | Steps: 4 | Val loss: 0.3365 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.8112 | Steps: 4 | Val loss: 0.7659 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.5125 | Steps: 4 | Val loss: 0.4072 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 16:28:53 (running for 00:04:50.54)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.522 |  0.175 |                   42 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.405 |  0.184 |                   45 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.371 |  0.166 |                   43 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.877 |  0.255 |                   42 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.18397179245948792
[2m[36m(func pid=77465)[0m mae:  0.1183866485953331
[2m[36m(func pid=77465)[0m rmse_per_class: [0.077, 0.25, 0.247, 0.339, 0.054, 0.182, 0.222, 0.254, 0.131, 0.086]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.1576431691646576
[2m[36m(func pid=77888)[0m mae:  0.09135517477989197
[2m[36m(func pid=77888)[0m rmse_per_class: [0.098, 0.207, 0.029, 0.255, 0.065, 0.257, 0.239, 0.127, 0.215, 0.085]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.20754149556159973
[2m[36m(func pid=78316)[0m mae:  0.1139175295829773
[2m[36m(func pid=78316)[0m rmse_per_class: [0.137, 0.315, 0.04, 0.328, 0.087, 0.22, 0.448, 0.144, 0.165, 0.19]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.17467758059501648
[2m[36m(func pid=77085)[0m mae:  0.12142528593540192
[2m[36m(func pid=77085)[0m rmse_per_class: [0.111, 0.266, 0.072, 0.357, 0.056, 0.192, 0.285, 0.143, 0.168, 0.095]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3875 | Steps: 4 | Val loss: 0.3243 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3564 | Steps: 4 | Val loss: 0.3229 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.6723 | Steps: 4 | Val loss: 0.7661 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=77465)[0m rmse: 0.17417947947978973
[2m[36m(func pid=77465)[0m mae:  0.11165032535791397
[2m[36m(func pid=77465)[0m rmse_per_class: [0.073, 0.243, 0.221, 0.335, 0.053, 0.175, 0.224, 0.198, 0.134, 0.086]
[2m[36m(func pid=77465)[0m 
== Status ==
Current time: 2024-01-07 16:28:58 (running for 00:04:55.89)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.513 |  0.175 |                   43 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.387 |  0.174 |                   46 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.383 |  0.158 |                   44 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.811 |  0.208 |                   43 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.5175 | Steps: 4 | Val loss: 0.4062 | Batch size: 32 | lr: 0.0001 | Duration: 3.14s
[2m[36m(func pid=77888)[0m rmse: 0.15161767601966858
[2m[36m(func pid=77888)[0m mae:  0.08454573154449463
[2m[36m(func pid=77888)[0m rmse_per_class: [0.124, 0.201, 0.031, 0.251, 0.067, 0.197, 0.23, 0.135, 0.2, 0.081]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.19893677532672882
[2m[36m(func pid=78316)[0m mae:  0.11072392761707306
[2m[36m(func pid=78316)[0m rmse_per_class: [0.091, 0.332, 0.08, 0.306, 0.058, 0.401, 0.318, 0.152, 0.13, 0.122]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.17446519434452057
[2m[36m(func pid=77085)[0m mae:  0.12122505903244019
[2m[36m(func pid=77085)[0m rmse_per_class: [0.11, 0.266, 0.072, 0.358, 0.056, 0.192, 0.287, 0.143, 0.165, 0.095]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3940 | Steps: 4 | Val loss: 0.3114 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3538 | Steps: 4 | Val loss: 0.3308 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.8935 | Steps: 4 | Val loss: 1.0550 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 16:29:04 (running for 00:05:01.19)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.517 |  0.174 |                   44 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.394 |  0.166 |                   47 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.356 |  0.152 |                   45 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.672 |  0.199 |                   44 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.16606445610523224
[2m[36m(func pid=77465)[0m mae:  0.10630585998296738
[2m[36m(func pid=77465)[0m rmse_per_class: [0.072, 0.236, 0.182, 0.33, 0.052, 0.172, 0.237, 0.157, 0.136, 0.087]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.5179 | Steps: 4 | Val loss: 0.3985 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=77888)[0m rmse: 0.1510561853647232
[2m[36m(func pid=77888)[0m mae:  0.08349649608135223
[2m[36m(func pid=77888)[0m rmse_per_class: [0.129, 0.203, 0.031, 0.27, 0.067, 0.178, 0.23, 0.147, 0.175, 0.081]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.21897225081920624
[2m[36m(func pid=78316)[0m mae:  0.12499283254146576
[2m[36m(func pid=78316)[0m rmse_per_class: [0.099, 0.45, 0.093, 0.381, 0.056, 0.334, 0.346, 0.159, 0.13, 0.141]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.17314589023590088
[2m[36m(func pid=77085)[0m mae:  0.12034700810909271
[2m[36m(func pid=77085)[0m rmse_per_class: [0.109, 0.264, 0.067, 0.358, 0.056, 0.192, 0.283, 0.143, 0.164, 0.095]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3590 | Steps: 4 | Val loss: 0.2991 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3317 | Steps: 4 | Val loss: 0.3339 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 1.0730 | Steps: 4 | Val loss: 1.0437 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 16:29:09 (running for 00:05:06.38)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.518 |  0.173 |                   45 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.359 |  0.158 |                   48 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.354 |  0.151 |                   46 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.894 |  0.219 |                   45 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.15797939896583557
[2m[36m(func pid=77465)[0m mae:  0.101498544216156
[2m[36m(func pid=77465)[0m rmse_per_class: [0.068, 0.228, 0.152, 0.326, 0.052, 0.168, 0.236, 0.121, 0.142, 0.088]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.5190 | Steps: 4 | Val loss: 0.3925 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=77888)[0m rmse: 0.1517602801322937
[2m[36m(func pid=77888)[0m mae:  0.08354049921035767
[2m[36m(func pid=77888)[0m rmse_per_class: [0.107, 0.207, 0.03, 0.28, 0.064, 0.185, 0.242, 0.161, 0.151, 0.091]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.23292234539985657
[2m[36m(func pid=78316)[0m mae:  0.12805527448654175
[2m[36m(func pid=78316)[0m rmse_per_class: [0.096, 0.446, 0.138, 0.383, 0.056, 0.311, 0.346, 0.17, 0.161, 0.223]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3439 | Steps: 4 | Val loss: 0.2858 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=77085)[0m rmse: 0.17297163605690002
[2m[36m(func pid=77085)[0m mae:  0.11998548358678818
[2m[36m(func pid=77085)[0m rmse_per_class: [0.109, 0.264, 0.065, 0.358, 0.056, 0.192, 0.287, 0.143, 0.163, 0.094]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3604 | Steps: 4 | Val loss: 0.3363 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.9456 | Steps: 4 | Val loss: 0.8198 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 16:29:14 (running for 00:05:11.55)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.519 |  0.173 |                   46 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.344 |  0.151 |                   49 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.332 |  0.152 |                   47 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  1.073 |  0.233 |                   46 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.1506614238023758
[2m[36m(func pid=77465)[0m mae:  0.09724952280521393
[2m[36m(func pid=77465)[0m rmse_per_class: [0.064, 0.22, 0.112, 0.318, 0.053, 0.167, 0.234, 0.106, 0.146, 0.089]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.1548282504081726
[2m[36m(func pid=77888)[0m mae:  0.08485326170921326
[2m[36m(func pid=77888)[0m rmse_per_class: [0.098, 0.21, 0.03, 0.27, 0.057, 0.191, 0.251, 0.189, 0.14, 0.113]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.5187 | Steps: 4 | Val loss: 0.3891 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=78316)[0m rmse: 0.23780056834220886
[2m[36m(func pid=78316)[0m mae:  0.12775589525699615
[2m[36m(func pid=78316)[0m rmse_per_class: [0.099, 0.345, 0.088, 0.324, 0.056, 0.33, 0.329, 0.255, 0.206, 0.346]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3519 | Steps: 4 | Val loss: 0.2796 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=77085)[0m rmse: 0.17270979285240173
[2m[36m(func pid=77085)[0m mae:  0.11937525123357773
[2m[36m(func pid=77085)[0m rmse_per_class: [0.109, 0.263, 0.063, 0.357, 0.056, 0.191, 0.29, 0.144, 0.16, 0.094]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3395 | Steps: 4 | Val loss: 0.3341 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.6535 | Steps: 4 | Val loss: 0.9343 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=77465)[0m rmse: 0.1468302309513092
[2m[36m(func pid=77465)[0m mae:  0.09538480639457703
[2m[36m(func pid=77465)[0m rmse_per_class: [0.063, 0.214, 0.086, 0.316, 0.056, 0.168, 0.217, 0.107, 0.152, 0.089]
[2m[36m(func pid=77465)[0m 
== Status ==
Current time: 2024-01-07 16:29:19 (running for 00:05:16.62)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.519 |  0.173 |                   47 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.352 |  0.147 |                   50 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.36  |  0.155 |                   48 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.946 |  0.238 |                   47 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.15859806537628174
[2m[36m(func pid=77888)[0m mae:  0.08662639558315277
[2m[36m(func pid=77888)[0m rmse_per_class: [0.091, 0.219, 0.028, 0.252, 0.055, 0.193, 0.263, 0.186, 0.132, 0.168]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4968 | Steps: 4 | Val loss: 0.3830 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=78316)[0m rmse: 0.20408448576927185
[2m[36m(func pid=78316)[0m mae:  0.11804582923650742
[2m[36m(func pid=78316)[0m rmse_per_class: [0.132, 0.302, 0.039, 0.344, 0.056, 0.207, 0.295, 0.247, 0.219, 0.201]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3407 | Steps: 4 | Val loss: 0.2746 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=77085)[0m rmse: 0.17207273840904236
[2m[36m(func pid=77085)[0m mae:  0.11943385750055313
[2m[36m(func pid=77085)[0m rmse_per_class: [0.112, 0.262, 0.062, 0.355, 0.056, 0.191, 0.283, 0.143, 0.161, 0.094]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3307 | Steps: 4 | Val loss: 0.3314 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.7865 | Steps: 4 | Val loss: 0.9239 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 16:29:24 (running for 00:05:21.72)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.497 |  0.172 |                   48 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.341 |  0.144 |                   51 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.34  |  0.159 |                   49 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.654 |  0.204 |                   48 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.1441998928785324
[2m[36m(func pid=77465)[0m mae:  0.09466583281755447
[2m[36m(func pid=77465)[0m rmse_per_class: [0.062, 0.212, 0.058, 0.312, 0.063, 0.173, 0.206, 0.11, 0.155, 0.09]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.16193486750125885
[2m[36m(func pid=77888)[0m mae:  0.08902646601200104
[2m[36m(func pid=77888)[0m rmse_per_class: [0.079, 0.226, 0.029, 0.252, 0.054, 0.182, 0.263, 0.192, 0.13, 0.212]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.5060 | Steps: 4 | Val loss: 0.3778 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=78316)[0m rmse: 0.23249273002147675
[2m[36m(func pid=78316)[0m mae:  0.13299639523029327
[2m[36m(func pid=78316)[0m rmse_per_class: [0.17, 0.36, 0.038, 0.354, 0.095, 0.216, 0.299, 0.184, 0.394, 0.215]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3272 | Steps: 4 | Val loss: 0.2691 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=77085)[0m rmse: 0.1717359572649002
[2m[36m(func pid=77085)[0m mae:  0.11886931955814362
[2m[36m(func pid=77085)[0m rmse_per_class: [0.109, 0.262, 0.06, 0.355, 0.056, 0.191, 0.286, 0.143, 0.16, 0.094]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3185 | Steps: 4 | Val loss: 0.3314 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.8630 | Steps: 4 | Val loss: 0.9740 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=77465)[0m rmse: 0.14098919928073883
[2m[36m(func pid=77465)[0m mae:  0.09304126352071762
[2m[36m(func pid=77465)[0m rmse_per_class: [0.062, 0.212, 0.038, 0.298, 0.072, 0.175, 0.199, 0.115, 0.15, 0.089]
[2m[36m(func pid=77465)[0m 
== Status ==
Current time: 2024-01-07 16:29:29 (running for 00:05:26.96)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.506 |  0.172 |                   49 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.327 |  0.141 |                   52 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.331 |  0.162 |                   50 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.786 |  0.232 |                   49 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77888)[0m rmse: 0.16371074318885803
[2m[36m(func pid=77888)[0m mae:  0.09043168276548386
[2m[36m(func pid=77888)[0m rmse_per_class: [0.076, 0.23, 0.032, 0.264, 0.054, 0.171, 0.248, 0.182, 0.135, 0.245]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.5097 | Steps: 4 | Val loss: 0.3756 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=78316)[0m rmse: 0.2577205300331116
[2m[36m(func pid=78316)[0m mae:  0.14221206307411194
[2m[36m(func pid=78316)[0m rmse_per_class: [0.139, 0.371, 0.043, 0.337, 0.412, 0.265, 0.346, 0.155, 0.301, 0.21]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3159 | Steps: 4 | Val loss: 0.2675 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3504 | Steps: 4 | Val loss: 0.3423 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=77085)[0m rmse: 0.17118199169635773
[2m[36m(func pid=77085)[0m mae:  0.11819684505462646
[2m[36m(func pid=77085)[0m rmse_per_class: [0.109, 0.262, 0.059, 0.354, 0.056, 0.191, 0.286, 0.143, 0.159, 0.094]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.8583 | Steps: 4 | Val loss: 0.9225 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 16:29:35 (running for 00:05:32.38)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.51  |  0.171 |                   50 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.316 |  0.14  |                   53 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.318 |  0.164 |                   51 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.863 |  0.258 |                   50 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.14003673195838928
[2m[36m(func pid=77465)[0m mae:  0.09270365536212921
[2m[36m(func pid=77465)[0m rmse_per_class: [0.062, 0.213, 0.032, 0.278, 0.084, 0.175, 0.197, 0.121, 0.148, 0.09]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.16973310708999634
[2m[36m(func pid=77888)[0m mae:  0.09602614492177963
[2m[36m(func pid=77888)[0m rmse_per_class: [0.07, 0.231, 0.032, 0.283, 0.054, 0.186, 0.241, 0.164, 0.157, 0.278]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.235849529504776
[2m[36m(func pid=78316)[0m mae:  0.13516798615455627
[2m[36m(func pid=78316)[0m rmse_per_class: [0.09, 0.303, 0.056, 0.328, 0.355, 0.456, 0.343, 0.149, 0.147, 0.132]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.5045 | Steps: 4 | Val loss: 0.3767 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3643 | Steps: 4 | Val loss: 0.2733 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3379 | Steps: 4 | Val loss: 0.3491 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=77085)[0m rmse: 0.17106695473194122
[2m[36m(func pid=77085)[0m mae:  0.11818148195743561
[2m[36m(func pid=77085)[0m rmse_per_class: [0.109, 0.262, 0.057, 0.354, 0.055, 0.191, 0.284, 0.144, 0.16, 0.094]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.8251 | Steps: 4 | Val loss: 0.7219 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 16:29:40 (running for 00:05:37.57)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.504 |  0.171 |                   51 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.364 |  0.143 |                   54 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.35  |  0.17  |                   52 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.858 |  0.236 |                   51 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.14275076985359192
[2m[36m(func pid=77465)[0m mae:  0.09481941163539886
[2m[36m(func pid=77465)[0m rmse_per_class: [0.065, 0.213, 0.031, 0.265, 0.098, 0.176, 0.21, 0.131, 0.15, 0.089]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.17136406898498535
[2m[36m(func pid=77888)[0m mae:  0.09988032281398773
[2m[36m(func pid=77888)[0m rmse_per_class: [0.067, 0.227, 0.032, 0.288, 0.054, 0.247, 0.251, 0.135, 0.172, 0.241]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.21011307835578918
[2m[36m(func pid=78316)[0m mae:  0.11019936949014664
[2m[36m(func pid=78316)[0m rmse_per_class: [0.09, 0.299, 0.101, 0.351, 0.164, 0.28, 0.346, 0.177, 0.136, 0.157]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4817 | Steps: 4 | Val loss: 0.3730 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3288 | Steps: 4 | Val loss: 0.2779 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2976 | Steps: 4 | Val loss: 0.3408 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 16:29:45 (running for 00:05:42.70)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.482 |  0.17  |                   52 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.364 |  0.143 |                   54 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.338 |  0.171 |                   53 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.825 |  0.21  |                   52 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77085)[0m rmse: 0.17027181386947632
[2m[36m(func pid=77085)[0m mae:  0.11770167201757431
[2m[36m(func pid=77085)[0m rmse_per_class: [0.109, 0.261, 0.056, 0.353, 0.055, 0.191, 0.279, 0.144, 0.161, 0.094]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.7242 | Steps: 4 | Val loss: 0.7675 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=77465)[0m rmse: 0.14412730932235718
[2m[36m(func pid=77465)[0m mae:  0.09586070477962494
[2m[36m(func pid=77465)[0m rmse_per_class: [0.067, 0.21, 0.032, 0.251, 0.111, 0.177, 0.221, 0.136, 0.149, 0.088]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.16646546125411987
[2m[36m(func pid=77888)[0m mae:  0.09845289587974548
[2m[36m(func pid=77888)[0m rmse_per_class: [0.068, 0.222, 0.032, 0.288, 0.054, 0.281, 0.245, 0.117, 0.17, 0.189]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.21481361985206604
[2m[36m(func pid=78316)[0m mae:  0.11840083450078964
[2m[36m(func pid=78316)[0m rmse_per_class: [0.088, 0.328, 0.084, 0.312, 0.066, 0.222, 0.347, 0.333, 0.135, 0.234]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3374 | Steps: 4 | Val loss: 0.2806 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4834 | Steps: 4 | Val loss: 0.3638 | Batch size: 32 | lr: 0.0001 | Duration: 3.08s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3233 | Steps: 4 | Val loss: 0.3231 | Batch size: 32 | lr: 0.01 | Duration: 2.69s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.7559 | Steps: 4 | Val loss: 0.8974 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 16:29:51 (running for 00:05:48.14)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.482 |  0.17  |                   52 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.337 |  0.146 |                   56 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.298 |  0.166 |                   54 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.724 |  0.215 |                   53 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.14585061371326447
[2m[36m(func pid=77465)[0m mae:  0.09686459600925446
[2m[36m(func pid=77465)[0m rmse_per_class: [0.067, 0.21, 0.033, 0.246, 0.126, 0.177, 0.227, 0.136, 0.15, 0.086]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.1695401668548584
[2m[36m(func pid=77085)[0m mae:  0.11729125678539276
[2m[36m(func pid=77085)[0m rmse_per_class: [0.106, 0.26, 0.056, 0.351, 0.055, 0.191, 0.279, 0.143, 0.159, 0.094]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.15981611609458923
[2m[36m(func pid=77888)[0m mae:  0.09281197935342789
[2m[36m(func pid=77888)[0m rmse_per_class: [0.084, 0.223, 0.033, 0.287, 0.053, 0.236, 0.228, 0.117, 0.197, 0.141]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.24295201897621155
[2m[36m(func pid=78316)[0m mae:  0.1346200406551361
[2m[36m(func pid=78316)[0m rmse_per_class: [0.12, 0.392, 0.091, 0.336, 0.056, 0.267, 0.344, 0.31, 0.183, 0.329]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3372 | Steps: 4 | Val loss: 0.2845 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4782 | Steps: 4 | Val loss: 0.3613 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3124 | Steps: 4 | Val loss: 0.3113 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.6971 | Steps: 4 | Val loss: 1.0317 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 16:29:56 (running for 00:05:53.38)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.483 |  0.17  |                   53 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.337 |  0.148 |                   57 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.323 |  0.16  |                   55 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.756 |  0.243 |                   54 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.14788995683193207
[2m[36m(func pid=77465)[0m mae:  0.09816508740186691
[2m[36m(func pid=77465)[0m rmse_per_class: [0.071, 0.212, 0.034, 0.242, 0.133, 0.177, 0.237, 0.139, 0.151, 0.084]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.16943348944187164
[2m[36m(func pid=77085)[0m mae:  0.11699853837490082
[2m[36m(func pid=77085)[0m rmse_per_class: [0.104, 0.259, 0.056, 0.351, 0.055, 0.191, 0.282, 0.143, 0.159, 0.094]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.15459001064300537
[2m[36m(func pid=77888)[0m mae:  0.0877104252576828
[2m[36m(func pid=77888)[0m rmse_per_class: [0.119, 0.221, 0.04, 0.273, 0.055, 0.175, 0.221, 0.117, 0.211, 0.115]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.24380651116371155
[2m[36m(func pid=78316)[0m mae:  0.14270907640457153
[2m[36m(func pid=78316)[0m rmse_per_class: [0.21, 0.309, 0.047, 0.352, 0.056, 0.503, 0.349, 0.149, 0.257, 0.206]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3386 | Steps: 4 | Val loss: 0.2861 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4796 | Steps: 4 | Val loss: 0.3593 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3134 | Steps: 4 | Val loss: 0.3146 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 16:30:01 (running for 00:05:58.59)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.478 |  0.169 |                   54 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.339 |  0.148 |                   58 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.312 |  0.155 |                   56 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.697 |  0.244 |                   55 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.14767906069755554
[2m[36m(func pid=77465)[0m mae:  0.09788878262042999
[2m[36m(func pid=77465)[0m rmse_per_class: [0.067, 0.214, 0.036, 0.242, 0.133, 0.176, 0.245, 0.138, 0.145, 0.081]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.8331 | Steps: 4 | Val loss: 0.8847 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=77085)[0m rmse: 0.16952833533287048
[2m[36m(func pid=77085)[0m mae:  0.1168481856584549
[2m[36m(func pid=77085)[0m rmse_per_class: [0.105, 0.26, 0.055, 0.351, 0.055, 0.191, 0.284, 0.143, 0.157, 0.094]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.15309549868106842
[2m[36m(func pid=77888)[0m mae:  0.08575159311294556
[2m[36m(func pid=77888)[0m rmse_per_class: [0.135, 0.22, 0.047, 0.259, 0.064, 0.173, 0.225, 0.117, 0.196, 0.094]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.2388778179883957
[2m[36m(func pid=78316)[0m mae:  0.1328565776348114
[2m[36m(func pid=78316)[0m rmse_per_class: [0.238, 0.335, 0.042, 0.354, 0.056, 0.273, 0.355, 0.16, 0.422, 0.154]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3298 | Steps: 4 | Val loss: 0.2809 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4792 | Steps: 4 | Val loss: 0.3540 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3132 | Steps: 4 | Val loss: 0.3227 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 16:30:06 (running for 00:06:03.81)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.48  |  0.17  |                   55 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.33  |  0.147 |                   59 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.313 |  0.153 |                   57 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.833 |  0.239 |                   56 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.1467243880033493
[2m[36m(func pid=77465)[0m mae:  0.09676645696163177
[2m[36m(func pid=77465)[0m rmse_per_class: [0.067, 0.218, 0.037, 0.239, 0.131, 0.174, 0.244, 0.135, 0.141, 0.082]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 1.1233 | Steps: 4 | Val loss: 0.8477 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=77085)[0m rmse: 0.16910122334957123
[2m[36m(func pid=77085)[0m mae:  0.11662633717060089
[2m[36m(func pid=77085)[0m rmse_per_class: [0.106, 0.259, 0.054, 0.35, 0.055, 0.191, 0.281, 0.143, 0.158, 0.094]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.15429189801216125
[2m[36m(func pid=77888)[0m mae:  0.08594464510679245
[2m[36m(func pid=77888)[0m rmse_per_class: [0.167, 0.213, 0.046, 0.252, 0.08, 0.189, 0.232, 0.117, 0.162, 0.084]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3172 | Steps: 4 | Val loss: 0.2774 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=78316)[0m rmse: 0.21757686138153076
[2m[36m(func pid=78316)[0m mae:  0.12322373688220978
[2m[36m(func pid=78316)[0m rmse_per_class: [0.101, 0.324, 0.042, 0.339, 0.056, 0.225, 0.455, 0.188, 0.328, 0.117]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4527 | Steps: 4 | Val loss: 0.3510 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3078 | Steps: 4 | Val loss: 0.3244 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 16:30:11 (running for 00:06:09.06)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.479 |  0.169 |                   56 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.317 |  0.147 |                   60 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.313 |  0.154 |                   58 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  1.123 |  0.218 |                   57 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.1468041092157364
[2m[36m(func pid=77465)[0m mae:  0.09631530940532684
[2m[36m(func pid=77465)[0m rmse_per_class: [0.069, 0.222, 0.037, 0.238, 0.127, 0.173, 0.242, 0.133, 0.141, 0.086]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.8581 | Steps: 4 | Val loss: 0.8693 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=77085)[0m rmse: 0.16886094212532043
[2m[36m(func pid=77085)[0m mae:  0.11663389205932617
[2m[36m(func pid=77085)[0m rmse_per_class: [0.106, 0.259, 0.054, 0.349, 0.055, 0.19, 0.277, 0.144, 0.16, 0.094]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.1525542438030243
[2m[36m(func pid=77888)[0m mae:  0.08431889861822128
[2m[36m(func pid=77888)[0m rmse_per_class: [0.148, 0.208, 0.042, 0.251, 0.092, 0.196, 0.24, 0.117, 0.148, 0.083]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3299 | Steps: 4 | Val loss: 0.2733 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=78316)[0m rmse: 0.22168168425559998
[2m[36m(func pid=78316)[0m mae:  0.12516526877880096
[2m[36m(func pid=78316)[0m rmse_per_class: [0.1, 0.347, 0.039, 0.39, 0.056, 0.234, 0.343, 0.401, 0.184, 0.123]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4578 | Steps: 4 | Val loss: 0.3456 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3344 | Steps: 4 | Val loss: 0.3236 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=77465)[0m rmse: 0.14706557989120483
[2m[36m(func pid=77465)[0m mae:  0.09596423804759979
[2m[36m(func pid=77465)[0m rmse_per_class: [0.068, 0.228, 0.037, 0.235, 0.117, 0.173, 0.238, 0.129, 0.141, 0.104]
== Status ==
Current time: 2024-01-07 16:30:16 (running for 00:06:14.07)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.453 |  0.169 |                   57 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.33  |  0.147 |                   61 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.308 |  0.153 |                   59 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.858 |  0.222 |                   58 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.8761 | Steps: 4 | Val loss: 0.9147 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=77085)[0m rmse: 0.1682102233171463
[2m[36m(func pid=77085)[0m mae:  0.11619792878627777
[2m[36m(func pid=77085)[0m rmse_per_class: [0.106, 0.259, 0.052, 0.348, 0.055, 0.191, 0.274, 0.144, 0.158, 0.094]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.15194660425186157
[2m[36m(func pid=77888)[0m mae:  0.08314783871173859
[2m[36m(func pid=77888)[0m rmse_per_class: [0.122, 0.206, 0.039, 0.255, 0.102, 0.193, 0.235, 0.137, 0.147, 0.083]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3105 | Steps: 4 | Val loss: 0.2735 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=78316)[0m rmse: 0.2167610228061676
[2m[36m(func pid=78316)[0m mae:  0.12113267183303833
[2m[36m(func pid=78316)[0m rmse_per_class: [0.097, 0.304, 0.065, 0.375, 0.057, 0.321, 0.35, 0.304, 0.144, 0.152]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4607 | Steps: 4 | Val loss: 0.3407 | Batch size: 32 | lr: 0.0001 | Duration: 3.15s
== Status ==
Current time: 2024-01-07 16:30:22 (running for 00:06:19.42)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.458 |  0.168 |                   58 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.31  |  0.149 |                   62 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.334 |  0.152 |                   60 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.876 |  0.217 |                   59 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.14875520765781403
[2m[36m(func pid=77465)[0m mae:  0.09630302339792252
[2m[36m(func pid=77465)[0m rmse_per_class: [0.073, 0.234, 0.036, 0.236, 0.101, 0.17, 0.235, 0.129, 0.139, 0.134]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3073 | Steps: 4 | Val loss: 0.3191 | Batch size: 32 | lr: 0.01 | Duration: 3.17s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.7391 | Steps: 4 | Val loss: 0.8081 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=77085)[0m rmse: 0.16779199242591858
[2m[36m(func pid=77085)[0m mae:  0.11619509756565094
[2m[36m(func pid=77085)[0m rmse_per_class: [0.109, 0.258, 0.053, 0.346, 0.055, 0.19, 0.268, 0.144, 0.16, 0.095]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.15203401446342468
[2m[36m(func pid=77888)[0m mae:  0.0830492451786995
[2m[36m(func pid=77888)[0m rmse_per_class: [0.112, 0.206, 0.036, 0.258, 0.108, 0.181, 0.231, 0.159, 0.144, 0.085]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3067 | Steps: 4 | Val loss: 0.2723 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=78316)[0m rmse: 0.2211330682039261
[2m[36m(func pid=78316)[0m mae:  0.12095533311367035
[2m[36m(func pid=78316)[0m rmse_per_class: [0.105, 0.3, 0.119, 0.336, 0.101, 0.38, 0.33, 0.177, 0.138, 0.227]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4594 | Steps: 4 | Val loss: 0.3330 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 16:30:27 (running for 00:06:24.66)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.461 |  0.168 |                   59 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.307 |  0.148 |                   63 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.307 |  0.152 |                   61 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.739 |  0.221 |                   60 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.14802715182304382
[2m[36m(func pid=77465)[0m mae:  0.0955597534775734
[2m[36m(func pid=77465)[0m rmse_per_class: [0.064, 0.239, 0.034, 0.236, 0.086, 0.169, 0.231, 0.124, 0.139, 0.158]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3338 | Steps: 4 | Val loss: 0.3187 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.6624 | Steps: 4 | Val loss: 0.9654 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=77085)[0m rmse: 0.1671239733695984
[2m[36m(func pid=77085)[0m mae:  0.11598912626504898
[2m[36m(func pid=77085)[0m rmse_per_class: [0.11, 0.257, 0.053, 0.344, 0.055, 0.19, 0.267, 0.143, 0.158, 0.094]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m rmse: 0.15493401885032654
[2m[36m(func pid=77888)[0m mae:  0.08658493310213089
[2m[36m(func pid=77888)[0m rmse_per_class: [0.085, 0.209, 0.031, 0.251, 0.096, 0.187, 0.243, 0.208, 0.152, 0.086]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3202 | Steps: 4 | Val loss: 0.2722 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=78316)[0m rmse: 0.22623984515666962
[2m[36m(func pid=78316)[0m mae:  0.1256658136844635
[2m[36m(func pid=78316)[0m rmse_per_class: [0.18, 0.309, 0.082, 0.354, 0.21, 0.213, 0.312, 0.145, 0.146, 0.31]
[2m[36m(func pid=78316)[0m 
== Status ==
Current time: 2024-01-07 16:30:32 (running for 00:06:30.01)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.459 |  0.167 |                   60 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.32  |  0.148 |                   64 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.334 |  0.155 |                   62 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.662 |  0.226 |                   61 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4466 | Steps: 4 | Val loss: 0.3312 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=77465)[0m rmse: 0.1481618583202362
[2m[36m(func pid=77465)[0m mae:  0.09503774344921112
[2m[36m(func pid=77465)[0m rmse_per_class: [0.063, 0.239, 0.033, 0.235, 0.074, 0.168, 0.224, 0.119, 0.134, 0.194]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3182 | Steps: 4 | Val loss: 0.3225 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.8564 | Steps: 4 | Val loss: 1.0925 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=77085)[0m rmse: 0.16685593128204346
[2m[36m(func pid=77085)[0m mae:  0.11569581180810928
[2m[36m(func pid=77085)[0m rmse_per_class: [0.108, 0.257, 0.052, 0.343, 0.055, 0.19, 0.267, 0.143, 0.158, 0.094]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3151 | Steps: 4 | Val loss: 0.2729 | Batch size: 32 | lr: 0.001 | Duration: 2.74s
[2m[36m(func pid=77888)[0m rmse: 0.16061687469482422
[2m[36m(func pid=77888)[0m mae:  0.09234006702899933
[2m[36m(func pid=77888)[0m rmse_per_class: [0.084, 0.214, 0.03, 0.254, 0.092, 0.243, 0.256, 0.193, 0.154, 0.086]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.26373547315597534
[2m[36m(func pid=78316)[0m mae:  0.14765852689743042
[2m[36m(func pid=78316)[0m rmse_per_class: [0.281, 0.345, 0.042, 0.379, 0.318, 0.233, 0.307, 0.158, 0.243, 0.333]
[2m[36m(func pid=78316)[0m 
== Status ==
Current time: 2024-01-07 16:30:38 (running for 00:06:35.20)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.447 |  0.167 |                   61 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.315 |  0.148 |                   65 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.318 |  0.161 |                   63 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.856 |  0.264 |                   62 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.14752233028411865
[2m[36m(func pid=77465)[0m mae:  0.09432842582464218
[2m[36m(func pid=77465)[0m rmse_per_class: [0.059, 0.245, 0.03, 0.234, 0.064, 0.167, 0.213, 0.113, 0.132, 0.219]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4456 | Steps: 4 | Val loss: 0.3269 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3095 | Steps: 4 | Val loss: 0.3284 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.8032 | Steps: 4 | Val loss: 1.1299 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3254 | Steps: 4 | Val loss: 0.2779 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=77888)[0m rmse: 0.16592001914978027
[2m[36m(func pid=77888)[0m mae:  0.09762097895145416
[2m[36m(func pid=77888)[0m rmse_per_class: [0.109, 0.222, 0.033, 0.264, 0.082, 0.288, 0.259, 0.161, 0.155, 0.087]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.16641749441623688
[2m[36m(func pid=77085)[0m mae:  0.11552733182907104
[2m[36m(func pid=77085)[0m rmse_per_class: [0.109, 0.256, 0.052, 0.344, 0.055, 0.189, 0.265, 0.143, 0.156, 0.095]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.27188819646835327
[2m[36m(func pid=78316)[0m mae:  0.14935347437858582
[2m[36m(func pid=78316)[0m rmse_per_class: [0.214, 0.434, 0.042, 0.382, 0.179, 0.257, 0.346, 0.262, 0.403, 0.201]
[2m[36m(func pid=78316)[0m 
== Status ==
Current time: 2024-01-07 16:30:43 (running for 00:06:40.60)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.446 |  0.166 |                   62 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.325 |  0.15  |                   66 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.309 |  0.166 |                   64 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.803 |  0.272 |                   63 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.14999577403068542
[2m[36m(func pid=77465)[0m mae:  0.0959981232881546
[2m[36m(func pid=77465)[0m rmse_per_class: [0.06, 0.245, 0.029, 0.239, 0.061, 0.167, 0.213, 0.113, 0.132, 0.241]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4330 | Steps: 4 | Val loss: 0.3226 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3025 | Steps: 4 | Val loss: 0.3256 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.7732 | Steps: 4 | Val loss: 0.9341 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3129 | Steps: 4 | Val loss: 0.2799 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=77888)[0m rmse: 0.16640329360961914
[2m[36m(func pid=77888)[0m mae:  0.09884031116962433
[2m[36m(func pid=77888)[0m rmse_per_class: [0.132, 0.218, 0.035, 0.279, 0.079, 0.279, 0.251, 0.131, 0.167, 0.092]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.16576218605041504
[2m[36m(func pid=77085)[0m mae:  0.11502953618764877
[2m[36m(func pid=77085)[0m rmse_per_class: [0.107, 0.256, 0.051, 0.341, 0.055, 0.189, 0.264, 0.143, 0.156, 0.095]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.23905479907989502
[2m[36m(func pid=78316)[0m mae:  0.13423898816108704
[2m[36m(func pid=78316)[0m rmse_per_class: [0.129, 0.351, 0.044, 0.361, 0.059, 0.397, 0.346, 0.302, 0.282, 0.118]
[2m[36m(func pid=78316)[0m 
== Status ==
Current time: 2024-01-07 16:30:48 (running for 00:06:45.90)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.433 |  0.166 |                   63 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.313 |  0.15  |                   67 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.302 |  0.166 |                   65 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.773 |  0.239 |                   64 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.14983785152435303
[2m[36m(func pid=77465)[0m mae:  0.09538491070270538
[2m[36m(func pid=77465)[0m rmse_per_class: [0.06, 0.244, 0.027, 0.244, 0.055, 0.165, 0.207, 0.11, 0.129, 0.256]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3422 | Steps: 4 | Val loss: 0.3186 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4313 | Steps: 4 | Val loss: 0.3207 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.8122 | Steps: 4 | Val loss: 0.7581 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3155 | Steps: 4 | Val loss: 0.2794 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=77888)[0m rmse: 0.16427725553512573
[2m[36m(func pid=77888)[0m mae:  0.09609328955411911
[2m[36m(func pid=77888)[0m rmse_per_class: [0.138, 0.22, 0.038, 0.293, 0.075, 0.213, 0.232, 0.127, 0.192, 0.114]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.198392853140831
[2m[36m(func pid=78316)[0m mae:  0.11085192859172821
[2m[36m(func pid=78316)[0m rmse_per_class: [0.113, 0.29, 0.043, 0.356, 0.056, 0.34, 0.297, 0.207, 0.186, 0.096]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.16543690860271454
[2m[36m(func pid=77085)[0m mae:  0.11477161943912506
[2m[36m(func pid=77085)[0m rmse_per_class: [0.109, 0.255, 0.05, 0.341, 0.055, 0.19, 0.262, 0.143, 0.155, 0.095]
[2m[36m(func pid=77085)[0m 
== Status ==
Current time: 2024-01-07 16:30:54 (running for 00:06:51.27)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.431 |  0.165 |                   64 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.315 |  0.148 |                   68 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.342 |  0.164 |                   66 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.812 |  0.198 |                   65 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.14766927063465118
[2m[36m(func pid=77465)[0m mae:  0.09344206005334854
[2m[36m(func pid=77465)[0m rmse_per_class: [0.06, 0.238, 0.025, 0.252, 0.053, 0.164, 0.202, 0.11, 0.13, 0.243]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3086 | Steps: 4 | Val loss: 0.3152 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.9966 | Steps: 4 | Val loss: 0.8413 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4285 | Steps: 4 | Val loss: 0.3170 | Batch size: 32 | lr: 0.0001 | Duration: 3.11s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3008 | Steps: 4 | Val loss: 0.2769 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=77888)[0m rmse: 0.1642032414674759
[2m[36m(func pid=77888)[0m mae:  0.09400544315576553
[2m[36m(func pid=77888)[0m rmse_per_class: [0.108, 0.224, 0.039, 0.294, 0.082, 0.179, 0.236, 0.124, 0.204, 0.152]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.18284742534160614
[2m[36m(func pid=78316)[0m mae:  0.10289520025253296
[2m[36m(func pid=78316)[0m rmse_per_class: [0.198, 0.295, 0.044, 0.316, 0.056, 0.202, 0.327, 0.142, 0.151, 0.096]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.1648760735988617
[2m[36m(func pid=77085)[0m mae:  0.11470925807952881
[2m[36m(func pid=77085)[0m rmse_per_class: [0.108, 0.255, 0.05, 0.338, 0.055, 0.19, 0.257, 0.142, 0.157, 0.096]
[2m[36m(func pid=77085)[0m 
== Status ==
Current time: 2024-01-07 16:30:59 (running for 00:06:56.45)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.428 |  0.165 |                   65 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.301 |  0.145 |                   69 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.309 |  0.164 |                   67 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.997 |  0.183 |                   66 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.14500340819358826
[2m[36m(func pid=77465)[0m mae:  0.09102697670459747
[2m[36m(func pid=77465)[0m rmse_per_class: [0.06, 0.236, 0.024, 0.25, 0.051, 0.162, 0.199, 0.11, 0.127, 0.231]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3093 | Steps: 4 | Val loss: 0.3273 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.9136 | Steps: 4 | Val loss: 0.8043 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4351 | Steps: 4 | Val loss: 0.3124 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=77888)[0m rmse: 0.17018941044807434
[2m[36m(func pid=77888)[0m mae:  0.09696552157402039
[2m[36m(func pid=77888)[0m rmse_per_class: [0.092, 0.229, 0.038, 0.293, 0.081, 0.186, 0.238, 0.12, 0.223, 0.202]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3041 | Steps: 4 | Val loss: 0.2743 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=78316)[0m rmse: 0.22805431485176086
[2m[36m(func pid=78316)[0m mae:  0.1239597424864769
[2m[36m(func pid=78316)[0m rmse_per_class: [0.375, 0.368, 0.077, 0.35, 0.056, 0.208, 0.314, 0.169, 0.166, 0.197]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.16406230628490448
[2m[36m(func pid=77085)[0m mae:  0.11438095569610596
[2m[36m(func pid=77085)[0m rmse_per_class: [0.107, 0.255, 0.05, 0.336, 0.055, 0.19, 0.254, 0.142, 0.156, 0.096]
[2m[36m(func pid=77085)[0m 
== Status ==
Current time: 2024-01-07 16:31:04 (running for 00:07:01.66)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.435 |  0.164 |                   66 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.304 |  0.142 |                   70 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.309 |  0.17  |                   68 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.914 |  0.228 |                   67 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.1420327126979828
[2m[36m(func pid=77465)[0m mae:  0.08868461102247238
[2m[36m(func pid=77465)[0m rmse_per_class: [0.06, 0.23, 0.024, 0.255, 0.05, 0.161, 0.201, 0.111, 0.129, 0.199]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3182 | Steps: 4 | Val loss: 0.3405 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.7138 | Steps: 4 | Val loss: 0.9852 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4140 | Steps: 4 | Val loss: 0.3087 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2988 | Steps: 4 | Val loss: 0.2709 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=77888)[0m rmse: 0.17261895537376404
[2m[36m(func pid=77888)[0m mae:  0.0988822728395462
[2m[36m(func pid=77888)[0m rmse_per_class: [0.079, 0.236, 0.035, 0.274, 0.081, 0.2, 0.235, 0.12, 0.204, 0.263]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.26238998770713806
[2m[36m(func pid=78316)[0m mae:  0.14262919127941132
[2m[36m(func pid=78316)[0m rmse_per_class: [0.149, 0.383, 0.24, 0.367, 0.056, 0.263, 0.331, 0.264, 0.186, 0.384]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.16348817944526672
[2m[36m(func pid=77085)[0m mae:  0.11395128071308136
[2m[36m(func pid=77085)[0m rmse_per_class: [0.105, 0.255, 0.05, 0.335, 0.055, 0.19, 0.254, 0.141, 0.154, 0.096]
[2m[36m(func pid=77085)[0m 
== Status ==
Current time: 2024-01-07 16:31:09 (running for 00:07:06.93)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.414 |  0.163 |                   67 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.299 |  0.139 |                   71 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.318 |  0.173 |                   69 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.714 |  0.262 |                   68 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.13897527754306793
[2m[36m(func pid=77465)[0m mae:  0.08685160428285599
[2m[36m(func pid=77465)[0m rmse_per_class: [0.061, 0.222, 0.024, 0.26, 0.049, 0.161, 0.202, 0.111, 0.131, 0.166]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3152 | Steps: 4 | Val loss: 0.3424 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.7314 | Steps: 4 | Val loss: 1.0644 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4226 | Steps: 4 | Val loss: 0.3062 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3058 | Steps: 4 | Val loss: 0.2719 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=77888)[0m rmse: 0.17213678359985352
[2m[36m(func pid=77888)[0m mae:  0.09859555214643478
[2m[36m(func pid=77888)[0m rmse_per_class: [0.08, 0.232, 0.03, 0.266, 0.081, 0.2, 0.237, 0.123, 0.173, 0.299]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.2558842599391937
[2m[36m(func pid=78316)[0m mae:  0.14457504451274872
[2m[36m(func pid=78316)[0m rmse_per_class: [0.107, 0.379, 0.16, 0.372, 0.057, 0.309, 0.334, 0.204, 0.228, 0.409]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.16315527260303497
[2m[36m(func pid=77085)[0m mae:  0.11384381353855133
[2m[36m(func pid=77085)[0m rmse_per_class: [0.106, 0.253, 0.05, 0.334, 0.055, 0.19, 0.253, 0.141, 0.153, 0.097]
[2m[36m(func pid=77085)[0m 
== Status ==
Current time: 2024-01-07 16:31:15 (running for 00:07:12.16)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.423 |  0.163 |                   68 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.306 |  0.139 |                   72 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.315 |  0.172 |                   70 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.731 |  0.256 |                   69 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.1388300359249115
[2m[36m(func pid=77465)[0m mae:  0.08663827180862427
[2m[36m(func pid=77465)[0m rmse_per_class: [0.061, 0.223, 0.025, 0.267, 0.049, 0.162, 0.21, 0.119, 0.134, 0.139]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3435 | Steps: 4 | Val loss: 0.3339 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.7270 | Steps: 4 | Val loss: 0.8197 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4249 | Steps: 4 | Val loss: 0.3045 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3057 | Steps: 4 | Val loss: 0.2703 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=77888)[0m rmse: 0.16912336647510529
[2m[36m(func pid=77888)[0m mae:  0.09551851451396942
[2m[36m(func pid=77888)[0m rmse_per_class: [0.083, 0.229, 0.029, 0.263, 0.087, 0.194, 0.238, 0.135, 0.152, 0.282]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.21888108551502228
[2m[36m(func pid=78316)[0m mae:  0.12131277471780777
[2m[36m(func pid=78316)[0m rmse_per_class: [0.118, 0.365, 0.068, 0.357, 0.059, 0.218, 0.315, 0.159, 0.316, 0.213]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.16294245421886444
[2m[36m(func pid=77085)[0m mae:  0.11389831453561783
[2m[36m(func pid=77085)[0m rmse_per_class: [0.106, 0.253, 0.049, 0.334, 0.055, 0.19, 0.25, 0.14, 0.153, 0.098]
[2m[36m(func pid=77085)[0m 
== Status ==
Current time: 2024-01-07 16:31:20 (running for 00:07:17.37)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.425 |  0.163 |                   69 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.306 |  0.139 |                   73 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.344 |  0.169 |                   71 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.727 |  0.219 |                   70 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.13866135478019714
[2m[36m(func pid=77465)[0m mae:  0.08659955114126205
[2m[36m(func pid=77465)[0m rmse_per_class: [0.059, 0.222, 0.026, 0.267, 0.049, 0.162, 0.215, 0.129, 0.132, 0.126]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2915 | Steps: 4 | Val loss: 0.3119 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.7061 | Steps: 4 | Val loss: 0.7445 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4126 | Steps: 4 | Val loss: 0.3018 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2953 | Steps: 4 | Val loss: 0.2652 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=77888)[0m rmse: 0.15969954431056976
[2m[36m(func pid=77888)[0m mae:  0.08938353508710861
[2m[36m(func pid=77888)[0m rmse_per_class: [0.092, 0.225, 0.032, 0.26, 0.074, 0.181, 0.238, 0.15, 0.13, 0.214]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.2035718411207199
[2m[36m(func pid=78316)[0m mae:  0.1110134869813919
[2m[36m(func pid=78316)[0m rmse_per_class: [0.198, 0.306, 0.045, 0.327, 0.118, 0.206, 0.303, 0.157, 0.267, 0.108]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.1624487340450287
[2m[36m(func pid=77085)[0m mae:  0.11388973146677017
[2m[36m(func pid=77085)[0m rmse_per_class: [0.106, 0.253, 0.05, 0.33, 0.055, 0.19, 0.25, 0.139, 0.154, 0.097]
[2m[36m(func pid=77085)[0m 
== Status ==
Current time: 2024-01-07 16:31:25 (running for 00:07:22.59)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.413 |  0.162 |                   70 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.295 |  0.136 |                   74 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.291 |  0.16  |                   72 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.706 |  0.204 |                   71 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.1356361359357834
[2m[36m(func pid=77465)[0m mae:  0.08476598560810089
[2m[36m(func pid=77465)[0m rmse_per_class: [0.059, 0.213, 0.025, 0.262, 0.049, 0.163, 0.213, 0.131, 0.132, 0.108]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2879 | Steps: 4 | Val loss: 0.2993 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.7841 | Steps: 4 | Val loss: 0.8803 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3996 | Steps: 4 | Val loss: 0.2990 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2767 | Steps: 4 | Val loss: 0.2603 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=77888)[0m rmse: 0.15324680507183075
[2m[36m(func pid=77888)[0m mae:  0.08755272626876831
[2m[36m(func pid=77888)[0m rmse_per_class: [0.092, 0.22, 0.033, 0.266, 0.06, 0.191, 0.239, 0.167, 0.124, 0.141]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.22299794852733612
[2m[36m(func pid=78316)[0m mae:  0.12485186755657196
[2m[36m(func pid=78316)[0m rmse_per_class: [0.259, 0.296, 0.043, 0.414, 0.191, 0.218, 0.327, 0.238, 0.148, 0.095]
[2m[36m(func pid=78316)[0m 
== Status ==
Current time: 2024-01-07 16:31:30 (running for 00:07:27.81)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: None
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.4   |  0.162 |                   71 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.295 |  0.136 |                   74 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.288 |  0.153 |                   73 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.784 |  0.223 |                   72 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77085)[0m rmse: 0.16192734241485596
[2m[36m(func pid=77085)[0m mae:  0.113775834441185
[2m[36m(func pid=77085)[0m rmse_per_class: [0.106, 0.253, 0.05, 0.327, 0.055, 0.19, 0.248, 0.138, 0.154, 0.098]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.13320180773735046
[2m[36m(func pid=77465)[0m mae:  0.08335977047681808
[2m[36m(func pid=77465)[0m rmse_per_class: [0.059, 0.208, 0.027, 0.258, 0.049, 0.162, 0.209, 0.13, 0.133, 0.097]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3298 | Steps: 4 | Val loss: 0.2998 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.8403 | Steps: 4 | Val loss: 0.8690 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2827 | Steps: 4 | Val loss: 0.2585 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4068 | Steps: 4 | Val loss: 0.2983 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=77888)[0m rmse: 0.15041688084602356
[2m[36m(func pid=77888)[0m mae:  0.08877477049827576
[2m[36m(func pid=77888)[0m rmse_per_class: [0.087, 0.211, 0.034, 0.269, 0.055, 0.235, 0.237, 0.154, 0.122, 0.099]
[2m[36m(func pid=77888)[0m 
[2m[36m(func pid=78316)[0m rmse: 0.23700709640979767
[2m[36m(func pid=78316)[0m mae:  0.128595232963562
[2m[36m(func pid=78316)[0m rmse_per_class: [0.183, 0.348, 0.044, 0.4, 0.224, 0.302, 0.343, 0.259, 0.134, 0.135]
[2m[36m(func pid=78316)[0m 
== Status ==
Current time: 2024-01-07 16:31:36 (running for 00:07:33.17)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=0
Bracket: Iter 75.000: -0.13300000131130219
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (20 PENDING, 4 RUNNING)
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status   | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING  | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.4   |  0.162 |                   71 |
| train_c9cb4_00001 | RUNNING  | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.283 |  0.133 |                   76 |
| train_c9cb4_00002 | RUNNING  | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.33  |  0.15  |                   74 |
| train_c9cb4_00003 | RUNNING  | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.84  |  0.237 |                   73 |
| train_c9cb4_00004 | PENDING  |                    | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING  |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING  |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING  |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING  |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING  |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING  |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING  |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING  |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING  |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING  |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING  |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING  |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING  |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING  |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING  |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
+-------------------+----------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.1326332539319992
[2m[36m(func pid=77465)[0m mae:  0.08321119099855423
[2m[36m(func pid=77465)[0m rmse_per_class: [0.058, 0.206, 0.029, 0.257, 0.05, 0.159, 0.209, 0.136, 0.134, 0.089]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.16210968792438507
[2m[36m(func pid=77085)[0m mae:  0.11418326199054718
[2m[36m(func pid=77085)[0m rmse_per_class: [0.108, 0.253, 0.051, 0.324, 0.055, 0.189, 0.248, 0.139, 0.155, 0.1]
[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77888)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3064 | Steps: 4 | Val loss: 0.3083 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.7803 | Steps: 4 | Val loss: 0.8230 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.3202 | Steps: 4 | Val loss: 0.2640 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4233 | Steps: 4 | Val loss: 0.2972 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=77888)[0m rmse: 0.15366056561470032
[2m[36m(func pid=77888)[0m mae:  0.0924624651670456
[2m[36m(func pid=77888)[0m rmse_per_class: [0.087, 0.211, 0.034, 0.277, 0.054, 0.266, 0.24, 0.152, 0.126, 0.088]
[2m[36m(func pid=78316)[0m rmse: 0.23217299580574036
[2m[36m(func pid=78316)[0m mae:  0.12789885699748993
[2m[36m(func pid=78316)[0m rmse_per_class: [0.129, 0.444, 0.048, 0.359, 0.143, 0.306, 0.321, 0.207, 0.134, 0.232]
[2m[36m(func pid=78316)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.13593938946723938
[2m[36m(func pid=77465)[0m mae:  0.08542218059301376
[2m[36m(func pid=77465)[0m rmse_per_class: [0.059, 0.205, 0.03, 0.264, 0.05, 0.161, 0.214, 0.156, 0.134, 0.086]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.16197863221168518
[2m[36m(func pid=77085)[0m mae:  0.11412863433361053
[2m[36m(func pid=77085)[0m rmse_per_class: [0.11, 0.252, 0.051, 0.322, 0.055, 0.189, 0.248, 0.139, 0.154, 0.1]
[2m[36m(func pid=78316)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.7696 | Steps: 4 | Val loss: 0.8511 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.3107 | Steps: 4 | Val loss: 0.2633 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=78316)[0m rmse: 0.21888700127601624
[2m[36m(func pid=78316)[0m mae:  0.12149164825677872
[2m[36m(func pid=78316)[0m rmse_per_class: [0.128, 0.315, 0.089, 0.341, 0.087, 0.222, 0.378, 0.185, 0.136, 0.308]
[2m[36m(func pid=77465)[0m rmse: 0.13598212599754333
[2m[36m(func pid=77465)[0m mae:  0.08557644486427307
[2m[36m(func pid=77465)[0m rmse_per_class: [0.059, 0.205, 0.031, 0.264, 0.051, 0.16, 0.213, 0.161, 0.133, 0.083]
== Status ==
Current time: 2024-01-07 16:31:41 (running for 00:07:38.41)
Memory usage on this node: 22.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=1
Bracket: Iter 75.000: -0.13825000077486038
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 4 RUNNING, 1 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING    | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.407 |  0.162 |                   72 |
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.32  |  0.136 |                   77 |
| train_c9cb4_00003 | RUNNING    | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.78  |  0.232 |                   74 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=95877)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=95877)[0m Configuration completed!
[2m[36m(func pid=95877)[0m New optimizer parameters:
[2m[36m(func pid=95877)[0m SGD (
[2m[36m(func pid=95877)[0m Parameter Group 0
[2m[36m(func pid=95877)[0m     dampening: 0
[2m[36m(func pid=95877)[0m     differentiable: False
[2m[36m(func pid=95877)[0m     foreach: None
[2m[36m(func pid=95877)[0m     lr: 0.0001
[2m[36m(func pid=95877)[0m     maximize: False
[2m[36m(func pid=95877)[0m     momentum: 0.9
[2m[36m(func pid=95877)[0m     nesterov: False
[2m[36m(func pid=95877)[0m     weight_decay: 0
[2m[36m(func pid=95877)[0m )
[2m[36m(func pid=95877)[0m 
== Status ==
Current time: 2024-01-07 16:31:48 (running for 00:07:46.04)
Memory usage on this node: 22.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.14350000023841858
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (19 PENDING, 3 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING    | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.407 |  0.162 |                   72 |
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.32  |  0.136 |                   77 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | PENDING    |                    | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.3120 | Steps: 4 | Val loss: 0.2607 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4008 | Steps: 4 | Val loss: 0.2963 | Batch size: 32 | lr: 0.0001 | Duration: 3.31s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0835 | Steps: 4 | Val loss: 0.8162 | Batch size: 32 | lr: 0.0001 | Duration: 4.78s
[2m[36m(func pid=77465)[0m rmse: 0.13446028530597687
[2m[36m(func pid=77465)[0m mae:  0.08478691428899765
[2m[36m(func pid=77465)[0m rmse_per_class: [0.059, 0.203, 0.031, 0.259, 0.051, 0.163, 0.214, 0.152, 0.132, 0.08]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.1618078052997589
[2m[36m(func pid=77085)[0m mae:  0.11421843618154526
[2m[36m(func pid=77085)[0m rmse_per_class: [0.109, 0.252, 0.051, 0.32, 0.055, 0.189, 0.249, 0.138, 0.153, 0.101]
[2m[36m(func pid=95877)[0m rmse: 0.17938408255577087
[2m[36m(func pid=95877)[0m mae:  0.13167992234230042
[2m[36m(func pid=95877)[0m rmse_per_class: [0.104, 0.265, 0.09, 0.325, 0.102, 0.193, 0.306, 0.153, 0.139, 0.117]
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2858 | Steps: 4 | Val loss: 0.2621 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 16:31:54 (running for 00:07:51.58)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.14350000023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING    | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.423 |  0.162 |                   73 |
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.312 |  0.134 |                   79 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |        |        |                      |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77085)[0m 
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=96425)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=96425)[0m Configuration completed!
[2m[36m(func pid=96425)[0m New optimizer parameters:
[2m[36m(func pid=96425)[0m SGD (
[2m[36m(func pid=96425)[0m Parameter Group 0
[2m[36m(func pid=96425)[0m     dampening: 0
[2m[36m(func pid=96425)[0m     differentiable: False
[2m[36m(func pid=96425)[0m     foreach: None
[2m[36m(func pid=96425)[0m     lr: 0.001
[2m[36m(func pid=96425)[0m     maximize: False
[2m[36m(func pid=96425)[0m     momentum: 0.9
[2m[36m(func pid=96425)[0m     nesterov: False
[2m[36m(func pid=96425)[0m     weight_decay: 0
[2m[36m(func pid=96425)[0m )
[2m[36m(func pid=96425)[0m 
== Status ==
Current time: 2024-01-07 16:31:59 (running for 00:07:56.80)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=2
Bracket: Iter 75.000: -0.14350000023841858
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (18 PENDING, 4 RUNNING, 2 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | RUNNING    | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.401 |  0.162 |                   74 |
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.286 |  0.136 |                   80 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  1.084 |  0.179 |                    1 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |        |        |                      |
| train_c9cb4_00006 | PENDING    |                    | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.13562601804733276
[2m[36m(func pid=77465)[0m mae:  0.0856921449303627
[2m[36m(func pid=77465)[0m rmse_per_class: [0.06, 0.207, 0.031, 0.258, 0.051, 0.163, 0.219, 0.155, 0.132, 0.08]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0746 | Steps: 4 | Val loss: 0.8192 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=77085)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3952 | Steps: 4 | Val loss: 0.2955 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0629 | Steps: 4 | Val loss: 0.7529 | Batch size: 32 | lr: 0.001 | Duration: 4.27s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2964 | Steps: 4 | Val loss: 0.2622 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=95877)[0m rmse: 0.18011535704135895
[2m[36m(func pid=95877)[0m mae:  0.13222850859165192
[2m[36m(func pid=95877)[0m rmse_per_class: [0.105, 0.266, 0.091, 0.325, 0.104, 0.193, 0.307, 0.153, 0.138, 0.119]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=77085)[0m rmse: 0.16156895458698273
[2m[36m(func pid=77085)[0m mae:  0.11407007277011871
[2m[36m(func pid=77085)[0m rmse_per_class: [0.108, 0.253, 0.05, 0.318, 0.055, 0.189, 0.25, 0.138, 0.153, 0.101]
[2m[36m(func pid=96425)[0m rmse: 0.17887379229068756
[2m[36m(func pid=96425)[0m mae:  0.13130402565002441
[2m[36m(func pid=96425)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.325, 0.101, 0.192, 0.305, 0.155, 0.139, 0.115]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.1358179897069931
[2m[36m(func pid=77465)[0m mae:  0.0859045758843422
[2m[36m(func pid=77465)[0m rmse_per_class: [0.058, 0.21, 0.028, 0.257, 0.051, 0.162, 0.223, 0.157, 0.133, 0.08]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 1.0499 | Steps: 4 | Val loss: 0.8004 | Batch size: 32 | lr: 0.0001 | Duration: 2.72s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.9189 | Steps: 4 | Val loss: 0.6426 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.3103 | Steps: 4 | Val loss: 0.2582 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=95877)[0m rmse: 0.1801670640707016
[2m[36m(func pid=95877)[0m mae:  0.13229700922966003
[2m[36m(func pid=95877)[0m rmse_per_class: [0.106, 0.266, 0.088, 0.324, 0.105, 0.193, 0.308, 0.154, 0.138, 0.119]
[2m[36m(func pid=96425)[0m rmse: 0.17897889018058777
[2m[36m(func pid=96425)[0m mae:  0.1311969757080078
[2m[36m(func pid=96425)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.324, 0.1, 0.193, 0.305, 0.156, 0.138, 0.117]
[2m[36m(func pid=77465)[0m rmse: 0.13413721323013306
[2m[36m(func pid=77465)[0m mae:  0.08496184647083282
[2m[36m(func pid=77465)[0m rmse_per_class: [0.057, 0.207, 0.031, 0.248, 0.051, 0.161, 0.226, 0.142, 0.138, 0.08]
== Status ==
Current time: 2024-01-07 16:32:04 (running for 00:08:02.09)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.296 |  0.136 |                   81 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  1.075 |  0.18  |                    2 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  1.063 |  0.179 |                    1 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


== Status ==
Current time: 2024-01-07 16:32:11 (running for 00:08:08.55)
Memory usage on this node: 23.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.296 |  0.136 |                   81 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  1.075 |  0.18  |                    2 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.919 |  0.179 |                    2 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=97213)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=97213)[0m Configuration completed!
[2m[36m(func pid=97213)[0m New optimizer parameters:
[2m[36m(func pid=97213)[0m SGD (
[2m[36m(func pid=97213)[0m Parameter Group 0
[2m[36m(func pid=97213)[0m     dampening: 0
[2m[36m(func pid=97213)[0m     differentiable: False
[2m[36m(func pid=97213)[0m     foreach: None
[2m[36m(func pid=97213)[0m     lr: 0.01
[2m[36m(func pid=97213)[0m     maximize: False
[2m[36m(func pid=97213)[0m     momentum: 0.9
[2m[36m(func pid=97213)[0m     nesterov: False
[2m[36m(func pid=97213)[0m     weight_decay: 0
[2m[36m(func pid=97213)[0m )
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2984 | Steps: 4 | Val loss: 0.2574 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.7493 | Steps: 4 | Val loss: 0.5194 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 1.0097 | Steps: 4 | Val loss: 0.7803 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8764 | Steps: 4 | Val loss: 0.4366 | Batch size: 32 | lr: 0.01 | Duration: 4.62s
== Status ==
Current time: 2024-01-07 16:32:16 (running for 00:08:13.57)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.31  |  0.134 |                   82 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  1.05  |  0.18  |                    3 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.919 |  0.179 |                    2 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |        |        |                      |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.1789707988500595
[2m[36m(func pid=96425)[0m mae:  0.1308804154396057
[2m[36m(func pid=96425)[0m rmse_per_class: [0.105, 0.267, 0.088, 0.325, 0.098, 0.193, 0.302, 0.157, 0.138, 0.117]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.13295605778694153
[2m[36m(func pid=77465)[0m mae:  0.08420295268297195
[2m[36m(func pid=77465)[0m rmse_per_class: [0.058, 0.206, 0.03, 0.241, 0.05, 0.16, 0.231, 0.138, 0.137, 0.078]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.1807149201631546
[2m[36m(func pid=95877)[0m mae:  0.1327567994594574
[2m[36m(func pid=95877)[0m rmse_per_class: [0.107, 0.266, 0.09, 0.324, 0.105, 0.194, 0.309, 0.153, 0.138, 0.12]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.17697225511074066
[2m[36m(func pid=97213)[0m mae:  0.12925180792808533
[2m[36m(func pid=97213)[0m rmse_per_class: [0.104, 0.27, 0.09, 0.327, 0.092, 0.192, 0.293, 0.152, 0.141, 0.11]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.3022 | Steps: 4 | Val loss: 0.2563 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.5986 | Steps: 4 | Val loss: 0.4247 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.9752 | Steps: 4 | Val loss: 0.7517 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.4497 | Steps: 4 | Val loss: 0.3195 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=96425)[0m rmse: 0.17888610064983368
[2m[36m(func pid=96425)[0m mae:  0.13058233261108398
[2m[36m(func pid=96425)[0m rmse_per_class: [0.106, 0.267, 0.094, 0.328, 0.097, 0.193, 0.298, 0.151, 0.139, 0.115]
[2m[36m(func pid=96425)[0m 
== Status ==
Current time: 2024-01-07 16:32:22 (running for 00:08:19.12)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.298 |  0.133 |                   83 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  1.01  |  0.181 |                    4 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.599 |  0.179 |                    4 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |  0.876 |  0.177 |                    1 |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.13244721293449402
[2m[36m(func pid=77465)[0m mae:  0.08383757621049881
[2m[36m(func pid=77465)[0m rmse_per_class: [0.057, 0.202, 0.033, 0.237, 0.05, 0.159, 0.233, 0.136, 0.139, 0.078]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.18094179034233093
[2m[36m(func pid=95877)[0m mae:  0.1329287588596344
[2m[36m(func pid=95877)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.106, 0.194, 0.31, 0.153, 0.138, 0.12]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.17196375131607056
[2m[36m(func pid=97213)[0m mae:  0.12357504665851593
[2m[36m(func pid=97213)[0m rmse_per_class: [0.106, 0.274, 0.09, 0.332, 0.075, 0.192, 0.275, 0.134, 0.145, 0.097]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.3048 | Steps: 4 | Val loss: 0.2545 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.5019 | Steps: 4 | Val loss: 0.3708 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.9424 | Steps: 4 | Val loss: 0.7240 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.4656 | Steps: 4 | Val loss: 0.3511 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 16:32:27 (running for 00:08:24.35)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.302 |  0.132 |                   84 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  0.975 |  0.181 |                    5 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.502 |  0.178 |                    5 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |  0.45  |  0.172 |                    2 |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.17788617312908173
[2m[36m(func pid=96425)[0m mae:  0.12966284155845642
[2m[36m(func pid=96425)[0m rmse_per_class: [0.106, 0.267, 0.097, 0.33, 0.094, 0.193, 0.293, 0.146, 0.14, 0.114]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.13120301067829132
[2m[36m(func pid=77465)[0m mae:  0.08305759727954865
[2m[36m(func pid=77465)[0m rmse_per_class: [0.058, 0.199, 0.031, 0.233, 0.049, 0.161, 0.231, 0.135, 0.138, 0.078]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.18119004368782043
[2m[36m(func pid=95877)[0m mae:  0.13312558829784393
[2m[36m(func pid=95877)[0m rmse_per_class: [0.108, 0.267, 0.09, 0.324, 0.106, 0.194, 0.31, 0.153, 0.138, 0.121]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.17011559009552002
[2m[36m(func pid=97213)[0m mae:  0.11989396810531616
[2m[36m(func pid=97213)[0m rmse_per_class: [0.107, 0.274, 0.076, 0.328, 0.063, 0.191, 0.279, 0.136, 0.155, 0.093]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4527 | Steps: 4 | Val loss: 0.3420 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2761 | Steps: 4 | Val loss: 0.2544 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.9111 | Steps: 4 | Val loss: 0.7015 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=96425)[0m rmse: 0.17760591208934784
[2m[36m(func pid=96425)[0m mae:  0.12927469611167908
[2m[36m(func pid=96425)[0m rmse_per_class: [0.109, 0.269, 0.098, 0.332, 0.09, 0.193, 0.289, 0.142, 0.142, 0.113]
[2m[36m(func pid=96425)[0m 
== Status ==
Current time: 2024-01-07 16:32:32 (running for 00:08:29.43)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.305 |  0.131 |                   85 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  0.942 |  0.181 |                    6 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.453 |  0.178 |                    6 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |  0.466 |  0.17  |                    3 |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.5194 | Steps: 4 | Val loss: 0.3541 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=77465)[0m rmse: 0.13243147730827332
[2m[36m(func pid=77465)[0m mae:  0.08374147862195969
[2m[36m(func pid=77465)[0m rmse_per_class: [0.059, 0.2, 0.034, 0.232, 0.049, 0.162, 0.235, 0.134, 0.14, 0.08]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.18122363090515137
[2m[36m(func pid=95877)[0m mae:  0.1331307291984558
[2m[36m(func pid=95877)[0m rmse_per_class: [0.108, 0.267, 0.09, 0.325, 0.106, 0.194, 0.31, 0.153, 0.138, 0.121]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.16674618422985077
[2m[36m(func pid=97213)[0m mae:  0.11565881967544556
[2m[36m(func pid=97213)[0m rmse_per_class: [0.104, 0.27, 0.059, 0.314, 0.058, 0.19, 0.281, 0.141, 0.159, 0.092]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4320 | Steps: 4 | Val loss: 0.3312 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2801 | Steps: 4 | Val loss: 0.2541 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.8773 | Steps: 4 | Val loss: 0.6696 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 16:32:37 (running for 00:08:34.66)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.276 |  0.132 |                   86 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  0.911 |  0.181 |                    7 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.432 |  0.178 |                    7 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |  0.519 |  0.167 |                    4 |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.17764373123645782
[2m[36m(func pid=96425)[0m mae:  0.12916824221611023
[2m[36m(func pid=96425)[0m rmse_per_class: [0.111, 0.269, 0.099, 0.335, 0.088, 0.193, 0.286, 0.14, 0.143, 0.112]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.13233253359794617
[2m[36m(func pid=77465)[0m mae:  0.08401448279619217
[2m[36m(func pid=77465)[0m rmse_per_class: [0.06, 0.202, 0.032, 0.231, 0.049, 0.164, 0.235, 0.119, 0.146, 0.085]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.5202 | Steps: 4 | Val loss: 0.3332 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=95877)[0m rmse: 0.18086807429790497
[2m[36m(func pid=95877)[0m mae:  0.13284873962402344
[2m[36m(func pid=95877)[0m rmse_per_class: [0.108, 0.266, 0.088, 0.324, 0.104, 0.194, 0.31, 0.154, 0.139, 0.121]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.16374054551124573
[2m[36m(func pid=97213)[0m mae:  0.11290343105792999
[2m[36m(func pid=97213)[0m rmse_per_class: [0.101, 0.265, 0.051, 0.302, 0.056, 0.188, 0.271, 0.145, 0.167, 0.092]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4339 | Steps: 4 | Val loss: 0.3263 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2770 | Steps: 4 | Val loss: 0.2553 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.8442 | Steps: 4 | Val loss: 0.6424 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=96425)[0m rmse: 0.1773723065853119
[2m[36m(func pid=96425)[0m mae:  0.12890318036079407
[2m[36m(func pid=96425)[0m rmse_per_class: [0.115, 0.269, 0.098, 0.337, 0.083, 0.193, 0.283, 0.139, 0.144, 0.113]
[2m[36m(func pid=96425)[0m 
== Status ==
Current time: 2024-01-07 16:32:42 (running for 00:08:40.08)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.28  |  0.132 |                   87 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  0.877 |  0.181 |                    8 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.434 |  0.177 |                    8 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |  0.52  |  0.164 |                    5 |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.1344992220401764
[2m[36m(func pid=77465)[0m mae:  0.08483774214982986
[2m[36m(func pid=77465)[0m rmse_per_class: [0.063, 0.207, 0.034, 0.232, 0.049, 0.163, 0.232, 0.121, 0.151, 0.093]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.18072839081287384
[2m[36m(func pid=95877)[0m mae:  0.13273772597312927
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.267, 0.086, 0.325, 0.102, 0.194, 0.309, 0.155, 0.139, 0.122]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4722 | Steps: 4 | Val loss: 0.3018 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2990 | Steps: 4 | Val loss: 0.2584 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.4211 | Steps: 4 | Val loss: 0.3235 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=97213)[0m rmse: 0.15889234840869904
[2m[36m(func pid=97213)[0m mae:  0.10949809849262238
[2m[36m(func pid=97213)[0m rmse_per_class: [0.099, 0.257, 0.048, 0.295, 0.055, 0.187, 0.258, 0.143, 0.156, 0.092]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.8187 | Steps: 4 | Val loss: 0.6214 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 16:32:48 (running for 00:08:45.42)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.277 |  0.134 |                   88 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  0.844 |  0.181 |                    9 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.421 |  0.176 |                    9 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |  0.472 |  0.159 |                    6 |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.17644551396369934
[2m[36m(func pid=96425)[0m mae:  0.12820687890052795
[2m[36m(func pid=96425)[0m rmse_per_class: [0.115, 0.269, 0.095, 0.336, 0.08, 0.193, 0.282, 0.138, 0.144, 0.112]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.1368248164653778
[2m[36m(func pid=77465)[0m mae:  0.0867042988538742
[2m[36m(func pid=77465)[0m rmse_per_class: [0.069, 0.211, 0.034, 0.233, 0.051, 0.163, 0.233, 0.113, 0.157, 0.104]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.18077367544174194
[2m[36m(func pid=95877)[0m mae:  0.13271889090538025
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.266, 0.086, 0.325, 0.103, 0.195, 0.309, 0.156, 0.138, 0.121]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4283 | Steps: 4 | Val loss: 0.2843 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2850 | Steps: 4 | Val loss: 0.2608 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4174 | Steps: 4 | Val loss: 0.3216 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=97213)[0m rmse: 0.15528085827827454
[2m[36m(func pid=97213)[0m mae:  0.10783064365386963
[2m[36m(func pid=97213)[0m rmse_per_class: [0.095, 0.253, 0.048, 0.293, 0.055, 0.186, 0.249, 0.136, 0.144, 0.094]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.7923 | Steps: 4 | Val loss: 0.6038 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=96425)[0m rmse: 0.17592473328113556
[2m[36m(func pid=96425)[0m mae:  0.12779733538627625
[2m[36m(func pid=96425)[0m rmse_per_class: [0.118, 0.269, 0.092, 0.333, 0.078, 0.193, 0.282, 0.136, 0.145, 0.113]
[2m[36m(func pid=96425)[0m 
== Status ==
Current time: 2024-01-07 16:32:53 (running for 00:08:50.54)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.299 |  0.137 |                   89 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  0.819 |  0.181 |                   10 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.417 |  0.176 |                   10 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |  0.428 |  0.155 |                    7 |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.13904587924480438
[2m[36m(func pid=77465)[0m mae:  0.08806954324245453
[2m[36m(func pid=77465)[0m rmse_per_class: [0.068, 0.22, 0.037, 0.233, 0.055, 0.162, 0.227, 0.11, 0.163, 0.114]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.18073567748069763
[2m[36m(func pid=95877)[0m mae:  0.1326359510421753
[2m[36m(func pid=95877)[0m rmse_per_class: [0.108, 0.266, 0.088, 0.326, 0.101, 0.194, 0.308, 0.156, 0.138, 0.122]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4034 | Steps: 4 | Val loss: 0.2887 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2981 | Steps: 4 | Val loss: 0.2658 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4143 | Steps: 4 | Val loss: 0.3200 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=97213)[0m rmse: 0.15750020742416382
[2m[36m(func pid=97213)[0m mae:  0.1107889786362648
[2m[36m(func pid=97213)[0m rmse_per_class: [0.094, 0.251, 0.048, 0.297, 0.055, 0.185, 0.254, 0.127, 0.141, 0.123]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.7581 | Steps: 4 | Val loss: 0.5862 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 16:32:58 (running for 00:08:55.77)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.285 |  0.139 |                   90 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  0.792 |  0.181 |                   11 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.414 |  0.175 |                   11 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |  0.403 |  0.158 |                    8 |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.1750856637954712
[2m[36m(func pid=96425)[0m mae:  0.12705835700035095
[2m[36m(func pid=96425)[0m rmse_per_class: [0.118, 0.269, 0.089, 0.332, 0.075, 0.193, 0.28, 0.136, 0.146, 0.113]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.14302824437618256
[2m[36m(func pid=77465)[0m mae:  0.09067364037036896
[2m[36m(func pid=77465)[0m rmse_per_class: [0.07, 0.224, 0.041, 0.237, 0.059, 0.163, 0.227, 0.111, 0.168, 0.13]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.18057718873023987
[2m[36m(func pid=95877)[0m mae:  0.13247624039649963
[2m[36m(func pid=95877)[0m rmse_per_class: [0.108, 0.267, 0.087, 0.325, 0.101, 0.194, 0.307, 0.155, 0.138, 0.123]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.3945 | Steps: 4 | Val loss: 0.2941 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2586 | Steps: 4 | Val loss: 0.2657 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4118 | Steps: 4 | Val loss: 0.3196 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.7455 | Steps: 4 | Val loss: 0.5667 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=97213)[0m rmse: 0.16075511276721954
[2m[36m(func pid=97213)[0m mae:  0.11355950683355331
[2m[36m(func pid=97213)[0m rmse_per_class: [0.094, 0.255, 0.049, 0.299, 0.055, 0.182, 0.26, 0.126, 0.138, 0.149]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.14293169975280762
[2m[36m(func pid=77465)[0m mae:  0.08975733816623688
[2m[36m(func pid=77465)[0m rmse_per_class: [0.072, 0.231, 0.04, 0.235, 0.062, 0.164, 0.22, 0.11, 0.158, 0.137]
[2m[36m(func pid=77465)[0m 
== Status ==
Current time: 2024-01-07 16:33:04 (running for 00:09:01.19)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.259 |  0.143 |                   92 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  0.758 |  0.181 |                   12 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.414 |  0.175 |                   11 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |  0.394 |  0.161 |                    9 |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.17453119158744812
[2m[36m(func pid=96425)[0m mae:  0.12657205760478973
[2m[36m(func pid=96425)[0m rmse_per_class: [0.118, 0.268, 0.086, 0.333, 0.074, 0.193, 0.278, 0.136, 0.145, 0.114]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.18072904646396637
[2m[36m(func pid=95877)[0m mae:  0.13252896070480347
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.267, 0.087, 0.325, 0.1, 0.194, 0.307, 0.155, 0.138, 0.124]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3685 | Steps: 4 | Val loss: 0.2991 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2884 | Steps: 4 | Val loss: 0.2693 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4155 | Steps: 4 | Val loss: 0.3183 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7129 | Steps: 4 | Val loss: 0.5478 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=97213)[0m rmse: 0.16447953879833221
[2m[36m(func pid=97213)[0m mae:  0.1161532774567604
[2m[36m(func pid=97213)[0m rmse_per_class: [0.091, 0.261, 0.057, 0.305, 0.055, 0.181, 0.265, 0.158, 0.138, 0.133]
[2m[36m(func pid=97213)[0m 
== Status ==
Current time: 2024-01-07 16:33:09 (running for 00:09:06.43)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.288 |  0.146 |                   93 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  0.745 |  0.181 |                   13 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.412 |  0.175 |                   12 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |  0.369 |  0.164 |                   10 |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.1456015557050705
[2m[36m(func pid=77465)[0m mae:  0.0912616103887558
[2m[36m(func pid=77465)[0m rmse_per_class: [0.074, 0.235, 0.038, 0.237, 0.068, 0.164, 0.216, 0.111, 0.16, 0.152]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.17372703552246094
[2m[36m(func pid=96425)[0m mae:  0.12592944502830505
[2m[36m(func pid=96425)[0m rmse_per_class: [0.116, 0.268, 0.085, 0.332, 0.073, 0.193, 0.277, 0.136, 0.146, 0.112]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.18021781742572784
[2m[36m(func pid=95877)[0m mae:  0.13202832639217377
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.268, 0.088, 0.324, 0.1, 0.194, 0.305, 0.154, 0.138, 0.123]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3758 | Steps: 4 | Val loss: 0.3022 | Batch size: 32 | lr: 0.01 | Duration: 3.15s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2680 | Steps: 4 | Val loss: 0.2698 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4101 | Steps: 4 | Val loss: 0.3179 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.7015 | Steps: 4 | Val loss: 0.5387 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=97213)[0m rmse: 0.16672495007514954
[2m[36m(func pid=97213)[0m mae:  0.11745371669530869
[2m[36m(func pid=97213)[0m rmse_per_class: [0.089, 0.263, 0.084, 0.312, 0.06, 0.18, 0.261, 0.161, 0.139, 0.119]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.14592020213603973
[2m[36m(func pid=77465)[0m mae:  0.09108276665210724
[2m[36m(func pid=77465)[0m rmse_per_class: [0.07, 0.238, 0.041, 0.237, 0.075, 0.164, 0.21, 0.111, 0.167, 0.146]
[2m[36m(func pid=77465)[0m 
== Status ==
Current time: 2024-01-07 16:33:14 (running for 00:09:11.74)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.268 |  0.146 |                   94 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  0.713 |  0.18  |                   14 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.415 |  0.174 |                   13 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |  0.376 |  0.167 |                   11 |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.1736319363117218
[2m[36m(func pid=96425)[0m mae:  0.12575004994869232
[2m[36m(func pid=96425)[0m rmse_per_class: [0.117, 0.269, 0.083, 0.331, 0.073, 0.193, 0.276, 0.135, 0.146, 0.114]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.18040628731250763
[2m[36m(func pid=95877)[0m mae:  0.1321638822555542
[2m[36m(func pid=95877)[0m rmse_per_class: [0.108, 0.267, 0.09, 0.325, 0.099, 0.194, 0.305, 0.154, 0.138, 0.123]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.3678 | Steps: 4 | Val loss: 0.2960 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2964 | Steps: 4 | Val loss: 0.2697 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4203 | Steps: 4 | Val loss: 0.3163 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.6761 | Steps: 4 | Val loss: 0.5234 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=97213)[0m rmse: 0.16322574019432068
[2m[36m(func pid=97213)[0m mae:  0.11462663114070892
[2m[36m(func pid=97213)[0m rmse_per_class: [0.087, 0.254, 0.117, 0.305, 0.068, 0.179, 0.253, 0.129, 0.139, 0.101]
[2m[36m(func pid=97213)[0m 
== Status ==
Current time: 2024-01-07 16:33:19 (running for 00:09:16.87)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.296 |  0.146 |                   95 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  0.702 |  0.18  |                   15 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.41  |  0.174 |                   14 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |  0.368 |  0.163 |                   12 |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.14562618732452393
[2m[36m(func pid=77465)[0m mae:  0.09084071218967438
[2m[36m(func pid=77465)[0m rmse_per_class: [0.067, 0.236, 0.035, 0.237, 0.08, 0.166, 0.207, 0.111, 0.163, 0.154]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.17269794642925262
[2m[36m(func pid=96425)[0m mae:  0.12503311038017273
[2m[36m(func pid=96425)[0m rmse_per_class: [0.115, 0.267, 0.081, 0.33, 0.07, 0.192, 0.276, 0.136, 0.145, 0.114]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.1805197298526764
[2m[36m(func pid=95877)[0m mae:  0.13215187191963196
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.268, 0.09, 0.324, 0.101, 0.194, 0.306, 0.154, 0.138, 0.123]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.3692 | Steps: 4 | Val loss: 0.2891 | Batch size: 32 | lr: 0.01 | Duration: 3.34s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2730 | Steps: 4 | Val loss: 0.2689 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.4092 | Steps: 4 | Val loss: 0.3154 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.6655 | Steps: 4 | Val loss: 0.5088 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 16:33:25 (running for 00:09:22.34)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.296 |  0.146 |                   95 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  0.676 |  0.181 |                   16 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.42  |  0.173 |                   15 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |  0.369 |  0.159 |                   13 |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=77465)[0m rmse: 0.1444859504699707
[2m[36m(func pid=77465)[0m mae:  0.08991284668445587
[2m[36m(func pid=77465)[0m rmse_per_class: [0.065, 0.235, 0.036, 0.239, 0.077, 0.166, 0.201, 0.11, 0.16, 0.157]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.17220912873744965
[2m[36m(func pid=96425)[0m mae:  0.12466512620449066
[2m[36m(func pid=96425)[0m rmse_per_class: [0.113, 0.268, 0.08, 0.329, 0.07, 0.193, 0.275, 0.136, 0.145, 0.114]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.1592922955751419
[2m[36m(func pid=97213)[0m mae:  0.11186808347702026
[2m[36m(func pid=97213)[0m rmse_per_class: [0.086, 0.245, 0.106, 0.302, 0.076, 0.177, 0.246, 0.119, 0.142, 0.094]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.1804664433002472
[2m[36m(func pid=95877)[0m mae:  0.1321631371974945
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.268, 0.091, 0.325, 0.1, 0.194, 0.306, 0.153, 0.139, 0.121]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4087 | Steps: 4 | Val loss: 0.3147 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2844 | Steps: 4 | Val loss: 0.2676 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.3512 | Steps: 4 | Val loss: 0.2803 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.6451 | Steps: 4 | Val loss: 0.4976 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 16:33:30 (running for 00:09:27.47)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.273 |  0.144 |                   96 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  0.666 |  0.18  |                   17 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.409 |  0.172 |                   17 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |  0.369 |  0.159 |                   13 |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.17181099951267242
[2m[36m(func pid=96425)[0m mae:  0.12436030060052872
[2m[36m(func pid=96425)[0m rmse_per_class: [0.112, 0.267, 0.079, 0.328, 0.069, 0.193, 0.276, 0.136, 0.145, 0.114]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.14314411580562592
[2m[36m(func pid=77465)[0m mae:  0.08916884660720825
[2m[36m(func pid=77465)[0m rmse_per_class: [0.06, 0.238, 0.036, 0.241, 0.076, 0.165, 0.202, 0.109, 0.159, 0.146]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.1531672477722168
[2m[36m(func pid=97213)[0m mae:  0.10722192376852036
[2m[36m(func pid=97213)[0m rmse_per_class: [0.083, 0.24, 0.072, 0.298, 0.08, 0.176, 0.237, 0.117, 0.138, 0.091]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.18011704087257385
[2m[36m(func pid=95877)[0m mae:  0.1318550705909729
[2m[36m(func pid=95877)[0m rmse_per_class: [0.108, 0.268, 0.089, 0.325, 0.101, 0.194, 0.305, 0.152, 0.139, 0.121]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4083 | Steps: 4 | Val loss: 0.3130 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2775 | Steps: 4 | Val loss: 0.2688 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.3459 | Steps: 4 | Val loss: 0.2705 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.6289 | Steps: 4 | Val loss: 0.4880 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 16:33:35 (running for 00:09:32.67)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.284 |  0.143 |                   97 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  0.645 |  0.18  |                   18 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.408 |  0.171 |                   18 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |  0.351 |  0.153 |                   14 |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.17088988423347473
[2m[36m(func pid=96425)[0m mae:  0.12358678877353668
[2m[36m(func pid=96425)[0m rmse_per_class: [0.11, 0.267, 0.077, 0.327, 0.069, 0.192, 0.274, 0.136, 0.145, 0.112]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.1437707245349884
[2m[36m(func pid=77465)[0m mae:  0.0893767848610878
[2m[36m(func pid=77465)[0m rmse_per_class: [0.061, 0.236, 0.035, 0.249, 0.082, 0.165, 0.204, 0.108, 0.154, 0.142]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.14666351675987244
[2m[36m(func pid=97213)[0m mae:  0.10203131288290024
[2m[36m(func pid=97213)[0m rmse_per_class: [0.079, 0.238, 0.052, 0.275, 0.071, 0.175, 0.234, 0.117, 0.136, 0.09]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.18010321259498596
[2m[36m(func pid=95877)[0m mae:  0.13190361857414246
[2m[36m(func pid=95877)[0m rmse_per_class: [0.107, 0.268, 0.091, 0.326, 0.098, 0.194, 0.305, 0.152, 0.139, 0.121]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.4071 | Steps: 4 | Val loss: 0.3128 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2811 | Steps: 4 | Val loss: 0.2672 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3375 | Steps: 4 | Val loss: 0.2708 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.6168 | Steps: 4 | Val loss: 0.4761 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 16:33:40 (running for 00:09:37.95)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.277 |  0.144 |                   98 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  0.629 |  0.18  |                   19 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.407 |  0.171 |                   19 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |  0.346 |  0.147 |                   15 |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.1708049774169922
[2m[36m(func pid=96425)[0m mae:  0.12358095496892929
[2m[36m(func pid=96425)[0m rmse_per_class: [0.111, 0.266, 0.075, 0.327, 0.069, 0.192, 0.275, 0.135, 0.145, 0.113]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.1428622007369995
[2m[36m(func pid=77465)[0m mae:  0.08899491280317307
[2m[36m(func pid=77465)[0m rmse_per_class: [0.06, 0.23, 0.031, 0.25, 0.086, 0.165, 0.205, 0.109, 0.148, 0.145]
[2m[36m(func pid=77465)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.1802949607372284
[2m[36m(func pid=95877)[0m mae:  0.1319437026977539
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.268, 0.091, 0.326, 0.098, 0.194, 0.304, 0.152, 0.139, 0.122]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.146803617477417
[2m[36m(func pid=97213)[0m mae:  0.10225164890289307
[2m[36m(func pid=97213)[0m rmse_per_class: [0.077, 0.241, 0.049, 0.268, 0.065, 0.174, 0.237, 0.117, 0.148, 0.092]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4020 | Steps: 4 | Val loss: 0.3116 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=77465)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2727 | Steps: 4 | Val loss: 0.2623 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.6079 | Steps: 4 | Val loss: 0.4699 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3366 | Steps: 4 | Val loss: 0.2731 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 16:33:46 (running for 00:09:43.22)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=3
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (17 PENDING, 4 RUNNING, 3 TERMINATED)
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00001 | RUNNING    | 192.168.7.53:77465 | 0.001  |       0.99 |         0      |  0.281 |  0.143 |                   99 |
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877 | 0.0001 |       0.9  |         0      |  0.617 |  0.18  |                   20 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425 | 0.001  |       0.9  |         0      |  0.402 |  0.17  |                   20 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213 | 0.01   |       0.9  |         0      |  0.338 |  0.147 |                   16 |
| train_c9cb4_00007 | PENDING    |                    | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                    | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                    | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                    | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                    | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                    | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                    | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                    | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                    | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                    | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                    | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                    | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                    | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085 | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888 | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316 | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+--------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.17032268643379211
[2m[36m(func pid=96425)[0m mae:  0.12316851317882538
[2m[36m(func pid=96425)[0m rmse_per_class: [0.11, 0.265, 0.073, 0.327, 0.07, 0.192, 0.274, 0.135, 0.145, 0.112]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=77465)[0m rmse: 0.1387196034193039
[2m[36m(func pid=77465)[0m mae:  0.0863448828458786
[2m[36m(func pid=77465)[0m rmse_per_class: [0.058, 0.224, 0.028, 0.248, 0.079, 0.166, 0.208, 0.109, 0.14, 0.127]
[2m[36m(func pid=95877)[0m rmse: 0.18052524328231812
[2m[36m(func pid=95877)[0m mae:  0.13213133811950684
[2m[36m(func pid=95877)[0m rmse_per_class: [0.108, 0.269, 0.092, 0.326, 0.098, 0.194, 0.304, 0.152, 0.14, 0.123]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.1484212875366211
[2m[36m(func pid=97213)[0m mae:  0.1033860594034195
[2m[36m(func pid=97213)[0m rmse_per_class: [0.077, 0.246, 0.047, 0.268, 0.061, 0.173, 0.239, 0.116, 0.159, 0.098]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4051 | Steps: 4 | Val loss: 0.3104 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.6012 | Steps: 4 | Val loss: 0.4597 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3357 | Steps: 4 | Val loss: 0.2770 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=96425)[0m rmse: 0.16954688727855682
[2m[36m(func pid=96425)[0m mae:  0.1224595457315445
[2m[36m(func pid=96425)[0m rmse_per_class: [0.107, 0.265, 0.073, 0.325, 0.069, 0.192, 0.273, 0.135, 0.145, 0.111]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.1805725395679474
[2m[36m(func pid=95877)[0m mae:  0.13211794197559357
[2m[36m(func pid=95877)[0m rmse_per_class: [0.108, 0.268, 0.092, 0.327, 0.1, 0.193, 0.304, 0.152, 0.14, 0.122]
[2m[36m(func pid=97213)[0m rmse: 0.15141339600086212
[2m[36m(func pid=97213)[0m mae:  0.10581450164318085
[2m[36m(func pid=97213)[0m rmse_per_class: [0.088, 0.244, 0.046, 0.276, 0.059, 0.173, 0.246, 0.116, 0.162, 0.105]
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4078 | Steps: 4 | Val loss: 0.3094 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
== Status ==
Current time: 2024-01-07 16:33:51 (running for 00:09:48.66)
Memory usage on this node: 22.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.608 |  0.181 |                   21 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.405 |  0.17  |                   21 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.337 |  0.148 |                   17 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=101872)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=101872)[0m Configuration completed!
[2m[36m(func pid=101872)[0m New optimizer parameters:
[2m[36m(func pid=101872)[0m SGD (
[2m[36m(func pid=101872)[0m Parameter Group 0
[2m[36m(func pid=101872)[0m     dampening: 0
[2m[36m(func pid=101872)[0m     differentiable: False
[2m[36m(func pid=101872)[0m     foreach: None
[2m[36m(func pid=101872)[0m     lr: 0.1
[2m[36m(func pid=101872)[0m     maximize: False
[2m[36m(func pid=101872)[0m     momentum: 0.9
[2m[36m(func pid=101872)[0m     nesterov: False
[2m[36m(func pid=101872)[0m     weight_decay: 0
[2m[36m(func pid=101872)[0m )
[2m[36m(func pid=101872)[0m 
== Status ==
Current time: 2024-01-07 16:33:56 (running for 00:09:53.92)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.601 |  0.181 |                   22 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.408 |  0.169 |                   22 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.336 |  0.151 |                   18 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.1690412014722824
[2m[36m(func pid=96425)[0m mae:  0.1220630556344986
[2m[36m(func pid=96425)[0m rmse_per_class: [0.108, 0.265, 0.072, 0.324, 0.069, 0.192, 0.272, 0.134, 0.146, 0.109]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.5809 | Steps: 4 | Val loss: 0.4511 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3282 | Steps: 4 | Val loss: 0.2724 | Batch size: 32 | lr: 0.01 | Duration: 3.14s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4004 | Steps: 4 | Val loss: 0.3095 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.6678 | Steps: 4 | Val loss: 0.4376 | Batch size: 32 | lr: 0.1 | Duration: 4.56s
[2m[36m(func pid=95877)[0m rmse: 0.1805703341960907
[2m[36m(func pid=95877)[0m mae:  0.13212800025939941
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.268, 0.093, 0.327, 0.099, 0.194, 0.304, 0.151, 0.14, 0.121]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.14812320470809937
[2m[36m(func pid=97213)[0m mae:  0.10292147099971771
[2m[36m(func pid=97213)[0m rmse_per_class: [0.091, 0.238, 0.045, 0.274, 0.058, 0.172, 0.236, 0.116, 0.144, 0.106]
[2m[36m(func pid=97213)[0m 
== Status ==
Current time: 2024-01-07 16:34:02 (running for 00:09:59.18)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.581 |  0.181 |                   23 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.4   |  0.169 |                   23 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.328 |  0.148 |                   19 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |        |        |                      |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.16893664002418518
[2m[36m(func pid=96425)[0m mae:  0.12211092561483383
[2m[36m(func pid=96425)[0m rmse_per_class: [0.106, 0.264, 0.069, 0.325, 0.069, 0.192, 0.273, 0.135, 0.149, 0.107]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.17743077874183655
[2m[36m(func pid=101872)[0m mae:  0.12222280353307724
[2m[36m(func pid=101872)[0m rmse_per_class: [0.128, 0.271, 0.075, 0.365, 0.056, 0.188, 0.313, 0.144, 0.143, 0.093]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.5800 | Steps: 4 | Val loss: 0.4451 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3290 | Steps: 4 | Val loss: 0.2686 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4055 | Steps: 4 | Val loss: 0.3094 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.7824 | Steps: 4 | Val loss: 0.4224 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=95877)[0m rmse: 0.18066386878490448
[2m[36m(func pid=95877)[0m mae:  0.13223782181739807
[2m[36m(func pid=95877)[0m rmse_per_class: [0.11, 0.269, 0.09, 0.326, 0.1, 0.194, 0.304, 0.151, 0.141, 0.122]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.1448781043291092
[2m[36m(func pid=97213)[0m mae:  0.10036114603281021
[2m[36m(func pid=97213)[0m rmse_per_class: [0.078, 0.23, 0.049, 0.278, 0.057, 0.173, 0.229, 0.115, 0.133, 0.107]
[2m[36m(func pid=97213)[0m 
== Status ==
Current time: 2024-01-07 16:34:07 (running for 00:10:04.47)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.58  |  0.181 |                   24 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.406 |  0.169 |                   24 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.329 |  0.145 |                   20 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.668 |  0.177 |                    1 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.1687650978565216
[2m[36m(func pid=96425)[0m mae:  0.12202107906341553
[2m[36m(func pid=96425)[0m rmse_per_class: [0.107, 0.264, 0.068, 0.325, 0.069, 0.192, 0.273, 0.135, 0.15, 0.105]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.1806926429271698
[2m[36m(func pid=101872)[0m mae:  0.1212591677904129
[2m[36m(func pid=101872)[0m rmse_per_class: [0.218, 0.287, 0.047, 0.385, 0.056, 0.187, 0.241, 0.155, 0.133, 0.097]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.5670 | Steps: 4 | Val loss: 0.4375 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3346 | Steps: 4 | Val loss: 0.2643 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4020 | Steps: 4 | Val loss: 0.3092 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.6085 | Steps: 4 | Val loss: 0.3726 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=95877)[0m rmse: 0.18019923567771912
[2m[36m(func pid=95877)[0m mae:  0.13182289898395538
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.269, 0.092, 0.326, 0.1, 0.193, 0.304, 0.15, 0.141, 0.119]
[2m[36m(func pid=95877)[0m 
== Status ==
Current time: 2024-01-07 16:34:12 (running for 00:10:09.60)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.567 |  0.18  |                   25 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.402 |  0.169 |                   25 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.329 |  0.145 |                   20 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.782 |  0.181 |                    2 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.16860990226268768
[2m[36m(func pid=96425)[0m mae:  0.12196382135152817
[2m[36m(func pid=96425)[0m rmse_per_class: [0.107, 0.262, 0.067, 0.327, 0.069, 0.191, 0.274, 0.135, 0.151, 0.103]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.1420908272266388
[2m[36m(func pid=97213)[0m mae:  0.09757527709007263
[2m[36m(func pid=97213)[0m rmse_per_class: [0.071, 0.228, 0.049, 0.269, 0.056, 0.171, 0.225, 0.115, 0.128, 0.109]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.1862359195947647
[2m[36m(func pid=101872)[0m mae:  0.12723007798194885
[2m[36m(func pid=101872)[0m rmse_per_class: [0.082, 0.274, 0.04, 0.304, 0.056, 0.277, 0.277, 0.154, 0.308, 0.09]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.5572 | Steps: 4 | Val loss: 0.4317 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3949 | Steps: 4 | Val loss: 0.3087 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3464 | Steps: 4 | Val loss: 0.2624 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=95877)[0m rmse: 0.18012210726737976
[2m[36m(func pid=95877)[0m mae:  0.1317518949508667
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.268, 0.09, 0.326, 0.099, 0.194, 0.303, 0.151, 0.141, 0.12]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4851 | Steps: 4 | Val loss: 0.3307 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 16:34:17 (running for 00:10:14.95)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.557 |  0.18  |                   26 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.395 |  0.168 |                   26 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.335 |  0.142 |                   21 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.608 |  0.186 |                    3 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.1683197170495987
[2m[36m(func pid=96425)[0m mae:  0.12183432281017303
[2m[36m(func pid=96425)[0m rmse_per_class: [0.106, 0.261, 0.066, 0.327, 0.07, 0.191, 0.274, 0.135, 0.147, 0.104]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.14107289910316467
[2m[36m(func pid=97213)[0m mae:  0.09636823832988739
[2m[36m(func pid=97213)[0m rmse_per_class: [0.069, 0.228, 0.049, 0.258, 0.057, 0.169, 0.225, 0.115, 0.129, 0.111]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.18069200217723846
[2m[36m(func pid=101872)[0m mae:  0.12031032890081406
[2m[36m(func pid=101872)[0m rmse_per_class: [0.074, 0.289, 0.173, 0.26, 0.088, 0.196, 0.282, 0.111, 0.129, 0.204]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.5523 | Steps: 4 | Val loss: 0.4276 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4013 | Steps: 4 | Val loss: 0.3079 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3209 | Steps: 4 | Val loss: 0.2685 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=95877)[0m rmse: 0.1799584925174713
[2m[36m(func pid=95877)[0m mae:  0.13156285881996155
[2m[36m(func pid=95877)[0m rmse_per_class: [0.108, 0.269, 0.091, 0.327, 0.099, 0.193, 0.302, 0.151, 0.14, 0.12]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4096 | Steps: 4 | Val loss: 0.2937 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 16:34:22 (running for 00:10:20.06)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.552 |  0.18  |                   27 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.401 |  0.168 |                   27 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.346 |  0.141 |                   22 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.485 |  0.181 |                    4 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.1681421548128128
[2m[36m(func pid=96425)[0m mae:  0.12168087065219879
[2m[36m(func pid=96425)[0m rmse_per_class: [0.106, 0.262, 0.066, 0.327, 0.07, 0.191, 0.274, 0.135, 0.146, 0.106]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.14565598964691162
[2m[36m(func pid=97213)[0m mae:  0.10017110407352448
[2m[36m(func pid=97213)[0m rmse_per_class: [0.069, 0.237, 0.049, 0.264, 0.058, 0.169, 0.232, 0.116, 0.144, 0.118]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.5421 | Steps: 4 | Val loss: 0.4189 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=101872)[0m rmse: 0.15018567442893982
[2m[36m(func pid=101872)[0m mae:  0.09797526150941849
[2m[36m(func pid=101872)[0m rmse_per_class: [0.067, 0.209, 0.027, 0.324, 0.095, 0.177, 0.217, 0.165, 0.127, 0.093]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3965 | Steps: 4 | Val loss: 0.3074 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3250 | Steps: 4 | Val loss: 0.2720 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=95877)[0m rmse: 0.1799267679452896
[2m[36m(func pid=95877)[0m mae:  0.13148941099643707
[2m[36m(func pid=95877)[0m rmse_per_class: [0.108, 0.269, 0.092, 0.326, 0.1, 0.194, 0.302, 0.15, 0.14, 0.119]
[2m[36m(func pid=95877)[0m 
== Status ==
Current time: 2024-01-07 16:34:28 (running for 00:10:25.22)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.542 |  0.18  |                   28 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.397 |  0.168 |                   28 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.321 |  0.146 |                   23 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.41  |  0.15  |                    5 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.1679338663816452
[2m[36m(func pid=96425)[0m mae:  0.12144794315099716
[2m[36m(func pid=96425)[0m rmse_per_class: [0.105, 0.261, 0.067, 0.327, 0.069, 0.191, 0.273, 0.136, 0.145, 0.106]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.3504 | Steps: 4 | Val loss: 0.2943 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=97213)[0m rmse: 0.14804518222808838
[2m[36m(func pid=97213)[0m mae:  0.10221882909536362
[2m[36m(func pid=97213)[0m rmse_per_class: [0.069, 0.241, 0.045, 0.268, 0.059, 0.172, 0.242, 0.115, 0.165, 0.105]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.5342 | Steps: 4 | Val loss: 0.4146 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4014 | Steps: 4 | Val loss: 0.3075 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=101872)[0m rmse: 0.15532135963439941
[2m[36m(func pid=101872)[0m mae:  0.10056893527507782
[2m[36m(func pid=101872)[0m rmse_per_class: [0.06, 0.267, 0.025, 0.262, 0.051, 0.204, 0.268, 0.125, 0.21, 0.082]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3223 | Steps: 4 | Val loss: 0.2762 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 16:34:33 (running for 00:10:30.36)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.534 |  0.18  |                   29 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.397 |  0.168 |                   28 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.325 |  0.148 |                   24 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.35  |  0.155 |                    6 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.179949089884758
[2m[36m(func pid=95877)[0m mae:  0.1315542757511139
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.269, 0.092, 0.327, 0.098, 0.194, 0.302, 0.149, 0.141, 0.121]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.16795401275157928
[2m[36m(func pid=96425)[0m mae:  0.12138092517852783
[2m[36m(func pid=96425)[0m rmse_per_class: [0.106, 0.26, 0.067, 0.326, 0.068, 0.191, 0.273, 0.137, 0.144, 0.108]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.3264 | Steps: 4 | Val loss: 0.2861 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=97213)[0m rmse: 0.1509591042995453
[2m[36m(func pid=97213)[0m mae:  0.10462380945682526
[2m[36m(func pid=97213)[0m rmse_per_class: [0.069, 0.238, 0.043, 0.276, 0.063, 0.173, 0.249, 0.113, 0.189, 0.096]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.5347 | Steps: 4 | Val loss: 0.4084 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3989 | Steps: 4 | Val loss: 0.3065 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=101872)[0m rmse: 0.15317276120185852
[2m[36m(func pid=101872)[0m mae:  0.09872908145189285
[2m[36m(func pid=101872)[0m rmse_per_class: [0.057, 0.204, 0.058, 0.266, 0.051, 0.186, 0.203, 0.112, 0.133, 0.262]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3155 | Steps: 4 | Val loss: 0.2715 | Batch size: 32 | lr: 0.01 | Duration: 3.14s
== Status ==
Current time: 2024-01-07 16:34:38 (running for 00:10:35.65)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.534 |  0.18  |                   29 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.399 |  0.167 |                   30 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.322 |  0.151 |                   25 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.326 |  0.153 |                    7 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.16747383773326874
[2m[36m(func pid=96425)[0m mae:  0.12108997255563736
[2m[36m(func pid=96425)[0m rmse_per_class: [0.103, 0.259, 0.066, 0.325, 0.067, 0.191, 0.273, 0.137, 0.143, 0.11]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.1797228753566742
[2m[36m(func pid=95877)[0m mae:  0.13123026490211487
[2m[36m(func pid=95877)[0m rmse_per_class: [0.108, 0.269, 0.094, 0.327, 0.098, 0.194, 0.3, 0.149, 0.14, 0.12]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.3212 | Steps: 4 | Val loss: 0.2724 | Batch size: 32 | lr: 0.1 | Duration: 3.17s
[2m[36m(func pid=97213)[0m rmse: 0.1472008228302002
[2m[36m(func pid=97213)[0m mae:  0.10171574354171753
[2m[36m(func pid=97213)[0m rmse_per_class: [0.069, 0.234, 0.041, 0.273, 0.065, 0.174, 0.246, 0.116, 0.158, 0.096]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3976 | Steps: 4 | Val loss: 0.3069 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.5205 | Steps: 4 | Val loss: 0.4033 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=101872)[0m rmse: 0.1428966224193573
[2m[36m(func pid=101872)[0m mae:  0.09131292253732681
[2m[36m(func pid=101872)[0m rmse_per_class: [0.061, 0.204, 0.045, 0.259, 0.05, 0.213, 0.237, 0.131, 0.148, 0.08]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3086 | Steps: 4 | Val loss: 0.2656 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
== Status ==
Current time: 2024-01-07 16:34:43 (running for 00:10:40.99)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.535 |  0.18  |                   30 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.398 |  0.168 |                   31 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.315 |  0.147 |                   26 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.321 |  0.143 |                    8 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.17953550815582275
[2m[36m(func pid=95877)[0m mae:  0.131000816822052
[2m[36m(func pid=95877)[0m rmse_per_class: [0.108, 0.269, 0.093, 0.327, 0.097, 0.194, 0.299, 0.149, 0.14, 0.119]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.16768710315227509
[2m[36m(func pid=96425)[0m mae:  0.1213379055261612
[2m[36m(func pid=96425)[0m rmse_per_class: [0.104, 0.259, 0.066, 0.324, 0.068, 0.19, 0.275, 0.137, 0.143, 0.111]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.3040 | Steps: 4 | Val loss: 0.2650 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=97213)[0m rmse: 0.14281848073005676
[2m[36m(func pid=97213)[0m mae:  0.09773635119199753
[2m[36m(func pid=97213)[0m rmse_per_class: [0.075, 0.228, 0.043, 0.263, 0.064, 0.168, 0.24, 0.117, 0.132, 0.098]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.5196 | Steps: 4 | Val loss: 0.3999 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3955 | Steps: 4 | Val loss: 0.3081 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=101872)[0m rmse: 0.14154689013957977
[2m[36m(func pid=101872)[0m mae:  0.08866780251264572
[2m[36m(func pid=101872)[0m rmse_per_class: [0.069, 0.202, 0.025, 0.236, 0.113, 0.17, 0.239, 0.132, 0.134, 0.095]
[2m[36m(func pid=101872)[0m 
== Status ==
Current time: 2024-01-07 16:34:49 (running for 00:10:46.20)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.521 |  0.18  |                   31 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.396 |  0.168 |                   32 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.309 |  0.143 |                   27 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.304 |  0.142 |                    9 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.1794213205575943
[2m[36m(func pid=95877)[0m mae:  0.13095945119857788
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.269, 0.093, 0.326, 0.098, 0.194, 0.3, 0.149, 0.14, 0.117]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.16828060150146484
[2m[36m(func pid=96425)[0m mae:  0.12194161117076874
[2m[36m(func pid=96425)[0m rmse_per_class: [0.102, 0.258, 0.069, 0.326, 0.068, 0.191, 0.276, 0.136, 0.143, 0.114]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3223 | Steps: 4 | Val loss: 0.2638 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3067 | Steps: 4 | Val loss: 0.2681 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=97213)[0m rmse: 0.1417817622423172
[2m[36m(func pid=97213)[0m mae:  0.09627948701381683
[2m[36m(func pid=97213)[0m rmse_per_class: [0.072, 0.227, 0.046, 0.261, 0.062, 0.168, 0.228, 0.117, 0.127, 0.11]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.5166 | Steps: 4 | Val loss: 0.3960 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3957 | Steps: 4 | Val loss: 0.3072 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=101872)[0m rmse: 0.14064474403858185
[2m[36m(func pid=101872)[0m mae:  0.08845173567533493
[2m[36m(func pid=101872)[0m rmse_per_class: [0.061, 0.2, 0.035, 0.253, 0.108, 0.186, 0.198, 0.106, 0.137, 0.123]
[2m[36m(func pid=101872)[0m 
== Status ==
Current time: 2024-01-07 16:34:54 (running for 00:10:51.31)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.52  |  0.179 |                   32 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.396 |  0.168 |                   33 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.322 |  0.142 |                   28 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.307 |  0.141 |                   10 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.16774660348892212
[2m[36m(func pid=96425)[0m mae:  0.12151583284139633
[2m[36m(func pid=96425)[0m rmse_per_class: [0.102, 0.258, 0.068, 0.325, 0.069, 0.19, 0.278, 0.135, 0.142, 0.112]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.17954954504966736
[2m[36m(func pid=95877)[0m mae:  0.13091441988945007
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.269, 0.094, 0.326, 0.1, 0.193, 0.299, 0.147, 0.139, 0.119]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3164 | Steps: 4 | Val loss: 0.2621 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3229 | Steps: 4 | Val loss: 0.2721 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
[2m[36m(func pid=97213)[0m rmse: 0.14038696885108948
[2m[36m(func pid=97213)[0m mae:  0.09559305757284164
[2m[36m(func pid=97213)[0m rmse_per_class: [0.066, 0.226, 0.045, 0.26, 0.059, 0.168, 0.223, 0.114, 0.134, 0.108]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.5089 | Steps: 4 | Val loss: 0.3928 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3926 | Steps: 4 | Val loss: 0.3061 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 16:34:59 (running for 00:10:56.35)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.517 |  0.18  |                   33 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.396 |  0.168 |                   33 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.316 |  0.14  |                   29 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.323 |  0.144 |                   11 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=101872)[0m rmse: 0.14435125887393951
[2m[36m(func pid=101872)[0m mae:  0.09103187173604965
[2m[36m(func pid=101872)[0m rmse_per_class: [0.072, 0.201, 0.045, 0.272, 0.062, 0.207, 0.24, 0.127, 0.133, 0.086]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.1673823744058609
[2m[36m(func pid=96425)[0m mae:  0.1211712509393692
[2m[36m(func pid=96425)[0m rmse_per_class: [0.104, 0.258, 0.067, 0.323, 0.068, 0.19, 0.277, 0.133, 0.141, 0.113]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.17952530086040497
[2m[36m(func pid=95877)[0m mae:  0.13101288676261902
[2m[36m(func pid=95877)[0m rmse_per_class: [0.11, 0.268, 0.092, 0.326, 0.098, 0.193, 0.3, 0.147, 0.14, 0.12]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3188 | Steps: 4 | Val loss: 0.2658 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.2870 | Steps: 4 | Val loss: 0.2857 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.5046 | Steps: 4 | Val loss: 0.3867 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3936 | Steps: 4 | Val loss: 0.3053 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=97213)[0m rmse: 0.1438942551612854
[2m[36m(func pid=97213)[0m mae:  0.09847069531679153
[2m[36m(func pid=97213)[0m rmse_per_class: [0.065, 0.23, 0.046, 0.266, 0.057, 0.168, 0.225, 0.112, 0.155, 0.116]
[2m[36m(func pid=97213)[0m 
== Status ==
Current time: 2024-01-07 16:35:04 (running for 00:11:01.96)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.509 |  0.18  |                   34 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.393 |  0.167 |                   34 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.319 |  0.144 |                   30 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.287 |  0.148 |                   12 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=101872)[0m rmse: 0.14818041026592255
[2m[36m(func pid=101872)[0m mae:  0.09294101595878601
[2m[36m(func pid=101872)[0m rmse_per_class: [0.064, 0.26, 0.026, 0.239, 0.049, 0.168, 0.214, 0.189, 0.148, 0.126]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.17950621247291565
[2m[36m(func pid=95877)[0m mae:  0.13096925616264343
[2m[36m(func pid=95877)[0m rmse_per_class: [0.11, 0.269, 0.092, 0.327, 0.098, 0.194, 0.298, 0.147, 0.141, 0.12]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.16725097596645355
[2m[36m(func pid=96425)[0m mae:  0.12099643051624298
[2m[36m(func pid=96425)[0m rmse_per_class: [0.105, 0.258, 0.067, 0.321, 0.066, 0.189, 0.275, 0.133, 0.142, 0.115]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3115 | Steps: 4 | Val loss: 0.2653 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4985 | Steps: 4 | Val loss: 0.3831 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3951 | Steps: 4 | Val loss: 0.3044 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.2874 | Steps: 4 | Val loss: 0.2669 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=97213)[0m rmse: 0.14304828643798828
[2m[36m(func pid=97213)[0m mae:  0.09703890979290009
[2m[36m(func pid=97213)[0m rmse_per_class: [0.065, 0.235, 0.042, 0.267, 0.057, 0.167, 0.217, 0.114, 0.156, 0.11]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.16680601239204407
[2m[36m(func pid=96425)[0m mae:  0.12050862610340118
[2m[36m(func pid=96425)[0m rmse_per_class: [0.104, 0.258, 0.067, 0.321, 0.065, 0.189, 0.272, 0.133, 0.142, 0.116]
[2m[36m(func pid=96425)[0m 
== Status ==
Current time: 2024-01-07 16:35:10 (running for 00:11:07.38)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.505 |  0.18  |                   35 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.395 |  0.167 |                   36 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.312 |  0.143 |                   31 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.287 |  0.148 |                   12 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.17960627377033234
[2m[36m(func pid=95877)[0m mae:  0.13102033734321594
[2m[36m(func pid=95877)[0m rmse_per_class: [0.11, 0.269, 0.094, 0.328, 0.098, 0.193, 0.298, 0.146, 0.141, 0.119]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.13460376858711243
[2m[36m(func pid=101872)[0m mae:  0.08369194716215134
[2m[36m(func pid=101872)[0m rmse_per_class: [0.057, 0.204, 0.028, 0.276, 0.05, 0.163, 0.218, 0.11, 0.125, 0.114]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3161 | Steps: 4 | Val loss: 0.2671 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4932 | Steps: 4 | Val loss: 0.3817 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3889 | Steps: 4 | Val loss: 0.3034 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.3005 | Steps: 4 | Val loss: 0.2657 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=97213)[0m rmse: 0.14463119208812714
[2m[36m(func pid=97213)[0m mae:  0.09820693731307983
[2m[36m(func pid=97213)[0m rmse_per_class: [0.065, 0.237, 0.043, 0.269, 0.059, 0.167, 0.22, 0.115, 0.145, 0.126]
[2m[36m(func pid=97213)[0m 
== Status ==
Current time: 2024-01-07 16:35:15 (running for 00:11:12.69)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.493 |  0.18  |                   37 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.395 |  0.167 |                   36 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.316 |  0.145 |                   32 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.287 |  0.135 |                   13 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.17975813150405884
[2m[36m(func pid=95877)[0m mae:  0.1312275230884552
[2m[36m(func pid=95877)[0m rmse_per_class: [0.11, 0.268, 0.092, 0.328, 0.098, 0.194, 0.3, 0.147, 0.141, 0.12]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.1663036197423935
[2m[36m(func pid=96425)[0m mae:  0.11998991668224335
[2m[36m(func pid=96425)[0m rmse_per_class: [0.104, 0.258, 0.068, 0.319, 0.065, 0.189, 0.271, 0.133, 0.142, 0.114]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.13853204250335693
[2m[36m(func pid=101872)[0m mae:  0.0869642049074173
[2m[36m(func pid=101872)[0m rmse_per_class: [0.073, 0.211, 0.029, 0.264, 0.055, 0.194, 0.22, 0.11, 0.128, 0.103]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3063 | Steps: 4 | Val loss: 0.2640 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4924 | Steps: 4 | Val loss: 0.3787 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3999 | Steps: 4 | Val loss: 0.3027 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=97213)[0m rmse: 0.1420971155166626
[2m[36m(func pid=97213)[0m mae:  0.09655150771141052
[2m[36m(func pid=97213)[0m rmse_per_class: [0.064, 0.228, 0.042, 0.268, 0.064, 0.166, 0.225, 0.113, 0.135, 0.115]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.2604 | Steps: 4 | Val loss: 0.2821 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=96425)[0m rmse: 0.16591152548789978
[2m[36m(func pid=96425)[0m mae:  0.11963994801044464
[2m[36m(func pid=96425)[0m rmse_per_class: [0.103, 0.259, 0.068, 0.317, 0.065, 0.189, 0.27, 0.133, 0.141, 0.114]
[2m[36m(func pid=96425)[0m 
== Status ==
Current time: 2024-01-07 16:35:20 (running for 00:11:18.00)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.493 |  0.18  |                   37 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.4   |  0.166 |                   38 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.306 |  0.142 |                   33 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.3   |  0.139 |                   14 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.17930008471012115
[2m[36m(func pid=95877)[0m mae:  0.13087697327136993
[2m[36m(func pid=95877)[0m rmse_per_class: [0.11, 0.269, 0.09, 0.327, 0.098, 0.194, 0.3, 0.146, 0.141, 0.118]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.14715729653835297
[2m[36m(func pid=101872)[0m mae:  0.09232829511165619
[2m[36m(func pid=101872)[0m rmse_per_class: [0.06, 0.223, 0.038, 0.281, 0.068, 0.168, 0.214, 0.18, 0.14, 0.1]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3028 | Steps: 4 | Val loss: 0.2605 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3916 | Steps: 4 | Val loss: 0.3021 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4840 | Steps: 4 | Val loss: 0.3799 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=97213)[0m rmse: 0.13972459733486176
[2m[36m(func pid=97213)[0m mae:  0.09470731019973755
[2m[36m(func pid=97213)[0m rmse_per_class: [0.065, 0.224, 0.041, 0.254, 0.07, 0.165, 0.231, 0.11, 0.129, 0.108]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.2952 | Steps: 4 | Val loss: 0.2669 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
== Status ==
Current time: 2024-01-07 16:35:26 (running for 00:11:23.20)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.484 |  0.179 |                   39 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.4   |  0.166 |                   38 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.303 |  0.14  |                   34 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.26  |  0.147 |                   15 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.17943410575389862
[2m[36m(func pid=95877)[0m mae:  0.13096502423286438
[2m[36m(func pid=95877)[0m rmse_per_class: [0.11, 0.269, 0.091, 0.328, 0.098, 0.193, 0.299, 0.147, 0.141, 0.119]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.16575422883033752
[2m[36m(func pid=96425)[0m mae:  0.11936638504266739
[2m[36m(func pid=96425)[0m rmse_per_class: [0.105, 0.259, 0.067, 0.317, 0.064, 0.189, 0.267, 0.133, 0.139, 0.117]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.13848835229873657
[2m[36m(func pid=101872)[0m mae:  0.0843437910079956
[2m[36m(func pid=101872)[0m rmse_per_class: [0.057, 0.213, 0.034, 0.248, 0.06, 0.165, 0.222, 0.129, 0.141, 0.116]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3021 | Steps: 4 | Val loss: 0.2611 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4886 | Steps: 4 | Val loss: 0.3764 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3930 | Steps: 4 | Val loss: 0.3023 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=97213)[0m rmse: 0.1404203474521637
[2m[36m(func pid=97213)[0m mae:  0.09534658491611481
[2m[36m(func pid=97213)[0m rmse_per_class: [0.063, 0.225, 0.039, 0.252, 0.069, 0.166, 0.232, 0.109, 0.13, 0.117]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.2646 | Steps: 4 | Val loss: 0.2866 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=95877)[0m rmse: 0.1791725903749466
[2m[36m(func pid=95877)[0m mae:  0.13068214058876038
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.269, 0.092, 0.327, 0.097, 0.193, 0.298, 0.147, 0.141, 0.119]
[2m[36m(func pid=95877)[0m 
== Status ==
Current time: 2024-01-07 16:35:31 (running for 00:11:28.46)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.489 |  0.179 |                   40 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.392 |  0.166 |                   39 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.302 |  0.14  |                   35 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.295 |  0.138 |                   16 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.16576668620109558
[2m[36m(func pid=96425)[0m mae:  0.11933555454015732
[2m[36m(func pid=96425)[0m rmse_per_class: [0.105, 0.259, 0.07, 0.316, 0.065, 0.189, 0.267, 0.132, 0.138, 0.116]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.14766095578670502
[2m[36m(func pid=101872)[0m mae:  0.09409958869218826
[2m[36m(func pid=101872)[0m rmse_per_class: [0.073, 0.223, 0.029, 0.289, 0.055, 0.181, 0.216, 0.128, 0.173, 0.109]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3040 | Steps: 4 | Val loss: 0.2642 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4877 | Steps: 4 | Val loss: 0.3740 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3981 | Steps: 4 | Val loss: 0.3020 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=97213)[0m rmse: 0.14338521659374237
[2m[36m(func pid=97213)[0m mae:  0.09715563803911209
[2m[36m(func pid=97213)[0m rmse_per_class: [0.064, 0.227, 0.036, 0.257, 0.063, 0.166, 0.232, 0.111, 0.128, 0.149]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.2859 | Steps: 4 | Val loss: 0.2863 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 16:35:36 (running for 00:11:33.72)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.488 |  0.179 |                   41 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.393 |  0.166 |                   40 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.304 |  0.143 |                   36 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.265 |  0.148 |                   17 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.17937599122524261
[2m[36m(func pid=95877)[0m mae:  0.13085103034973145
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.269, 0.092, 0.328, 0.098, 0.193, 0.298, 0.146, 0.141, 0.12]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.16575929522514343
[2m[36m(func pid=96425)[0m mae:  0.11928808689117432
[2m[36m(func pid=96425)[0m rmse_per_class: [0.105, 0.259, 0.07, 0.315, 0.065, 0.189, 0.267, 0.132, 0.138, 0.118]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.15042154490947723
[2m[36m(func pid=101872)[0m mae:  0.09237407147884369
[2m[36m(func pid=101872)[0m rmse_per_class: [0.073, 0.217, 0.032, 0.282, 0.084, 0.17, 0.211, 0.108, 0.141, 0.186]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2968 | Steps: 4 | Val loss: 0.2629 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4786 | Steps: 4 | Val loss: 0.3714 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3865 | Steps: 4 | Val loss: 0.3021 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=97213)[0m rmse: 0.1417314112186432
[2m[36m(func pid=97213)[0m mae:  0.09569752216339111
[2m[36m(func pid=97213)[0m rmse_per_class: [0.064, 0.227, 0.037, 0.258, 0.062, 0.165, 0.227, 0.111, 0.129, 0.138]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.2908 | Steps: 4 | Val loss: 0.2698 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 16:35:41 (running for 00:11:38.81)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.479 |  0.179 |                   42 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.398 |  0.166 |                   41 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.297 |  0.142 |                   37 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.286 |  0.15  |                   18 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.178617462515831
[2m[36m(func pid=95877)[0m mae:  0.13025493919849396
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.269, 0.091, 0.327, 0.095, 0.193, 0.296, 0.146, 0.141, 0.119]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.1658768206834793
[2m[36m(func pid=96425)[0m mae:  0.11935801804065704
[2m[36m(func pid=96425)[0m rmse_per_class: [0.105, 0.259, 0.07, 0.315, 0.064, 0.189, 0.267, 0.132, 0.139, 0.119]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.1435011923313141
[2m[36m(func pid=101872)[0m mae:  0.08731719851493835
[2m[36m(func pid=101872)[0m rmse_per_class: [0.08, 0.231, 0.042, 0.239, 0.066, 0.167, 0.224, 0.17, 0.128, 0.089]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3183 | Steps: 4 | Val loss: 0.2573 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4765 | Steps: 4 | Val loss: 0.3700 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3967 | Steps: 4 | Val loss: 0.3021 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 16:35:46 (running for 00:11:43.86)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.479 |  0.179 |                   42 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.387 |  0.166 |                   42 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.318 |  0.137 |                   38 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.291 |  0.144 |                   19 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.17888733744621277
[2m[36m(func pid=95877)[0m mae:  0.13057054579257965
[2m[36m(func pid=95877)[0m rmse_per_class: [0.11, 0.269, 0.092, 0.327, 0.093, 0.193, 0.297, 0.146, 0.142, 0.12]
[2m[36m(func pid=97213)[0m rmse: 0.13662585616111755
[2m[36m(func pid=97213)[0m mae:  0.09183899313211441
[2m[36m(func pid=97213)[0m rmse_per_class: [0.064, 0.224, 0.037, 0.249, 0.058, 0.164, 0.223, 0.113, 0.132, 0.103]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.1660217046737671
[2m[36m(func pid=96425)[0m mae:  0.11946340650320053
[2m[36m(func pid=96425)[0m rmse_per_class: [0.105, 0.26, 0.071, 0.314, 0.065, 0.188, 0.267, 0.13, 0.141, 0.119]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.2808 | Steps: 4 | Val loss: 0.2620 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=101872)[0m rmse: 0.1388457715511322
[2m[36m(func pid=101872)[0m mae:  0.08574296534061432
[2m[36m(func pid=101872)[0m rmse_per_class: [0.059, 0.208, 0.07, 0.249, 0.066, 0.169, 0.212, 0.11, 0.148, 0.098]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4734 | Steps: 4 | Val loss: 0.3655 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3921 | Steps: 4 | Val loss: 0.3013 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2995 | Steps: 4 | Val loss: 0.2560 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
== Status ==
Current time: 2024-01-07 16:35:52 (running for 00:11:49.18)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.473 |  0.179 |                   44 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.397 |  0.166 |                   43 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.318 |  0.137 |                   38 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.281 |  0.139 |                   20 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.17865769565105438
[2m[36m(func pid=95877)[0m mae:  0.13037221133708954
[2m[36m(func pid=95877)[0m rmse_per_class: [0.111, 0.269, 0.09, 0.328, 0.094, 0.194, 0.296, 0.145, 0.142, 0.119]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.1658502072095871
[2m[36m(func pid=96425)[0m mae:  0.1191353052854538
[2m[36m(func pid=96425)[0m rmse_per_class: [0.105, 0.26, 0.072, 0.312, 0.065, 0.188, 0.265, 0.131, 0.14, 0.121]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.1355901062488556
[2m[36m(func pid=97213)[0m mae:  0.09100112318992615
[2m[36m(func pid=97213)[0m rmse_per_class: [0.064, 0.225, 0.037, 0.243, 0.059, 0.163, 0.221, 0.114, 0.143, 0.089]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.2802 | Steps: 4 | Val loss: 0.2673 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4699 | Steps: 4 | Val loss: 0.3653 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3842 | Steps: 4 | Val loss: 0.3006 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=101872)[0m rmse: 0.14109313488006592
[2m[36m(func pid=101872)[0m mae:  0.08665230125188828
[2m[36m(func pid=101872)[0m rmse_per_class: [0.07, 0.207, 0.027, 0.246, 0.054, 0.169, 0.225, 0.111, 0.121, 0.181]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3037 | Steps: 4 | Val loss: 0.2556 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 16:35:57 (running for 00:11:54.47)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.47  |  0.179 |                   45 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.392 |  0.166 |                   44 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.299 |  0.136 |                   39 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.28  |  0.141 |                   21 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.17879071831703186
[2m[36m(func pid=95877)[0m mae:  0.1304977834224701
[2m[36m(func pid=95877)[0m rmse_per_class: [0.111, 0.268, 0.089, 0.328, 0.094, 0.194, 0.297, 0.146, 0.142, 0.118]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.16506503522396088
[2m[36m(func pid=96425)[0m mae:  0.11858813464641571
[2m[36m(func pid=96425)[0m rmse_per_class: [0.101, 0.259, 0.072, 0.311, 0.065, 0.188, 0.266, 0.131, 0.141, 0.115]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13536913692951202
[2m[36m(func pid=97213)[0m mae:  0.09082107245922089
[2m[36m(func pid=97213)[0m rmse_per_class: [0.062, 0.221, 0.035, 0.242, 0.062, 0.163, 0.223, 0.114, 0.147, 0.084]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.2799 | Steps: 4 | Val loss: 0.2732 | Batch size: 32 | lr: 0.1 | Duration: 3.19s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4716 | Steps: 4 | Val loss: 0.3626 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3872 | Steps: 4 | Val loss: 0.3006 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3011 | Steps: 4 | Val loss: 0.2582 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=101872)[0m rmse: 0.1441384106874466
[2m[36m(func pid=101872)[0m mae:  0.08801411837339401
[2m[36m(func pid=101872)[0m rmse_per_class: [0.097, 0.201, 0.032, 0.248, 0.051, 0.209, 0.255, 0.132, 0.136, 0.081]
[2m[36m(func pid=101872)[0m 
== Status ==
Current time: 2024-01-07 16:36:02 (running for 00:11:59.84)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.472 |  0.179 |                   46 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.384 |  0.165 |                   45 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.304 |  0.135 |                   40 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.28  |  0.144 |                   22 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.17898374795913696
[2m[36m(func pid=95877)[0m mae:  0.13064585626125336
[2m[36m(func pid=95877)[0m rmse_per_class: [0.112, 0.269, 0.09, 0.328, 0.094, 0.194, 0.297, 0.146, 0.142, 0.118]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.16525134444236755
[2m[36m(func pid=96425)[0m mae:  0.11873020976781845
[2m[36m(func pid=96425)[0m rmse_per_class: [0.103, 0.259, 0.069, 0.311, 0.065, 0.188, 0.267, 0.131, 0.14, 0.119]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.1374712586402893
[2m[36m(func pid=97213)[0m mae:  0.09256737679243088
[2m[36m(func pid=97213)[0m rmse_per_class: [0.062, 0.22, 0.034, 0.25, 0.067, 0.164, 0.226, 0.113, 0.152, 0.087]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.2734 | Steps: 4 | Val loss: 0.2612 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4705 | Steps: 4 | Val loss: 0.3620 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3870 | Steps: 4 | Val loss: 0.2998 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2959 | Steps: 4 | Val loss: 0.2621 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=101872)[0m rmse: 0.13522034883499146
[2m[36m(func pid=101872)[0m mae:  0.08334201574325562
[2m[36m(func pid=101872)[0m rmse_per_class: [0.062, 0.214, 0.029, 0.239, 0.054, 0.165, 0.215, 0.124, 0.168, 0.082]
[2m[36m(func pid=101872)[0m 
== Status ==
Current time: 2024-01-07 16:36:07 (running for 00:12:04.95)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.47  |  0.179 |                   47 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.387 |  0.165 |                   46 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.301 |  0.137 |                   41 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.273 |  0.135 |                   23 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.17872758209705353
[2m[36m(func pid=95877)[0m mae:  0.13035330176353455
[2m[36m(func pid=95877)[0m rmse_per_class: [0.111, 0.269, 0.092, 0.326, 0.094, 0.193, 0.297, 0.146, 0.142, 0.117]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.16481716930866241
[2m[36m(func pid=96425)[0m mae:  0.11843554675579071
[2m[36m(func pid=96425)[0m rmse_per_class: [0.103, 0.258, 0.068, 0.31, 0.065, 0.188, 0.266, 0.132, 0.139, 0.118]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.1402115374803543
[2m[36m(func pid=97213)[0m mae:  0.09457109868526459
[2m[36m(func pid=97213)[0m rmse_per_class: [0.063, 0.222, 0.035, 0.264, 0.068, 0.165, 0.227, 0.111, 0.148, 0.098]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.2869 | Steps: 4 | Val loss: 0.2646 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4648 | Steps: 4 | Val loss: 0.3582 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3884 | Steps: 4 | Val loss: 0.2988 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2994 | Steps: 4 | Val loss: 0.2625 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=101872)[0m rmse: 0.14062049984931946
[2m[36m(func pid=101872)[0m mae:  0.08651264011859894
[2m[36m(func pid=101872)[0m rmse_per_class: [0.061, 0.21, 0.039, 0.263, 0.083, 0.169, 0.207, 0.109, 0.155, 0.11]
[2m[36m(func pid=101872)[0m 
== Status ==
Current time: 2024-01-07 16:36:13 (running for 00:12:10.17)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.465 |  0.179 |                   48 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.387 |  0.165 |                   47 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.296 |  0.14  |                   42 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.287 |  0.141 |                   24 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.1786016970872879
[2m[36m(func pid=95877)[0m mae:  0.13022072613239288
[2m[36m(func pid=95877)[0m rmse_per_class: [0.111, 0.269, 0.092, 0.326, 0.093, 0.194, 0.296, 0.146, 0.142, 0.117]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.16423562169075012
[2m[36m(func pid=96425)[0m mae:  0.1178598403930664
[2m[36m(func pid=96425)[0m rmse_per_class: [0.102, 0.258, 0.065, 0.309, 0.064, 0.188, 0.265, 0.134, 0.139, 0.119]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.1411568969488144
[2m[36m(func pid=97213)[0m mae:  0.09496697038412094
[2m[36m(func pid=97213)[0m rmse_per_class: [0.065, 0.227, 0.034, 0.268, 0.062, 0.164, 0.22, 0.111, 0.14, 0.121]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.2718 | Steps: 4 | Val loss: 0.3053 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4615 | Steps: 4 | Val loss: 0.3570 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3768 | Steps: 4 | Val loss: 0.2991 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2982 | Steps: 4 | Val loss: 0.2645 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=101872)[0m rmse: 0.16090017557144165
[2m[36m(func pid=101872)[0m mae:  0.09979160130023956
[2m[36m(func pid=101872)[0m rmse_per_class: [0.082, 0.24, 0.033, 0.311, 0.089, 0.177, 0.221, 0.133, 0.175, 0.148]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.17892269790172577
[2m[36m(func pid=95877)[0m mae:  0.13046614825725555
[2m[36m(func pid=95877)[0m rmse_per_class: [0.112, 0.269, 0.093, 0.327, 0.094, 0.194, 0.296, 0.145, 0.141, 0.118]
== Status ==
Current time: 2024-01-07 16:36:18 (running for 00:12:15.40)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.462 |  0.179 |                   49 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.388 |  0.164 |                   48 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.299 |  0.141 |                   43 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.272 |  0.161 |                   25 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.16417671740055084
[2m[36m(func pid=96425)[0m mae:  0.11791075766086578
[2m[36m(func pid=96425)[0m rmse_per_class: [0.101, 0.257, 0.066, 0.309, 0.064, 0.188, 0.266, 0.134, 0.139, 0.117]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.14249944686889648
[2m[36m(func pid=97213)[0m mae:  0.09567956626415253
[2m[36m(func pid=97213)[0m rmse_per_class: [0.074, 0.228, 0.035, 0.269, 0.06, 0.164, 0.218, 0.11, 0.141, 0.126]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.2711 | Steps: 4 | Val loss: 0.2710 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4586 | Steps: 4 | Val loss: 0.3557 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3812 | Steps: 4 | Val loss: 0.2983 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3085 | Steps: 4 | Val loss: 0.2620 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=101872)[0m rmse: 0.139382004737854
[2m[36m(func pid=101872)[0m mae:  0.08658941090106964
[2m[36m(func pid=101872)[0m rmse_per_class: [0.06, 0.227, 0.027, 0.251, 0.053, 0.171, 0.256, 0.126, 0.13, 0.093]
[2m[36m(func pid=101872)[0m 
== Status ==
Current time: 2024-01-07 16:36:23 (running for 00:12:20.73)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.459 |  0.179 |                   50 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.377 |  0.164 |                   49 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.298 |  0.142 |                   44 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.271 |  0.139 |                   26 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.17859943211078644
[2m[36m(func pid=95877)[0m mae:  0.1302642673254013
[2m[36m(func pid=95877)[0m rmse_per_class: [0.111, 0.27, 0.093, 0.326, 0.093, 0.194, 0.296, 0.144, 0.142, 0.118]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.16369034349918365
[2m[36m(func pid=96425)[0m mae:  0.11746778339147568
[2m[36m(func pid=96425)[0m rmse_per_class: [0.101, 0.257, 0.066, 0.308, 0.064, 0.188, 0.266, 0.133, 0.138, 0.117]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.14021363854408264
[2m[36m(func pid=97213)[0m mae:  0.09391050040721893
[2m[36m(func pid=97213)[0m rmse_per_class: [0.071, 0.228, 0.039, 0.267, 0.058, 0.164, 0.212, 0.108, 0.145, 0.111]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.2816 | Steps: 4 | Val loss: 0.2539 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4604 | Steps: 4 | Val loss: 0.3532 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3824 | Steps: 4 | Val loss: 0.2978 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2849 | Steps: 4 | Val loss: 0.2531 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 16:36:28 (running for 00:12:25.75)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.459 |  0.179 |                   50 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.381 |  0.164 |                   50 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.308 |  0.14  |                   45 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.282 |  0.129 |                   27 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=101872)[0m rmse: 0.1288646012544632
[2m[36m(func pid=101872)[0m mae:  0.07814310491085052
[2m[36m(func pid=101872)[0m rmse_per_class: [0.067, 0.203, 0.026, 0.239, 0.051, 0.172, 0.209, 0.104, 0.122, 0.095]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.1781178116798401
[2m[36m(func pid=95877)[0m mae:  0.12985143065452576
[2m[36m(func pid=95877)[0m rmse_per_class: [0.11, 0.27, 0.093, 0.325, 0.092, 0.194, 0.294, 0.143, 0.142, 0.117]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.16365037858486176
[2m[36m(func pid=96425)[0m mae:  0.1173361986875534
[2m[36m(func pid=96425)[0m rmse_per_class: [0.102, 0.258, 0.066, 0.307, 0.064, 0.188, 0.264, 0.133, 0.138, 0.117]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13347753882408142
[2m[36m(func pid=97213)[0m mae:  0.08922959864139557
[2m[36m(func pid=97213)[0m rmse_per_class: [0.062, 0.216, 0.038, 0.242, 0.055, 0.162, 0.218, 0.108, 0.14, 0.094]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4560 | Steps: 4 | Val loss: 0.3508 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.2829 | Steps: 4 | Val loss: 0.3287 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3794 | Steps: 4 | Val loss: 0.2971 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2918 | Steps: 4 | Val loss: 0.2546 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=95877)[0m rmse: 0.17780688405036926
[2m[36m(func pid=95877)[0m mae:  0.12946903705596924
[2m[36m(func pid=95877)[0m rmse_per_class: [0.11, 0.269, 0.092, 0.326, 0.093, 0.194, 0.293, 0.142, 0.142, 0.117]
[2m[36m(func pid=95877)[0m 
== Status ==
Current time: 2024-01-07 16:36:34 (running for 00:12:31.31)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.456 |  0.178 |                   52 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.382 |  0.164 |                   51 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.285 |  0.133 |                   46 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.282 |  0.129 |                   27 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.1632925420999527
[2m[36m(func pid=96425)[0m mae:  0.11695349216461182
[2m[36m(func pid=96425)[0m rmse_per_class: [0.102, 0.258, 0.069, 0.305, 0.064, 0.187, 0.263, 0.132, 0.138, 0.115]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.1687672883272171
[2m[36m(func pid=101872)[0m mae:  0.10432343184947968
[2m[36m(func pid=101872)[0m rmse_per_class: [0.079, 0.241, 0.038, 0.327, 0.078, 0.178, 0.234, 0.196, 0.157, 0.159]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13474029302597046
[2m[36m(func pid=97213)[0m mae:  0.09036408364772797
[2m[36m(func pid=97213)[0m rmse_per_class: [0.061, 0.216, 0.036, 0.239, 0.054, 0.161, 0.228, 0.108, 0.152, 0.09]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3821 | Steps: 4 | Val loss: 0.2971 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4523 | Steps: 4 | Val loss: 0.3483 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.2987 | Steps: 4 | Val loss: 0.2737 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=96425)[0m rmse: 0.16309207677841187
[2m[36m(func pid=96425)[0m mae:  0.11682906001806259
[2m[36m(func pid=96425)[0m rmse_per_class: [0.102, 0.258, 0.068, 0.306, 0.064, 0.187, 0.264, 0.132, 0.138, 0.113]
== Status ==
Current time: 2024-01-07 16:36:39 (running for 00:12:36.58)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.456 |  0.178 |                   52 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.382 |  0.163 |                   53 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.292 |  0.135 |                   47 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.283 |  0.169 |                   28 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.17765623331069946
[2m[36m(func pid=95877)[0m mae:  0.12927183508872986
[2m[36m(func pid=95877)[0m rmse_per_class: [0.111, 0.269, 0.091, 0.325, 0.095, 0.194, 0.293, 0.142, 0.141, 0.116]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2996 | Steps: 4 | Val loss: 0.2547 | Batch size: 32 | lr: 0.01 | Duration: 3.23s
[2m[36m(func pid=101872)[0m rmse: 0.14693480730056763
[2m[36m(func pid=101872)[0m mae:  0.09037327021360397
[2m[36m(func pid=101872)[0m rmse_per_class: [0.081, 0.21, 0.033, 0.275, 0.107, 0.17, 0.215, 0.111, 0.153, 0.115]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3873 | Steps: 4 | Val loss: 0.2958 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=97213)[0m rmse: 0.13482031226158142
[2m[36m(func pid=97213)[0m mae:  0.08991292864084244
[2m[36m(func pid=97213)[0m rmse_per_class: [0.06, 0.219, 0.037, 0.238, 0.053, 0.161, 0.227, 0.108, 0.154, 0.09]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4544 | Steps: 4 | Val loss: 0.3493 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.2699 | Steps: 4 | Val loss: 0.2615 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=96425)[0m rmse: 0.1623864471912384
[2m[36m(func pid=96425)[0m mae:  0.11616197973489761
[2m[36m(func pid=96425)[0m rmse_per_class: [0.102, 0.256, 0.067, 0.307, 0.063, 0.186, 0.262, 0.132, 0.137, 0.111]
[2m[36m(func pid=96425)[0m 
== Status ==
Current time: 2024-01-07 16:36:44 (running for 00:12:41.87)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.452 |  0.178 |                   53 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.387 |  0.162 |                   54 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.3   |  0.135 |                   48 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.299 |  0.147 |                   29 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.17800165712833405
[2m[36m(func pid=95877)[0m mae:  0.1297089159488678
[2m[36m(func pid=95877)[0m rmse_per_class: [0.111, 0.269, 0.09, 0.326, 0.092, 0.194, 0.295, 0.144, 0.142, 0.118]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2977 | Steps: 4 | Val loss: 0.2547 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=101872)[0m rmse: 0.12941895425319672
[2m[36m(func pid=101872)[0m mae:  0.07980260252952576
[2m[36m(func pid=101872)[0m rmse_per_class: [0.063, 0.198, 0.03, 0.246, 0.055, 0.163, 0.205, 0.104, 0.148, 0.082]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3857 | Steps: 4 | Val loss: 0.2953 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4524 | Steps: 4 | Val loss: 0.3488 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=97213)[0m rmse: 0.13504263758659363
[2m[36m(func pid=97213)[0m mae:  0.08973012864589691
[2m[36m(func pid=97213)[0m rmse_per_class: [0.061, 0.218, 0.038, 0.243, 0.052, 0.168, 0.227, 0.11, 0.14, 0.094]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.2516 | Steps: 4 | Val loss: 0.3007 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 16:36:49 (running for 00:12:47.03)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.454 |  0.178 |                   54 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.386 |  0.162 |                   55 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.298 |  0.135 |                   49 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.27  |  0.129 |                   30 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.16211795806884766
[2m[36m(func pid=96425)[0m mae:  0.1157945767045021
[2m[36m(func pid=96425)[0m rmse_per_class: [0.101, 0.256, 0.065, 0.308, 0.063, 0.186, 0.261, 0.133, 0.137, 0.113]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.17751462757587433
[2m[36m(func pid=95877)[0m mae:  0.1293354034423828
[2m[36m(func pid=95877)[0m rmse_per_class: [0.111, 0.269, 0.089, 0.325, 0.091, 0.193, 0.293, 0.144, 0.142, 0.118]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2928 | Steps: 4 | Val loss: 0.2546 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=101872)[0m rmse: 0.15543007850646973
[2m[36m(func pid=101872)[0m mae:  0.09526161849498749
[2m[36m(func pid=101872)[0m rmse_per_class: [0.075, 0.222, 0.034, 0.276, 0.054, 0.17, 0.231, 0.165, 0.234, 0.093]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3798 | Steps: 4 | Val loss: 0.2957 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4541 | Steps: 4 | Val loss: 0.3463 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=97213)[0m rmse: 0.13488700985908508
[2m[36m(func pid=97213)[0m mae:  0.08964633196592331
[2m[36m(func pid=97213)[0m rmse_per_class: [0.062, 0.216, 0.04, 0.249, 0.053, 0.167, 0.223, 0.11, 0.134, 0.096]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3031 | Steps: 4 | Val loss: 0.2917 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 16:36:55 (running for 00:12:52.30)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.452 |  0.178 |                   55 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.38  |  0.162 |                   56 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.293 |  0.135 |                   50 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.252 |  0.155 |                   31 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.1622789204120636
[2m[36m(func pid=96425)[0m mae:  0.11608552932739258
[2m[36m(func pid=96425)[0m rmse_per_class: [0.101, 0.255, 0.063, 0.31, 0.064, 0.186, 0.261, 0.132, 0.138, 0.114]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.17751337587833405
[2m[36m(func pid=95877)[0m mae:  0.1292378008365631
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.269, 0.09, 0.326, 0.091, 0.193, 0.293, 0.144, 0.142, 0.117]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.15252678096294403
[2m[36m(func pid=101872)[0m mae:  0.09428401291370392
[2m[36m(func pid=101872)[0m rmse_per_class: [0.073, 0.224, 0.028, 0.304, 0.063, 0.234, 0.217, 0.107, 0.128, 0.146]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2760 | Steps: 4 | Val loss: 0.2547 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3795 | Steps: 4 | Val loss: 0.2952 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4440 | Steps: 4 | Val loss: 0.3466 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=97213)[0m rmse: 0.13536112010478973
[2m[36m(func pid=97213)[0m mae:  0.09001829475164413
[2m[36m(func pid=97213)[0m rmse_per_class: [0.066, 0.218, 0.039, 0.248, 0.055, 0.162, 0.217, 0.108, 0.135, 0.107]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.2790 | Steps: 4 | Val loss: 0.2719 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=96425)[0m rmse: 0.16191041469573975
[2m[36m(func pid=96425)[0m mae:  0.11594288051128387
[2m[36m(func pid=96425)[0m rmse_per_class: [0.099, 0.254, 0.063, 0.31, 0.065, 0.185, 0.263, 0.131, 0.139, 0.111]
[2m[36m(func pid=96425)[0m 
== Status ==
Current time: 2024-01-07 16:37:00 (running for 00:12:57.58)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.454 |  0.178 |                   56 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.379 |  0.162 |                   57 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.276 |  0.135 |                   51 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.303 |  0.153 |                   32 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.177651509642601
[2m[36m(func pid=95877)[0m mae:  0.12937816977500916
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.268, 0.091, 0.327, 0.092, 0.193, 0.293, 0.144, 0.142, 0.116]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3083 | Steps: 4 | Val loss: 0.2593 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=101872)[0m rmse: 0.14248333871364594
[2m[36m(func pid=101872)[0m mae:  0.08650968223810196
[2m[36m(func pid=101872)[0m rmse_per_class: [0.072, 0.209, 0.029, 0.245, 0.148, 0.179, 0.215, 0.106, 0.124, 0.097]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3781 | Steps: 4 | Val loss: 0.2956 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4432 | Steps: 4 | Val loss: 0.3439 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=97213)[0m rmse: 0.1391935646533966
[2m[36m(func pid=97213)[0m mae:  0.09267712384462357
[2m[36m(func pid=97213)[0m rmse_per_class: [0.066, 0.222, 0.035, 0.25, 0.056, 0.165, 0.219, 0.109, 0.14, 0.129]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2652 | Steps: 4 | Val loss: 0.2775 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 16:37:05 (running for 00:13:03.00)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.444 |  0.178 |                   57 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.378 |  0.162 |                   58 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.308 |  0.139 |                   52 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.279 |  0.142 |                   33 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.16214178502559662
[2m[36m(func pid=96425)[0m mae:  0.11616991460323334
[2m[36m(func pid=96425)[0m rmse_per_class: [0.098, 0.255, 0.064, 0.31, 0.065, 0.186, 0.262, 0.131, 0.141, 0.11]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.17774426937103271
[2m[36m(func pid=95877)[0m mae:  0.1293785572052002
[2m[36m(func pid=95877)[0m rmse_per_class: [0.11, 0.269, 0.091, 0.327, 0.092, 0.193, 0.293, 0.143, 0.142, 0.117]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2831 | Steps: 4 | Val loss: 0.2594 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=101872)[0m rmse: 0.1454113870859146
[2m[36m(func pid=101872)[0m mae:  0.08650994300842285
[2m[36m(func pid=101872)[0m rmse_per_class: [0.061, 0.219, 0.067, 0.247, 0.057, 0.17, 0.221, 0.14, 0.172, 0.1]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3781 | Steps: 4 | Val loss: 0.2961 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4429 | Steps: 4 | Val loss: 0.3449 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=97213)[0m rmse: 0.13886812329292297
[2m[36m(func pid=97213)[0m mae:  0.09237489849328995
[2m[36m(func pid=97213)[0m rmse_per_class: [0.065, 0.221, 0.032, 0.257, 0.068, 0.166, 0.212, 0.109, 0.138, 0.121]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2511 | Steps: 4 | Val loss: 0.2834 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 16:37:11 (running for 00:13:08.12)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.443 |  0.178 |                   58 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.378 |  0.162 |                   59 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.283 |  0.139 |                   53 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.265 |  0.145 |                   34 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.16238950192928314
[2m[36m(func pid=96425)[0m mae:  0.11637625843286514
[2m[36m(func pid=96425)[0m rmse_per_class: [0.098, 0.254, 0.065, 0.312, 0.065, 0.186, 0.261, 0.13, 0.141, 0.112]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.17767459154129028
[2m[36m(func pid=95877)[0m mae:  0.1294073462486267
[2m[36m(func pid=95877)[0m rmse_per_class: [0.111, 0.269, 0.092, 0.327, 0.089, 0.193, 0.293, 0.144, 0.142, 0.118]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2748 | Steps: 4 | Val loss: 0.2591 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=101872)[0m rmse: 0.1497037708759308
[2m[36m(func pid=101872)[0m mae:  0.09062573313713074
[2m[36m(func pid=101872)[0m rmse_per_class: [0.073, 0.227, 0.065, 0.285, 0.053, 0.18, 0.228, 0.129, 0.146, 0.112]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3782 | Steps: 4 | Val loss: 0.2962 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4454 | Steps: 4 | Val loss: 0.3438 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=97213)[0m rmse: 0.13811977207660675
[2m[36m(func pid=97213)[0m mae:  0.0921366810798645
[2m[36m(func pid=97213)[0m rmse_per_class: [0.061, 0.217, 0.032, 0.26, 0.074, 0.164, 0.216, 0.11, 0.144, 0.103]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.16246676445007324
[2m[36m(func pid=96425)[0m mae:  0.11641915887594223
[2m[36m(func pid=96425)[0m rmse_per_class: [0.099, 0.254, 0.066, 0.312, 0.065, 0.186, 0.26, 0.13, 0.141, 0.111]
[2m[36m(func pid=96425)[0m 
== Status ==
Current time: 2024-01-07 16:37:16 (running for 00:13:13.32)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.443 |  0.178 |                   59 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.378 |  0.162 |                   60 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.275 |  0.138 |                   54 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.251 |  0.15  |                   35 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2820 | Steps: 4 | Val loss: 0.2682 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=95877)[0m rmse: 0.1777590662240982
[2m[36m(func pid=95877)[0m mae:  0.12943682074546814
[2m[36m(func pid=95877)[0m rmse_per_class: [0.11, 0.269, 0.091, 0.327, 0.091, 0.194, 0.292, 0.143, 0.142, 0.119]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2953 | Steps: 4 | Val loss: 0.2589 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3840 | Steps: 4 | Val loss: 0.2948 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=101872)[0m rmse: 0.14035752415657043
[2m[36m(func pid=101872)[0m mae:  0.0845252200961113
[2m[36m(func pid=101872)[0m rmse_per_class: [0.074, 0.219, 0.026, 0.251, 0.051, 0.17, 0.224, 0.12, 0.151, 0.119]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4434 | Steps: 4 | Val loss: 0.3423 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 16:37:21 (running for 00:13:18.49)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.445 |  0.178 |                   60 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.378 |  0.162 |                   60 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.295 |  0.138 |                   55 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.282 |  0.14  |                   36 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.1617809683084488
[2m[36m(func pid=96425)[0m mae:  0.115805484354496
[2m[36m(func pid=96425)[0m rmse_per_class: [0.098, 0.253, 0.066, 0.311, 0.065, 0.186, 0.26, 0.129, 0.141, 0.11]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13774245977401733
[2m[36m(func pid=97213)[0m mae:  0.09165509045124054
[2m[36m(func pid=97213)[0m rmse_per_class: [0.06, 0.214, 0.031, 0.264, 0.071, 0.163, 0.216, 0.116, 0.148, 0.093]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.17797771096229553
[2m[36m(func pid=95877)[0m mae:  0.12969771027565002
[2m[36m(func pid=95877)[0m rmse_per_class: [0.11, 0.269, 0.09, 0.327, 0.09, 0.194, 0.293, 0.144, 0.144, 0.119]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2573 | Steps: 4 | Val loss: 0.2729 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3821 | Steps: 4 | Val loss: 0.2946 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2927 | Steps: 4 | Val loss: 0.2600 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=101872)[0m rmse: 0.14536088705062866
[2m[36m(func pid=101872)[0m mae:  0.08865565061569214
[2m[36m(func pid=101872)[0m rmse_per_class: [0.06, 0.218, 0.033, 0.247, 0.061, 0.194, 0.24, 0.111, 0.179, 0.111]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4404 | Steps: 4 | Val loss: 0.3405 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=96425)[0m rmse: 0.16176700592041016
[2m[36m(func pid=96425)[0m mae:  0.11577384173870087
[2m[36m(func pid=96425)[0m rmse_per_class: [0.099, 0.252, 0.066, 0.311, 0.066, 0.185, 0.26, 0.128, 0.14, 0.111]
[2m[36m(func pid=96425)[0m 
== Status ==
Current time: 2024-01-07 16:37:26 (running for 00:13:23.86)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.443 |  0.178 |                   61 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.382 |  0.162 |                   62 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.295 |  0.138 |                   55 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.257 |  0.145 |                   37 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=97213)[0m rmse: 0.13878169655799866
[2m[36m(func pid=97213)[0m mae:  0.09251024574041367
[2m[36m(func pid=97213)[0m rmse_per_class: [0.061, 0.215, 0.03, 0.265, 0.065, 0.163, 0.224, 0.119, 0.154, 0.091]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.1780848503112793
[2m[36m(func pid=95877)[0m mae:  0.12968392670154572
[2m[36m(func pid=95877)[0m rmse_per_class: [0.111, 0.269, 0.091, 0.327, 0.09, 0.193, 0.293, 0.144, 0.143, 0.121]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2653 | Steps: 4 | Val loss: 0.2834 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3825 | Steps: 4 | Val loss: 0.2941 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2742 | Steps: 4 | Val loss: 0.2570 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=101872)[0m rmse: 0.15055641531944275
[2m[36m(func pid=101872)[0m mae:  0.09110475331544876
[2m[36m(func pid=101872)[0m rmse_per_class: [0.1, 0.223, 0.027, 0.296, 0.104, 0.177, 0.212, 0.111, 0.142, 0.114]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4387 | Steps: 4 | Val loss: 0.3419 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 16:37:32 (running for 00:13:29.26)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.44  |  0.178 |                   62 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.382 |  0.162 |                   63 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.293 |  0.139 |                   56 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.265 |  0.151 |                   38 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.161562979221344
[2m[36m(func pid=96425)[0m mae:  0.1155783161520958
[2m[36m(func pid=96425)[0m rmse_per_class: [0.097, 0.253, 0.066, 0.31, 0.066, 0.185, 0.259, 0.128, 0.14, 0.111]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13651415705680847
[2m[36m(func pid=97213)[0m mae:  0.09088760614395142
[2m[36m(func pid=97213)[0m rmse_per_class: [0.07, 0.214, 0.031, 0.253, 0.059, 0.161, 0.227, 0.114, 0.143, 0.092]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.178158700466156
[2m[36m(func pid=95877)[0m mae:  0.1297907680273056
[2m[36m(func pid=95877)[0m rmse_per_class: [0.111, 0.268, 0.093, 0.328, 0.09, 0.193, 0.293, 0.143, 0.142, 0.121]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2727 | Steps: 4 | Val loss: 0.2771 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3759 | Steps: 4 | Val loss: 0.2932 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2804 | Steps: 4 | Val loss: 0.2578 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4396 | Steps: 4 | Val loss: 0.3381 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=101872)[0m rmse: 0.14800438284873962
[2m[36m(func pid=101872)[0m mae:  0.08862987905740738
[2m[36m(func pid=101872)[0m rmse_per_class: [0.059, 0.217, 0.039, 0.254, 0.062, 0.173, 0.23, 0.151, 0.143, 0.151]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=96425)[0m rmse: 0.16084107756614685
[2m[36m(func pid=96425)[0m mae:  0.1149776354432106
[2m[36m(func pid=96425)[0m rmse_per_class: [0.094, 0.253, 0.064, 0.309, 0.067, 0.186, 0.258, 0.129, 0.141, 0.108]
[2m[36m(func pid=96425)[0m 
== Status ==
Current time: 2024-01-07 16:37:37 (running for 00:13:34.51)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.439 |  0.178 |                   63 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.376 |  0.161 |                   64 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.274 |  0.137 |                   57 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.273 |  0.148 |                   39 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.17727217078208923
[2m[36m(func pid=95877)[0m mae:  0.12896449863910675
[2m[36m(func pid=95877)[0m rmse_per_class: [0.111, 0.269, 0.091, 0.326, 0.089, 0.193, 0.291, 0.142, 0.141, 0.119]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13725757598876953
[2m[36m(func pid=97213)[0m mae:  0.09125664830207825
[2m[36m(func pid=97213)[0m rmse_per_class: [0.072, 0.218, 0.034, 0.249, 0.055, 0.161, 0.229, 0.113, 0.144, 0.098]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2875 | Steps: 4 | Val loss: 0.2610 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3738 | Steps: 4 | Val loss: 0.2947 | Batch size: 32 | lr: 0.001 | Duration: 2.77s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4373 | Steps: 4 | Val loss: 0.3400 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2904 | Steps: 4 | Val loss: 0.2582 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=101872)[0m rmse: 0.13487088680267334
[2m[36m(func pid=101872)[0m mae:  0.08095954358577728
[2m[36m(func pid=101872)[0m rmse_per_class: [0.067, 0.211, 0.054, 0.245, 0.052, 0.17, 0.216, 0.109, 0.133, 0.091]
[2m[36m(func pid=101872)[0m 
== Status ==
Current time: 2024-01-07 16:37:42 (running for 00:13:39.62)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.44  |  0.177 |                   64 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.374 |  0.162 |                   65 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.137 |                   58 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.288 |  0.135 |                   40 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.16152486205101013
[2m[36m(func pid=96425)[0m mae:  0.11557061970233917
[2m[36m(func pid=96425)[0m rmse_per_class: [0.094, 0.253, 0.066, 0.31, 0.068, 0.186, 0.26, 0.128, 0.142, 0.107]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.1774035394191742
[2m[36m(func pid=95877)[0m mae:  0.12920184433460236
[2m[36m(func pid=95877)[0m rmse_per_class: [0.109, 0.269, 0.09, 0.327, 0.089, 0.193, 0.292, 0.142, 0.142, 0.121]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.137292742729187
[2m[36m(func pid=97213)[0m mae:  0.090916708111763
[2m[36m(func pid=97213)[0m rmse_per_class: [0.068, 0.221, 0.038, 0.253, 0.053, 0.16, 0.219, 0.11, 0.15, 0.102]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2854 | Steps: 4 | Val loss: 0.3149 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3749 | Steps: 4 | Val loss: 0.2942 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4383 | Steps: 4 | Val loss: 0.3386 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2851 | Steps: 4 | Val loss: 0.2584 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=101872)[0m rmse: 0.16406872868537903
[2m[36m(func pid=101872)[0m mae:  0.10125700384378433
[2m[36m(func pid=101872)[0m rmse_per_class: [0.081, 0.231, 0.112, 0.33, 0.053, 0.177, 0.229, 0.112, 0.185, 0.129]
[2m[36m(func pid=101872)[0m 
== Status ==
Current time: 2024-01-07 16:37:47 (running for 00:13:44.79)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.437 |  0.177 |                   65 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.375 |  0.161 |                   66 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.29  |  0.137 |                   59 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.285 |  0.164 |                   41 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.16141660511493683
[2m[36m(func pid=96425)[0m mae:  0.11540824174880981
[2m[36m(func pid=96425)[0m rmse_per_class: [0.093, 0.253, 0.067, 0.311, 0.068, 0.185, 0.26, 0.128, 0.141, 0.108]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.17718975245952606
[2m[36m(func pid=95877)[0m mae:  0.12908050417900085
[2m[36m(func pid=95877)[0m rmse_per_class: [0.11, 0.268, 0.09, 0.327, 0.089, 0.193, 0.292, 0.142, 0.142, 0.119]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13697536289691925
[2m[36m(func pid=97213)[0m mae:  0.09016511589288712
[2m[36m(func pid=97213)[0m rmse_per_class: [0.063, 0.222, 0.045, 0.261, 0.054, 0.16, 0.207, 0.109, 0.142, 0.106]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3172 | Steps: 4 | Val loss: 0.2641 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3774 | Steps: 4 | Val loss: 0.2953 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4413 | Steps: 4 | Val loss: 0.3364 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2792 | Steps: 4 | Val loss: 0.2572 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=101872)[0m rmse: 0.1393393874168396
[2m[36m(func pid=101872)[0m mae:  0.08537544310092926
[2m[36m(func pid=101872)[0m rmse_per_class: [0.058, 0.211, 0.032, 0.246, 0.059, 0.167, 0.228, 0.136, 0.14, 0.118]
[2m[36m(func pid=101872)[0m 
== Status ==
Current time: 2024-01-07 16:37:52 (running for 00:13:49.95)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.438 |  0.177 |                   66 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.377 |  0.162 |                   67 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.285 |  0.137 |                   60 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.317 |  0.139 |                   42 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.16200192272663116
[2m[36m(func pid=96425)[0m mae:  0.11591927707195282
[2m[36m(func pid=96425)[0m rmse_per_class: [0.093, 0.253, 0.067, 0.313, 0.068, 0.186, 0.26, 0.128, 0.141, 0.111]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.17727121710777283
[2m[36m(func pid=95877)[0m mae:  0.1290428340435028
[2m[36m(func pid=95877)[0m rmse_per_class: [0.111, 0.268, 0.092, 0.327, 0.088, 0.193, 0.291, 0.141, 0.142, 0.119]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.1363406479358673
[2m[36m(func pid=97213)[0m mae:  0.08918078988790512
[2m[36m(func pid=97213)[0m rmse_per_class: [0.06, 0.223, 0.045, 0.258, 0.054, 0.159, 0.205, 0.108, 0.134, 0.117]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3694 | Steps: 4 | Val loss: 0.2949 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2480 | Steps: 4 | Val loss: 0.2719 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4403 | Steps: 4 | Val loss: 0.3364 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2977 | Steps: 4 | Val loss: 0.2584 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 16:37:57 (running for 00:13:55.03)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.441 |  0.177 |                   67 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.369 |  0.162 |                   68 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.279 |  0.136 |                   61 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.317 |  0.139 |                   42 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.16186818480491638
[2m[36m(func pid=96425)[0m mae:  0.11585196107625961
[2m[36m(func pid=96425)[0m rmse_per_class: [0.093, 0.253, 0.067, 0.311, 0.069, 0.185, 0.26, 0.127, 0.142, 0.112]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.1457858383655548
[2m[36m(func pid=101872)[0m mae:  0.08865851163864136
[2m[36m(func pid=101872)[0m rmse_per_class: [0.068, 0.229, 0.068, 0.249, 0.069, 0.168, 0.215, 0.109, 0.175, 0.107]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.17715957760810852
[2m[36m(func pid=95877)[0m mae:  0.1288524717092514
[2m[36m(func pid=95877)[0m rmse_per_class: [0.111, 0.268, 0.094, 0.327, 0.089, 0.193, 0.29, 0.14, 0.141, 0.117]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.1370299905538559
[2m[36m(func pid=97213)[0m mae:  0.0896688923239708
[2m[36m(func pid=97213)[0m rmse_per_class: [0.06, 0.221, 0.042, 0.262, 0.058, 0.161, 0.209, 0.112, 0.13, 0.117]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3681 | Steps: 4 | Val loss: 0.2946 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2868 | Steps: 4 | Val loss: 0.2849 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4340 | Steps: 4 | Val loss: 0.3347 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 16:38:03 (running for 00:14:00.18)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.44  |  0.177 |                   68 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.368 |  0.162 |                   69 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.298 |  0.137 |                   62 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.248 |  0.146 |                   43 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.16166134178638458
[2m[36m(func pid=96425)[0m mae:  0.11568216234445572
[2m[36m(func pid=96425)[0m rmse_per_class: [0.092, 0.253, 0.065, 0.312, 0.068, 0.185, 0.26, 0.128, 0.142, 0.112]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2874 | Steps: 4 | Val loss: 0.2557 | Batch size: 32 | lr: 0.01 | Duration: 3.17s
[2m[36m(func pid=101872)[0m rmse: 0.15124741196632385
[2m[36m(func pid=101872)[0m mae:  0.0923386961221695
[2m[36m(func pid=101872)[0m rmse_per_class: [0.106, 0.22, 0.032, 0.284, 0.075, 0.176, 0.228, 0.128, 0.167, 0.095]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.17708756029605865
[2m[36m(func pid=95877)[0m mae:  0.1287645399570465
[2m[36m(func pid=95877)[0m rmse_per_class: [0.111, 0.268, 0.093, 0.327, 0.089, 0.193, 0.291, 0.14, 0.142, 0.117]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3727 | Steps: 4 | Val loss: 0.2930 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=97213)[0m rmse: 0.1353725641965866
[2m[36m(func pid=97213)[0m mae:  0.08913933485746384
[2m[36m(func pid=97213)[0m rmse_per_class: [0.059, 0.213, 0.034, 0.252, 0.063, 0.163, 0.221, 0.116, 0.128, 0.104]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2594 | Steps: 4 | Val loss: 0.2790 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4373 | Steps: 4 | Val loss: 0.3344 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
== Status ==
Current time: 2024-01-07 16:38:08 (running for 00:14:05.58)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.434 |  0.177 |                   69 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.373 |  0.161 |                   70 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.287 |  0.135 |                   63 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.287 |  0.151 |                   44 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.16065607964992523
[2m[36m(func pid=96425)[0m mae:  0.114865742623806
[2m[36m(func pid=96425)[0m rmse_per_class: [0.093, 0.252, 0.062, 0.309, 0.067, 0.184, 0.258, 0.128, 0.142, 0.11]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2895 | Steps: 4 | Val loss: 0.2563 | Batch size: 32 | lr: 0.01 | Duration: 3.20s
[2m[36m(func pid=101872)[0m rmse: 0.1481551229953766
[2m[36m(func pid=101872)[0m mae:  0.08943028748035431
[2m[36m(func pid=101872)[0m rmse_per_class: [0.073, 0.222, 0.03, 0.268, 0.089, 0.191, 0.245, 0.122, 0.121, 0.121]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.17669694125652313
[2m[36m(func pid=95877)[0m mae:  0.12855882942676544
[2m[36m(func pid=95877)[0m rmse_per_class: [0.111, 0.268, 0.09, 0.326, 0.089, 0.193, 0.291, 0.142, 0.142, 0.115]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3662 | Steps: 4 | Val loss: 0.2924 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=97213)[0m rmse: 0.1359078288078308
[2m[36m(func pid=97213)[0m mae:  0.08957599103450775
[2m[36m(func pid=97213)[0m rmse_per_class: [0.059, 0.209, 0.039, 0.251, 0.066, 0.163, 0.229, 0.115, 0.126, 0.102]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2766 | Steps: 4 | Val loss: 0.2651 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4335 | Steps: 4 | Val loss: 0.3340 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 16:38:13 (running for 00:14:10.89)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.437 |  0.177 |                   70 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.366 |  0.16  |                   71 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.29  |  0.136 |                   64 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.259 |  0.148 |                   45 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.16048237681388855
[2m[36m(func pid=96425)[0m mae:  0.11468057334423065
[2m[36m(func pid=96425)[0m rmse_per_class: [0.093, 0.253, 0.063, 0.305, 0.067, 0.184, 0.258, 0.128, 0.143, 0.111]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2792 | Steps: 4 | Val loss: 0.2575 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=95877)[0m rmse: 0.17695918679237366
[2m[36m(func pid=95877)[0m mae:  0.12869466841220856
[2m[36m(func pid=95877)[0m rmse_per_class: [0.113, 0.268, 0.089, 0.326, 0.091, 0.193, 0.29, 0.141, 0.142, 0.115]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.13856692612171173
[2m[36m(func pid=101872)[0m mae:  0.08362419903278351
[2m[36m(func pid=101872)[0m rmse_per_class: [0.065, 0.216, 0.031, 0.246, 0.054, 0.167, 0.214, 0.117, 0.133, 0.141]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3731 | Steps: 4 | Val loss: 0.2915 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=97213)[0m rmse: 0.13629703223705292
[2m[36m(func pid=97213)[0m mae:  0.09045899659395218
[2m[36m(func pid=97213)[0m rmse_per_class: [0.061, 0.21, 0.038, 0.252, 0.062, 0.162, 0.234, 0.11, 0.138, 0.095]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4325 | Steps: 4 | Val loss: 0.3337 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2787 | Steps: 4 | Val loss: 0.2789 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 16:38:19 (running for 00:14:16.11)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.434 |  0.177 |                   71 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.373 |  0.16  |                   72 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.279 |  0.136 |                   65 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.277 |  0.139 |                   46 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.1598825603723526
[2m[36m(func pid=96425)[0m mae:  0.11413487046957016
[2m[36m(func pid=96425)[0m rmse_per_class: [0.092, 0.252, 0.065, 0.304, 0.066, 0.184, 0.257, 0.127, 0.144, 0.108]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.17713649570941925
[2m[36m(func pid=95877)[0m mae:  0.12886188924312592
[2m[36m(func pid=95877)[0m rmse_per_class: [0.113, 0.269, 0.088, 0.326, 0.092, 0.194, 0.29, 0.141, 0.143, 0.116]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2748 | Steps: 4 | Val loss: 0.2558 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
[2m[36m(func pid=101872)[0m rmse: 0.1498565375804901
[2m[36m(func pid=101872)[0m mae:  0.09160339832305908
[2m[36m(func pid=101872)[0m rmse_per_class: [0.116, 0.215, 0.07, 0.264, 0.051, 0.175, 0.23, 0.115, 0.18, 0.083]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3712 | Steps: 4 | Val loss: 0.2918 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=97213)[0m rmse: 0.1350293755531311
[2m[36m(func pid=97213)[0m mae:  0.089604452252388
[2m[36m(func pid=97213)[0m rmse_per_class: [0.06, 0.211, 0.033, 0.243, 0.058, 0.161, 0.231, 0.11, 0.148, 0.096]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4321 | Steps: 4 | Val loss: 0.3333 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2652 | Steps: 4 | Val loss: 0.2854 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 16:38:24 (running for 00:14:21.14)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.432 |  0.177 |                   72 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.371 |  0.16  |                   73 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.275 |  0.135 |                   66 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.279 |  0.15  |                   47 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.16002660989761353
[2m[36m(func pid=96425)[0m mae:  0.114349365234375
[2m[36m(func pid=96425)[0m rmse_per_class: [0.093, 0.253, 0.063, 0.303, 0.065, 0.184, 0.257, 0.128, 0.147, 0.108]
[2m[36m(func pid=96425)[0m 
[2m[36m(func pid=95877)[0m rmse: 0.1769714653491974
[2m[36m(func pid=95877)[0m mae:  0.12876823544502258
[2m[36m(func pid=95877)[0m rmse_per_class: [0.111, 0.269, 0.086, 0.326, 0.089, 0.194, 0.29, 0.143, 0.144, 0.117]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2830 | Steps: 4 | Val loss: 0.2563 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=101872)[0m rmse: 0.1468987762928009
[2m[36m(func pid=101872)[0m mae:  0.08867130428552628
[2m[36m(func pid=101872)[0m rmse_per_class: [0.062, 0.234, 0.047, 0.299, 0.056, 0.169, 0.216, 0.11, 0.159, 0.116]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3713 | Steps: 4 | Val loss: 0.2919 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4301 | Steps: 4 | Val loss: 0.3329 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=97213)[0m rmse: 0.13565364480018616
[2m[36m(func pid=97213)[0m mae:  0.08955110609531403
[2m[36m(func pid=97213)[0m rmse_per_class: [0.061, 0.214, 0.034, 0.245, 0.056, 0.161, 0.224, 0.109, 0.145, 0.107]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2759 | Steps: 4 | Val loss: 0.2769 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=96425)[0m rmse: 0.1600600779056549
[2m[36m(func pid=96425)[0m mae:  0.11439254134893417
[2m[36m(func pid=96425)[0m rmse_per_class: [0.093, 0.252, 0.063, 0.304, 0.064, 0.184, 0.257, 0.128, 0.147, 0.108]
[2m[36m(func pid=96425)[0m 
== Status ==
Current time: 2024-01-07 16:38:29 (running for 00:14:26.51)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=4
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 4 RUNNING, 4 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.432 |  0.177 |                   73 |
| train_c9cb4_00005 | RUNNING    | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.371 |  0.16  |                   74 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.283 |  0.136 |                   67 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.265 |  0.147 |                   48 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=95877)[0m rmse: 0.1763923019170761
[2m[36m(func pid=95877)[0m mae:  0.12838560342788696
[2m[36m(func pid=95877)[0m rmse_per_class: [0.11, 0.268, 0.085, 0.326, 0.087, 0.193, 0.29, 0.144, 0.143, 0.119]
[2m[36m(func pid=95877)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.14754855632781982
[2m[36m(func pid=101872)[0m mae:  0.08886279910802841
[2m[36m(func pid=101872)[0m rmse_per_class: [0.079, 0.222, 0.028, 0.25, 0.068, 0.17, 0.217, 0.11, 0.125, 0.207]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2904 | Steps: 4 | Val loss: 0.2562 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
[2m[36m(func pid=96425)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3699 | Steps: 4 | Val loss: 0.2919 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=95877)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4314 | Steps: 4 | Val loss: 0.3331 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=97213)[0m rmse: 0.1356939673423767
[2m[36m(func pid=97213)[0m mae:  0.08903524279594421
[2m[36m(func pid=97213)[0m rmse_per_class: [0.062, 0.217, 0.034, 0.253, 0.057, 0.162, 0.214, 0.109, 0.139, 0.111]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2532 | Steps: 4 | Val loss: 0.2859 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 16:38:34 (running for 00:14:31.96)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=5
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (16 PENDING, 3 RUNNING, 5 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00004 | RUNNING    | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.43  |  0.176 |                   74 |
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.29  |  0.136 |                   68 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.276 |  0.148 |                   49 |
| train_c9cb4_00008 | PENDING    |                     | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | PENDING    |                     | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=96425)[0m rmse: 0.16006463766098022
[2m[36m(func pid=96425)[0m mae:  0.11444787681102753
[2m[36m(func pid=96425)[0m rmse_per_class: [0.095, 0.251, 0.063, 0.305, 0.066, 0.184, 0.258, 0.126, 0.147, 0.106]
[2m[36m(func pid=95877)[0m rmse: 0.1768939346075058
[2m[36m(func pid=95877)[0m mae:  0.12881065905094147
[2m[36m(func pid=95877)[0m rmse_per_class: [0.111, 0.268, 0.087, 0.327, 0.088, 0.194, 0.291, 0.143, 0.142, 0.119]
[2m[36m(func pid=101872)[0m rmse: 0.15416091680526733
[2m[36m(func pid=101872)[0m mae:  0.09307103604078293
[2m[36m(func pid=101872)[0m rmse_per_class: [0.11, 0.215, 0.031, 0.268, 0.111, 0.18, 0.238, 0.15, 0.154, 0.084]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2629 | Steps: 4 | Val loss: 0.2585 | Batch size: 32 | lr: 0.01 | Duration: 3.24s
[2m[36m(func pid=97213)[0m rmse: 0.1375146210193634
[2m[36m(func pid=97213)[0m mae:  0.09018059074878693
[2m[36m(func pid=97213)[0m rmse_per_class: [0.06, 0.223, 0.033, 0.257, 0.066, 0.165, 0.211, 0.108, 0.137, 0.115]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3019 | Steps: 4 | Val loss: 0.2760 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=101872)[0m rmse: 0.14215604960918427
[2m[36m(func pid=101872)[0m mae:  0.0855419784784317
[2m[36m(func pid=101872)[0m rmse_per_class: [0.077, 0.233, 0.037, 0.271, 0.066, 0.17, 0.213, 0.114, 0.163, 0.08]
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2815 | Steps: 4 | Val loss: 0.2581 | Batch size: 32 | lr: 0.01 | Duration: 3.13s
[2m[36m(func pid=114403)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=114403)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=114403)[0m Configuration completed!
[2m[36m(func pid=114403)[0m New optimizer parameters:
[2m[36m(func pid=114403)[0m SGD (
[2m[36m(func pid=114403)[0m Parameter Group 0
[2m[36m(func pid=114403)[0m     dampening: 0
[2m[36m(func pid=114403)[0m     differentiable: False
[2m[36m(func pid=114403)[0m     foreach: None
[2m[36m(func pid=114403)[0m     lr: 0.0001
[2m[36m(func pid=114403)[0m     maximize: False
[2m[36m(func pid=114403)[0m     momentum: 0.99
[2m[36m(func pid=114403)[0m     nesterov: False
[2m[36m(func pid=114403)[0m     weight_decay: 0.0001
[2m[36m(func pid=114403)[0m )
[2m[36m(func pid=114403)[0m 
== Status ==
Current time: 2024-01-07 16:38:40 (running for 00:14:37.20)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.15549999848008156
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.263 |  0.138 |                   69 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.253 |  0.154 |                   50 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


== Status ==
Current time: 2024-01-07 16:38:45 (running for 00:14:42.48)
Memory usage on this node: 23.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.15549999848008156
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.263 |  0.138 |                   69 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.302 |  0.142 |                   51 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=114490)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114490)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=114490)[0m Configuration completed!
[2m[36m(func pid=114490)[0m New optimizer parameters:
[2m[36m(func pid=114490)[0m SGD (
[2m[36m(func pid=114490)[0m Parameter Group 0
[2m[36m(func pid=114490)[0m     dampening: 0
[2m[36m(func pid=114490)[0m     differentiable: False
[2m[36m(func pid=114490)[0m     foreach: None
[2m[36m(func pid=114490)[0m     lr: 0.001
[2m[36m(func pid=114490)[0m     maximize: False
[2m[36m(func pid=114490)[0m     momentum: 0.99
[2m[36m(func pid=114490)[0m     nesterov: False
[2m[36m(func pid=114490)[0m     weight_decay: 0.0001
[2m[36m(func pid=114490)[0m )
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13702377676963806
[2m[36m(func pid=97213)[0m mae:  0.08933304995298386
[2m[36m(func pid=97213)[0m rmse_per_class: [0.059, 0.223, 0.032, 0.256, 0.068, 0.165, 0.209, 0.108, 0.134, 0.115]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0792 | Steps: 4 | Val loss: 0.8068 | Batch size: 32 | lr: 0.0001 | Duration: 4.45s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2552 | Steps: 4 | Val loss: 0.2779 | Batch size: 32 | lr: 0.1 | Duration: 3.23s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2788 | Steps: 4 | Val loss: 0.2556 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0552 | Steps: 4 | Val loss: 0.7535 | Batch size: 32 | lr: 0.001 | Duration: 4.63s
== Status ==
Current time: 2024-01-07 16:38:50 (running for 00:14:48.01)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.15549999848008156
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.282 |  0.137 |                   70 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.302 |  0.142 |                   51 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.1785203516483307
[2m[36m(func pid=114403)[0m mae:  0.13108830153942108
[2m[36m(func pid=114403)[0m rmse_per_class: [0.105, 0.264, 0.086, 0.324, 0.1, 0.192, 0.305, 0.153, 0.139, 0.116]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.1464286595582962
[2m[36m(func pid=101872)[0m mae:  0.0879480242729187
[2m[36m(func pid=101872)[0m rmse_per_class: [0.064, 0.243, 0.043, 0.253, 0.057, 0.166, 0.214, 0.106, 0.154, 0.166]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13492295145988464
[2m[36m(func pid=97213)[0m mae:  0.08810773491859436
[2m[36m(func pid=97213)[0m rmse_per_class: [0.059, 0.216, 0.031, 0.256, 0.068, 0.164, 0.21, 0.109, 0.131, 0.106]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.17849937081336975
[2m[36m(func pid=114490)[0m mae:  0.13088323175907135
[2m[36m(func pid=114490)[0m rmse_per_class: [0.105, 0.266, 0.087, 0.324, 0.1, 0.192, 0.303, 0.154, 0.138, 0.115]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0609 | Steps: 4 | Val loss: 0.8038 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2951 | Steps: 4 | Val loss: 0.3000 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2802 | Steps: 4 | Val loss: 0.2535 | Batch size: 32 | lr: 0.01 | Duration: 3.18s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.8994 | Steps: 4 | Val loss: 0.6076 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 16:38:56 (running for 00:14:53.21)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.15549999848008156
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.279 |  0.135 |                   71 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.255 |  0.146 |                   52 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  1.061 |  0.179 |                    2 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  1.055 |  0.178 |                    1 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17920131981372833
[2m[36m(func pid=114403)[0m mae:  0.13166852295398712
[2m[36m(func pid=114403)[0m rmse_per_class: [0.106, 0.264, 0.088, 0.324, 0.102, 0.193, 0.306, 0.153, 0.139, 0.117]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.15839755535125732
[2m[36m(func pid=101872)[0m mae:  0.09704776108264923
[2m[36m(func pid=101872)[0m rmse_per_class: [0.071, 0.229, 0.029, 0.314, 0.057, 0.17, 0.227, 0.154, 0.175, 0.158]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13347479701042175
[2m[36m(func pid=97213)[0m mae:  0.08727293461561203
[2m[36m(func pid=97213)[0m rmse_per_class: [0.06, 0.213, 0.029, 0.248, 0.065, 0.161, 0.214, 0.109, 0.134, 0.102]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.17897558212280273
[2m[36m(func pid=114490)[0m mae:  0.13100312650203705
[2m[36m(func pid=114490)[0m rmse_per_class: [0.105, 0.267, 0.089, 0.323, 0.1, 0.193, 0.303, 0.157, 0.138, 0.115]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 1.0313 | Steps: 4 | Val loss: 0.7798 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2845 | Steps: 4 | Val loss: 0.2793 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2752 | Steps: 4 | Val loss: 0.2528 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.6675 | Steps: 4 | Val loss: 0.4457 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 16:39:01 (running for 00:14:58.59)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.15549999848008156
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.133 |                   72 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.295 |  0.158 |                   53 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  1.031 |  0.18  |                    3 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.899 |  0.179 |                    2 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17990949749946594
[2m[36m(func pid=114403)[0m mae:  0.13219250738620758
[2m[36m(func pid=114403)[0m rmse_per_class: [0.106, 0.265, 0.088, 0.325, 0.103, 0.193, 0.308, 0.154, 0.139, 0.119]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.14498063921928406
[2m[36m(func pid=101872)[0m mae:  0.08687522262334824
[2m[36m(func pid=101872)[0m rmse_per_class: [0.089, 0.244, 0.027, 0.286, 0.076, 0.171, 0.218, 0.121, 0.129, 0.089]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13332554697990417
[2m[36m(func pid=97213)[0m mae:  0.08723486959934235
[2m[36m(func pid=97213)[0m rmse_per_class: [0.062, 0.211, 0.029, 0.246, 0.066, 0.16, 0.217, 0.109, 0.133, 0.101]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.17875608801841736
[2m[36m(func pid=114490)[0m mae:  0.13046151399612427
[2m[36m(func pid=114490)[0m rmse_per_class: [0.106, 0.268, 0.09, 0.325, 0.097, 0.194, 0.299, 0.157, 0.138, 0.114]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.9824 | Steps: 4 | Val loss: 0.7415 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2593 | Steps: 4 | Val loss: 0.2907 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2849 | Steps: 4 | Val loss: 0.2559 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4988 | Steps: 4 | Val loss: 0.3475 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 16:39:06 (running for 00:15:03.77)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.15549999848008156
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.275 |  0.133 |                   73 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.284 |  0.145 |                   54 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.982 |  0.18  |                    4 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.668 |  0.179 |                    3 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.1801433265209198
[2m[36m(func pid=114403)[0m mae:  0.13221964240074158
[2m[36m(func pid=114403)[0m rmse_per_class: [0.106, 0.266, 0.089, 0.324, 0.104, 0.193, 0.307, 0.154, 0.138, 0.119]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.15424618124961853
[2m[36m(func pid=101872)[0m mae:  0.09127085655927658
[2m[36m(func pid=101872)[0m rmse_per_class: [0.068, 0.217, 0.039, 0.272, 0.117, 0.177, 0.251, 0.114, 0.159, 0.128]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.1362878978252411
[2m[36m(func pid=97213)[0m mae:  0.08909160643815994
[2m[36m(func pid=97213)[0m rmse_per_class: [0.065, 0.214, 0.03, 0.249, 0.066, 0.16, 0.22, 0.11, 0.137, 0.113]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1776169240474701
[2m[36m(func pid=114490)[0m mae:  0.12918008863925934
[2m[36m(func pid=114490)[0m rmse_per_class: [0.109, 0.269, 0.093, 0.332, 0.092, 0.193, 0.289, 0.148, 0.141, 0.11]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.9296 | Steps: 4 | Val loss: 0.6912 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2953 | Steps: 4 | Val loss: 0.2944 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2715 | Steps: 4 | Val loss: 0.2576 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 16:39:11 (running for 00:15:09.01)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.15549999848008156
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.285 |  0.136 |                   74 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.259 |  0.154 |                   55 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.93  |  0.18  |                    5 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.499 |  0.178 |                    4 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.18039602041244507
[2m[36m(func pid=114403)[0m mae:  0.1323898732662201
[2m[36m(func pid=114403)[0m rmse_per_class: [0.107, 0.266, 0.089, 0.324, 0.104, 0.194, 0.308, 0.154, 0.138, 0.121]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4374 | Steps: 4 | Val loss: 0.3230 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=101872)[0m rmse: 0.15242016315460205
[2m[36m(func pid=101872)[0m mae:  0.09517883509397507
[2m[36m(func pid=101872)[0m rmse_per_class: [0.059, 0.223, 0.032, 0.311, 0.058, 0.196, 0.213, 0.107, 0.182, 0.145]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13750429451465607
[2m[36m(func pid=97213)[0m mae:  0.08957581222057343
[2m[36m(func pid=97213)[0m rmse_per_class: [0.062, 0.218, 0.031, 0.252, 0.064, 0.159, 0.218, 0.12, 0.14, 0.111]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.17599745094776154
[2m[36m(func pid=114490)[0m mae:  0.12728433310985565
[2m[36m(func pid=114490)[0m rmse_per_class: [0.111, 0.271, 0.096, 0.339, 0.085, 0.193, 0.277, 0.139, 0.145, 0.104]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.8627 | Steps: 4 | Val loss: 0.6414 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2717 | Steps: 4 | Val loss: 0.2683 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2879 | Steps: 4 | Val loss: 0.2593 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 16:39:17 (running for 00:15:14.38)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.271 |  0.138 |                   75 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.295 |  0.152 |                   56 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.863 |  0.181 |                    6 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.437 |  0.176 |                    5 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.18085823953151703
[2m[36m(func pid=114403)[0m mae:  0.13271135091781616
[2m[36m(func pid=114403)[0m rmse_per_class: [0.107, 0.267, 0.09, 0.324, 0.104, 0.194, 0.308, 0.154, 0.138, 0.123]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4263 | Steps: 4 | Val loss: 0.3426 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=101872)[0m rmse: 0.14243194460868835
[2m[36m(func pid=101872)[0m mae:  0.08432579040527344
[2m[36m(func pid=101872)[0m rmse_per_class: [0.073, 0.212, 0.034, 0.25, 0.069, 0.17, 0.218, 0.159, 0.142, 0.098]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13873888552188873
[2m[36m(func pid=97213)[0m mae:  0.09083258360624313
[2m[36m(func pid=97213)[0m rmse_per_class: [0.06, 0.218, 0.032, 0.254, 0.059, 0.159, 0.223, 0.124, 0.15, 0.108]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.17528009414672852
[2m[36m(func pid=114490)[0m mae:  0.12558849155902863
[2m[36m(func pid=114490)[0m rmse_per_class: [0.114, 0.272, 0.095, 0.348, 0.077, 0.193, 0.27, 0.135, 0.149, 0.1]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.7877 | Steps: 4 | Val loss: 0.5811 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2690 | Steps: 4 | Val loss: 0.2823 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=114403)[0m rmse: 0.18042880296707153
[2m[36m(func pid=114403)[0m mae:  0.13235053420066833
[2m[36m(func pid=114403)[0m rmse_per_class: [0.107, 0.267, 0.089, 0.324, 0.102, 0.194, 0.307, 0.153, 0.139, 0.121]
[2m[36m(func pid=114403)[0m 
== Status ==
Current time: 2024-01-07 16:39:22 (running for 00:15:19.48)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.288 |  0.139 |                   76 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.272 |  0.142 |                   57 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.788 |  0.18  |                    7 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.426 |  0.175 |                    6 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2811 | Steps: 4 | Val loss: 0.2590 | Batch size: 32 | lr: 0.01 | Duration: 3.14s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4670 | Steps: 4 | Val loss: 0.3792 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=101872)[0m rmse: 0.14776760339736938
[2m[36m(func pid=101872)[0m mae:  0.08827010542154312
[2m[36m(func pid=101872)[0m rmse_per_class: [0.082, 0.22, 0.029, 0.268, 0.068, 0.17, 0.215, 0.119, 0.214, 0.093]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.1386031210422516
[2m[36m(func pid=97213)[0m mae:  0.09062492847442627
[2m[36m(func pid=97213)[0m rmse_per_class: [0.063, 0.217, 0.039, 0.254, 0.055, 0.16, 0.223, 0.123, 0.144, 0.107]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.7258 | Steps: 4 | Val loss: 0.5269 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=114490)[0m rmse: 0.17511828243732452
[2m[36m(func pid=114490)[0m mae:  0.12391351163387299
[2m[36m(func pid=114490)[0m rmse_per_class: [0.114, 0.273, 0.086, 0.356, 0.068, 0.194, 0.275, 0.135, 0.153, 0.097]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2593 | Steps: 4 | Val loss: 0.2781 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 16:39:27 (running for 00:15:24.80)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.281 |  0.139 |                   77 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.148 |                   58 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.726 |  0.18  |                    8 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.467 |  0.175 |                    7 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.18004384636878967
[2m[36m(func pid=114403)[0m mae:  0.1319509744644165
[2m[36m(func pid=114403)[0m rmse_per_class: [0.107, 0.267, 0.089, 0.324, 0.1, 0.194, 0.306, 0.152, 0.139, 0.122]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2659 | Steps: 4 | Val loss: 0.2599 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5186 | Steps: 4 | Val loss: 0.4191 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=101872)[0m rmse: 0.1456858068704605
[2m[36m(func pid=101872)[0m mae:  0.08848409354686737
[2m[36m(func pid=101872)[0m rmse_per_class: [0.062, 0.215, 0.025, 0.277, 0.059, 0.228, 0.228, 0.116, 0.125, 0.121]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.6579 | Steps: 4 | Val loss: 0.4824 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=97213)[0m rmse: 0.1392321139574051
[2m[36m(func pid=97213)[0m mae:  0.09118170291185379
[2m[36m(func pid=97213)[0m rmse_per_class: [0.069, 0.217, 0.042, 0.261, 0.053, 0.16, 0.22, 0.117, 0.146, 0.108]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.17685218155384064
[2m[36m(func pid=114490)[0m mae:  0.12289895862340927
[2m[36m(func pid=114490)[0m rmse_per_class: [0.11, 0.274, 0.081, 0.363, 0.062, 0.195, 0.298, 0.137, 0.154, 0.094]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2843 | Steps: 4 | Val loss: 0.2798 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 16:39:32 (running for 00:15:30.10)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.266 |  0.139 |                   78 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.259 |  0.146 |                   59 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.658 |  0.18  |                    9 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.519 |  0.177 |                    8 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17990857362747192
[2m[36m(func pid=114403)[0m mae:  0.1317395269870758
[2m[36m(func pid=114403)[0m rmse_per_class: [0.108, 0.268, 0.09, 0.325, 0.099, 0.194, 0.304, 0.152, 0.139, 0.121]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2837 | Steps: 4 | Val loss: 0.2565 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5626 | Steps: 4 | Val loss: 0.4576 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=101872)[0m rmse: 0.1485063135623932
[2m[36m(func pid=101872)[0m mae:  0.08737654983997345
[2m[36m(func pid=101872)[0m rmse_per_class: [0.077, 0.217, 0.027, 0.246, 0.077, 0.184, 0.219, 0.129, 0.136, 0.173]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.5994 | Steps: 4 | Val loss: 0.4399 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=97213)[0m rmse: 0.13585425913333893
[2m[36m(func pid=97213)[0m mae:  0.08925473690032959
[2m[36m(func pid=97213)[0m rmse_per_class: [0.064, 0.209, 0.045, 0.259, 0.054, 0.161, 0.216, 0.11, 0.141, 0.099]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.17900913953781128
[2m[36m(func pid=114490)[0m mae:  0.12226319313049316
[2m[36m(func pid=114490)[0m rmse_per_class: [0.108, 0.275, 0.071, 0.369, 0.058, 0.195, 0.326, 0.14, 0.156, 0.093]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:39:38 (running for 00:15:35.30)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.284 |  0.136 |                   79 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.284 |  0.149 |                   60 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.599 |  0.18  |                   10 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.563 |  0.179 |                    9 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17980344593524933
[2m[36m(func pid=114403)[0m mae:  0.13147947192192078
[2m[36m(func pid=114403)[0m rmse_per_class: [0.108, 0.269, 0.092, 0.325, 0.099, 0.194, 0.301, 0.149, 0.14, 0.12]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2631 | Steps: 4 | Val loss: 0.3071 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2769 | Steps: 4 | Val loss: 0.2556 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.6265 | Steps: 4 | Val loss: 0.4927 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=101872)[0m rmse: 0.16047346591949463
[2m[36m(func pid=101872)[0m mae:  0.09727976471185684
[2m[36m(func pid=101872)[0m rmse_per_class: [0.064, 0.23, 0.031, 0.315, 0.08, 0.174, 0.238, 0.136, 0.198, 0.141]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.5488 | Steps: 4 | Val loss: 0.4067 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=97213)[0m rmse: 0.13486717641353607
[2m[36m(func pid=97213)[0m mae:  0.08823888003826141
[2m[36m(func pid=97213)[0m rmse_per_class: [0.061, 0.21, 0.046, 0.257, 0.053, 0.16, 0.214, 0.11, 0.136, 0.102]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.18189996480941772
[2m[36m(func pid=114490)[0m mae:  0.1222321018576622
[2m[36m(func pid=114490)[0m rmse_per_class: [0.105, 0.277, 0.063, 0.373, 0.056, 0.195, 0.359, 0.143, 0.155, 0.092]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:39:43 (running for 00:15:40.56)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.277 |  0.135 |                   80 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.263 |  0.16  |                   61 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.549 |  0.18  |                   11 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.627 |  0.182 |                   10 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17965050041675568
[2m[36m(func pid=114403)[0m mae:  0.13119740784168243
[2m[36m(func pid=114403)[0m rmse_per_class: [0.108, 0.269, 0.095, 0.326, 0.098, 0.194, 0.299, 0.146, 0.141, 0.12]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2722 | Steps: 4 | Val loss: 0.2749 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2617 | Steps: 4 | Val loss: 0.2562 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.6411 | Steps: 4 | Val loss: 0.5181 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.5112 | Steps: 4 | Val loss: 0.3763 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=101872)[0m rmse: 0.14309431612491608
[2m[36m(func pid=101872)[0m mae:  0.08754013478755951
[2m[36m(func pid=101872)[0m rmse_per_class: [0.061, 0.212, 0.028, 0.249, 0.058, 0.195, 0.261, 0.127, 0.145, 0.095]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13535933196544647
[2m[36m(func pid=97213)[0m mae:  0.08839166909456253
[2m[36m(func pid=97213)[0m rmse_per_class: [0.057, 0.21, 0.043, 0.257, 0.056, 0.162, 0.214, 0.113, 0.14, 0.101]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.18468356132507324
[2m[36m(func pid=114490)[0m mae:  0.12240509688854218
[2m[36m(func pid=114490)[0m rmse_per_class: [0.102, 0.278, 0.057, 0.376, 0.056, 0.195, 0.394, 0.145, 0.152, 0.092]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:39:48 (running for 00:15:45.86)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.262 |  0.135 |                   81 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.272 |  0.143 |                   62 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.511 |  0.18  |                   12 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.641 |  0.185 |                   11 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17963151633739471
[2m[36m(func pid=114403)[0m mae:  0.1309206783771515
[2m[36m(func pid=114403)[0m rmse_per_class: [0.11, 0.269, 0.095, 0.328, 0.098, 0.194, 0.295, 0.145, 0.141, 0.12]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2691 | Steps: 4 | Val loss: 0.2695 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2949 | Steps: 4 | Val loss: 0.2589 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.6798 | Steps: 4 | Val loss: 0.5276 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4743 | Steps: 4 | Val loss: 0.3548 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=101872)[0m rmse: 0.14092354476451874
[2m[36m(func pid=101872)[0m mae:  0.08362182229757309
[2m[36m(func pid=101872)[0m rmse_per_class: [0.082, 0.219, 0.027, 0.247, 0.062, 0.17, 0.224, 0.12, 0.139, 0.117]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13763365149497986
[2m[36m(func pid=97213)[0m mae:  0.09015978872776031
[2m[36m(func pid=97213)[0m rmse_per_class: [0.058, 0.215, 0.033, 0.258, 0.057, 0.164, 0.219, 0.115, 0.15, 0.107]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.18725088238716125
[2m[36m(func pid=114490)[0m mae:  0.1227383017539978
[2m[36m(func pid=114490)[0m rmse_per_class: [0.1, 0.279, 0.053, 0.379, 0.056, 0.194, 0.426, 0.147, 0.147, 0.093]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:39:54 (running for 00:15:51.10)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.295 |  0.138 |                   82 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.141 |                   63 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.474 |  0.179 |                   13 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.68  |  0.187 |                   12 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17947237193584442
[2m[36m(func pid=114403)[0m mae:  0.13066446781158447
[2m[36m(func pid=114403)[0m rmse_per_class: [0.11, 0.271, 0.098, 0.33, 0.097, 0.194, 0.292, 0.142, 0.143, 0.119]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2421 | Steps: 4 | Val loss: 0.3343 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2642 | Steps: 4 | Val loss: 0.2569 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.6920 | Steps: 4 | Val loss: 0.5430 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4481 | Steps: 4 | Val loss: 0.3404 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=101872)[0m rmse: 0.1708957701921463
[2m[36m(func pid=101872)[0m mae:  0.10356155782938004
[2m[36m(func pid=101872)[0m rmse_per_class: [0.077, 0.242, 0.037, 0.34, 0.068, 0.204, 0.246, 0.122, 0.178, 0.195]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13587616384029388
[2m[36m(func pid=97213)[0m mae:  0.08915090560913086
[2m[36m(func pid=97213)[0m rmse_per_class: [0.059, 0.21, 0.029, 0.257, 0.056, 0.163, 0.223, 0.113, 0.149, 0.099]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1898857206106186
[2m[36m(func pid=114490)[0m mae:  0.12324933707714081
[2m[36m(func pid=114490)[0m rmse_per_class: [0.099, 0.279, 0.05, 0.381, 0.056, 0.194, 0.455, 0.149, 0.143, 0.094]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:39:59 (running for 00:15:56.40)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.264 |  0.136 |                   83 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.242 |  0.171 |                   64 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.448 |  0.179 |                   14 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.692 |  0.19  |                   13 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17905305325984955
[2m[36m(func pid=114403)[0m mae:  0.13025496900081635
[2m[36m(func pid=114403)[0m rmse_per_class: [0.111, 0.271, 0.099, 0.331, 0.094, 0.194, 0.289, 0.14, 0.145, 0.117]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2743 | Steps: 4 | Val loss: 0.2998 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2683 | Steps: 4 | Val loss: 0.2586 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7226 | Steps: 4 | Val loss: 0.5474 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4340 | Steps: 4 | Val loss: 0.3323 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=101872)[0m rmse: 0.1568981260061264
[2m[36m(func pid=101872)[0m mae:  0.09504126012325287
[2m[36m(func pid=101872)[0m rmse_per_class: [0.072, 0.229, 0.033, 0.308, 0.069, 0.203, 0.236, 0.118, 0.178, 0.123]
[2m[36m(func pid=101872)[0m 
== Status ==
Current time: 2024-01-07 16:40:04 (running for 00:16:01.41)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.268 |  0.137 |                   84 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.274 |  0.157 |                   65 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.448 |  0.179 |                   14 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.692 |  0.19  |                   13 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=97213)[0m rmse: 0.1370265781879425
[2m[36m(func pid=97213)[0m mae:  0.09015828371047974
[2m[36m(func pid=97213)[0m rmse_per_class: [0.061, 0.211, 0.028, 0.257, 0.057, 0.161, 0.228, 0.114, 0.161, 0.092]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.17874355614185333
[2m[36m(func pid=114403)[0m mae:  0.12989605963230133
[2m[36m(func pid=114403)[0m rmse_per_class: [0.111, 0.271, 0.099, 0.334, 0.092, 0.194, 0.285, 0.138, 0.147, 0.117]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.19210933148860931
[2m[36m(func pid=114490)[0m mae:  0.12372110038995743
[2m[36m(func pid=114490)[0m rmse_per_class: [0.098, 0.28, 0.049, 0.383, 0.056, 0.192, 0.481, 0.15, 0.139, 0.094]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2692 | Steps: 4 | Val loss: 0.2762 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2825 | Steps: 4 | Val loss: 0.2590 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.4244 | Steps: 4 | Val loss: 0.3272 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.7257 | Steps: 4 | Val loss: 0.5506 | Batch size: 32 | lr: 0.001 | Duration: 3.15s
[2m[36m(func pid=101872)[0m rmse: 0.14351747930049896
[2m[36m(func pid=101872)[0m mae:  0.08597198128700256
[2m[36m(func pid=101872)[0m rmse_per_class: [0.068, 0.236, 0.028, 0.242, 0.067, 0.175, 0.212, 0.117, 0.174, 0.116]
[2m[36m(func pid=101872)[0m 
== Status ==
Current time: 2024-01-07 16:40:09 (running for 00:16:06.71)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.268 |  0.137 |                   84 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.144 |                   66 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.424 |  0.178 |                   16 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.723 |  0.192 |                   14 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.1782563328742981
[2m[36m(func pid=114403)[0m mae:  0.12943439185619354
[2m[36m(func pid=114403)[0m rmse_per_class: [0.11, 0.271, 0.098, 0.335, 0.088, 0.195, 0.282, 0.138, 0.148, 0.118]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13800394535064697
[2m[36m(func pid=97213)[0m mae:  0.09052059054374695
[2m[36m(func pid=97213)[0m rmse_per_class: [0.073, 0.211, 0.029, 0.255, 0.056, 0.161, 0.227, 0.115, 0.161, 0.094]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1943512111902237
[2m[36m(func pid=114490)[0m mae:  0.12438857555389404
[2m[36m(func pid=114490)[0m rmse_per_class: [0.097, 0.28, 0.048, 0.384, 0.056, 0.191, 0.505, 0.152, 0.136, 0.095]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2523 | Steps: 4 | Val loss: 0.2792 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4198 | Steps: 4 | Val loss: 0.3249 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2869 | Steps: 4 | Val loss: 0.2558 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.7131 | Steps: 4 | Val loss: 0.5396 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=101872)[0m rmse: 0.14813756942749023
[2m[36m(func pid=101872)[0m mae:  0.08906678855419159
[2m[36m(func pid=101872)[0m rmse_per_class: [0.06, 0.211, 0.049, 0.266, 0.066, 0.21, 0.243, 0.126, 0.132, 0.119]
[2m[36m(func pid=101872)[0m 
== Status ==
Current time: 2024-01-07 16:40:14 (running for 00:16:11.88)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.283 |  0.138 |                   85 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.252 |  0.148 |                   67 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.42  |  0.178 |                   17 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.726 |  0.194 |                   15 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.1775939166545868
[2m[36m(func pid=114403)[0m mae:  0.12877820432186127
[2m[36m(func pid=114403)[0m rmse_per_class: [0.109, 0.272, 0.099, 0.336, 0.085, 0.194, 0.279, 0.137, 0.15, 0.116]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13597646355628967
[2m[36m(func pid=97213)[0m mae:  0.08844416588544846
[2m[36m(func pid=97213)[0m rmse_per_class: [0.07, 0.213, 0.028, 0.252, 0.058, 0.16, 0.216, 0.117, 0.14, 0.106]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1949448585510254
[2m[36m(func pid=114490)[0m mae:  0.12443011999130249
[2m[36m(func pid=114490)[0m rmse_per_class: [0.096, 0.278, 0.048, 0.385, 0.056, 0.191, 0.513, 0.152, 0.135, 0.095]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2597 | Steps: 4 | Val loss: 0.2720 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4290 | Steps: 4 | Val loss: 0.3260 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2896 | Steps: 4 | Val loss: 0.2553 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.7347 | Steps: 4 | Val loss: 0.5233 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
== Status ==
Current time: 2024-01-07 16:40:20 (running for 00:16:17.13)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.287 |  0.136 |                   86 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.252 |  0.148 |                   67 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.429 |  0.177 |                   18 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.713 |  0.195 |                   16 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17741024494171143
[2m[36m(func pid=114403)[0m mae:  0.1283700168132782
[2m[36m(func pid=114403)[0m rmse_per_class: [0.11, 0.272, 0.1, 0.339, 0.084, 0.194, 0.276, 0.136, 0.151, 0.112]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.140142560005188
[2m[36m(func pid=101872)[0m mae:  0.08292891085147858
[2m[36m(func pid=101872)[0m rmse_per_class: [0.079, 0.214, 0.031, 0.264, 0.071, 0.173, 0.21, 0.109, 0.133, 0.118]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13524144887924194
[2m[36m(func pid=97213)[0m mae:  0.08750731498003006
[2m[36m(func pid=97213)[0m rmse_per_class: [0.062, 0.216, 0.032, 0.253, 0.057, 0.16, 0.21, 0.115, 0.133, 0.114]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.19503796100616455
[2m[36m(func pid=114490)[0m mae:  0.12418731302022934
[2m[36m(func pid=114490)[0m rmse_per_class: [0.095, 0.277, 0.048, 0.385, 0.056, 0.19, 0.517, 0.153, 0.134, 0.095]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.4257 | Steps: 4 | Val loss: 0.3281 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2710 | Steps: 4 | Val loss: 0.2829 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2525 | Steps: 4 | Val loss: 0.2544 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.6936 | Steps: 4 | Val loss: 0.5148 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 16:40:25 (running for 00:16:22.41)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.29  |  0.135 |                   87 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.26  |  0.14  |                   68 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.426 |  0.177 |                   19 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.735 |  0.195 |                   17 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17687876522541046
[2m[36m(func pid=114403)[0m mae:  0.12775392830371857
[2m[36m(func pid=114403)[0m rmse_per_class: [0.111, 0.273, 0.101, 0.339, 0.081, 0.194, 0.275, 0.136, 0.151, 0.109]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.1496948003768921
[2m[36m(func pid=101872)[0m mae:  0.09073923528194427
[2m[36m(func pid=101872)[0m rmse_per_class: [0.068, 0.239, 0.029, 0.254, 0.061, 0.169, 0.218, 0.124, 0.206, 0.13]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13432669639587402
[2m[36m(func pid=97213)[0m mae:  0.08692824840545654
[2m[36m(func pid=97213)[0m rmse_per_class: [0.066, 0.215, 0.031, 0.25, 0.059, 0.161, 0.21, 0.113, 0.136, 0.103]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.19513212144374847
[2m[36m(func pid=114490)[0m mae:  0.12398721277713776
[2m[36m(func pid=114490)[0m rmse_per_class: [0.094, 0.276, 0.048, 0.386, 0.056, 0.19, 0.519, 0.153, 0.133, 0.096]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4280 | Steps: 4 | Val loss: 0.3326 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2638 | Steps: 4 | Val loss: 0.2841 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2752 | Steps: 4 | Val loss: 0.2574 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.6679 | Steps: 4 | Val loss: 0.4984 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 16:40:30 (running for 00:16:27.73)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.252 |  0.134 |                   88 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.271 |  0.15  |                   69 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.428 |  0.177 |                   20 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.694 |  0.195 |                   18 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17689913511276245
[2m[36m(func pid=114403)[0m mae:  0.12752196192741394
[2m[36m(func pid=114403)[0m rmse_per_class: [0.111, 0.273, 0.102, 0.342, 0.078, 0.194, 0.275, 0.136, 0.151, 0.108]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.15209203958511353
[2m[36m(func pid=101872)[0m mae:  0.09281589090824127
[2m[36m(func pid=101872)[0m rmse_per_class: [0.062, 0.221, 0.026, 0.254, 0.067, 0.18, 0.244, 0.16, 0.209, 0.098]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13696715235710144
[2m[36m(func pid=97213)[0m mae:  0.08900896459817886
[2m[36m(func pid=97213)[0m rmse_per_class: [0.063, 0.216, 0.032, 0.253, 0.056, 0.16, 0.216, 0.113, 0.145, 0.115]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1939244568347931
[2m[36m(func pid=114490)[0m mae:  0.12310465425252914
[2m[36m(func pid=114490)[0m rmse_per_class: [0.092, 0.274, 0.049, 0.387, 0.056, 0.192, 0.508, 0.154, 0.133, 0.096]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4315 | Steps: 4 | Val loss: 0.3382 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2815 | Steps: 4 | Val loss: 0.2925 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2783 | Steps: 4 | Val loss: 0.2568 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.6372 | Steps: 4 | Val loss: 0.4758 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 16:40:35 (running for 00:16:32.87)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.275 |  0.137 |                   89 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.264 |  0.152 |                   70 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.431 |  0.177 |                   21 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.668 |  0.194 |                   19 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17676527798175812
[2m[36m(func pid=114403)[0m mae:  0.12721773982048035
[2m[36m(func pid=114403)[0m rmse_per_class: [0.111, 0.273, 0.102, 0.343, 0.077, 0.195, 0.274, 0.135, 0.151, 0.107]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.15106850862503052
[2m[36m(func pid=101872)[0m mae:  0.09138916432857513
[2m[36m(func pid=101872)[0m rmse_per_class: [0.073, 0.247, 0.03, 0.266, 0.073, 0.178, 0.237, 0.112, 0.181, 0.114]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13663449883460999
[2m[36m(func pid=97213)[0m mae:  0.08897252380847931
[2m[36m(func pid=97213)[0m rmse_per_class: [0.06, 0.216, 0.034, 0.253, 0.053, 0.16, 0.217, 0.116, 0.146, 0.112]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.19133445620536804
[2m[36m(func pid=114490)[0m mae:  0.1215779036283493
[2m[36m(func pid=114490)[0m rmse_per_class: [0.09, 0.27, 0.049, 0.387, 0.056, 0.197, 0.483, 0.154, 0.132, 0.096]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4412 | Steps: 4 | Val loss: 0.3459 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2541 | Steps: 4 | Val loss: 0.2925 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2733 | Steps: 4 | Val loss: 0.2537 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.6294 | Steps: 4 | Val loss: 0.4511 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 16:40:40 (running for 00:16:38.07)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.278 |  0.137 |                   90 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.282 |  0.151 |                   71 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.441 |  0.177 |                   22 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.637 |  0.191 |                   20 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17721478641033173
[2m[36m(func pid=114403)[0m mae:  0.12717363238334656
[2m[36m(func pid=114403)[0m rmse_per_class: [0.111, 0.274, 0.106, 0.347, 0.075, 0.194, 0.273, 0.135, 0.152, 0.106]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.15356996655464172
[2m[36m(func pid=101872)[0m mae:  0.0923594981431961
[2m[36m(func pid=101872)[0m rmse_per_class: [0.087, 0.226, 0.087, 0.313, 0.055, 0.169, 0.234, 0.107, 0.137, 0.121]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13424071669578552
[2m[36m(func pid=97213)[0m mae:  0.08737234771251678
[2m[36m(func pid=97213)[0m rmse_per_class: [0.058, 0.214, 0.035, 0.245, 0.053, 0.161, 0.216, 0.114, 0.14, 0.105]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.18631039559841156
[2m[36m(func pid=114490)[0m mae:  0.11893178522586823
[2m[36m(func pid=114490)[0m rmse_per_class: [0.088, 0.262, 0.049, 0.387, 0.056, 0.203, 0.437, 0.154, 0.132, 0.096]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4478 | Steps: 4 | Val loss: 0.3480 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2800 | Steps: 4 | Val loss: 0.2884 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2985 | Steps: 4 | Val loss: 0.2504 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.5985 | Steps: 4 | Val loss: 0.4254 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 16:40:46 (running for 00:16:43.35)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.273 |  0.134 |                   91 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.254 |  0.154 |                   72 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.448 |  0.176 |                   23 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.629 |  0.186 |                   21 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17599673569202423
[2m[36m(func pid=114403)[0m mae:  0.12600593268871307
[2m[36m(func pid=114403)[0m rmse_per_class: [0.113, 0.273, 0.099, 0.346, 0.073, 0.194, 0.271, 0.135, 0.152, 0.104]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=101872)[0m rmse: 0.15320512652397156
[2m[36m(func pid=101872)[0m mae:  0.09234367311000824
[2m[36m(func pid=101872)[0m rmse_per_class: [0.06, 0.216, 0.043, 0.257, 0.061, 0.2, 0.264, 0.181, 0.141, 0.111]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.1315421462059021
[2m[36m(func pid=97213)[0m mae:  0.08523952960968018
[2m[36m(func pid=97213)[0m rmse_per_class: [0.058, 0.211, 0.034, 0.237, 0.056, 0.16, 0.214, 0.118, 0.133, 0.095]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.18096961081027985
[2m[36m(func pid=114490)[0m mae:  0.11649118363857269
[2m[36m(func pid=114490)[0m rmse_per_class: [0.089, 0.254, 0.049, 0.386, 0.056, 0.22, 0.375, 0.153, 0.132, 0.096]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4512 | Steps: 4 | Val loss: 0.3568 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2849 | Steps: 4 | Val loss: 0.2733 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 16:40:51 (running for 00:16:48.51)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.298 |  0.132 |                   92 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.28  |  0.153 |                   73 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.451 |  0.175 |                   24 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.599 |  0.181 |                   22 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.1753099262714386
[2m[36m(func pid=114403)[0m mae:  0.1249675378203392
[2m[36m(func pid=114403)[0m rmse_per_class: [0.112, 0.273, 0.095, 0.346, 0.07, 0.194, 0.271, 0.136, 0.152, 0.103]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.5739 | Steps: 4 | Val loss: 0.4071 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2793 | Steps: 4 | Val loss: 0.2509 | Batch size: 32 | lr: 0.01 | Duration: 3.14s
[2m[36m(func pid=101872)[0m rmse: 0.14080019295215607
[2m[36m(func pid=101872)[0m mae:  0.08403138816356659
[2m[36m(func pid=101872)[0m rmse_per_class: [0.06, 0.218, 0.031, 0.251, 0.077, 0.179, 0.213, 0.112, 0.155, 0.112]
[2m[36m(func pid=101872)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13086944818496704
[2m[36m(func pid=97213)[0m mae:  0.08544065058231354
[2m[36m(func pid=97213)[0m rmse_per_class: [0.059, 0.206, 0.029, 0.247, 0.057, 0.16, 0.218, 0.114, 0.127, 0.091]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4663 | Steps: 4 | Val loss: 0.3594 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=114490)[0m rmse: 0.17550049722194672
[2m[36m(func pid=114490)[0m mae:  0.11446865648031235
[2m[36m(func pid=114490)[0m rmse_per_class: [0.098, 0.244, 0.049, 0.386, 0.056, 0.231, 0.308, 0.153, 0.133, 0.095]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=101872)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2692 | Steps: 4 | Val loss: 0.3164 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 16:40:56 (running for 00:16:53.88)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=6
Bracket: Iter 75.000: -0.1459999978542328
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (14 PENDING, 4 RUNNING, 6 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.279 |  0.131 |                   93 |
| train_c9cb4_00007 | RUNNING    | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.285 |  0.141 |                   74 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.466 |  0.175 |                   25 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.574 |  0.176 |                   23 |
| train_c9cb4_00010 | PENDING    |                     | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.1754319816827774
[2m[36m(func pid=114403)[0m mae:  0.12500467896461487
[2m[36m(func pid=114403)[0m rmse_per_class: [0.112, 0.272, 0.096, 0.348, 0.068, 0.194, 0.273, 0.136, 0.151, 0.103]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2776 | Steps: 4 | Val loss: 0.2513 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.5779 | Steps: 4 | Val loss: 0.3909 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=101872)[0m rmse: 0.15963253378868103
[2m[36m(func pid=101872)[0m mae:  0.09742482006549835
[2m[36m(func pid=101872)[0m rmse_per_class: [0.092, 0.231, 0.031, 0.35, 0.064, 0.19, 0.226, 0.107, 0.151, 0.153]
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4802 | Steps: 4 | Val loss: 0.3663 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=97213)[0m rmse: 0.13141676783561707
[2m[36m(func pid=97213)[0m mae:  0.0856282189488411
[2m[36m(func pid=97213)[0m rmse_per_class: [0.061, 0.206, 0.03, 0.246, 0.058, 0.16, 0.217, 0.115, 0.13, 0.09]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1725817620754242
[2m[36m(func pid=114490)[0m mae:  0.1144302636384964
[2m[36m(func pid=114490)[0m rmse_per_class: [0.115, 0.239, 0.049, 0.385, 0.056, 0.244, 0.253, 0.153, 0.136, 0.095]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.17563462257385254
[2m[36m(func pid=114403)[0m mae:  0.12475863844156265
[2m[36m(func pid=114403)[0m rmse_per_class: [0.114, 0.272, 0.096, 0.349, 0.067, 0.194, 0.274, 0.137, 0.151, 0.102]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2737 | Steps: 4 | Val loss: 0.2552 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.5506 | Steps: 4 | Val loss: 0.3769 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4722 | Steps: 4 | Val loss: 0.3731 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=97213)[0m rmse: 0.13476628065109253
[2m[36m(func pid=97213)[0m mae:  0.08786611258983612
[2m[36m(func pid=97213)[0m rmse_per_class: [0.076, 0.209, 0.031, 0.255, 0.057, 0.161, 0.218, 0.112, 0.136, 0.092]
[2m[36m(func pid=114490)[0m rmse: 0.17121359705924988
[2m[36m(func pid=114490)[0m mae:  0.1152133122086525
[2m[36m(func pid=114490)[0m rmse_per_class: [0.131, 0.236, 0.049, 0.384, 0.056, 0.246, 0.224, 0.152, 0.139, 0.095]
[2m[36m(func pid=114403)[0m rmse: 0.17538738250732422
[2m[36m(func pid=114403)[0m mae:  0.12409897893667221
[2m[36m(func pid=114403)[0m rmse_per_class: [0.113, 0.272, 0.094, 0.35, 0.066, 0.193, 0.276, 0.137, 0.152, 0.101]
== Status ==
Current time: 2024-01-07 16:41:02 (running for 00:16:59.23)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.278 |  0.131 |                   94 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.48  |  0.176 |                   26 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.578 |  0.173 |                   24 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


== Status ==
Current time: 2024-01-07 16:41:07 (running for 00:17:04.79)
Memory usage on this node: 23.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.278 |  0.131 |                   94 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.472 |  0.175 |                   27 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.578 |  0.173 |                   24 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=120822)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=120822)[0m Configuration completed!
[2m[36m(func pid=120822)[0m New optimizer parameters:
[2m[36m(func pid=120822)[0m SGD (
[2m[36m(func pid=120822)[0m Parameter Group 0
[2m[36m(func pid=120822)[0m     dampening: 0
[2m[36m(func pid=120822)[0m     differentiable: False
[2m[36m(func pid=120822)[0m     foreach: None
[2m[36m(func pid=120822)[0m     lr: 0.01
[2m[36m(func pid=120822)[0m     maximize: False
[2m[36m(func pid=120822)[0m     momentum: 0.99
[2m[36m(func pid=120822)[0m     nesterov: False
[2m[36m(func pid=120822)[0m     weight_decay: 0.0001
[2m[36m(func pid=120822)[0m )
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4857 | Steps: 4 | Val loss: 0.3807 | Batch size: 32 | lr: 0.0001 | Duration: 3.13s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2772 | Steps: 4 | Val loss: 0.2591 | Batch size: 32 | lr: 0.01 | Duration: 3.22s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.5397 | Steps: 4 | Val loss: 0.3663 | Batch size: 32 | lr: 0.001 | Duration: 3.29s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8667 | Steps: 4 | Val loss: 0.4199 | Batch size: 32 | lr: 0.01 | Duration: 4.69s
== Status ==
Current time: 2024-01-07 16:41:12 (running for 00:17:09.81)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.274 |  0.135 |                   95 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.472 |  0.175 |                   27 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.551 |  0.171 |                   25 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17563846707344055
[2m[36m(func pid=114403)[0m mae:  0.12387952953577042
[2m[36m(func pid=114403)[0m rmse_per_class: [0.113, 0.273, 0.093, 0.351, 0.065, 0.194, 0.278, 0.138, 0.151, 0.1]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.17191581428050995
[2m[36m(func pid=114490)[0m mae:  0.11694417148828506
[2m[36m(func pid=114490)[0m rmse_per_class: [0.146, 0.24, 0.049, 0.381, 0.056, 0.236, 0.22, 0.151, 0.146, 0.094]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13837461173534393
[2m[36m(func pid=97213)[0m mae:  0.08975062519311905
[2m[36m(func pid=97213)[0m rmse_per_class: [0.079, 0.217, 0.031, 0.259, 0.058, 0.162, 0.216, 0.11, 0.137, 0.116]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=120822)[0m rmse: 0.17699643969535828
[2m[36m(func pid=120822)[0m mae:  0.12915363907814026
[2m[36m(func pid=120822)[0m rmse_per_class: [0.104, 0.27, 0.09, 0.327, 0.091, 0.192, 0.291, 0.152, 0.14, 0.112]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4892 | Steps: 4 | Val loss: 0.3829 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2601 | Steps: 4 | Val loss: 0.2584 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.5260 | Steps: 4 | Val loss: 0.3572 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.4588 | Steps: 4 | Val loss: 0.3442 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=114403)[0m rmse: 0.17543619871139526
[2m[36m(func pid=114403)[0m mae:  0.12350640445947647
[2m[36m(func pid=114403)[0m rmse_per_class: [0.114, 0.273, 0.091, 0.352, 0.064, 0.193, 0.282, 0.138, 0.149, 0.1]
[2m[36m(func pid=114403)[0m 
== Status ==
Current time: 2024-01-07 16:41:18 (running for 00:17:15.64)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.277 |  0.138 |                   96 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.489 |  0.175 |                   29 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.54  |  0.172 |                   26 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.867 |  0.177 |                    1 |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=97213)[0m rmse: 0.13752475380897522
[2m[36m(func pid=97213)[0m mae:  0.08887003362178802
[2m[36m(func pid=97213)[0m rmse_per_class: [0.063, 0.219, 0.028, 0.256, 0.058, 0.163, 0.214, 0.112, 0.137, 0.125]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1722988784313202
[2m[36m(func pid=114490)[0m mae:  0.11791206896305084
[2m[36m(func pid=114490)[0m rmse_per_class: [0.146, 0.246, 0.049, 0.375, 0.056, 0.227, 0.23, 0.149, 0.153, 0.093]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m rmse: 0.1748296469449997
[2m[36m(func pid=120822)[0m mae:  0.122891366481781
[2m[36m(func pid=120822)[0m rmse_per_class: [0.104, 0.278, 0.09, 0.345, 0.067, 0.192, 0.301, 0.132, 0.144, 0.095]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4941 | Steps: 4 | Val loss: 0.3877 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2691 | Steps: 4 | Val loss: 0.2582 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.5088 | Steps: 4 | Val loss: 0.3513 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.5827 | Steps: 4 | Val loss: 0.4713 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 16:41:23 (running for 00:17:20.88)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.26  |  0.138 |                   97 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.494 |  0.175 |                   30 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.526 |  0.172 |                   27 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.459 |  0.175 |                    2 |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17535214126110077
[2m[36m(func pid=114403)[0m mae:  0.12318406254053116
[2m[36m(func pid=114403)[0m rmse_per_class: [0.115, 0.273, 0.091, 0.351, 0.064, 0.193, 0.28, 0.138, 0.15, 0.099]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13736005127429962
[2m[36m(func pid=97213)[0m mae:  0.08888402581214905
[2m[36m(func pid=97213)[0m rmse_per_class: [0.059, 0.22, 0.029, 0.254, 0.061, 0.163, 0.21, 0.11, 0.147, 0.12]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1736607402563095
[2m[36m(func pid=114490)[0m mae:  0.11963032186031342
[2m[36m(func pid=114490)[0m rmse_per_class: [0.148, 0.25, 0.048, 0.365, 0.056, 0.213, 0.247, 0.147, 0.17, 0.092]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m rmse: 0.18989935517311096
[2m[36m(func pid=120822)[0m mae:  0.12425078451633453
[2m[36m(func pid=120822)[0m rmse_per_class: [0.101, 0.285, 0.061, 0.367, 0.056, 0.194, 0.462, 0.142, 0.138, 0.093]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.5078 | Steps: 4 | Val loss: 0.3909 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2613 | Steps: 4 | Val loss: 0.2560 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4897 | Steps: 4 | Val loss: 0.3405 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.7701 | Steps: 4 | Val loss: 0.5763 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 16:41:28 (running for 00:17:25.98)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.269 |  0.137 |                   98 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.508 |  0.175 |                   31 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.509 |  0.174 |                   28 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.583 |  0.19  |                    3 |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17536647617816925
[2m[36m(func pid=114403)[0m mae:  0.12305402755737305
[2m[36m(func pid=114403)[0m rmse_per_class: [0.116, 0.273, 0.091, 0.351, 0.062, 0.193, 0.28, 0.139, 0.15, 0.098]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.13551701605319977
[2m[36m(func pid=97213)[0m mae:  0.0875655859708786
[2m[36m(func pid=97213)[0m rmse_per_class: [0.057, 0.217, 0.031, 0.252, 0.063, 0.162, 0.207, 0.11, 0.15, 0.106]
[2m[36m(func pid=97213)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1724230945110321
[2m[36m(func pid=114490)[0m mae:  0.11914511770009995
[2m[36m(func pid=114490)[0m rmse_per_class: [0.149, 0.248, 0.048, 0.346, 0.056, 0.195, 0.261, 0.145, 0.186, 0.09]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m rmse: 0.20458197593688965
[2m[36m(func pid=120822)[0m mae:  0.13035151362419128
[2m[36m(func pid=120822)[0m rmse_per_class: [0.1, 0.291, 0.049, 0.377, 0.056, 0.203, 0.591, 0.151, 0.134, 0.095]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.5006 | Steps: 4 | Val loss: 0.3903 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=97213)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2799 | Steps: 4 | Val loss: 0.2559 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4695 | Steps: 4 | Val loss: 0.3248 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.8527 | Steps: 4 | Val loss: 0.6308 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 16:41:34 (running for 00:17:31.20)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=7
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (13 PENDING, 4 RUNNING, 7 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00006 | RUNNING    | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.261 |  0.136 |                   99 |
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.501 |  0.175 |                   32 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.49  |  0.172 |                   29 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.77  |  0.205 |                    4 |
| train_c9cb4_00011 | PENDING    |                     | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.1746349036693573
[2m[36m(func pid=114403)[0m mae:  0.12235905975103378
[2m[36m(func pid=114403)[0m rmse_per_class: [0.113, 0.273, 0.089, 0.35, 0.062, 0.193, 0.279, 0.139, 0.149, 0.098]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=97213)[0m rmse: 0.1354255974292755
[2m[36m(func pid=97213)[0m mae:  0.0876583382487297
[2m[36m(func pid=97213)[0m rmse_per_class: [0.057, 0.214, 0.032, 0.252, 0.061, 0.16, 0.209, 0.11, 0.153, 0.106]
[2m[36m(func pid=114490)[0m rmse: 0.16732685267925262
[2m[36m(func pid=114490)[0m mae:  0.11604849249124527
[2m[36m(func pid=114490)[0m rmse_per_class: [0.133, 0.244, 0.048, 0.318, 0.056, 0.182, 0.27, 0.14, 0.193, 0.089]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m rmse: 0.21319332718849182
[2m[36m(func pid=120822)[0m mae:  0.13595324754714966
[2m[36m(func pid=120822)[0m rmse_per_class: [0.098, 0.294, 0.048, 0.383, 0.056, 0.213, 0.655, 0.155, 0.134, 0.096]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.5104 | Steps: 4 | Val loss: 0.3987 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4242 | Steps: 4 | Val loss: 0.3086 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.8486 | Steps: 4 | Val loss: 0.6129 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=114403)[0m rmse: 0.17503392696380615
[2m[36m(func pid=114403)[0m mae:  0.12219206988811493
[2m[36m(func pid=114403)[0m rmse_per_class: [0.112, 0.272, 0.09, 0.352, 0.061, 0.193, 0.284, 0.14, 0.149, 0.098]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m rmse: 0.21396227180957794
[2m[36m(func pid=120822)[0m mae:  0.1369587928056717
[2m[36m(func pid=120822)[0m rmse_per_class: [0.109, 0.295, 0.049, 0.386, 0.056, 0.217, 0.641, 0.156, 0.134, 0.097]
[2m[36m(func pid=114490)[0m rmse: 0.16052326560020447
[2m[36m(func pid=114490)[0m mae:  0.11145766079425812
[2m[36m(func pid=114490)[0m rmse_per_class: [0.111, 0.235, 0.047, 0.284, 0.056, 0.176, 0.276, 0.133, 0.193, 0.094]
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.5215 | Steps: 4 | Val loss: 0.3985 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 16:41:39 (running for 00:17:36.33)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.51  |  0.175 |                   33 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.469 |  0.167 |                   30 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.853 |  0.213 |                    5 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=122557)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=122557)[0m Configuration completed!
[2m[36m(func pid=122557)[0m New optimizer parameters:
[2m[36m(func pid=122557)[0m SGD (
[2m[36m(func pid=122557)[0m Parameter Group 0
[2m[36m(func pid=122557)[0m     dampening: 0
[2m[36m(func pid=122557)[0m     differentiable: False
[2m[36m(func pid=122557)[0m     foreach: None
[2m[36m(func pid=122557)[0m     lr: 0.1
[2m[36m(func pid=122557)[0m     maximize: False
[2m[36m(func pid=122557)[0m     momentum: 0.99
[2m[36m(func pid=122557)[0m     nesterov: False
[2m[36m(func pid=122557)[0m     weight_decay: 0.0001
[2m[36m(func pid=122557)[0m )
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:41:44 (running for 00:17:41.72)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.521 |  0.175 |                   34 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.424 |  0.161 |                   31 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.849 |  0.214 |                    6 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.1746423989534378
[2m[36m(func pid=114403)[0m mae:  0.12170518934726715
[2m[36m(func pid=114403)[0m rmse_per_class: [0.113, 0.271, 0.083, 0.353, 0.06, 0.193, 0.287, 0.14, 0.15, 0.096]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.8480 | Steps: 4 | Val loss: 0.5392 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3946 | Steps: 4 | Val loss: 0.2997 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.5087 | Steps: 4 | Val loss: 0.4022 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.6852 | Steps: 4 | Val loss: 0.5045 | Batch size: 32 | lr: 0.1 | Duration: 4.51s
[2m[36m(func pid=120822)[0m rmse: 0.21192076802253723
[2m[36m(func pid=120822)[0m mae:  0.13465242087841034
[2m[36m(func pid=120822)[0m rmse_per_class: [0.216, 0.294, 0.049, 0.386, 0.056, 0.214, 0.519, 0.156, 0.132, 0.097]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.15575899183750153
[2m[36m(func pid=114490)[0m mae:  0.10814156383275986
[2m[36m(func pid=114490)[0m rmse_per_class: [0.09, 0.233, 0.046, 0.263, 0.056, 0.173, 0.28, 0.122, 0.181, 0.115]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:41:49 (running for 00:17:46.98)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.509 |  0.175 |                   35 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.395 |  0.156 |                   32 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.848 |  0.212 |                    7 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |        |        |                      |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.1747083067893982
[2m[36m(func pid=114403)[0m mae:  0.12144257873296738
[2m[36m(func pid=114403)[0m rmse_per_class: [0.112, 0.272, 0.081, 0.352, 0.06, 0.193, 0.29, 0.141, 0.151, 0.096]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.19750650227069855
[2m[36m(func pid=122557)[0m mae:  0.12790308892726898
[2m[36m(func pid=122557)[0m rmse_per_class: [0.099, 0.289, 0.058, 0.379, 0.056, 0.189, 0.524, 0.148, 0.138, 0.095]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.7567 | Steps: 4 | Val loss: 0.4559 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3938 | Steps: 4 | Val loss: 0.3032 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.5221 | Steps: 4 | Val loss: 0.4000 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.9985 | Steps: 4 | Val loss: 0.6737 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=120822)[0m rmse: 0.20109422504901886
[2m[36m(func pid=120822)[0m mae:  0.1287984549999237
[2m[36m(func pid=120822)[0m rmse_per_class: [0.329, 0.284, 0.049, 0.382, 0.056, 0.192, 0.335, 0.156, 0.131, 0.097]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.15620121359825134
[2m[36m(func pid=114490)[0m mae:  0.107454814016819
[2m[36m(func pid=114490)[0m rmse_per_class: [0.075, 0.242, 0.044, 0.263, 0.056, 0.177, 0.285, 0.113, 0.165, 0.142]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:41:55 (running for 00:17:52.28)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.522 |  0.175 |                   36 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.394 |  0.156 |                   33 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.757 |  0.201 |                    8 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.685 |  0.198 |                    1 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17452675104141235
[2m[36m(func pid=114403)[0m mae:  0.12141189724206924
[2m[36m(func pid=114403)[0m rmse_per_class: [0.111, 0.272, 0.082, 0.352, 0.059, 0.194, 0.289, 0.141, 0.151, 0.096]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.22374972701072693
[2m[36m(func pid=122557)[0m mae:  0.14322224259376526
[2m[36m(func pid=122557)[0m rmse_per_class: [0.11, 0.301, 0.049, 0.389, 0.056, 0.202, 0.742, 0.156, 0.135, 0.097]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.6461 | Steps: 4 | Val loss: 0.3838 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4343 | Steps: 4 | Val loss: 0.3152 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.5261 | Steps: 4 | Val loss: 0.4032 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.9496 | Steps: 4 | Val loss: 0.5418 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=120822)[0m rmse: 0.17755994200706482
[2m[36m(func pid=120822)[0m mae:  0.12015055119991302
[2m[36m(func pid=120822)[0m rmse_per_class: [0.211, 0.24, 0.049, 0.362, 0.056, 0.189, 0.216, 0.156, 0.2, 0.095]
[2m[36m(func pid=120822)[0m 
== Status ==
Current time: 2024-01-07 16:42:00 (running for 00:17:57.33)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.522 |  0.175 |                   36 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.434 |  0.161 |                   34 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.646 |  0.178 |                    9 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.999 |  0.224 |                    2 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114490)[0m rmse: 0.161194309592247
[2m[36m(func pid=114490)[0m mae:  0.1098422035574913
[2m[36m(func pid=114490)[0m rmse_per_class: [0.074, 0.254, 0.041, 0.271, 0.056, 0.186, 0.289, 0.114, 0.148, 0.179]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.17473922669887543
[2m[36m(func pid=114403)[0m mae:  0.12115643173456192
[2m[36m(func pid=114403)[0m rmse_per_class: [0.112, 0.271, 0.08, 0.353, 0.058, 0.193, 0.293, 0.141, 0.15, 0.095]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.2127843201160431
[2m[36m(func pid=122557)[0m mae:  0.14550453424453735
[2m[36m(func pid=122557)[0m rmse_per_class: [0.071, 0.263, 0.049, 0.385, 0.056, 0.385, 0.304, 0.156, 0.361, 0.097]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.5610 | Steps: 4 | Val loss: 0.3975 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4471 | Steps: 4 | Val loss: 0.3284 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.5267 | Steps: 4 | Val loss: 0.4026 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.7359 | Steps: 4 | Val loss: 0.3408 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=120822)[0m rmse: 0.1682240515947342
[2m[36m(func pid=120822)[0m mae:  0.11554793268442154
[2m[36m(func pid=120822)[0m rmse_per_class: [0.073, 0.244, 0.049, 0.299, 0.056, 0.215, 0.279, 0.155, 0.223, 0.089]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.17479176819324493
[2m[36m(func pid=114403)[0m mae:  0.1211124062538147
[2m[36m(func pid=114403)[0m rmse_per_class: [0.112, 0.271, 0.078, 0.354, 0.058, 0.193, 0.295, 0.141, 0.152, 0.095]
== Status ==
Current time: 2024-01-07 16:42:05 (running for 00:18:02.86)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.527 |  0.175 |                   38 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.434 |  0.161 |                   34 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.561 |  0.168 |                   10 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.95  |  0.213 |                    3 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.16694718599319458
[2m[36m(func pid=114490)[0m mae:  0.1130075678229332
[2m[36m(func pid=114490)[0m rmse_per_class: [0.079, 0.267, 0.039, 0.269, 0.056, 0.194, 0.289, 0.131, 0.135, 0.21]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.16163453459739685
[2m[36m(func pid=122557)[0m mae:  0.09945085644721985
[2m[36m(func pid=122557)[0m rmse_per_class: [0.068, 0.252, 0.042, 0.458, 0.053, 0.191, 0.214, 0.125, 0.131, 0.083]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.5406 | Steps: 4 | Val loss: 0.3708 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.5204 | Steps: 4 | Val loss: 0.4014 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4211 | Steps: 4 | Val loss: 0.3356 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.5816 | Steps: 4 | Val loss: 0.6602 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=120822)[0m rmse: 0.16073915362358093
[2m[36m(func pid=120822)[0m mae:  0.11095599830150604
[2m[36m(func pid=120822)[0m rmse_per_class: [0.089, 0.23, 0.049, 0.263, 0.056, 0.182, 0.305, 0.15, 0.16, 0.123]
[2m[36m(func pid=120822)[0m 
== Status ==
Current time: 2024-01-07 16:42:11 (running for 00:18:08.24)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.52  |  0.175 |                   39 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.447 |  0.167 |                   35 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.541 |  0.161 |                   11 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.736 |  0.162 |                    4 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17478039860725403
[2m[36m(func pid=114403)[0m mae:  0.1210303083062172
[2m[36m(func pid=114403)[0m rmse_per_class: [0.111, 0.271, 0.078, 0.354, 0.058, 0.193, 0.295, 0.142, 0.15, 0.095]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1717454195022583
[2m[36m(func pid=114490)[0m mae:  0.11566825211048126
[2m[36m(func pid=114490)[0m rmse_per_class: [0.083, 0.274, 0.039, 0.261, 0.056, 0.199, 0.288, 0.162, 0.13, 0.225]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.2141493558883667
[2m[36m(func pid=122557)[0m mae:  0.13489419221878052
[2m[36m(func pid=122557)[0m rmse_per_class: [0.11, 0.302, 0.135, 0.36, 0.179, 0.183, 0.242, 0.379, 0.131, 0.12]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4617 | Steps: 4 | Val loss: 0.3462 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.5279 | Steps: 4 | Val loss: 0.3940 | Batch size: 32 | lr: 0.0001 | Duration: 2.71s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.7589 | Steps: 4 | Val loss: 0.5851 | Batch size: 32 | lr: 0.1 | Duration: 2.71s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4393 | Steps: 4 | Val loss: 0.3394 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=120822)[0m rmse: 0.1775929033756256
[2m[36m(func pid=120822)[0m mae:  0.11670013517141342
[2m[36m(func pid=120822)[0m rmse_per_class: [0.094, 0.244, 0.044, 0.299, 0.056, 0.174, 0.306, 0.123, 0.126, 0.309]
[2m[36m(func pid=120822)[0m 
== Status ==
Current time: 2024-01-07 16:42:16 (running for 00:18:13.46)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.528 |  0.174 |                   40 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.421 |  0.172 |                   36 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.462 |  0.178 |                   12 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.582 |  0.214 |                    5 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17394889891147614
[2m[36m(func pid=114403)[0m mae:  0.12031664699316025
[2m[36m(func pid=114403)[0m rmse_per_class: [0.111, 0.27, 0.075, 0.353, 0.057, 0.193, 0.296, 0.141, 0.148, 0.096]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.22061339020729065
[2m[36m(func pid=122557)[0m mae:  0.13455744087696075
[2m[36m(func pid=122557)[0m rmse_per_class: [0.11, 0.302, 0.189, 0.334, 0.123, 0.26, 0.251, 0.126, 0.413, 0.097]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1761421412229538
[2m[36m(func pid=114490)[0m mae:  0.11792008578777313
[2m[36m(func pid=114490)[0m rmse_per_class: [0.087, 0.278, 0.046, 0.25, 0.056, 0.202, 0.282, 0.204, 0.128, 0.227]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4898 | Steps: 4 | Val loss: 0.3407 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.5361 | Steps: 4 | Val loss: 0.3957 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.6031 | Steps: 4 | Val loss: 0.3900 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4131 | Steps: 4 | Val loss: 0.3390 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=120822)[0m rmse: 0.1853296458721161
[2m[36m(func pid=120822)[0m mae:  0.11677265167236328
[2m[36m(func pid=120822)[0m rmse_per_class: [0.087, 0.278, 0.024, 0.253, 0.056, 0.192, 0.283, 0.185, 0.131, 0.363]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.17391976714134216
[2m[36m(func pid=114403)[0m mae:  0.12005609273910522
[2m[36m(func pid=114403)[0m rmse_per_class: [0.112, 0.269, 0.073, 0.353, 0.057, 0.192, 0.297, 0.142, 0.15, 0.095]
== Status ==
Current time: 2024-01-07 16:42:21 (running for 00:18:18.85)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.536 |  0.174 |                   41 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.439 |  0.176 |                   37 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.49  |  0.185 |                   13 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.759 |  0.221 |                    6 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.15907174348831177
[2m[36m(func pid=122557)[0m mae:  0.08985409885644913
[2m[36m(func pid=122557)[0m rmse_per_class: [0.072, 0.229, 0.041, 0.246, 0.05, 0.17, 0.341, 0.147, 0.197, 0.097]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.18057528138160706
[2m[36m(func pid=114490)[0m mae:  0.1198422759771347
[2m[36m(func pid=114490)[0m rmse_per_class: [0.088, 0.281, 0.068, 0.245, 0.056, 0.204, 0.277, 0.24, 0.128, 0.219]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4495 | Steps: 4 | Val loss: 0.4170 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.5261 | Steps: 4 | Val loss: 0.3957 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.6415 | Steps: 4 | Val loss: 0.4881 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4091 | Steps: 4 | Val loss: 0.3339 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=120822)[0m rmse: 0.20983722805976868
[2m[36m(func pid=120822)[0m mae:  0.13351595401763916
[2m[36m(func pid=120822)[0m rmse_per_class: [0.08, 0.288, 0.143, 0.287, 0.056, 0.208, 0.255, 0.5, 0.135, 0.147]
[2m[36m(func pid=120822)[0m 
== Status ==
Current time: 2024-01-07 16:42:26 (running for 00:18:24.09)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.526 |  0.174 |                   42 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.413 |  0.181 |                   38 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.449 |  0.21  |                   14 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.603 |  0.159 |                    7 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.1737133115530014
[2m[36m(func pid=114403)[0m mae:  0.11998190730810165
[2m[36m(func pid=114403)[0m rmse_per_class: [0.112, 0.269, 0.071, 0.353, 0.057, 0.192, 0.296, 0.141, 0.151, 0.095]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.16547347605228424
[2m[36m(func pid=122557)[0m mae:  0.09554540365934372
[2m[36m(func pid=122557)[0m rmse_per_class: [0.167, 0.257, 0.042, 0.255, 0.055, 0.272, 0.251, 0.141, 0.126, 0.089]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.18295511603355408
[2m[36m(func pid=114490)[0m mae:  0.12041300535202026
[2m[36m(func pid=114490)[0m rmse_per_class: [0.086, 0.281, 0.103, 0.247, 0.056, 0.202, 0.266, 0.267, 0.128, 0.193]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.5223 | Steps: 4 | Val loss: 0.4888 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.5434 | Steps: 4 | Val loss: 0.3916 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5321 | Steps: 4 | Val loss: 0.4595 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=120822)[0m rmse: 0.224893718957901
[2m[36m(func pid=120822)[0m mae:  0.1448258012533188
[2m[36m(func pid=120822)[0m rmse_per_class: [0.079, 0.295, 0.291, 0.362, 0.054, 0.215, 0.231, 0.498, 0.137, 0.087]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4040 | Steps: 4 | Val loss: 0.3315 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 16:42:32 (running for 00:18:29.54)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.543 |  0.173 |                   43 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.409 |  0.183 |                   39 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.522 |  0.225 |                   15 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.641 |  0.165 |                    8 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m rmse: 0.17320196330547333
[2m[36m(func pid=114403)[0m mae:  0.11932507902383804
[2m[36m(func pid=114403)[0m rmse_per_class: [0.112, 0.269, 0.069, 0.352, 0.057, 0.192, 0.296, 0.142, 0.149, 0.094]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.19197668135166168
[2m[36m(func pid=122557)[0m mae:  0.10663697868585587
[2m[36m(func pid=122557)[0m rmse_per_class: [0.12, 0.29, 0.043, 0.275, 0.059, 0.302, 0.255, 0.135, 0.144, 0.297]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.18514703214168549
[2m[36m(func pid=114490)[0m mae:  0.12071285396814346
[2m[36m(func pid=114490)[0m rmse_per_class: [0.084, 0.277, 0.147, 0.259, 0.056, 0.2, 0.253, 0.288, 0.128, 0.159]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.5381 | Steps: 4 | Val loss: 0.4706 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.5770 | Steps: 4 | Val loss: 0.6729 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.5266 | Steps: 4 | Val loss: 0.3895 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=120822)[0m rmse: 0.2119523584842682
[2m[36m(func pid=120822)[0m mae:  0.13397446274757385
[2m[36m(func pid=120822)[0m rmse_per_class: [0.073, 0.295, 0.331, 0.375, 0.049, 0.2, 0.26, 0.311, 0.135, 0.09]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3882 | Steps: 4 | Val loss: 0.3270 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 16:42:37 (running for 00:18:34.72)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.543 |  0.173 |                   43 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.404 |  0.185 |                   40 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.538 |  0.212 |                   16 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.577 |  0.212 |                   10 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.21225294470787048
[2m[36m(func pid=122557)[0m mae:  0.12344012409448624
[2m[36m(func pid=122557)[0m rmse_per_class: [0.085, 0.302, 0.043, 0.29, 0.15, 0.204, 0.266, 0.177, 0.349, 0.257]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.17323021590709686
[2m[36m(func pid=114403)[0m mae:  0.11938440799713135
[2m[36m(func pid=114403)[0m rmse_per_class: [0.109, 0.269, 0.069, 0.353, 0.056, 0.192, 0.298, 0.141, 0.151, 0.094]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4796 | Steps: 4 | Val loss: 0.4214 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=114490)[0m rmse: 0.1844858080148697
[2m[36m(func pid=114490)[0m mae:  0.11939658224582672
[2m[36m(func pid=114490)[0m rmse_per_class: [0.084, 0.272, 0.184, 0.272, 0.056, 0.195, 0.24, 0.28, 0.129, 0.133]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.6083 | Steps: 4 | Val loss: 0.6224 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.5135 | Steps: 4 | Val loss: 0.3911 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=120822)[0m rmse: 0.1979026198387146
[2m[36m(func pid=120822)[0m mae:  0.12009631097316742
[2m[36m(func pid=120822)[0m rmse_per_class: [0.115, 0.286, 0.239, 0.377, 0.154, 0.173, 0.286, 0.13, 0.13, 0.09]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3965 | Steps: 4 | Val loss: 0.3235 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 16:42:42 (running for 00:18:39.87)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.527 |  0.173 |                   44 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.388 |  0.184 |                   41 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.48  |  0.198 |                   17 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.608 |  0.205 |                   11 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.20480823516845703
[2m[36m(func pid=122557)[0m mae:  0.11255113780498505
[2m[36m(func pid=122557)[0m rmse_per_class: [0.085, 0.301, 0.034, 0.277, 0.249, 0.209, 0.372, 0.219, 0.208, 0.094]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.17318497598171234
[2m[36m(func pid=114403)[0m mae:  0.11918586492538452
[2m[36m(func pid=114403)[0m rmse_per_class: [0.11, 0.268, 0.067, 0.353, 0.056, 0.192, 0.297, 0.142, 0.153, 0.093]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4415 | Steps: 4 | Val loss: 0.4061 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=114490)[0m rmse: 0.18256041407585144
[2m[36m(func pid=114490)[0m mae:  0.11744828522205353
[2m[36m(func pid=114490)[0m rmse_per_class: [0.081, 0.265, 0.234, 0.286, 0.055, 0.191, 0.228, 0.247, 0.129, 0.109]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.6551 | Steps: 4 | Val loss: 0.5231 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.5165 | Steps: 4 | Val loss: 0.3849 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=120822)[0m rmse: 0.1929592788219452
[2m[36m(func pid=120822)[0m mae:  0.12168922275304794
[2m[36m(func pid=120822)[0m rmse_per_class: [0.146, 0.266, 0.07, 0.378, 0.33, 0.193, 0.213, 0.115, 0.128, 0.091]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3876 | Steps: 4 | Val loss: 0.3219 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 16:42:47 (running for 00:18:44.98)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.514 |  0.173 |                   45 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.397 |  0.183 |                   42 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.442 |  0.193 |                   18 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.655 |  0.186 |                   12 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.1864318698644638
[2m[36m(func pid=122557)[0m mae:  0.10351341962814331
[2m[36m(func pid=122557)[0m rmse_per_class: [0.091, 0.276, 0.075, 0.267, 0.084, 0.325, 0.339, 0.177, 0.135, 0.095]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.17234200239181519
[2m[36m(func pid=114403)[0m mae:  0.1186203807592392
[2m[36m(func pid=114403)[0m rmse_per_class: [0.109, 0.268, 0.065, 0.352, 0.056, 0.192, 0.296, 0.142, 0.151, 0.093]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.4504 | Steps: 4 | Val loss: 0.3990 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=114490)[0m rmse: 0.17881537973880768
[2m[36m(func pid=114490)[0m mae:  0.11451961100101471
[2m[36m(func pid=114490)[0m rmse_per_class: [0.079, 0.26, 0.231, 0.301, 0.054, 0.185, 0.224, 0.234, 0.129, 0.092]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.7319 | Steps: 4 | Val loss: 0.5131 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.5161 | Steps: 4 | Val loss: 0.3821 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=120822)[0m rmse: 0.1863512098789215
[2m[36m(func pid=120822)[0m mae:  0.12157118320465088
[2m[36m(func pid=120822)[0m rmse_per_class: [0.11, 0.221, 0.024, 0.369, 0.277, 0.235, 0.238, 0.135, 0.165, 0.089]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3904 | Steps: 4 | Val loss: 0.3187 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 16:42:53 (running for 00:18:50.23)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.516 |  0.172 |                   46 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.388 |  0.179 |                   43 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.45  |  0.186 |                   19 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.732 |  0.174 |                   13 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.17388242483139038
[2m[36m(func pid=122557)[0m mae:  0.09227871894836426
[2m[36m(func pid=122557)[0m rmse_per_class: [0.089, 0.271, 0.136, 0.271, 0.055, 0.263, 0.267, 0.164, 0.126, 0.097]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.17220920324325562
[2m[36m(func pid=114403)[0m mae:  0.11854950338602066
[2m[36m(func pid=114403)[0m rmse_per_class: [0.108, 0.267, 0.065, 0.352, 0.056, 0.192, 0.296, 0.142, 0.15, 0.094]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4561 | Steps: 4 | Val loss: 0.3769 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=114490)[0m rmse: 0.17425313591957092
[2m[36m(func pid=114490)[0m mae:  0.11090967804193497
[2m[36m(func pid=114490)[0m rmse_per_class: [0.075, 0.25, 0.236, 0.313, 0.053, 0.179, 0.228, 0.192, 0.129, 0.086]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.6479 | Steps: 4 | Val loss: 0.5358 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=120822)[0m rmse: 0.17320376634597778
[2m[36m(func pid=120822)[0m mae:  0.1136670932173729
[2m[36m(func pid=120822)[0m rmse_per_class: [0.064, 0.228, 0.031, 0.32, 0.121, 0.232, 0.264, 0.144, 0.243, 0.085]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.5111 | Steps: 4 | Val loss: 0.3845 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 16:42:58 (running for 00:18:55.51)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.516 |  0.172 |                   47 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.39  |  0.174 |                   44 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.456 |  0.173 |                   20 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.648 |  0.171 |                   14 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.17115506529808044
[2m[36m(func pid=122557)[0m mae:  0.09322318434715271
[2m[36m(func pid=122557)[0m rmse_per_class: [0.096, 0.316, 0.089, 0.279, 0.056, 0.189, 0.297, 0.146, 0.165, 0.079]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3814 | Steps: 4 | Val loss: 0.3150 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=114403)[0m rmse: 0.17277640104293823
[2m[36m(func pid=114403)[0m mae:  0.11844176054000854
[2m[36m(func pid=114403)[0m rmse_per_class: [0.109, 0.267, 0.065, 0.352, 0.056, 0.192, 0.302, 0.143, 0.149, 0.093]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4129 | Steps: 4 | Val loss: 0.3412 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=114490)[0m rmse: 0.16921372711658478
[2m[36m(func pid=114490)[0m mae:  0.1075403243303299
[2m[36m(func pid=114490)[0m rmse_per_class: [0.075, 0.235, 0.224, 0.327, 0.052, 0.172, 0.235, 0.159, 0.128, 0.085]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.5613 | Steps: 4 | Val loss: 0.5214 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4987 | Steps: 4 | Val loss: 0.3790 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=120822)[0m rmse: 0.15510328114032745
[2m[36m(func pid=120822)[0m mae:  0.10029449313879013
[2m[36m(func pid=120822)[0m rmse_per_class: [0.064, 0.224, 0.038, 0.25, 0.056, 0.194, 0.256, 0.144, 0.247, 0.079]
[2m[36m(func pid=120822)[0m 
== Status ==
Current time: 2024-01-07 16:43:03 (running for 00:19:00.96)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.511 |  0.173 |                   48 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.381 |  0.169 |                   45 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.413 |  0.155 |                   21 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.561 |  0.188 |                   15 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.18770930171012878
[2m[36m(func pid=122557)[0m mae:  0.1058730036020279
[2m[36m(func pid=122557)[0m rmse_per_class: [0.087, 0.246, 0.04, 0.287, 0.055, 0.186, 0.266, 0.137, 0.339, 0.234]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3554 | Steps: 4 | Val loss: 0.3084 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=114403)[0m rmse: 0.17197826504707336
[2m[36m(func pid=114403)[0m mae:  0.1178349107503891
[2m[36m(func pid=114403)[0m rmse_per_class: [0.108, 0.266, 0.062, 0.35, 0.056, 0.192, 0.301, 0.143, 0.149, 0.093]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3951 | Steps: 4 | Val loss: 0.3402 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.6629 | Steps: 4 | Val loss: 0.6541 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=114490)[0m rmse: 0.16079719364643097
[2m[36m(func pid=114490)[0m mae:  0.10253963619470596
[2m[36m(func pid=114490)[0m rmse_per_class: [0.069, 0.219, 0.191, 0.336, 0.052, 0.166, 0.237, 0.125, 0.128, 0.085]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.5051 | Steps: 4 | Val loss: 0.3706 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=120822)[0m rmse: 0.15416327118873596
[2m[36m(func pid=120822)[0m mae:  0.0954245775938034
[2m[36m(func pid=120822)[0m rmse_per_class: [0.072, 0.206, 0.042, 0.297, 0.049, 0.173, 0.243, 0.144, 0.18, 0.135]
[2m[36m(func pid=120822)[0m 
== Status ==
Current time: 2024-01-07 16:43:09 (running for 00:19:06.23)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.499 |  0.172 |                   49 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.355 |  0.161 |                   46 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.395 |  0.154 |                   22 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.663 |  0.188 |                   16 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.18798276782035828
[2m[36m(func pid=122557)[0m mae:  0.11058537662029266
[2m[36m(func pid=122557)[0m rmse_per_class: [0.085, 0.286, 0.031, 0.275, 0.053, 0.261, 0.25, 0.128, 0.17, 0.342]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.17092594504356384
[2m[36m(func pid=114403)[0m mae:  0.11745993793010712
[2m[36m(func pid=114403)[0m rmse_per_class: [0.108, 0.265, 0.061, 0.349, 0.056, 0.192, 0.293, 0.142, 0.15, 0.094]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3744 | Steps: 4 | Val loss: 0.3067 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4017 | Steps: 4 | Val loss: 0.3586 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.6025 | Steps: 4 | Val loss: 0.5669 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=114490)[0m rmse: 0.15580911934375763
[2m[36m(func pid=114490)[0m mae:  0.09990308433771133
[2m[36m(func pid=114490)[0m rmse_per_class: [0.065, 0.214, 0.153, 0.347, 0.052, 0.163, 0.239, 0.112, 0.127, 0.086]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m rmse: 0.16603632271289825
[2m[36m(func pid=120822)[0m mae:  0.09878233820199966
[2m[36m(func pid=120822)[0m rmse_per_class: [0.077, 0.236, 0.044, 0.346, 0.052, 0.18, 0.219, 0.145, 0.131, 0.23]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4853 | Steps: 4 | Val loss: 0.3679 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 16:43:14 (running for 00:19:11.45)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.505 |  0.171 |                   50 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.374 |  0.156 |                   47 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.402 |  0.166 |                   23 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.603 |  0.196 |                   17 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.19570034742355347
[2m[36m(func pid=122557)[0m mae:  0.1027231216430664
[2m[36m(func pid=122557)[0m rmse_per_class: [0.086, 0.27, 0.041, 0.312, 0.153, 0.256, 0.296, 0.206, 0.146, 0.191]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.17024390399456024
[2m[36m(func pid=114403)[0m mae:  0.11682961881160736
[2m[36m(func pid=114403)[0m rmse_per_class: [0.107, 0.264, 0.06, 0.347, 0.055, 0.191, 0.293, 0.142, 0.149, 0.093]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3621 | Steps: 4 | Val loss: 0.3023 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4463 | Steps: 4 | Val loss: 0.3644 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.7129 | Steps: 4 | Val loss: 0.6187 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=114490)[0m rmse: 0.15061135590076447
[2m[36m(func pid=114490)[0m mae:  0.09746204316616058
[2m[36m(func pid=114490)[0m rmse_per_class: [0.063, 0.212, 0.1, 0.354, 0.053, 0.167, 0.236, 0.108, 0.127, 0.087]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m rmse: 0.17017093300819397
[2m[36m(func pid=120822)[0m mae:  0.09770718961954117
[2m[36m(func pid=120822)[0m rmse_per_class: [0.079, 0.265, 0.044, 0.311, 0.054, 0.183, 0.216, 0.141, 0.123, 0.284]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4888 | Steps: 4 | Val loss: 0.3652 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 16:43:19 (running for 00:19:16.79)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.485 |  0.17  |                   51 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.362 |  0.151 |                   48 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.446 |  0.17  |                   24 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.713 |  0.212 |                   18 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.211564302444458
[2m[36m(func pid=122557)[0m mae:  0.11390592157840729
[2m[36m(func pid=122557)[0m rmse_per_class: [0.101, 0.27, 0.044, 0.311, 0.281, 0.23, 0.305, 0.33, 0.161, 0.083]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.16993102431297302
[2m[36m(func pid=114403)[0m mae:  0.11683891713619232
[2m[36m(func pid=114403)[0m rmse_per_class: [0.108, 0.263, 0.06, 0.347, 0.055, 0.191, 0.288, 0.143, 0.151, 0.093]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4499 | Steps: 4 | Val loss: 0.3582 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3554 | Steps: 4 | Val loss: 0.2974 | Batch size: 32 | lr: 0.001 | Duration: 3.23s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.8021 | Steps: 4 | Val loss: 0.5834 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=120822)[0m rmse: 0.16970126330852509
[2m[36m(func pid=120822)[0m mae:  0.0949564129114151
[2m[36m(func pid=120822)[0m rmse_per_class: [0.075, 0.271, 0.043, 0.254, 0.055, 0.172, 0.289, 0.134, 0.124, 0.279]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4881 | Steps: 4 | Val loss: 0.3635 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=114490)[0m rmse: 0.14815136790275574
[2m[36m(func pid=114490)[0m mae:  0.09666403383016586
[2m[36m(func pid=114490)[0m rmse_per_class: [0.061, 0.215, 0.076, 0.353, 0.06, 0.173, 0.219, 0.109, 0.127, 0.088]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:43:25 (running for 00:19:22.17)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.489 |  0.17  |                   52 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.355 |  0.148 |                   49 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.45  |  0.17  |                   25 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.802 |  0.19  |                   19 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.1898404061794281
[2m[36m(func pid=122557)[0m mae:  0.104201540350914
[2m[36m(func pid=122557)[0m rmse_per_class: [0.111, 0.3, 0.043, 0.334, 0.084, 0.217, 0.295, 0.148, 0.27, 0.096]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.16961905360221863
[2m[36m(func pid=114403)[0m mae:  0.11657247692346573
[2m[36m(func pid=114403)[0m rmse_per_class: [0.107, 0.263, 0.059, 0.347, 0.055, 0.191, 0.287, 0.143, 0.152, 0.093]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4298 | Steps: 4 | Val loss: 0.3640 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3429 | Steps: 4 | Val loss: 0.2956 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.6354 | Steps: 4 | Val loss: 0.6669 | Batch size: 32 | lr: 0.1 | Duration: 2.72s
[2m[36m(func pid=120822)[0m rmse: 0.16813308000564575
[2m[36m(func pid=120822)[0m mae:  0.09470603615045547
[2m[36m(func pid=120822)[0m rmse_per_class: [0.071, 0.26, 0.04, 0.255, 0.055, 0.167, 0.348, 0.126, 0.125, 0.235]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4969 | Steps: 4 | Val loss: 0.3580 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=114490)[0m rmse: 0.14770428836345673
[2m[36m(func pid=114490)[0m mae:  0.09718241542577744
[2m[36m(func pid=114490)[0m rmse_per_class: [0.062, 0.223, 0.052, 0.354, 0.068, 0.183, 0.209, 0.112, 0.127, 0.088]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:43:30 (running for 00:19:27.27)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.488 |  0.17  |                   53 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.343 |  0.148 |                   50 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.43  |  0.168 |                   26 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.635 |  0.189 |                   20 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.18922248482704163
[2m[36m(func pid=122557)[0m mae:  0.11056236177682877
[2m[36m(func pid=122557)[0m rmse_per_class: [0.198, 0.265, 0.027, 0.316, 0.058, 0.295, 0.276, 0.135, 0.233, 0.089]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.16921059787273407
[2m[36m(func pid=114403)[0m mae:  0.11650592088699341
[2m[36m(func pid=114403)[0m rmse_per_class: [0.107, 0.262, 0.057, 0.346, 0.055, 0.191, 0.285, 0.142, 0.154, 0.093]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4382 | Steps: 4 | Val loss: 0.3709 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3489 | Steps: 4 | Val loss: 0.2977 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.6708 | Steps: 4 | Val loss: 0.5741 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=120822)[0m rmse: 0.1659672111272812
[2m[36m(func pid=120822)[0m mae:  0.09440552443265915
[2m[36m(func pid=120822)[0m rmse_per_class: [0.075, 0.243, 0.036, 0.283, 0.056, 0.218, 0.315, 0.125, 0.13, 0.178]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4665 | Steps: 4 | Val loss: 0.3557 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=114490)[0m rmse: 0.1491856724023819
[2m[36m(func pid=114490)[0m mae:  0.09882955998182297
[2m[36m(func pid=114490)[0m rmse_per_class: [0.063, 0.227, 0.039, 0.355, 0.081, 0.192, 0.202, 0.115, 0.13, 0.088]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:43:35 (running for 00:19:32.60)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.497 |  0.169 |                   54 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.349 |  0.149 |                   51 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.438 |  0.166 |                   27 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.671 |  0.186 |                   21 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.1863487958908081
[2m[36m(func pid=122557)[0m mae:  0.10138660669326782
[2m[36m(func pid=122557)[0m rmse_per_class: [0.144, 0.282, 0.087, 0.351, 0.06, 0.234, 0.292, 0.14, 0.168, 0.106]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.16872921586036682
[2m[36m(func pid=114403)[0m mae:  0.11615300178527832
[2m[36m(func pid=114403)[0m rmse_per_class: [0.106, 0.261, 0.056, 0.347, 0.055, 0.192, 0.282, 0.142, 0.153, 0.093]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4145 | Steps: 4 | Val loss: 0.3752 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3453 | Steps: 4 | Val loss: 0.3030 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.6056 | Steps: 4 | Val loss: 0.5440 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=120822)[0m rmse: 0.1715584397315979
[2m[36m(func pid=120822)[0m mae:  0.0994601920247078
[2m[36m(func pid=120822)[0m rmse_per_class: [0.09, 0.231, 0.034, 0.31, 0.056, 0.314, 0.26, 0.174, 0.135, 0.112]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4712 | Steps: 4 | Val loss: 0.3517 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=114490)[0m rmse: 0.15386170148849487
[2m[36m(func pid=114490)[0m mae:  0.10242229700088501
[2m[36m(func pid=114490)[0m rmse_per_class: [0.067, 0.237, 0.032, 0.355, 0.097, 0.199, 0.206, 0.125, 0.133, 0.088]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:43:40 (running for 00:19:37.82)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.467 |  0.169 |                   55 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.345 |  0.154 |                   52 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.415 |  0.172 |                   28 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.606 |  0.192 |                   22 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.1921539157629013
[2m[36m(func pid=122557)[0m mae:  0.1039281114935875
[2m[36m(func pid=122557)[0m rmse_per_class: [0.092, 0.253, 0.099, 0.302, 0.057, 0.21, 0.335, 0.136, 0.15, 0.288]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.1681521236896515
[2m[36m(func pid=114403)[0m mae:  0.11593632400035858
[2m[36m(func pid=114403)[0m rmse_per_class: [0.106, 0.26, 0.055, 0.346, 0.055, 0.191, 0.278, 0.142, 0.154, 0.093]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4153 | Steps: 4 | Val loss: 0.3838 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3735 | Steps: 4 | Val loss: 0.3034 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.7079 | Steps: 4 | Val loss: 0.6418 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=120822)[0m rmse: 0.17768411338329315
[2m[36m(func pid=120822)[0m mae:  0.10472631454467773
[2m[36m(func pid=120822)[0m rmse_per_class: [0.098, 0.237, 0.031, 0.334, 0.056, 0.305, 0.268, 0.216, 0.153, 0.08]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4589 | Steps: 4 | Val loss: 0.3457 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 16:43:46 (running for 00:19:43.22)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.471 |  0.168 |                   56 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.373 |  0.157 |                   53 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.415 |  0.178 |                   29 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.606 |  0.192 |                   22 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114490)[0m rmse: 0.15658721327781677
[2m[36m(func pid=114490)[0m mae:  0.10465352237224579
[2m[36m(func pid=114490)[0m rmse_per_class: [0.073, 0.234, 0.031, 0.35, 0.121, 0.195, 0.213, 0.127, 0.136, 0.087]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.21008241176605225
[2m[36m(func pid=122557)[0m mae:  0.12012097984552383
[2m[36m(func pid=122557)[0m rmse_per_class: [0.102, 0.256, 0.046, 0.322, 0.058, 0.287, 0.289, 0.267, 0.162, 0.311]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3654 | Steps: 4 | Val loss: 0.3798 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=114403)[0m rmse: 0.16714556515216827
[2m[36m(func pid=114403)[0m mae:  0.11546683311462402
[2m[36m(func pid=114403)[0m rmse_per_class: [0.107, 0.259, 0.055, 0.343, 0.055, 0.191, 0.272, 0.142, 0.153, 0.094]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.5625 | Steps: 4 | Val loss: 0.5276 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3250 | Steps: 4 | Val loss: 0.3035 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=120822)[0m rmse: 0.1736467182636261
[2m[36m(func pid=120822)[0m mae:  0.1028667688369751
[2m[36m(func pid=120822)[0m rmse_per_class: [0.09, 0.252, 0.03, 0.334, 0.055, 0.222, 0.269, 0.225, 0.181, 0.079]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4596 | Steps: 4 | Val loss: 0.3409 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 16:43:51 (running for 00:19:48.45)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.459 |  0.167 |                   57 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.373 |  0.157 |                   53 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.365 |  0.174 |                   30 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.562 |  0.195 |                   24 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.19459804892539978
[2m[36m(func pid=122557)[0m mae:  0.11020880937576294
[2m[36m(func pid=122557)[0m rmse_per_class: [0.094, 0.25, 0.04, 0.31, 0.066, 0.364, 0.286, 0.222, 0.187, 0.128]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.15909507870674133
[2m[36m(func pid=114490)[0m mae:  0.10652641952037811
[2m[36m(func pid=114490)[0m rmse_per_class: [0.071, 0.222, 0.032, 0.343, 0.145, 0.203, 0.222, 0.128, 0.14, 0.085]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.1667354851961136
[2m[36m(func pid=114403)[0m mae:  0.11512543261051178
[2m[36m(func pid=114403)[0m rmse_per_class: [0.106, 0.259, 0.054, 0.342, 0.055, 0.191, 0.272, 0.142, 0.152, 0.094]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4487 | Steps: 4 | Val loss: 0.3873 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.5316 | Steps: 4 | Val loss: 0.5736 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3523 | Steps: 4 | Val loss: 0.3001 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=120822)[0m rmse: 0.16746996343135834
[2m[36m(func pid=120822)[0m mae:  0.10039949417114258
[2m[36m(func pid=120822)[0m rmse_per_class: [0.088, 0.248, 0.026, 0.327, 0.055, 0.164, 0.25, 0.218, 0.218, 0.081]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4541 | Steps: 4 | Val loss: 0.3368 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 16:43:56 (running for 00:19:53.65)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.46  |  0.167 |                   58 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.325 |  0.159 |                   54 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.449 |  0.167 |                   31 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.532 |  0.205 |                   25 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.20475824177265167
[2m[36m(func pid=122557)[0m mae:  0.11030642688274384
[2m[36m(func pid=122557)[0m rmse_per_class: [0.265, 0.253, 0.048, 0.312, 0.131, 0.237, 0.309, 0.148, 0.262, 0.081]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1597270667552948
[2m[36m(func pid=114490)[0m mae:  0.10692542791366577
[2m[36m(func pid=114490)[0m rmse_per_class: [0.073, 0.217, 0.034, 0.328, 0.161, 0.199, 0.23, 0.129, 0.143, 0.083]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.16614258289337158
[2m[36m(func pid=114403)[0m mae:  0.11487029492855072
[2m[36m(func pid=114403)[0m rmse_per_class: [0.107, 0.258, 0.053, 0.342, 0.055, 0.192, 0.268, 0.142, 0.153, 0.093]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4438 | Steps: 4 | Val loss: 0.3532 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.6952 | Steps: 4 | Val loss: 0.6482 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=120822)[0m rmse: 0.15473458170890808
[2m[36m(func pid=120822)[0m mae:  0.09265267103910446
[2m[36m(func pid=120822)[0m rmse_per_class: [0.083, 0.22, 0.025, 0.291, 0.051, 0.16, 0.231, 0.18, 0.226, 0.08]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3598 | Steps: 4 | Val loss: 0.2988 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4670 | Steps: 4 | Val loss: 0.3311 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 16:44:01 (running for 00:19:58.72)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.454 |  0.166 |                   59 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.352 |  0.16  |                   55 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.444 |  0.155 |                   32 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.695 |  0.201 |                   26 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.20118387043476105
[2m[36m(func pid=122557)[0m mae:  0.11285523325204849
[2m[36m(func pid=122557)[0m rmse_per_class: [0.314, 0.239, 0.049, 0.315, 0.128, 0.226, 0.302, 0.152, 0.193, 0.095]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.16045135259628296
[2m[36m(func pid=114490)[0m mae:  0.10739914327859879
[2m[36m(func pid=114490)[0m rmse_per_class: [0.08, 0.215, 0.035, 0.317, 0.163, 0.193, 0.238, 0.13, 0.151, 0.082]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.16554462909698486
[2m[36m(func pid=114403)[0m mae:  0.1147795096039772
[2m[36m(func pid=114403)[0m rmse_per_class: [0.106, 0.257, 0.053, 0.34, 0.055, 0.192, 0.264, 0.141, 0.153, 0.093]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3848 | Steps: 4 | Val loss: 0.3156 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.7766 | Steps: 4 | Val loss: 0.6416 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=120822)[0m rmse: 0.14751149713993073
[2m[36m(func pid=120822)[0m mae:  0.08722980320453644
[2m[36m(func pid=120822)[0m rmse_per_class: [0.091, 0.203, 0.025, 0.254, 0.049, 0.167, 0.226, 0.146, 0.237, 0.077]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3350 | Steps: 4 | Val loss: 0.2919 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4443 | Steps: 4 | Val loss: 0.3276 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 16:44:06 (running for 00:20:03.90)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.467 |  0.166 |                   60 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.36  |  0.16  |                   56 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.385 |  0.148 |                   33 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.777 |  0.21  |                   27 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.2100767344236374
[2m[36m(func pid=122557)[0m mae:  0.12037812173366547
[2m[36m(func pid=122557)[0m rmse_per_class: [0.099, 0.263, 0.049, 0.324, 0.119, 0.44, 0.316, 0.199, 0.193, 0.098]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1586729735136032
[2m[36m(func pid=114490)[0m mae:  0.10560771077871323
[2m[36m(func pid=114490)[0m rmse_per_class: [0.083, 0.212, 0.036, 0.293, 0.168, 0.189, 0.241, 0.129, 0.153, 0.082]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.16525287926197052
[2m[36m(func pid=114403)[0m mae:  0.11472705751657486
[2m[36m(func pid=114403)[0m rmse_per_class: [0.106, 0.257, 0.052, 0.339, 0.055, 0.192, 0.262, 0.141, 0.154, 0.094]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3624 | Steps: 4 | Val loss: 0.3056 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.9149 | Steps: 4 | Val loss: 0.7225 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=120822)[0m rmse: 0.1516013741493225
[2m[36m(func pid=120822)[0m mae:  0.08478521555662155
[2m[36m(func pid=120822)[0m rmse_per_class: [0.091, 0.217, 0.04, 0.243, 0.077, 0.174, 0.223, 0.142, 0.193, 0.115]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4367 | Steps: 4 | Val loss: 0.3245 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3364 | Steps: 4 | Val loss: 0.2844 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 16:44:12 (running for 00:20:09.12)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.444 |  0.165 |                   61 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.335 |  0.159 |                   57 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.362 |  0.152 |                   34 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.915 |  0.227 |                   28 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.22719815373420715
[2m[36m(func pid=122557)[0m mae:  0.12955574691295624
[2m[36m(func pid=122557)[0m rmse_per_class: [0.096, 0.29, 0.049, 0.348, 0.106, 0.265, 0.342, 0.433, 0.252, 0.09]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.16485735774040222
[2m[36m(func pid=114403)[0m mae:  0.11465625464916229
[2m[36m(func pid=114403)[0m rmse_per_class: [0.106, 0.257, 0.052, 0.337, 0.055, 0.192, 0.258, 0.141, 0.155, 0.094]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.15555359423160553
[2m[36m(func pid=114490)[0m mae:  0.10319699347019196
[2m[36m(func pid=114490)[0m rmse_per_class: [0.078, 0.217, 0.037, 0.272, 0.159, 0.183, 0.24, 0.125, 0.157, 0.088]
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3571 | Steps: 4 | Val loss: 0.3363 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.7355 | Steps: 4 | Val loss: 0.6330 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=120822)[0m rmse: 0.16655388474464417
[2m[36m(func pid=120822)[0m mae:  0.09104560315608978
[2m[36m(func pid=120822)[0m rmse_per_class: [0.076, 0.239, 0.067, 0.288, 0.124, 0.184, 0.221, 0.14, 0.146, 0.182]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4283 | Steps: 4 | Val loss: 0.3210 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3369 | Steps: 4 | Val loss: 0.2809 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 16:44:17 (running for 00:20:14.27)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.437 |  0.165 |                   62 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.336 |  0.156 |                   58 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.357 |  0.167 |                   35 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.735 |  0.2   |                   29 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.20028789341449738
[2m[36m(func pid=122557)[0m mae:  0.10866670310497284
[2m[36m(func pid=122557)[0m rmse_per_class: [0.152, 0.282, 0.047, 0.333, 0.079, 0.23, 0.375, 0.238, 0.178, 0.088]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.16428807377815247
[2m[36m(func pid=114403)[0m mae:  0.11434295028448105
[2m[36m(func pid=114403)[0m rmse_per_class: [0.107, 0.257, 0.052, 0.335, 0.055, 0.192, 0.255, 0.141, 0.155, 0.095]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4065 | Steps: 4 | Val loss: 0.3782 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=114490)[0m rmse: 0.1536121666431427
[2m[36m(func pid=114490)[0m mae:  0.10163333266973495
[2m[36m(func pid=114490)[0m rmse_per_class: [0.076, 0.225, 0.037, 0.25, 0.137, 0.178, 0.246, 0.127, 0.158, 0.102]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.6494 | Steps: 4 | Val loss: 0.6194 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=120822)[0m rmse: 0.18229886889457703
[2m[36m(func pid=120822)[0m mae:  0.10169285535812378
[2m[36m(func pid=120822)[0m rmse_per_class: [0.066, 0.266, 0.085, 0.302, 0.157, 0.187, 0.236, 0.135, 0.136, 0.252]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4367 | Steps: 4 | Val loss: 0.3182 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 16:44:22 (running for 00:20:19.44)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.428 |  0.164 |                   63 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.337 |  0.154 |                   59 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.406 |  0.182 |                   36 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.649 |  0.201 |                   30 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.20147347450256348
[2m[36m(func pid=122557)[0m mae:  0.1135033592581749
[2m[36m(func pid=122557)[0m rmse_per_class: [0.258, 0.263, 0.042, 0.342, 0.058, 0.321, 0.307, 0.16, 0.13, 0.134]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3520 | Steps: 4 | Val loss: 0.2817 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=114403)[0m rmse: 0.16404342651367188
[2m[36m(func pid=114403)[0m mae:  0.11413159221410751
[2m[36m(func pid=114403)[0m rmse_per_class: [0.107, 0.256, 0.051, 0.335, 0.055, 0.191, 0.254, 0.141, 0.155, 0.095]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3925 | Steps: 4 | Val loss: 0.3781 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=114490)[0m rmse: 0.15412017703056335
[2m[36m(func pid=114490)[0m mae:  0.10160680115222931
[2m[36m(func pid=114490)[0m rmse_per_class: [0.075, 0.231, 0.037, 0.243, 0.118, 0.17, 0.25, 0.128, 0.16, 0.128]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.6284 | Steps: 4 | Val loss: 0.7385 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=120822)[0m rmse: 0.18371151387691498
[2m[36m(func pid=120822)[0m mae:  0.10184991359710693
[2m[36m(func pid=120822)[0m rmse_per_class: [0.07, 0.269, 0.105, 0.282, 0.17, 0.193, 0.236, 0.13, 0.132, 0.249]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4300 | Steps: 4 | Val loss: 0.3124 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 16:44:27 (running for 00:20:24.74)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.437 |  0.164 |                   64 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.352 |  0.154 |                   60 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.393 |  0.184 |                   37 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.628 |  0.246 |                   31 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.24625392258167267
[2m[36m(func pid=122557)[0m mae:  0.13507598638534546
[2m[36m(func pid=122557)[0m rmse_per_class: [0.29, 0.272, 0.069, 0.346, 0.058, 0.299, 0.337, 0.274, 0.188, 0.331]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3224 | Steps: 4 | Val loss: 0.2802 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=114403)[0m rmse: 0.16346459090709686
[2m[36m(func pid=114403)[0m mae:  0.11381267011165619
[2m[36m(func pid=114403)[0m rmse_per_class: [0.108, 0.255, 0.051, 0.333, 0.055, 0.191, 0.254, 0.14, 0.152, 0.094]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4169 | Steps: 4 | Val loss: 0.3692 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.7456 | Steps: 4 | Val loss: 0.7990 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=114490)[0m rmse: 0.15252654254436493
[2m[36m(func pid=114490)[0m mae:  0.09992380440235138
[2m[36m(func pid=114490)[0m rmse_per_class: [0.067, 0.241, 0.037, 0.24, 0.097, 0.167, 0.247, 0.126, 0.151, 0.152]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4393 | Steps: 4 | Val loss: 0.3081 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=120822)[0m rmse: 0.18089668452739716
[2m[36m(func pid=120822)[0m mae:  0.10044777393341064
[2m[36m(func pid=120822)[0m rmse_per_class: [0.079, 0.262, 0.095, 0.25, 0.185, 0.215, 0.234, 0.128, 0.13, 0.229]
[2m[36m(func pid=120822)[0m 
== Status ==
Current time: 2024-01-07 16:44:32 (running for 00:20:30.05)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.43  |  0.163 |                   65 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.322 |  0.153 |                   61 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.417 |  0.181 |                   38 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.746 |  0.244 |                   32 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.2444906234741211
[2m[36m(func pid=122557)[0m mae:  0.13689526915550232
[2m[36m(func pid=122557)[0m rmse_per_class: [0.091, 0.29, 0.141, 0.35, 0.077, 0.219, 0.315, 0.234, 0.365, 0.363]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3264 | Steps: 4 | Val loss: 0.2816 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=114403)[0m rmse: 0.162811741232872
[2m[36m(func pid=114403)[0m mae:  0.11353111267089844
[2m[36m(func pid=114403)[0m rmse_per_class: [0.109, 0.255, 0.051, 0.33, 0.055, 0.191, 0.251, 0.14, 0.152, 0.095]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4151 | Steps: 4 | Val loss: 0.3729 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.7242 | Steps: 4 | Val loss: 0.6828 | Batch size: 32 | lr: 0.1 | Duration: 3.05s
[2m[36m(func pid=114490)[0m rmse: 0.15274465084075928
[2m[36m(func pid=114490)[0m mae:  0.09964530169963837
[2m[36m(func pid=114490)[0m rmse_per_class: [0.063, 0.251, 0.037, 0.244, 0.076, 0.165, 0.244, 0.122, 0.147, 0.177]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:44:38 (running for 00:20:35.12)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.439 |  0.163 |                   66 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.326 |  0.153 |                   62 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.415 |  0.182 |                   39 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.746 |  0.244 |                   32 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4382 | Steps: 4 | Val loss: 0.3063 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=120822)[0m rmse: 0.18216797709465027
[2m[36m(func pid=120822)[0m mae:  0.10378047078847885
[2m[36m(func pid=120822)[0m rmse_per_class: [0.077, 0.254, 0.088, 0.269, 0.172, 0.279, 0.244, 0.126, 0.132, 0.181]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.21055591106414795
[2m[36m(func pid=122557)[0m mae:  0.11755343526601791
[2m[36m(func pid=122557)[0m rmse_per_class: [0.089, 0.268, 0.134, 0.347, 0.092, 0.225, 0.402, 0.154, 0.236, 0.158]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3138 | Steps: 4 | Val loss: 0.2816 | Batch size: 32 | lr: 0.001 | Duration: 3.13s
[2m[36m(func pid=114403)[0m rmse: 0.16241057217121124
[2m[36m(func pid=114403)[0m mae:  0.11323414742946625
[2m[36m(func pid=114403)[0m rmse_per_class: [0.11, 0.254, 0.05, 0.329, 0.055, 0.19, 0.249, 0.141, 0.151, 0.095]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3993 | Steps: 4 | Val loss: 0.3650 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.5927 | Steps: 4 | Val loss: 0.6255 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=114490)[0m rmse: 0.1527768075466156
[2m[36m(func pid=114490)[0m mae:  0.09929455071687698
[2m[36m(func pid=114490)[0m rmse_per_class: [0.061, 0.255, 0.037, 0.247, 0.064, 0.165, 0.242, 0.118, 0.145, 0.194]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4243 | Steps: 4 | Val loss: 0.3026 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 16:44:43 (running for 00:20:40.52)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.438 |  0.162 |                   67 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.314 |  0.153 |                   63 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.399 |  0.174 |                   40 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.724 |  0.211 |                   33 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=120822)[0m rmse: 0.17440298199653625
[2m[36m(func pid=120822)[0m mae:  0.1007220521569252
[2m[36m(func pid=120822)[0m rmse_per_class: [0.073, 0.233, 0.079, 0.299, 0.127, 0.284, 0.259, 0.126, 0.138, 0.126]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.22058133780956268
[2m[36m(func pid=122557)[0m mae:  0.11950719356536865
[2m[36m(func pid=122557)[0m rmse_per_class: [0.179, 0.285, 0.11, 0.351, 0.192, 0.392, 0.289, 0.187, 0.142, 0.08]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3254 | Steps: 4 | Val loss: 0.2785 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=114403)[0m rmse: 0.1619195193052292
[2m[36m(func pid=114403)[0m mae:  0.1132841557264328
[2m[36m(func pid=114403)[0m rmse_per_class: [0.108, 0.253, 0.05, 0.326, 0.055, 0.191, 0.249, 0.14, 0.152, 0.095]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3905 | Steps: 4 | Val loss: 0.3550 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.7331 | Steps: 4 | Val loss: 0.8082 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=114490)[0m rmse: 0.150109201669693
[2m[36m(func pid=114490)[0m mae:  0.0967574268579483
[2m[36m(func pid=114490)[0m rmse_per_class: [0.058, 0.259, 0.035, 0.25, 0.057, 0.164, 0.232, 0.114, 0.141, 0.19]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:44:48 (running for 00:20:45.82)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.424 |  0.162 |                   68 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.325 |  0.15  |                   64 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.391 |  0.165 |                   41 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.593 |  0.221 |                   34 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4083 | Steps: 4 | Val loss: 0.3005 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=120822)[0m rmse: 0.1649223119020462
[2m[36m(func pid=120822)[0m mae:  0.09606523811817169
[2m[36m(func pid=120822)[0m rmse_per_class: [0.069, 0.232, 0.047, 0.316, 0.103, 0.263, 0.261, 0.125, 0.148, 0.086]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.23656809329986572
[2m[36m(func pid=122557)[0m mae:  0.1370438039302826
[2m[36m(func pid=122557)[0m rmse_per_class: [0.303, 0.268, 0.032, 0.356, 0.148, 0.464, 0.347, 0.231, 0.128, 0.089]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3464 | Steps: 4 | Val loss: 0.2746 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=114403)[0m rmse: 0.1615479439496994
[2m[36m(func pid=114403)[0m mae:  0.11310730129480362
[2m[36m(func pid=114403)[0m rmse_per_class: [0.109, 0.253, 0.05, 0.324, 0.055, 0.19, 0.248, 0.138, 0.152, 0.096]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3596 | Steps: 4 | Val loss: 0.3634 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.8225 | Steps: 4 | Val loss: 0.7588 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=114490)[0m rmse: 0.1480395346879959
[2m[36m(func pid=114490)[0m mae:  0.09462074935436249
[2m[36m(func pid=114490)[0m rmse_per_class: [0.059, 0.259, 0.035, 0.247, 0.053, 0.164, 0.222, 0.109, 0.137, 0.197]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4232 | Steps: 4 | Val loss: 0.2989 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=120822)[0m rmse: 0.1631762832403183
[2m[36m(func pid=120822)[0m mae:  0.0935870110988617
[2m[36m(func pid=120822)[0m rmse_per_class: [0.074, 0.276, 0.034, 0.328, 0.08, 0.208, 0.254, 0.129, 0.172, 0.077]
== Status ==
Current time: 2024-01-07 16:44:54 (running for 00:20:51.13)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.408 |  0.162 |                   69 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.346 |  0.148 |                   65 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.36  |  0.163 |                   42 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.733 |  0.237 |                   35 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.22757625579833984
[2m[36m(func pid=122557)[0m mae:  0.1310579478740692
[2m[36m(func pid=122557)[0m rmse_per_class: [0.201, 0.281, 0.047, 0.363, 0.1, 0.236, 0.315, 0.513, 0.128, 0.093]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3166 | Steps: 4 | Val loss: 0.2725 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
[2m[36m(func pid=114403)[0m rmse: 0.1611821949481964
[2m[36m(func pid=114403)[0m mae:  0.11283306032419205
[2m[36m(func pid=114403)[0m rmse_per_class: [0.108, 0.254, 0.05, 0.321, 0.055, 0.19, 0.246, 0.139, 0.152, 0.097]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3443 | Steps: 4 | Val loss: 0.3886 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.7428 | Steps: 4 | Val loss: 0.6610 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=114490)[0m rmse: 0.14641527831554413
[2m[36m(func pid=114490)[0m mae:  0.09245722740888596
[2m[36m(func pid=114490)[0m rmse_per_class: [0.059, 0.258, 0.033, 0.255, 0.05, 0.162, 0.219, 0.109, 0.133, 0.188]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4036 | Steps: 4 | Val loss: 0.2970 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=120822)[0m rmse: 0.16961124539375305
[2m[36m(func pid=120822)[0m mae:  0.09709842503070831
[2m[36m(func pid=120822)[0m rmse_per_class: [0.113, 0.31, 0.026, 0.338, 0.066, 0.175, 0.25, 0.143, 0.197, 0.077]
[2m[36m(func pid=120822)[0m 
== Status ==
Current time: 2024-01-07 16:44:59 (running for 00:20:56.54)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.423 |  0.161 |                   70 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.317 |  0.146 |                   66 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.17  |                   43 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.822 |  0.228 |                   36 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=122557)[0m rmse: 0.1877317726612091
[2m[36m(func pid=122557)[0m mae:  0.10788817703723907
[2m[36m(func pid=122557)[0m rmse_per_class: [0.095, 0.265, 0.049, 0.333, 0.06, 0.219, 0.446, 0.193, 0.128, 0.091]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3150 | Steps: 4 | Val loss: 0.2681 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=114403)[0m rmse: 0.16087807714939117
[2m[36m(func pid=114403)[0m mae:  0.1126832365989685
[2m[36m(func pid=114403)[0m rmse_per_class: [0.108, 0.254, 0.049, 0.321, 0.055, 0.191, 0.245, 0.138, 0.15, 0.098]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3784 | Steps: 4 | Val loss: 0.3996 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.6879 | Steps: 4 | Val loss: 0.6311 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=114490)[0m rmse: 0.1429014503955841
[2m[36m(func pid=114490)[0m mae:  0.0896114856004715
[2m[36m(func pid=114490)[0m rmse_per_class: [0.059, 0.257, 0.029, 0.245, 0.049, 0.16, 0.209, 0.108, 0.134, 0.178]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3991 | Steps: 4 | Val loss: 0.2957 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 16:45:04 (running for 00:21:01.79)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.404 |  0.161 |                   71 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.315 |  0.143 |                   67 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.378 |  0.175 |                   44 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.743 |  0.188 |                   37 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=120822)[0m rmse: 0.17543481290340424
[2m[36m(func pid=120822)[0m mae:  0.10106708854436874
[2m[36m(func pid=120822)[0m rmse_per_class: [0.159, 0.309, 0.028, 0.337, 0.055, 0.175, 0.243, 0.152, 0.218, 0.078]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.2014002799987793
[2m[36m(func pid=122557)[0m mae:  0.1126520186662674
[2m[36m(func pid=122557)[0m rmse_per_class: [0.106, 0.301, 0.049, 0.352, 0.056, 0.344, 0.283, 0.156, 0.288, 0.08]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3221 | Steps: 4 | Val loss: 0.2649 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=114403)[0m rmse: 0.1608043611049652
[2m[36m(func pid=114403)[0m mae:  0.11282863467931747
[2m[36m(func pid=114403)[0m rmse_per_class: [0.107, 0.252, 0.05, 0.319, 0.055, 0.191, 0.248, 0.137, 0.152, 0.098]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3744 | Steps: 4 | Val loss: 0.3860 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.6526 | Steps: 4 | Val loss: 0.9049 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=114490)[0m rmse: 0.1409073919057846
[2m[36m(func pid=114490)[0m mae:  0.08820147067308426
[2m[36m(func pid=114490)[0m rmse_per_class: [0.058, 0.25, 0.027, 0.238, 0.049, 0.16, 0.205, 0.11, 0.136, 0.176]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:45:09 (running for 00:21:07.09)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.399 |  0.161 |                   72 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.322 |  0.141 |                   68 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.378 |  0.175 |                   44 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.653 |  0.239 |                   39 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3992 | Steps: 4 | Val loss: 0.2947 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=122557)[0m rmse: 0.23879949748516083
[2m[36m(func pid=122557)[0m mae:  0.14197398722171783
[2m[36m(func pid=122557)[0m rmse_per_class: [0.165, 0.309, 0.049, 0.368, 0.059, 0.366, 0.348, 0.151, 0.458, 0.115]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=120822)[0m rmse: 0.1779523342847824
[2m[36m(func pid=120822)[0m mae:  0.10188353061676025
[2m[36m(func pid=120822)[0m rmse_per_class: [0.163, 0.258, 0.032, 0.325, 0.053, 0.183, 0.249, 0.185, 0.253, 0.079]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.16052843630313873
[2m[36m(func pid=114403)[0m mae:  0.11275336891412735
[2m[36m(func pid=114403)[0m rmse_per_class: [0.105, 0.253, 0.05, 0.316, 0.055, 0.191, 0.248, 0.137, 0.152, 0.099]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2981 | Steps: 4 | Val loss: 0.2608 | Batch size: 32 | lr: 0.001 | Duration: 3.19s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3870 | Steps: 4 | Val loss: 0.3569 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.7508 | Steps: 4 | Val loss: 0.7660 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 16:45:15 (running for 00:21:12.32)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.399 |  0.161 |                   73 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.322 |  0.141 |                   68 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.374 |  0.178 |                   45 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.751 |  0.249 |                   40 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4082 | Steps: 4 | Val loss: 0.2931 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=122557)[0m rmse: 0.2487000674009323
[2m[36m(func pid=122557)[0m mae:  0.13519999384880066
[2m[36m(func pid=122557)[0m rmse_per_class: [0.356, 0.312, 0.047, 0.356, 0.136, 0.267, 0.341, 0.192, 0.266, 0.213]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=120822)[0m rmse: 0.17170050740242004
[2m[36m(func pid=120822)[0m mae:  0.09811170399188995
[2m[36m(func pid=120822)[0m rmse_per_class: [0.127, 0.227, 0.037, 0.296, 0.053, 0.173, 0.25, 0.21, 0.265, 0.079]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.13614247739315033
[2m[36m(func pid=114490)[0m mae:  0.08478040993213654
[2m[36m(func pid=114490)[0m rmse_per_class: [0.058, 0.243, 0.025, 0.234, 0.049, 0.158, 0.203, 0.112, 0.138, 0.143]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.16030944883823395
[2m[36m(func pid=114403)[0m mae:  0.11277204751968384
[2m[36m(func pid=114403)[0m rmse_per_class: [0.106, 0.253, 0.05, 0.313, 0.055, 0.189, 0.249, 0.137, 0.151, 0.1]
[2m[36m(func pid=114403)[0m 
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.6680 | Steps: 4 | Val loss: 0.6378 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3796 | Steps: 4 | Val loss: 0.3437 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2849 | Steps: 4 | Val loss: 0.2610 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=114403)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3884 | Steps: 4 | Val loss: 0.2921 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=122557)[0m rmse: 0.21913954615592957
[2m[36m(func pid=122557)[0m mae:  0.11574636399745941
[2m[36m(func pid=122557)[0m rmse_per_class: [0.171, 0.325, 0.047, 0.349, 0.159, 0.228, 0.286, 0.215, 0.136, 0.274]
[2m[36m(func pid=122557)[0m 
== Status ==
Current time: 2024-01-07 16:45:20 (running for 00:21:17.68)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=8
Bracket: Iter 75.000: -0.14999999850988388
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (12 PENDING, 4 RUNNING, 8 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00008 | RUNNING    | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.408 |  0.16  |                   74 |
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.298 |  0.136 |                   69 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.387 |  0.172 |                   46 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.219 |                   41 |
| train_c9cb4_00012 | PENDING    |                     | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 PENDING)


[2m[36m(func pid=120822)[0m rmse: 0.1663171648979187
[2m[36m(func pid=120822)[0m mae:  0.09498704969882965
[2m[36m(func pid=120822)[0m rmse_per_class: [0.082, 0.229, 0.039, 0.262, 0.054, 0.165, 0.252, 0.224, 0.261, 0.095]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.134767085313797
[2m[36m(func pid=114490)[0m mae:  0.08367399126291275
[2m[36m(func pid=114490)[0m rmse_per_class: [0.058, 0.236, 0.024, 0.229, 0.049, 0.157, 0.203, 0.122, 0.136, 0.133]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=114403)[0m rmse: 0.16002069413661957
[2m[36m(func pid=114403)[0m mae:  0.11276234686374664
[2m[36m(func pid=114403)[0m rmse_per_class: [0.106, 0.253, 0.05, 0.311, 0.055, 0.189, 0.249, 0.136, 0.151, 0.101]
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.6158 | Steps: 4 | Val loss: 0.7187 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3429 | Steps: 4 | Val loss: 0.3429 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3081 | Steps: 4 | Val loss: 0.2651 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=120822)[0m rmse: 0.16615793108940125
[2m[36m(func pid=120822)[0m mae:  0.09382224082946777
[2m[36m(func pid=120822)[0m rmse_per_class: [0.067, 0.251, 0.041, 0.255, 0.055, 0.18, 0.247, 0.195, 0.218, 0.152]
[2m[36m(func pid=122557)[0m rmse: 0.19774296879768372
[2m[36m(func pid=122557)[0m mae:  0.11230577528476715
[2m[36m(func pid=122557)[0m rmse_per_class: [0.103, 0.272, 0.04, 0.348, 0.073, 0.214, 0.417, 0.152, 0.124, 0.235]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1363377869129181
[2m[36m(func pid=114490)[0m mae:  0.08492802828550339
[2m[36m(func pid=114490)[0m rmse_per_class: [0.059, 0.233, 0.025, 0.234, 0.05, 0.158, 0.209, 0.137, 0.139, 0.12]
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.6587 | Steps: 4 | Val loss: 0.6936 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 16:45:25 (running for 00:21:23.05)
Memory usage on this node: 22.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.285 |  0.135 |                   70 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.38  |  0.166 |                   47 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.616 |  0.198 |                   42 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


== Status ==
Current time: 2024-01-07 16:45:31 (running for 00:21:28.52)
Memory usage on this node: 23.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.308 |  0.136 |                   71 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.38  |  0.166 |                   47 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.616 |  0.198 |                   42 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.22717002034187317
[2m[36m(func pid=122557)[0m mae:  0.12322697788476944
[2m[36m(func pid=122557)[0m rmse_per_class: [0.21, 0.284, 0.098, 0.367, 0.066, 0.396, 0.285, 0.222, 0.129, 0.214]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=132449)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=132449)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=132449)[0m Configuration completed!
[2m[36m(func pid=132449)[0m New optimizer parameters:
[2m[36m(func pid=132449)[0m SGD (
[2m[36m(func pid=132449)[0m Parameter Group 0
[2m[36m(func pid=132449)[0m     dampening: 0
[2m[36m(func pid=132449)[0m     differentiable: False
[2m[36m(func pid=132449)[0m     foreach: None
[2m[36m(func pid=132449)[0m     lr: 0.0001
[2m[36m(func pid=132449)[0m     maximize: False
[2m[36m(func pid=132449)[0m     momentum: 0.9
[2m[36m(func pid=132449)[0m     nesterov: False
[2m[36m(func pid=132449)[0m     weight_decay: 0.0001
[2m[36m(func pid=132449)[0m )
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3765 | Steps: 4 | Val loss: 0.3561 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.6949 | Steps: 4 | Val loss: 0.7942 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3256 | Steps: 4 | Val loss: 0.2702 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0848 | Steps: 4 | Val loss: 0.8111 | Batch size: 32 | lr: 0.0001 | Duration: 4.44s
== Status ==
Current time: 2024-01-07 16:45:36 (running for 00:21:33.53)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.308 |  0.136 |                   71 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.343 |  0.166 |                   48 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.659 |  0.227 |                   43 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=122557)[0m rmse: 0.25288623571395874
[2m[36m(func pid=122557)[0m mae:  0.13956478238105774
[2m[36m(func pid=122557)[0m rmse_per_class: [0.384, 0.308, 0.159, 0.368, 0.063, 0.335, 0.334, 0.294, 0.162, 0.123]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=120822)[0m rmse: 0.16813522577285767
[2m[36m(func pid=120822)[0m mae:  0.09584373235702515
[2m[36m(func pid=120822)[0m rmse_per_class: [0.077, 0.266, 0.042, 0.255, 0.055, 0.226, 0.245, 0.158, 0.155, 0.203]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1390150636434555
[2m[36m(func pid=114490)[0m mae:  0.08693747222423553
[2m[36m(func pid=114490)[0m rmse_per_class: [0.059, 0.224, 0.025, 0.253, 0.05, 0.159, 0.214, 0.152, 0.138, 0.116]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.17912694811820984
[2m[36m(func pid=132449)[0m mae:  0.13150641322135925
[2m[36m(func pid=132449)[0m rmse_per_class: [0.105, 0.265, 0.088, 0.325, 0.101, 0.192, 0.305, 0.154, 0.138, 0.117]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4777 | Steps: 4 | Val loss: 0.3722 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.6427 | Steps: 4 | Val loss: 0.6933 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2946 | Steps: 4 | Val loss: 0.2707 | Batch size: 32 | lr: 0.001 | Duration: 2.78s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0614 | Steps: 4 | Val loss: 0.8094 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 16:45:41 (running for 00:21:39.05)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.326 |  0.139 |                   72 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.478 |  0.172 |                   50 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.695 |  0.253 |                   44 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  1.085 |  0.179 |                    1 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.17237456142902374
[2m[36m(func pid=120822)[0m mae:  0.09944827854633331
[2m[36m(func pid=120822)[0m rmse_per_class: [0.087, 0.271, 0.041, 0.256, 0.056, 0.24, 0.244, 0.135, 0.133, 0.261]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.23508098721504211
[2m[36m(func pid=122557)[0m mae:  0.12698312103748322
[2m[36m(func pid=122557)[0m rmse_per_class: [0.266, 0.316, 0.191, 0.355, 0.062, 0.247, 0.306, 0.249, 0.275, 0.083]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.13878034055233002
[2m[36m(func pid=114490)[0m mae:  0.08721626549959183
[2m[36m(func pid=114490)[0m rmse_per_class: [0.059, 0.215, 0.026, 0.264, 0.05, 0.16, 0.215, 0.155, 0.139, 0.105]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.17967049777507782
[2m[36m(func pid=132449)[0m mae:  0.13190056383609772
[2m[36m(func pid=132449)[0m rmse_per_class: [0.105, 0.266, 0.089, 0.324, 0.103, 0.193, 0.307, 0.154, 0.138, 0.117]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4049 | Steps: 4 | Val loss: 0.3652 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.6481 | Steps: 4 | Val loss: 0.6468 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2916 | Steps: 4 | Val loss: 0.2750 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 1.0324 | Steps: 4 | Val loss: 0.8020 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 16:45:47 (running for 00:21:44.37)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.295 |  0.139 |                   73 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.405 |  0.171 |                   51 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.643 |  0.235 |                   45 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  1.061 |  0.18  |                    2 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.1707923263311386
[2m[36m(func pid=120822)[0m mae:  0.09806153923273087
[2m[36m(func pid=120822)[0m rmse_per_class: [0.086, 0.267, 0.038, 0.261, 0.055, 0.222, 0.235, 0.124, 0.129, 0.289]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.1907869577407837
[2m[36m(func pid=122557)[0m mae:  0.10618342459201813
[2m[36m(func pid=122557)[0m rmse_per_class: [0.14, 0.28, 0.105, 0.315, 0.057, 0.218, 0.302, 0.138, 0.261, 0.092]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.14037932455539703
[2m[36m(func pid=114490)[0m mae:  0.08821462094783783
[2m[36m(func pid=114490)[0m rmse_per_class: [0.059, 0.21, 0.028, 0.278, 0.05, 0.162, 0.218, 0.169, 0.136, 0.094]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.1803017556667328
[2m[36m(func pid=132449)[0m mae:  0.1323705017566681
[2m[36m(func pid=132449)[0m rmse_per_class: [0.107, 0.266, 0.089, 0.324, 0.105, 0.194, 0.309, 0.154, 0.137, 0.118]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4280 | Steps: 4 | Val loss: 0.3404 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.6304 | Steps: 4 | Val loss: 0.6398 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3005 | Steps: 4 | Val loss: 0.2726 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 1.0132 | Steps: 4 | Val loss: 0.7822 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=120822)[0m rmse: 0.16004160046577454
[2m[36m(func pid=120822)[0m mae:  0.09011359512805939
[2m[36m(func pid=120822)[0m rmse_per_class: [0.074, 0.252, 0.032, 0.27, 0.054, 0.19, 0.231, 0.118, 0.128, 0.251]
[2m[36m(func pid=120822)[0m 
== Status ==
Current time: 2024-01-07 16:45:52 (running for 00:21:49.72)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.292 |  0.14  |                   74 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.428 |  0.16  |                   52 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.648 |  0.191 |                   46 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  1.032 |  0.18  |                    3 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=122557)[0m rmse: 0.2040098011493683
[2m[36m(func pid=122557)[0m mae:  0.11624051630496979
[2m[36m(func pid=122557)[0m rmse_per_class: [0.223, 0.285, 0.062, 0.338, 0.062, 0.321, 0.28, 0.156, 0.219, 0.092]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.13948647677898407
[2m[36m(func pid=114490)[0m mae:  0.08748269826173782
[2m[36m(func pid=114490)[0m rmse_per_class: [0.059, 0.209, 0.03, 0.285, 0.051, 0.162, 0.214, 0.166, 0.134, 0.086]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.18073993921279907
[2m[36m(func pid=132449)[0m mae:  0.13272860646247864
[2m[36m(func pid=132449)[0m rmse_per_class: [0.107, 0.266, 0.089, 0.324, 0.105, 0.194, 0.309, 0.154, 0.138, 0.12]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3713 | Steps: 4 | Val loss: 0.3222 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.5953 | Steps: 4 | Val loss: 0.7037 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.3036 | Steps: 4 | Val loss: 0.2774 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.9735 | Steps: 4 | Val loss: 0.7556 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 16:45:57 (running for 00:21:54.85)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.301 |  0.139 |                   75 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.371 |  0.151 |                   53 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.63  |  0.204 |                   47 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  1.013 |  0.181 |                    4 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.15107634663581848
[2m[36m(func pid=120822)[0m mae:  0.08390443027019501
[2m[36m(func pid=120822)[0m rmse_per_class: [0.069, 0.234, 0.029, 0.261, 0.052, 0.175, 0.266, 0.116, 0.13, 0.179]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.2337941825389862
[2m[36m(func pid=122557)[0m mae:  0.1312173306941986
[2m[36m(func pid=122557)[0m rmse_per_class: [0.279, 0.282, 0.04, 0.346, 0.149, 0.293, 0.328, 0.355, 0.179, 0.087]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.14202573895454407
[2m[36m(func pid=114490)[0m mae:  0.08958698809146881
[2m[36m(func pid=114490)[0m rmse_per_class: [0.058, 0.216, 0.032, 0.304, 0.051, 0.163, 0.213, 0.165, 0.135, 0.084]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.18078644573688507
[2m[36m(func pid=132449)[0m mae:  0.132719025015831
[2m[36m(func pid=132449)[0m rmse_per_class: [0.107, 0.266, 0.089, 0.325, 0.106, 0.194, 0.309, 0.155, 0.137, 0.12]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3730 | Steps: 4 | Val loss: 0.3124 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.6095 | Steps: 4 | Val loss: 0.6303 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.9434 | Steps: 4 | Val loss: 0.7326 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.3199 | Steps: 4 | Val loss: 0.2795 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 16:46:03 (running for 00:22:00.17)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.304 |  0.142 |                   76 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.373 |  0.146 |                   54 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.595 |  0.234 |                   48 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.974 |  0.181 |                    5 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.14603257179260254
[2m[36m(func pid=120822)[0m mae:  0.08081220090389252
[2m[36m(func pid=120822)[0m rmse_per_class: [0.107, 0.217, 0.028, 0.261, 0.052, 0.174, 0.254, 0.115, 0.135, 0.117]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.2192772626876831
[2m[36m(func pid=122557)[0m mae:  0.11858701705932617
[2m[36m(func pid=122557)[0m rmse_per_class: [0.17, 0.293, 0.044, 0.351, 0.227, 0.258, 0.31, 0.295, 0.158, 0.086]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.1808137446641922
[2m[36m(func pid=132449)[0m mae:  0.1327606588602066
[2m[36m(func pid=132449)[0m rmse_per_class: [0.107, 0.266, 0.089, 0.324, 0.105, 0.194, 0.31, 0.155, 0.137, 0.121]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1433931142091751
[2m[36m(func pid=114490)[0m mae:  0.0906105488538742
[2m[36m(func pid=114490)[0m rmse_per_class: [0.059, 0.217, 0.035, 0.312, 0.051, 0.166, 0.214, 0.161, 0.138, 0.081]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3228 | Steps: 4 | Val loss: 0.3261 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.5709 | Steps: 4 | Val loss: 0.5741 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.9041 | Steps: 4 | Val loss: 0.7069 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2990 | Steps: 4 | Val loss: 0.2805 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 16:46:08 (running for 00:22:05.43)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.32  |  0.143 |                   77 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.323 |  0.15  |                   55 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.61  |  0.219 |                   49 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.943 |  0.181 |                    6 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.15027853846549988
[2m[36m(func pid=120822)[0m mae:  0.08421175181865692
[2m[36m(func pid=120822)[0m rmse_per_class: [0.159, 0.252, 0.027, 0.272, 0.059, 0.178, 0.226, 0.116, 0.135, 0.078]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.17855462431907654
[2m[36m(func pid=122557)[0m mae:  0.10122672468423843
[2m[36m(func pid=122557)[0m rmse_per_class: [0.104, 0.267, 0.048, 0.305, 0.078, 0.253, 0.31, 0.147, 0.13, 0.142]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.18098175525665283
[2m[36m(func pid=132449)[0m mae:  0.13284537196159363
[2m[36m(func pid=132449)[0m rmse_per_class: [0.108, 0.267, 0.089, 0.324, 0.106, 0.194, 0.31, 0.155, 0.137, 0.122]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1441306620836258
[2m[36m(func pid=114490)[0m mae:  0.0911092683672905
[2m[36m(func pid=114490)[0m rmse_per_class: [0.06, 0.218, 0.036, 0.315, 0.051, 0.168, 0.215, 0.164, 0.136, 0.08]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3717 | Steps: 4 | Val loss: 0.3704 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.6631 | Steps: 4 | Val loss: 0.6968 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.8740 | Steps: 4 | Val loss: 0.6752 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.3068 | Steps: 4 | Val loss: 0.2802 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 16:46:13 (running for 00:22:10.64)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.299 |  0.144 |                   78 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.372 |  0.165 |                   56 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.571 |  0.179 |                   50 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.904 |  0.181 |                    7 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.1646769493818283
[2m[36m(func pid=120822)[0m mae:  0.09623722732067108
[2m[36m(func pid=120822)[0m rmse_per_class: [0.197, 0.315, 0.026, 0.291, 0.067, 0.187, 0.227, 0.118, 0.138, 0.079]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.21097460389137268
[2m[36m(func pid=122557)[0m mae:  0.12147269397974014
[2m[36m(func pid=122557)[0m rmse_per_class: [0.155, 0.303, 0.049, 0.335, 0.061, 0.313, 0.302, 0.179, 0.137, 0.275]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.18097934126853943
[2m[36m(func pid=132449)[0m mae:  0.13284525275230408
[2m[36m(func pid=132449)[0m rmse_per_class: [0.107, 0.267, 0.087, 0.324, 0.104, 0.195, 0.31, 0.156, 0.137, 0.123]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.14488105475902557
[2m[36m(func pid=114490)[0m mae:  0.09154372662305832
[2m[36m(func pid=114490)[0m rmse_per_class: [0.059, 0.222, 0.04, 0.314, 0.051, 0.17, 0.217, 0.159, 0.138, 0.079]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3676 | Steps: 4 | Val loss: 0.3690 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.7177 | Steps: 4 | Val loss: 0.8417 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.8388 | Steps: 4 | Val loss: 0.6514 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.3207 | Steps: 4 | Val loss: 0.2817 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 16:46:18 (running for 00:22:15.95)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.307 |  0.145 |                   79 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.368 |  0.165 |                   57 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.663 |  0.211 |                   51 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.874 |  0.181 |                    8 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.16537126898765564
[2m[36m(func pid=120822)[0m mae:  0.09607766568660736
[2m[36m(func pid=120822)[0m rmse_per_class: [0.17, 0.308, 0.032, 0.301, 0.082, 0.191, 0.224, 0.117, 0.144, 0.084]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.253601610660553
[2m[36m(func pid=122557)[0m mae:  0.14459261298179626
[2m[36m(func pid=122557)[0m rmse_per_class: [0.189, 0.295, 0.048, 0.362, 0.06, 0.258, 0.33, 0.37, 0.288, 0.336]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.1805146038532257
[2m[36m(func pid=132449)[0m mae:  0.13239099085330963
[2m[36m(func pid=132449)[0m rmse_per_class: [0.108, 0.267, 0.088, 0.323, 0.102, 0.194, 0.308, 0.155, 0.137, 0.123]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1458667814731598
[2m[36m(func pid=114490)[0m mae:  0.09234631806612015
[2m[36m(func pid=114490)[0m rmse_per_class: [0.06, 0.226, 0.04, 0.318, 0.051, 0.173, 0.22, 0.155, 0.137, 0.079]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3916 | Steps: 4 | Val loss: 0.3439 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.7164 | Steps: 4 | Val loss: 0.6891 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.8209 | Steps: 4 | Val loss: 0.6271 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2963 | Steps: 4 | Val loss: 0.2795 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
== Status ==
Current time: 2024-01-07 16:46:24 (running for 00:22:21.32)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.321 |  0.146 |                   80 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.392 |  0.163 |                   58 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.718 |  0.254 |                   52 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.839 |  0.181 |                    9 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.16261962056159973
[2m[36m(func pid=120822)[0m mae:  0.09238000959157944
[2m[36m(func pid=120822)[0m rmse_per_class: [0.106, 0.254, 0.054, 0.302, 0.101, 0.224, 0.22, 0.115, 0.166, 0.084]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.2192927896976471
[2m[36m(func pid=122557)[0m mae:  0.12493462860584259
[2m[36m(func pid=122557)[0m rmse_per_class: [0.109, 0.284, 0.042, 0.347, 0.057, 0.266, 0.41, 0.188, 0.33, 0.16]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.18071401119232178
[2m[36m(func pid=132449)[0m mae:  0.13252316415309906
[2m[36m(func pid=132449)[0m rmse_per_class: [0.108, 0.267, 0.09, 0.323, 0.104, 0.194, 0.309, 0.154, 0.137, 0.121]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.14537222683429718
[2m[36m(func pid=114490)[0m mae:  0.09231064468622208
[2m[36m(func pid=114490)[0m rmse_per_class: [0.059, 0.226, 0.042, 0.313, 0.05, 0.177, 0.224, 0.145, 0.14, 0.079]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3526 | Steps: 4 | Val loss: 0.3446 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.5767 | Steps: 4 | Val loss: 0.5683 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.7845 | Steps: 4 | Val loss: 0.6041 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
== Status ==
Current time: 2024-01-07 16:46:29 (running for 00:22:26.63)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.296 |  0.145 |                   81 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.353 |  0.167 |                   59 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.716 |  0.219 |                   53 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.821 |  0.181 |                   10 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.16704638302326202
[2m[36m(func pid=120822)[0m mae:  0.09697329998016357
[2m[36m(func pid=120822)[0m rmse_per_class: [0.072, 0.218, 0.076, 0.296, 0.131, 0.252, 0.22, 0.114, 0.207, 0.084]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.3045 | Steps: 4 | Val loss: 0.2752 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=122557)[0m rmse: 0.18860197067260742
[2m[36m(func pid=122557)[0m mae:  0.1073949933052063
[2m[36m(func pid=122557)[0m rmse_per_class: [0.106, 0.263, 0.044, 0.367, 0.059, 0.298, 0.315, 0.173, 0.174, 0.088]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.18077892065048218
[2m[36m(func pid=132449)[0m mae:  0.13248351216316223
[2m[36m(func pid=132449)[0m rmse_per_class: [0.108, 0.267, 0.089, 0.324, 0.104, 0.194, 0.307, 0.154, 0.138, 0.122]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.1441211998462677
[2m[36m(func pid=114490)[0m mae:  0.091525599360466
[2m[36m(func pid=114490)[0m rmse_per_class: [0.061, 0.234, 0.044, 0.299, 0.05, 0.172, 0.229, 0.132, 0.142, 0.079]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3446 | Steps: 4 | Val loss: 0.3661 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.6660 | Steps: 4 | Val loss: 0.6758 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.7657 | Steps: 4 | Val loss: 0.5838 | Batch size: 32 | lr: 0.0001 | Duration: 2.67s
== Status ==
Current time: 2024-01-07 16:46:34 (running for 00:22:32.04)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.304 |  0.144 |                   82 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.345 |  0.178 |                   60 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.577 |  0.189 |                   54 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.784 |  0.181 |                   11 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.17818813025951385
[2m[36m(func pid=120822)[0m mae:  0.10405981540679932
[2m[36m(func pid=120822)[0m rmse_per_class: [0.075, 0.24, 0.094, 0.286, 0.163, 0.236, 0.227, 0.122, 0.256, 0.082]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.2059592306613922
[2m[36m(func pid=122557)[0m mae:  0.11847950518131256
[2m[36m(func pid=122557)[0m rmse_per_class: [0.146, 0.324, 0.054, 0.342, 0.066, 0.312, 0.332, 0.269, 0.13, 0.085]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2945 | Steps: 4 | Val loss: 0.2703 | Batch size: 32 | lr: 0.001 | Duration: 3.14s
[2m[36m(func pid=132449)[0m rmse: 0.18086367845535278
[2m[36m(func pid=132449)[0m mae:  0.13252881169319153
[2m[36m(func pid=132449)[0m rmse_per_class: [0.108, 0.268, 0.09, 0.324, 0.104, 0.195, 0.308, 0.154, 0.138, 0.121]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3837 | Steps: 4 | Val loss: 0.3780 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=114490)[0m rmse: 0.1420127898454666
[2m[36m(func pid=114490)[0m mae:  0.09045631438493729
[2m[36m(func pid=114490)[0m rmse_per_class: [0.06, 0.221, 0.042, 0.285, 0.049, 0.176, 0.232, 0.127, 0.149, 0.079]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.7015 | Steps: 4 | Val loss: 0.7581 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.7465 | Steps: 4 | Val loss: 0.5633 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 16:46:40 (running for 00:22:37.25)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.295 |  0.142 |                   83 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.384 |  0.184 |                   61 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.666 |  0.206 |                   55 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.766 |  0.181 |                   12 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.18421536684036255
[2m[36m(func pid=120822)[0m mae:  0.10600769519805908
[2m[36m(func pid=120822)[0m rmse_per_class: [0.08, 0.265, 0.089, 0.279, 0.171, 0.197, 0.231, 0.179, 0.259, 0.093]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.23584601283073425
[2m[36m(func pid=122557)[0m mae:  0.13428285717964172
[2m[36m(func pid=122557)[0m rmse_per_class: [0.3, 0.294, 0.059, 0.37, 0.138, 0.311, 0.315, 0.349, 0.136, 0.086]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.18090364336967468
[2m[36m(func pid=132449)[0m mae:  0.13257378339767456
[2m[36m(func pid=132449)[0m rmse_per_class: [0.109, 0.268, 0.09, 0.323, 0.103, 0.195, 0.308, 0.154, 0.138, 0.121]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2863 | Steps: 4 | Val loss: 0.2669 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3747 | Steps: 4 | Val loss: 0.3860 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=114490)[0m rmse: 0.140801340341568
[2m[36m(func pid=114490)[0m mae:  0.08955235034227371
[2m[36m(func pid=114490)[0m rmse_per_class: [0.063, 0.213, 0.045, 0.274, 0.049, 0.177, 0.233, 0.121, 0.151, 0.082]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.7216 | Steps: 4 | Val loss: 0.7196 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7198 | Steps: 4 | Val loss: 0.5488 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 16:46:45 (running for 00:22:42.70)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.286 |  0.141 |                   84 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.375 |  0.19  |                   62 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.701 |  0.236 |                   56 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.747 |  0.181 |                   13 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.18961523473262787
[2m[36m(func pid=120822)[0m mae:  0.10721465200185776
[2m[36m(func pid=120822)[0m rmse_per_class: [0.08, 0.28, 0.084, 0.27, 0.168, 0.192, 0.233, 0.232, 0.225, 0.132]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.2177431583404541
[2m[36m(func pid=122557)[0m mae:  0.12343315780162811
[2m[36m(func pid=122557)[0m rmse_per_class: [0.14, 0.291, 0.068, 0.37, 0.143, 0.293, 0.44, 0.16, 0.188, 0.085]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.18053987622261047
[2m[36m(func pid=132449)[0m mae:  0.132346510887146
[2m[36m(func pid=132449)[0m rmse_per_class: [0.109, 0.268, 0.089, 0.323, 0.1, 0.194, 0.308, 0.154, 0.138, 0.121]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2891 | Steps: 4 | Val loss: 0.2661 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3691 | Steps: 4 | Val loss: 0.3957 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=114490)[0m rmse: 0.1404820829629898
[2m[36m(func pid=114490)[0m mae:  0.0894479751586914
[2m[36m(func pid=114490)[0m rmse_per_class: [0.063, 0.211, 0.049, 0.269, 0.049, 0.174, 0.232, 0.117, 0.157, 0.083]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.7020 | Steps: 4 | Val loss: 0.7335 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.6970 | Steps: 4 | Val loss: 0.5372 | Batch size: 32 | lr: 0.0001 | Duration: 2.71s
== Status ==
Current time: 2024-01-07 16:46:50 (running for 00:22:47.99)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.289 |  0.14  |                   85 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.369 |  0.194 |                   63 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.722 |  0.218 |                   57 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.72  |  0.181 |                   14 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.19378021359443665
[2m[36m(func pid=120822)[0m mae:  0.10720992088317871
[2m[36m(func pid=120822)[0m rmse_per_class: [0.073, 0.287, 0.073, 0.271, 0.162, 0.195, 0.237, 0.221, 0.188, 0.229]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.18070277571678162
[2m[36m(func pid=132449)[0m mae:  0.13245847821235657
[2m[36m(func pid=132449)[0m rmse_per_class: [0.109, 0.268, 0.091, 0.324, 0.1, 0.194, 0.308, 0.153, 0.138, 0.122]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.2331780195236206
[2m[36m(func pid=122557)[0m mae:  0.13557098805904388
[2m[36m(func pid=122557)[0m rmse_per_class: [0.117, 0.289, 0.055, 0.346, 0.085, 0.337, 0.316, 0.171, 0.477, 0.138]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2972 | Steps: 4 | Val loss: 0.2616 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3771 | Steps: 4 | Val loss: 0.3907 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.5564 | Steps: 4 | Val loss: 0.7561 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.6757 | Steps: 4 | Val loss: 0.5216 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=114490)[0m rmse: 0.138289213180542
[2m[36m(func pid=114490)[0m mae:  0.08806648850440979
[2m[36m(func pid=114490)[0m rmse_per_class: [0.065, 0.209, 0.047, 0.254, 0.049, 0.165, 0.227, 0.117, 0.164, 0.087]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:46:56 (running for 00:22:53.22)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.297 |  0.138 |                   86 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.377 |  0.189 |                   64 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.702 |  0.233 |                   58 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.697 |  0.181 |                   15 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.18923646211624146
[2m[36m(func pid=120822)[0m mae:  0.1059499979019165
[2m[36m(func pid=120822)[0m rmse_per_class: [0.074, 0.284, 0.048, 0.276, 0.135, 0.196, 0.242, 0.168, 0.152, 0.318]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.20397433638572693
[2m[36m(func pid=122557)[0m mae:  0.11873354017734528
[2m[36m(func pid=122557)[0m rmse_per_class: [0.138, 0.262, 0.047, 0.344, 0.057, 0.227, 0.347, 0.216, 0.194, 0.208]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.1804279386997223
[2m[36m(func pid=132449)[0m mae:  0.13210734724998474
[2m[36m(func pid=132449)[0m rmse_per_class: [0.108, 0.268, 0.09, 0.323, 0.101, 0.194, 0.306, 0.152, 0.138, 0.122]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2772 | Steps: 4 | Val loss: 0.2578 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3978 | Steps: 4 | Val loss: 0.3742 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.7450 | Steps: 4 | Val loss: 0.6997 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.6551 | Steps: 4 | Val loss: 0.5129 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=114490)[0m rmse: 0.13576647639274597
[2m[36m(func pid=114490)[0m mae:  0.08635355532169342
[2m[36m(func pid=114490)[0m rmse_per_class: [0.064, 0.206, 0.046, 0.241, 0.05, 0.164, 0.224, 0.112, 0.164, 0.085]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:47:01 (running for 00:22:58.62)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.277 |  0.136 |                   87 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.398 |  0.181 |                   65 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.556 |  0.204 |                   59 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.676 |  0.18  |                   16 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.1814277470111847
[2m[36m(func pid=120822)[0m mae:  0.10289746522903442
[2m[36m(func pid=120822)[0m rmse_per_class: [0.107, 0.276, 0.032, 0.275, 0.098, 0.197, 0.239, 0.121, 0.128, 0.341]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.1804332435131073
[2m[36m(func pid=132449)[0m mae:  0.13220158219337463
[2m[36m(func pid=132449)[0m rmse_per_class: [0.109, 0.268, 0.09, 0.324, 0.1, 0.194, 0.307, 0.153, 0.139, 0.122]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.21496446430683136
[2m[36m(func pid=122557)[0m mae:  0.12245406955480576
[2m[36m(func pid=122557)[0m rmse_per_class: [0.169, 0.296, 0.051, 0.324, 0.057, 0.233, 0.312, 0.277, 0.133, 0.299]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2830 | Steps: 4 | Val loss: 0.2565 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3557 | Steps: 4 | Val loss: 0.3489 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.6495 | Steps: 4 | Val loss: 0.5006 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.5675 | Steps: 4 | Val loss: 0.7791 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=114490)[0m rmse: 0.13467849791049957
[2m[36m(func pid=114490)[0m mae:  0.08517754822969437
[2m[36m(func pid=114490)[0m rmse_per_class: [0.065, 0.212, 0.037, 0.236, 0.05, 0.162, 0.217, 0.111, 0.163, 0.094]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:47:06 (running for 00:23:03.89)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.283 |  0.135 |                   88 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.356 |  0.178 |                   66 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.745 |  0.215 |                   60 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.655 |  0.18  |                   17 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.1775955855846405
[2m[36m(func pid=120822)[0m mae:  0.10166548192501068
[2m[36m(func pid=120822)[0m rmse_per_class: [0.23, 0.254, 0.026, 0.267, 0.072, 0.198, 0.231, 0.117, 0.123, 0.258]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.1805315911769867
[2m[36m(func pid=132449)[0m mae:  0.13223710656166077
[2m[36m(func pid=132449)[0m rmse_per_class: [0.109, 0.268, 0.09, 0.324, 0.1, 0.194, 0.306, 0.152, 0.139, 0.122]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.21495573222637177
[2m[36m(func pid=122557)[0m mae:  0.12191858142614365
[2m[36m(func pid=122557)[0m rmse_per_class: [0.129, 0.324, 0.049, 0.379, 0.056, 0.249, 0.449, 0.147, 0.132, 0.236]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2933 | Steps: 4 | Val loss: 0.2588 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3657 | Steps: 4 | Val loss: 0.3288 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.7002 | Steps: 4 | Val loss: 0.8941 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.6310 | Steps: 4 | Val loss: 0.4908 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=114490)[0m rmse: 0.13680407404899597
[2m[36m(func pid=114490)[0m mae:  0.08622560650110245
[2m[36m(func pid=114490)[0m rmse_per_class: [0.066, 0.222, 0.038, 0.233, 0.053, 0.162, 0.213, 0.108, 0.167, 0.106]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:47:12 (running for 00:23:09.14)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.293 |  0.137 |                   89 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.366 |  0.166 |                   67 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.568 |  0.215 |                   61 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.649 |  0.181 |                   18 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.16586557030677795
[2m[36m(func pid=120822)[0m mae:  0.09636016190052032
[2m[36m(func pid=120822)[0m rmse_per_class: [0.25, 0.226, 0.035, 0.263, 0.054, 0.207, 0.214, 0.13, 0.123, 0.156]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.2399340569972992
[2m[36m(func pid=122557)[0m mae:  0.13752412796020508
[2m[36m(func pid=122557)[0m rmse_per_class: [0.325, 0.32, 0.045, 0.385, 0.06, 0.475, 0.315, 0.183, 0.142, 0.151]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.18017809092998505
[2m[36m(func pid=132449)[0m mae:  0.1319275051355362
[2m[36m(func pid=132449)[0m rmse_per_class: [0.109, 0.268, 0.088, 0.324, 0.1, 0.194, 0.305, 0.151, 0.139, 0.123]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2834 | Steps: 4 | Val loss: 0.2620 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3546 | Steps: 4 | Val loss: 0.3177 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.8552 | Steps: 4 | Val loss: 0.8219 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.6160 | Steps: 4 | Val loss: 0.4823 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=114490)[0m rmse: 0.13896867632865906
[2m[36m(func pid=114490)[0m mae:  0.08781975507736206
[2m[36m(func pid=114490)[0m rmse_per_class: [0.064, 0.232, 0.04, 0.233, 0.057, 0.161, 0.21, 0.11, 0.171, 0.111]
[2m[36m(func pid=114490)[0m 
== Status ==
Current time: 2024-01-07 16:47:17 (running for 00:23:14.48)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.283 |  0.139 |                   90 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.355 |  0.154 |                   68 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.7   |  0.24  |                   62 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.631 |  0.18  |                   19 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.15374363958835602
[2m[36m(func pid=120822)[0m mae:  0.08889192342758179
[2m[36m(func pid=120822)[0m rmse_per_class: [0.171, 0.218, 0.039, 0.275, 0.053, 0.209, 0.209, 0.136, 0.123, 0.103]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.18007811903953552
[2m[36m(func pid=132449)[0m mae:  0.13184228539466858
[2m[36m(func pid=132449)[0m rmse_per_class: [0.108, 0.267, 0.087, 0.324, 0.1, 0.194, 0.305, 0.153, 0.139, 0.122]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.24568407237529755
[2m[36m(func pid=122557)[0m mae:  0.14159396290779114
[2m[36m(func pid=122557)[0m rmse_per_class: [0.393, 0.32, 0.043, 0.372, 0.102, 0.351, 0.326, 0.193, 0.266, 0.09]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.3063 | Steps: 4 | Val loss: 0.2648 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3574 | Steps: 4 | Val loss: 0.3448 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.6055 | Steps: 4 | Val loss: 0.4700 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.6101 | Steps: 4 | Val loss: 0.6902 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 16:47:22 (running for 00:23:19.59)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.306 |  0.141 |                   91 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.355 |  0.154 |                   68 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.855 |  0.246 |                   63 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.616 |  0.18  |                   20 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=114490)[0m rmse: 0.14102505147457123
[2m[36m(func pid=114490)[0m mae:  0.08915693312883377
[2m[36m(func pid=114490)[0m rmse_per_class: [0.063, 0.234, 0.04, 0.235, 0.062, 0.162, 0.213, 0.112, 0.165, 0.124]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m rmse: 0.15248382091522217
[2m[36m(func pid=120822)[0m mae:  0.08935317397117615
[2m[36m(func pid=120822)[0m rmse_per_class: [0.073, 0.29, 0.042, 0.293, 0.054, 0.21, 0.218, 0.135, 0.13, 0.081]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.18030068278312683
[2m[36m(func pid=132449)[0m mae:  0.13194355368614197
[2m[36m(func pid=132449)[0m rmse_per_class: [0.108, 0.268, 0.089, 0.325, 0.101, 0.194, 0.305, 0.153, 0.139, 0.12]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.20588994026184082
[2m[36m(func pid=122557)[0m mae:  0.11684759706258774
[2m[36m(func pid=122557)[0m rmse_per_class: [0.139, 0.305, 0.046, 0.315, 0.158, 0.219, 0.285, 0.179, 0.32, 0.092]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2895 | Steps: 4 | Val loss: 0.2666 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3845 | Steps: 4 | Val loss: 0.3583 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.5923 | Steps: 4 | Val loss: 0.4623 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.6405 | Steps: 4 | Val loss: 0.6796 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 16:47:28 (running for 00:23:25.14)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.306 |  0.141 |                   91 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.385 |  0.159 |                   70 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.61  |  0.206 |                   64 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.605 |  0.18  |                   21 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=114490)[0m rmse: 0.1418258398771286
[2m[36m(func pid=114490)[0m mae:  0.08943700790405273
[2m[36m(func pid=114490)[0m rmse_per_class: [0.061, 0.237, 0.038, 0.238, 0.069, 0.162, 0.21, 0.116, 0.155, 0.132]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m rmse: 0.15916664898395538
[2m[36m(func pid=120822)[0m mae:  0.09420496225357056
[2m[36m(func pid=120822)[0m rmse_per_class: [0.079, 0.333, 0.043, 0.297, 0.054, 0.207, 0.224, 0.121, 0.152, 0.082]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.1804378479719162
[2m[36m(func pid=132449)[0m mae:  0.1321530044078827
[2m[36m(func pid=132449)[0m rmse_per_class: [0.108, 0.268, 0.09, 0.325, 0.099, 0.194, 0.306, 0.152, 0.14, 0.121]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.17965646088123322
[2m[36m(func pid=122557)[0m mae:  0.10318392515182495
[2m[36m(func pid=122557)[0m rmse_per_class: [0.097, 0.276, 0.047, 0.316, 0.096, 0.212, 0.271, 0.137, 0.198, 0.147]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3716 | Steps: 4 | Val loss: 0.3647 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2909 | Steps: 4 | Val loss: 0.2668 | Batch size: 32 | lr: 0.001 | Duration: 3.25s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.5837 | Steps: 4 | Val loss: 0.4531 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.5530 | Steps: 4 | Val loss: 0.7353 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 16:47:33 (running for 00:23:30.33)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.289 |  0.142 |                   92 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.372 |  0.169 |                   71 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.64  |  0.18  |                   65 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.592 |  0.18  |                   22 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.16902165114879608
[2m[36m(func pid=120822)[0m mae:  0.09882847964763641
[2m[36m(func pid=120822)[0m rmse_per_class: [0.09, 0.319, 0.041, 0.305, 0.054, 0.191, 0.238, 0.139, 0.231, 0.083]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.18050986528396606
[2m[36m(func pid=132449)[0m mae:  0.13214583694934845
[2m[36m(func pid=132449)[0m rmse_per_class: [0.109, 0.269, 0.09, 0.325, 0.1, 0.194, 0.306, 0.152, 0.14, 0.121]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.14113613963127136
[2m[36m(func pid=114490)[0m mae:  0.0883856788277626
[2m[36m(func pid=114490)[0m rmse_per_class: [0.06, 0.244, 0.032, 0.237, 0.067, 0.162, 0.204, 0.114, 0.146, 0.146]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.23299594223499298
[2m[36m(func pid=122557)[0m mae:  0.12897978723049164
[2m[36m(func pid=122557)[0m rmse_per_class: [0.222, 0.312, 0.046, 0.326, 0.074, 0.34, 0.318, 0.189, 0.162, 0.34]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4014 | Steps: 4 | Val loss: 0.3753 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.5758 | Steps: 4 | Val loss: 0.4462 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2951 | Steps: 4 | Val loss: 0.2668 | Batch size: 32 | lr: 0.001 | Duration: 3.13s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.6318 | Steps: 4 | Val loss: 0.9636 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 16:47:38 (running for 00:23:35.56)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.291 |  0.141 |                   93 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.401 |  0.181 |                   72 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.553 |  0.233 |                   66 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.584 |  0.181 |                   23 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.1805284321308136
[2m[36m(func pid=120822)[0m mae:  0.10681424289941788
[2m[36m(func pid=120822)[0m rmse_per_class: [0.091, 0.267, 0.04, 0.299, 0.054, 0.179, 0.261, 0.228, 0.3, 0.084]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.18022006750106812
[2m[36m(func pid=132449)[0m mae:  0.13187289237976074
[2m[36m(func pid=132449)[0m rmse_per_class: [0.108, 0.269, 0.088, 0.325, 0.1, 0.194, 0.305, 0.152, 0.14, 0.121]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.2500557601451874
[2m[36m(func pid=122557)[0m mae:  0.14405810832977295
[2m[36m(func pid=122557)[0m rmse_per_class: [0.411, 0.308, 0.045, 0.363, 0.057, 0.34, 0.319, 0.17, 0.136, 0.351]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.14122626185417175
[2m[36m(func pid=114490)[0m mae:  0.0884350910782814
[2m[36m(func pid=114490)[0m rmse_per_class: [0.058, 0.247, 0.033, 0.235, 0.071, 0.161, 0.203, 0.112, 0.142, 0.15]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3564 | Steps: 4 | Val loss: 0.3781 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.5668 | Steps: 4 | Val loss: 0.4370 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.6992 | Steps: 4 | Val loss: 1.0073 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2853 | Steps: 4 | Val loss: 0.2666 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 16:47:43 (running for 00:23:40.83)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.295 |  0.141 |                   94 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.356 |  0.184 |                   73 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.632 |  0.25  |                   67 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.576 |  0.18  |                   24 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.18435439467430115
[2m[36m(func pid=120822)[0m mae:  0.11077697575092316
[2m[36m(func pid=120822)[0m rmse_per_class: [0.086, 0.233, 0.039, 0.291, 0.053, 0.181, 0.267, 0.303, 0.303, 0.086]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.18038681149482727
[2m[36m(func pid=132449)[0m mae:  0.1319623589515686
[2m[36m(func pid=132449)[0m rmse_per_class: [0.109, 0.269, 0.092, 0.325, 0.101, 0.194, 0.304, 0.15, 0.14, 0.12]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.23169109225273132
[2m[36m(func pid=122557)[0m mae:  0.13345026969909668
[2m[36m(func pid=122557)[0m rmse_per_class: [0.156, 0.306, 0.044, 0.379, 0.056, 0.247, 0.533, 0.154, 0.157, 0.285]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.14128577709197998
[2m[36m(func pid=114490)[0m mae:  0.08825810253620148
[2m[36m(func pid=114490)[0m rmse_per_class: [0.058, 0.242, 0.033, 0.238, 0.085, 0.163, 0.204, 0.114, 0.14, 0.138]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4107 | Steps: 4 | Val loss: 0.3686 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.5600 | Steps: 4 | Val loss: 0.4320 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.6447 | Steps: 4 | Val loss: 0.8708 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2997 | Steps: 4 | Val loss: 0.2657 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 16:47:49 (running for 00:23:46.14)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=9
Bracket: Iter 75.000: -0.14274999871850014
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 4 RUNNING, 9 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.285 |  0.141 |                   95 |
| train_c9cb4_00010 | RUNNING    | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.411 |  0.177 |                   74 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.699 |  0.232 |                   68 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.567 |  0.18  |                   25 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (3 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.177313894033432
[2m[36m(func pid=120822)[0m mae:  0.10666953027248383
[2m[36m(func pid=120822)[0m rmse_per_class: [0.079, 0.241, 0.036, 0.281, 0.052, 0.185, 0.246, 0.288, 0.277, 0.089]
[2m[36m(func pid=120822)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.18021973967552185
[2m[36m(func pid=132449)[0m mae:  0.13182903826236725
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.269, 0.091, 0.325, 0.1, 0.194, 0.304, 0.15, 0.139, 0.121]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.2425694763660431
[2m[36m(func pid=122557)[0m mae:  0.13682058453559875
[2m[36m(func pid=122557)[0m rmse_per_class: [0.098, 0.323, 0.056, 0.369, 0.056, 0.302, 0.337, 0.291, 0.382, 0.213]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.14092649519443512
[2m[36m(func pid=114490)[0m mae:  0.08784400671720505
[2m[36m(func pid=114490)[0m rmse_per_class: [0.059, 0.234, 0.031, 0.24, 0.09, 0.163, 0.205, 0.115, 0.137, 0.136]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=120822)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3442 | Steps: 4 | Val loss: 0.3438 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.5490 | Steps: 4 | Val loss: 0.4276 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.6834 | Steps: 4 | Val loss: 0.8313 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2904 | Steps: 4 | Val loss: 0.2628 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 16:47:54 (running for 00:23:51.36)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (11 PENDING, 3 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.3   |  0.141 |                   96 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.645 |  0.243 |                   69 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.56  |  0.18  |                   26 |
| train_c9cb4_00013 | PENDING    |                     | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 1 TERMINATED)


[2m[36m(func pid=120822)[0m rmse: 0.1609179675579071
[2m[36m(func pid=120822)[0m mae:  0.09535543620586395
[2m[36m(func pid=120822)[0m rmse_per_class: [0.069, 0.257, 0.034, 0.27, 0.054, 0.194, 0.244, 0.188, 0.201, 0.098]
[2m[36m(func pid=122557)[0m rmse: 0.21712429821491241
[2m[36m(func pid=122557)[0m mae:  0.1289287507534027
[2m[36m(func pid=122557)[0m rmse_per_class: [0.088, 0.34, 0.049, 0.334, 0.056, 0.268, 0.334, 0.239, 0.338, 0.125]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.18015959858894348
[2m[36m(func pid=132449)[0m mae:  0.13178879022598267
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.269, 0.092, 0.326, 0.096, 0.194, 0.303, 0.15, 0.139, 0.122]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.14023227989673615
[2m[36m(func pid=114490)[0m mae:  0.08714853227138519
[2m[36m(func pid=114490)[0m rmse_per_class: [0.058, 0.231, 0.033, 0.233, 0.096, 0.163, 0.202, 0.111, 0.138, 0.139]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.5383 | Steps: 4 | Val loss: 0.4260 | Batch size: 32 | lr: 0.0001 | Duration: 2.62s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.6835 | Steps: 4 | Val loss: 0.6693 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2844 | Steps: 4 | Val loss: 0.2613 | Batch size: 32 | lr: 0.001 | Duration: 3.14s
[2m[36m(func pid=132449)[0m rmse: 0.1796523779630661
[2m[36m(func pid=132449)[0m mae:  0.1314423680305481
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.268, 0.092, 0.325, 0.096, 0.194, 0.303, 0.15, 0.14, 0.12]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=122557)[0m rmse: 0.19169583916664124
[2m[36m(func pid=122557)[0m mae:  0.109430231153965
[2m[36m(func pid=122557)[0m rmse_per_class: [0.173, 0.274, 0.034, 0.35, 0.071, 0.215, 0.294, 0.147, 0.228, 0.131]
[2m[36m(func pid=114490)[0m rmse: 0.1389685422182083
[2m[36m(func pid=114490)[0m mae:  0.08591385185718536
[2m[36m(func pid=114490)[0m rmse_per_class: [0.058, 0.232, 0.029, 0.23, 0.094, 0.162, 0.2, 0.109, 0.135, 0.142]
== Status ==
Current time: 2024-01-07 16:48:00 (running for 00:23:57.25)
Memory usage on this node: 22.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.29  |  0.14  |                   97 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.683 |  0.217 |                   70 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.538 |  0.18  |                   28 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=139223)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=139223)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=139223)[0m Configuration completed!
[2m[36m(func pid=139223)[0m New optimizer parameters:
[2m[36m(func pid=139223)[0m SGD (
[2m[36m(func pid=139223)[0m Parameter Group 0
[2m[36m(func pid=139223)[0m     dampening: 0
[2m[36m(func pid=139223)[0m     differentiable: False
[2m[36m(func pid=139223)[0m     foreach: None
[2m[36m(func pid=139223)[0m     lr: 0.001
[2m[36m(func pid=139223)[0m     maximize: False
[2m[36m(func pid=139223)[0m     momentum: 0.9
[2m[36m(func pid=139223)[0m     nesterov: False
[2m[36m(func pid=139223)[0m     weight_decay: 0.0001
[2m[36m(func pid=139223)[0m )
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.5366 | Steps: 4 | Val loss: 0.4184 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 16:48:05 (running for 00:24:02.65)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.284 |  0.139 |                   98 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.684 |  0.192 |                   71 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.537 |  0.18  |                   29 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.17982889711856842
[2m[36m(func pid=132449)[0m mae:  0.1315324753522873
[2m[36m(func pid=132449)[0m rmse_per_class: [0.109, 0.269, 0.091, 0.326, 0.097, 0.194, 0.302, 0.148, 0.14, 0.121]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2787 | Steps: 4 | Val loss: 0.2599 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.6554 | Steps: 4 | Val loss: 0.7075 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0563 | Steps: 4 | Val loss: 0.7516 | Batch size: 32 | lr: 0.001 | Duration: 4.47s
[2m[36m(func pid=122557)[0m rmse: 0.20238688588142395
[2m[36m(func pid=122557)[0m mae:  0.11044599115848541
[2m[36m(func pid=122557)[0m rmse_per_class: [0.137, 0.298, 0.035, 0.37, 0.118, 0.222, 0.364, 0.143, 0.154, 0.183]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=114490)[0m rmse: 0.13825193047523499
[2m[36m(func pid=114490)[0m mae:  0.0854133814573288
[2m[36m(func pid=114490)[0m rmse_per_class: [0.058, 0.226, 0.029, 0.232, 0.095, 0.163, 0.201, 0.108, 0.133, 0.138]
[2m[36m(func pid=114490)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.5270 | Steps: 4 | Val loss: 0.4115 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=139223)[0m rmse: 0.17889879643917084
[2m[36m(func pid=139223)[0m mae:  0.13131144642829895
[2m[36m(func pid=139223)[0m rmse_per_class: [0.104, 0.265, 0.088, 0.325, 0.101, 0.192, 0.305, 0.155, 0.139, 0.115]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.17948278784751892
[2m[36m(func pid=132449)[0m mae:  0.1312256008386612
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.269, 0.091, 0.325, 0.097, 0.194, 0.301, 0.147, 0.141, 0.121]
[2m[36m(func pid=132449)[0m 
== Status ==
Current time: 2024-01-07 16:48:10 (running for 00:24:07.90)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=10
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (10 PENDING, 4 RUNNING, 10 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00009 | RUNNING    | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.279 |  0.138 |                   99 |
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.655 |  0.202 |                   72 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.527 |  0.179 |                   30 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  1.056 |  0.179 |                    1 |
| train_c9cb4_00014 | PENDING    |                     | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (2 PENDING, 2 TERMINATED)


[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.6630 | Steps: 4 | Val loss: 0.8229 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=114490)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2779 | Steps: 4 | Val loss: 0.2600 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.9196 | Steps: 4 | Val loss: 0.6432 | Batch size: 32 | lr: 0.001 | Duration: 2.72s
[2m[36m(func pid=122557)[0m rmse: 0.23965784907341003
[2m[36m(func pid=122557)[0m mae:  0.13207125663757324
[2m[36m(func pid=122557)[0m rmse_per_class: [0.122, 0.302, 0.044, 0.332, 0.167, 0.456, 0.347, 0.24, 0.144, 0.243]
[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.5244 | Steps: 4 | Val loss: 0.4082 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=114490)[0m rmse: 0.1379188448190689
[2m[36m(func pid=114490)[0m mae:  0.08509880304336548
[2m[36m(func pid=114490)[0m rmse_per_class: [0.058, 0.227, 0.028, 0.234, 0.091, 0.163, 0.203, 0.109, 0.134, 0.132]
[2m[36m(func pid=139223)[0m rmse: 0.17931102216243744
[2m[36m(func pid=139223)[0m mae:  0.13143424689769745
[2m[36m(func pid=139223)[0m rmse_per_class: [0.105, 0.266, 0.089, 0.325, 0.101, 0.193, 0.305, 0.157, 0.138, 0.116]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.17970597743988037
[2m[36m(func pid=132449)[0m mae:  0.1314316838979721
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.268, 0.093, 0.327, 0.097, 0.194, 0.301, 0.148, 0.141, 0.119]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.7161 | Steps: 4 | Val loss: 0.9142 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.7325 | Steps: 4 | Val loss: 0.5195 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=122557)[0m rmse: 0.2372131049633026
[2m[36m(func pid=122557)[0m mae:  0.13832591474056244
[2m[36m(func pid=122557)[0m rmse_per_class: [0.117, 0.299, 0.046, 0.372, 0.092, 0.426, 0.332, 0.346, 0.132, 0.21]
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.5177 | Steps: 4 | Val loss: 0.4028 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=139223)[0m rmse: 0.179428368806839
[2m[36m(func pid=139223)[0m mae:  0.13133788108825684
[2m[36m(func pid=139223)[0m rmse_per_class: [0.106, 0.267, 0.09, 0.326, 0.098, 0.194, 0.303, 0.158, 0.139, 0.115]
[2m[36m(func pid=132449)[0m rmse: 0.17936165630817413
[2m[36m(func pid=132449)[0m mae:  0.13114318251609802
[2m[36m(func pid=132449)[0m rmse_per_class: [0.109, 0.268, 0.092, 0.327, 0.095, 0.194, 0.3, 0.147, 0.14, 0.121]
== Status ==
Current time: 2024-01-07 16:48:16 (running for 00:24:13.21)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.663 |  0.24  |                   73 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.524 |  0.18  |                   31 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.92  |  0.179 |                    2 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=122557)[0m 
[2m[36m(func pid=140307)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=140307)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=140307)[0m Configuration completed!
[2m[36m(func pid=140307)[0m New optimizer parameters:
[2m[36m(func pid=140307)[0m SGD (
[2m[36m(func pid=140307)[0m Parameter Group 0
[2m[36m(func pid=140307)[0m     dampening: 0
[2m[36m(func pid=140307)[0m     differentiable: False
[2m[36m(func pid=140307)[0m     foreach: None
[2m[36m(func pid=140307)[0m     lr: 0.01
[2m[36m(func pid=140307)[0m     maximize: False
[2m[36m(func pid=140307)[0m     momentum: 0.9
[2m[36m(func pid=140307)[0m     nesterov: False
[2m[36m(func pid=140307)[0m     weight_decay: 0.0001
[2m[36m(func pid=140307)[0m )
== Status ==
Current time: 2024-01-07 16:48:22 (running for 00:24:19.66)
Memory usage on this node: 23.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.716 |  0.237 |                   74 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.524 |  0.18  |                   31 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.92  |  0.179 |                    2 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)

[2m[36m(func pid=140307)[0m 

[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=122557)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.6679 | Steps: 4 | Val loss: 0.9207 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.5138 | Steps: 4 | Val loss: 0.4007 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.5959 | Steps: 4 | Val loss: 0.4274 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8783 | Steps: 4 | Val loss: 0.4357 | Batch size: 32 | lr: 0.01 | Duration: 4.63s
== Status ==
Current time: 2024-01-07 16:48:27 (running for 00:24:24.68)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=11
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (9 PENDING, 4 RUNNING, 11 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00011 | RUNNING    | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.716 |  0.237 |                   74 |
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.518 |  0.179 |                   32 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.732 |  0.179 |                    3 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00015 | PENDING    |                     | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (1 PENDING, 3 TERMINATED)


[2m[36m(func pid=122557)[0m rmse: 0.22555124759674072
[2m[36m(func pid=122557)[0m mae:  0.1263456642627716
[2m[36m(func pid=122557)[0m rmse_per_class: [0.233, 0.352, 0.047, 0.383, 0.062, 0.224, 0.317, 0.202, 0.142, 0.295]
[2m[36m(func pid=139223)[0m rmse: 0.1795395016670227
[2m[36m(func pid=139223)[0m mae:  0.13114508986473083
[2m[36m(func pid=139223)[0m rmse_per_class: [0.106, 0.268, 0.094, 0.329, 0.095, 0.194, 0.299, 0.155, 0.139, 0.117]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.17928417026996613
[2m[36m(func pid=132449)[0m mae:  0.13091744482517242
[2m[36m(func pid=132449)[0m rmse_per_class: [0.109, 0.268, 0.092, 0.326, 0.097, 0.194, 0.3, 0.147, 0.139, 0.121]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.1771892011165619
[2m[36m(func pid=140307)[0m mae:  0.1295909434556961
[2m[36m(func pid=140307)[0m rmse_per_class: [0.104, 0.269, 0.088, 0.327, 0.091, 0.192, 0.294, 0.153, 0.143, 0.11]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4981 | Steps: 4 | Val loss: 0.3955 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.5068 | Steps: 4 | Val loss: 0.3696 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.4494 | Steps: 4 | Val loss: 0.3307 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=132449)[0m rmse: 0.17951862514019012
[2m[36m(func pid=132449)[0m mae:  0.1311163753271103
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.268, 0.092, 0.325, 0.097, 0.194, 0.301, 0.146, 0.14, 0.122]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.17878016829490662
[2m[36m(func pid=139223)[0m mae:  0.1303020566701889
[2m[36m(func pid=139223)[0m rmse_per_class: [0.108, 0.269, 0.095, 0.332, 0.093, 0.194, 0.293, 0.149, 0.14, 0.115]
[2m[36m(func pid=140307)[0m rmse: 0.17780020833015442
[2m[36m(func pid=140307)[0m mae:  0.12886697053909302
[2m[36m(func pid=140307)[0m rmse_per_class: [0.106, 0.273, 0.085, 0.344, 0.073, 0.192, 0.277, 0.133, 0.198, 0.097]
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.5108 | Steps: 4 | Val loss: 0.3881 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 16:48:33 (running for 00:24:30.36)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.498 |  0.18  |                   34 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.596 |  0.18  |                    4 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.878 |  0.177 |                    1 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=141107)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=141107)[0m Configuration completed!
[2m[36m(func pid=141107)[0m New optimizer parameters:
[2m[36m(func pid=141107)[0m SGD (
[2m[36m(func pid=141107)[0m Parameter Group 0
[2m[36m(func pid=141107)[0m     dampening: 0
[2m[36m(func pid=141107)[0m     differentiable: False
[2m[36m(func pid=141107)[0m     foreach: None
[2m[36m(func pid=141107)[0m     lr: 0.1
[2m[36m(func pid=141107)[0m     maximize: False
[2m[36m(func pid=141107)[0m     momentum: 0.9
[2m[36m(func pid=141107)[0m     nesterov: False
[2m[36m(func pid=141107)[0m     weight_decay: 0.0001
[2m[36m(func pid=141107)[0m )
[2m[36m(func pid=141107)[0m 
== Status ==
Current time: 2024-01-07 16:48:38 (running for 00:24:35.68)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.511 |  0.179 |                   35 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.507 |  0.179 |                    5 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.449 |  0.178 |                    2 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |        |        |                      |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.17911067605018616
[2m[36m(func pid=132449)[0m mae:  0.1306733638048172
[2m[36m(func pid=132449)[0m rmse_per_class: [0.109, 0.268, 0.092, 0.326, 0.097, 0.194, 0.298, 0.147, 0.14, 0.121]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.4812 | Steps: 4 | Val loss: 0.3701 | Batch size: 32 | lr: 0.01 | Duration: 2.68s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4618 | Steps: 4 | Val loss: 0.3437 | Batch size: 32 | lr: 0.001 | Duration: 2.80s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.6591 | Steps: 4 | Val loss: 0.4337 | Batch size: 32 | lr: 0.1 | Duration: 4.41s
[2m[36m(func pid=140307)[0m rmse: 0.1790500432252884
[2m[36m(func pid=140307)[0m mae:  0.1274682730436325
[2m[36m(func pid=140307)[0m rmse_per_class: [0.108, 0.274, 0.073, 0.351, 0.06, 0.193, 0.27, 0.137, 0.232, 0.093]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.5057 | Steps: 4 | Val loss: 0.3849 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=139223)[0m rmse: 0.17838795483112335
[2m[36m(func pid=139223)[0m mae:  0.1298823207616806
[2m[36m(func pid=139223)[0m rmse_per_class: [0.111, 0.269, 0.097, 0.333, 0.092, 0.193, 0.291, 0.144, 0.142, 0.111]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=141107)[0m rmse: 0.18191513419151306
[2m[36m(func pid=141107)[0m mae:  0.12251844257116318
[2m[36m(func pid=141107)[0m rmse_per_class: [0.097, 0.273, 0.059, 0.371, 0.055, 0.188, 0.38, 0.143, 0.159, 0.094]
[2m[36m(func pid=141107)[0m 
== Status ==
Current time: 2024-01-07 16:48:44 (running for 00:24:41.11)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.506 |  0.179 |                   36 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.462 |  0.178 |                    6 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.481 |  0.179 |                    3 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.659 |  0.182 |                    1 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.17892855405807495
[2m[36m(func pid=132449)[0m mae:  0.13055995106697083
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.268, 0.089, 0.326, 0.097, 0.193, 0.298, 0.147, 0.14, 0.12]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4332 | Steps: 4 | Val loss: 0.3323 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.5230 | Steps: 4 | Val loss: 0.3786 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.7492 | Steps: 4 | Val loss: 0.4160 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=140307)[0m rmse: 0.1745956987142563
[2m[36m(func pid=140307)[0m mae:  0.12260966002941132
[2m[36m(func pid=140307)[0m rmse_per_class: [0.108, 0.27, 0.06, 0.352, 0.056, 0.199, 0.268, 0.141, 0.199, 0.092]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4919 | Steps: 4 | Val loss: 0.3824 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=139223)[0m rmse: 0.17860856652259827
[2m[36m(func pid=139223)[0m mae:  0.12981002032756805
[2m[36m(func pid=139223)[0m rmse_per_class: [0.112, 0.269, 0.099, 0.336, 0.092, 0.193, 0.288, 0.14, 0.142, 0.114]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=141107)[0m rmse: 0.1749795377254486
[2m[36m(func pid=141107)[0m mae:  0.11669020354747772
[2m[36m(func pid=141107)[0m rmse_per_class: [0.099, 0.239, 0.049, 0.386, 0.056, 0.187, 0.328, 0.154, 0.154, 0.097]
[2m[36m(func pid=141107)[0m 
== Status ==
Current time: 2024-01-07 16:48:49 (running for 00:24:46.45)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.492 |  0.179 |                   37 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.433 |  0.179 |                    7 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.523 |  0.175 |                    4 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.749 |  0.175 |                    2 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.17910298705101013
[2m[36m(func pid=132449)[0m mae:  0.13072744011878967
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.268, 0.092, 0.327, 0.096, 0.194, 0.298, 0.145, 0.141, 0.12]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.5085 | Steps: 4 | Val loss: 0.3606 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4277 | Steps: 4 | Val loss: 0.3263 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.6295 | Steps: 4 | Val loss: 0.3025 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=140307)[0m rmse: 0.1719488650560379
[2m[36m(func pid=140307)[0m mae:  0.11915359646081924
[2m[36m(func pid=140307)[0m rmse_per_class: [0.114, 0.268, 0.053, 0.352, 0.055, 0.212, 0.264, 0.144, 0.167, 0.092]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.17796826362609863
[2m[36m(func pid=139223)[0m mae:  0.12913765013217926
[2m[36m(func pid=139223)[0m rmse_per_class: [0.114, 0.27, 0.097, 0.337, 0.091, 0.193, 0.284, 0.139, 0.142, 0.113]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4918 | Steps: 4 | Val loss: 0.3788 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=141107)[0m rmse: 0.16761377453804016
[2m[36m(func pid=141107)[0m mae:  0.11288194358348846
[2m[36m(func pid=141107)[0m rmse_per_class: [0.213, 0.253, 0.048, 0.269, 0.056, 0.176, 0.266, 0.124, 0.181, 0.09]
[2m[36m(func pid=141107)[0m 
== Status ==
Current time: 2024-01-07 16:48:54 (running for 00:24:51.79)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.492 |  0.179 |                   38 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.428 |  0.178 |                    8 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.509 |  0.172 |                    5 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.629 |  0.168 |                    3 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.17896680533885956
[2m[36m(func pid=132449)[0m mae:  0.13071198761463165
[2m[36m(func pid=132449)[0m rmse_per_class: [0.109, 0.268, 0.091, 0.327, 0.094, 0.194, 0.298, 0.146, 0.141, 0.12]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4627 | Steps: 4 | Val loss: 0.3229 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.4166 | Steps: 4 | Val loss: 0.3237 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4893 | Steps: 4 | Val loss: 0.3356 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=140307)[0m rmse: 0.16852062940597534
[2m[36m(func pid=140307)[0m mae:  0.11632213741540909
[2m[36m(func pid=140307)[0m rmse_per_class: [0.109, 0.264, 0.049, 0.342, 0.055, 0.217, 0.256, 0.141, 0.161, 0.091]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.17691001296043396
[2m[36m(func pid=139223)[0m mae:  0.12817345559597015
[2m[36m(func pid=139223)[0m rmse_per_class: [0.113, 0.269, 0.096, 0.337, 0.087, 0.194, 0.281, 0.138, 0.142, 0.113]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4867 | Steps: 4 | Val loss: 0.3773 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=141107)[0m rmse: 0.1844077855348587
[2m[36m(func pid=141107)[0m mae:  0.12256518751382828
[2m[36m(func pid=141107)[0m rmse_per_class: [0.073, 0.27, 0.048, 0.282, 0.056, 0.21, 0.246, 0.272, 0.129, 0.258]
[2m[36m(func pid=141107)[0m 
== Status ==
Current time: 2024-01-07 16:49:00 (running for 00:24:57.20)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.487 |  0.179 |                   39 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.417 |  0.177 |                    9 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.463 |  0.169 |                    6 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.489 |  0.184 |                    4 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.17872880399227142
[2m[36m(func pid=132449)[0m mae:  0.13049811124801636
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.268, 0.09, 0.327, 0.095, 0.194, 0.298, 0.146, 0.141, 0.119]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4129 | Steps: 4 | Val loss: 0.3216 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4300 | Steps: 4 | Val loss: 0.2973 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.3819 | Steps: 4 | Val loss: 0.3531 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=139223)[0m rmse: 0.17567797005176544
[2m[36m(func pid=139223)[0m mae:  0.1271219104528427
[2m[36m(func pid=139223)[0m rmse_per_class: [0.112, 0.269, 0.091, 0.336, 0.086, 0.193, 0.279, 0.136, 0.143, 0.113]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.1628219038248062
[2m[36m(func pid=140307)[0m mae:  0.11336449533700943
[2m[36m(func pid=140307)[0m rmse_per_class: [0.104, 0.258, 0.049, 0.32, 0.056, 0.201, 0.25, 0.135, 0.163, 0.092]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4875 | Steps: 4 | Val loss: 0.3744 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=141107)[0m rmse: 0.158075749874115
[2m[36m(func pid=141107)[0m mae:  0.10619399696588516
[2m[36m(func pid=141107)[0m rmse_per_class: [0.067, 0.219, 0.074, 0.381, 0.077, 0.182, 0.2, 0.14, 0.149, 0.091]
[2m[36m(func pid=141107)[0m 
== Status ==
Current time: 2024-01-07 16:49:05 (running for 00:25:02.65)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.487 |  0.179 |                   40 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.413 |  0.176 |                   10 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.43  |  0.163 |                    7 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.382 |  0.158 |                    5 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.17891451716423035
[2m[36m(func pid=132449)[0m mae:  0.13066577911376953
[2m[36m(func pid=132449)[0m rmse_per_class: [0.109, 0.268, 0.091, 0.327, 0.093, 0.194, 0.298, 0.147, 0.141, 0.121]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4160 | Steps: 4 | Val loss: 0.3209 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4152 | Steps: 4 | Val loss: 0.2879 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4113 | Steps: 4 | Val loss: 0.2837 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=139223)[0m rmse: 0.1750195324420929
[2m[36m(func pid=139223)[0m mae:  0.12663500010967255
[2m[36m(func pid=139223)[0m rmse_per_class: [0.112, 0.269, 0.087, 0.335, 0.084, 0.193, 0.279, 0.137, 0.144, 0.112]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.15671828389167786
[2m[36m(func pid=140307)[0m mae:  0.11046397686004639
[2m[36m(func pid=140307)[0m rmse_per_class: [0.098, 0.252, 0.049, 0.291, 0.055, 0.185, 0.257, 0.127, 0.153, 0.1]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4811 | Steps: 4 | Val loss: 0.3745 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=141107)[0m rmse: 0.1460762470960617
[2m[36m(func pid=141107)[0m mae:  0.09376632422208786
[2m[36m(func pid=141107)[0m rmse_per_class: [0.065, 0.221, 0.028, 0.234, 0.151, 0.202, 0.217, 0.131, 0.127, 0.085]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4140 | Steps: 4 | Val loss: 0.3207 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.3861 | Steps: 4 | Val loss: 0.2934 | Batch size: 32 | lr: 0.01 | Duration: 2.68s
== Status ==
Current time: 2024-01-07 16:49:10 (running for 00:25:08.01)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.481 |  0.18  |                   41 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.416 |  0.175 |                   11 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.415 |  0.157 |                    8 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.411 |  0.146 |                    6 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.17972485721111298
[2m[36m(func pid=132449)[0m mae:  0.1312555968761444
[2m[36m(func pid=132449)[0m rmse_per_class: [0.109, 0.27, 0.092, 0.327, 0.095, 0.194, 0.299, 0.147, 0.142, 0.122]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.3375 | Steps: 4 | Val loss: 0.2971 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=139223)[0m rmse: 0.1749005913734436
[2m[36m(func pid=139223)[0m mae:  0.12658925354480743
[2m[36m(func pid=139223)[0m rmse_per_class: [0.111, 0.268, 0.087, 0.335, 0.082, 0.193, 0.278, 0.137, 0.143, 0.116]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.1589348316192627
[2m[36m(func pid=140307)[0m mae:  0.11292865127325058
[2m[36m(func pid=140307)[0m rmse_per_class: [0.09, 0.249, 0.05, 0.285, 0.055, 0.184, 0.272, 0.131, 0.146, 0.126]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4806 | Steps: 4 | Val loss: 0.3700 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=141107)[0m rmse: 0.14939071238040924
[2m[36m(func pid=141107)[0m mae:  0.0937250554561615
[2m[36m(func pid=141107)[0m rmse_per_class: [0.1, 0.225, 0.028, 0.309, 0.053, 0.163, 0.242, 0.113, 0.139, 0.122]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4152 | Steps: 4 | Val loss: 0.3198 | Batch size: 32 | lr: 0.001 | Duration: 2.83s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3862 | Steps: 4 | Val loss: 0.2981 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 16:49:16 (running for 00:25:13.14)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.481 |  0.179 |                   42 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.414 |  0.175 |                   12 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.386 |  0.159 |                    9 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.338 |  0.149 |                    7 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.17933736741542816
[2m[36m(func pid=132449)[0m mae:  0.1309419572353363
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.269, 0.092, 0.327, 0.093, 0.194, 0.298, 0.146, 0.141, 0.123]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.3541 | Steps: 4 | Val loss: 0.2936 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=139223)[0m rmse: 0.17417211830615997
[2m[36m(func pid=139223)[0m mae:  0.12606938183307648
[2m[36m(func pid=139223)[0m rmse_per_class: [0.11, 0.268, 0.085, 0.334, 0.08, 0.193, 0.276, 0.136, 0.144, 0.115]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.16373567283153534
[2m[36m(func pid=140307)[0m mae:  0.1164637953042984
[2m[36m(func pid=140307)[0m rmse_per_class: [0.086, 0.248, 0.059, 0.289, 0.055, 0.188, 0.279, 0.142, 0.139, 0.152]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4731 | Steps: 4 | Val loss: 0.3685 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=141107)[0m rmse: 0.1537545770406723
[2m[36m(func pid=141107)[0m mae:  0.09776493161916733
[2m[36m(func pid=141107)[0m rmse_per_class: [0.059, 0.206, 0.045, 0.292, 0.053, 0.158, 0.227, 0.152, 0.258, 0.087]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4138 | Steps: 4 | Val loss: 0.3184 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3811 | Steps: 4 | Val loss: 0.2962 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 16:49:21 (running for 00:25:18.39)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.473 |  0.179 |                   43 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.415 |  0.174 |                   13 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.386 |  0.164 |                   10 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.354 |  0.154 |                    8 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.1790696680545807
[2m[36m(func pid=132449)[0m mae:  0.13074426352977753
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.269, 0.09, 0.327, 0.094, 0.194, 0.298, 0.146, 0.141, 0.121]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.3328 | Steps: 4 | Val loss: 0.3018 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=139223)[0m rmse: 0.1735740751028061
[2m[36m(func pid=139223)[0m mae:  0.1255657970905304
[2m[36m(func pid=139223)[0m rmse_per_class: [0.11, 0.267, 0.085, 0.333, 0.077, 0.193, 0.275, 0.136, 0.144, 0.115]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.164004385471344
[2m[36m(func pid=140307)[0m mae:  0.11638601869344711
[2m[36m(func pid=140307)[0m rmse_per_class: [0.084, 0.251, 0.071, 0.296, 0.057, 0.186, 0.269, 0.148, 0.144, 0.135]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4725 | Steps: 4 | Val loss: 0.3656 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=141107)[0m rmse: 0.15864655375480652
[2m[36m(func pid=141107)[0m mae:  0.09838126599788666
[2m[36m(func pid=141107)[0m rmse_per_class: [0.136, 0.212, 0.061, 0.313, 0.08, 0.203, 0.234, 0.128, 0.14, 0.08]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4096 | Steps: 4 | Val loss: 0.3161 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.3575 | Steps: 4 | Val loss: 0.2972 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 16:49:26 (running for 00:25:23.66)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.472 |  0.179 |                   44 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.414 |  0.174 |                   14 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.381 |  0.164 |                   11 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.333 |  0.159 |                    9 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.17884835600852966
[2m[36m(func pid=132449)[0m mae:  0.1304585337638855
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.269, 0.09, 0.327, 0.093, 0.194, 0.297, 0.147, 0.14, 0.121]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.2972 | Steps: 4 | Val loss: 0.2687 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=139223)[0m rmse: 0.17251162230968475
[2m[36m(func pid=139223)[0m mae:  0.12476037442684174
[2m[36m(func pid=139223)[0m rmse_per_class: [0.109, 0.267, 0.082, 0.331, 0.076, 0.192, 0.275, 0.136, 0.144, 0.114]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.163503497838974
[2m[36m(func pid=140307)[0m mae:  0.11593278497457504
[2m[36m(func pid=140307)[0m rmse_per_class: [0.082, 0.252, 0.085, 0.308, 0.068, 0.181, 0.258, 0.133, 0.163, 0.105]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4691 | Steps: 4 | Val loss: 0.3623 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=141107)[0m rmse: 0.14020206034183502
[2m[36m(func pid=141107)[0m mae:  0.08636613190174103
[2m[36m(func pid=141107)[0m rmse_per_class: [0.063, 0.207, 0.023, 0.231, 0.094, 0.164, 0.2, 0.11, 0.122, 0.188]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.4089 | Steps: 4 | Val loss: 0.3156 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.3572 | Steps: 4 | Val loss: 0.2939 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 16:49:31 (running for 00:25:28.91)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.469 |  0.179 |                   45 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.41  |  0.173 |                   15 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.357 |  0.164 |                   12 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.297 |  0.14  |                   10 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.17870743572711945
[2m[36m(func pid=132449)[0m mae:  0.13031895458698273
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.269, 0.09, 0.326, 0.093, 0.194, 0.297, 0.147, 0.141, 0.121]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3276 | Steps: 4 | Val loss: 0.2638 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=139223)[0m rmse: 0.17231842875480652
[2m[36m(func pid=139223)[0m mae:  0.12466571480035782
[2m[36m(func pid=139223)[0m rmse_per_class: [0.108, 0.267, 0.081, 0.33, 0.074, 0.193, 0.275, 0.136, 0.146, 0.113]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.16079965233802795
[2m[36m(func pid=140307)[0m mae:  0.11352851241827011
[2m[36m(func pid=140307)[0m rmse_per_class: [0.082, 0.252, 0.076, 0.312, 0.079, 0.178, 0.247, 0.124, 0.159, 0.099]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4697 | Steps: 4 | Val loss: 0.3579 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=141107)[0m rmse: 0.13724282383918762
[2m[36m(func pid=141107)[0m mae:  0.08558087795972824
[2m[36m(func pid=141107)[0m rmse_per_class: [0.06, 0.206, 0.024, 0.232, 0.059, 0.156, 0.234, 0.126, 0.197, 0.079]
[2m[36m(func pid=141107)[0m 
== Status ==
Current time: 2024-01-07 16:49:36 (running for 00:25:34.08)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.47  |  0.178 |                   46 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.409 |  0.172 |                   16 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.357 |  0.161 |                   13 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.328 |  0.137 |                   11 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.17836083471775055
[2m[36m(func pid=132449)[0m mae:  0.12999644875526428
[2m[36m(func pid=132449)[0m rmse_per_class: [0.111, 0.269, 0.089, 0.325, 0.094, 0.194, 0.297, 0.146, 0.141, 0.12]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4113 | Steps: 4 | Val loss: 0.3155 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.3547 | Steps: 4 | Val loss: 0.2879 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.2836 | Steps: 4 | Val loss: 0.3145 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=139223)[0m rmse: 0.1721949577331543
[2m[36m(func pid=139223)[0m mae:  0.12471780925989151
[2m[36m(func pid=139223)[0m rmse_per_class: [0.109, 0.266, 0.08, 0.33, 0.072, 0.192, 0.276, 0.136, 0.147, 0.115]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.15724071860313416
[2m[36m(func pid=140307)[0m mae:  0.11050941795110703
[2m[36m(func pid=140307)[0m rmse_per_class: [0.081, 0.249, 0.066, 0.31, 0.085, 0.177, 0.238, 0.121, 0.147, 0.098]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4680 | Steps: 4 | Val loss: 0.3584 | Batch size: 32 | lr: 0.0001 | Duration: 2.72s
[2m[36m(func pid=141107)[0m rmse: 0.16883590817451477
[2m[36m(func pid=141107)[0m mae:  0.10539217293262482
[2m[36m(func pid=141107)[0m rmse_per_class: [0.116, 0.241, 0.06, 0.31, 0.048, 0.175, 0.248, 0.14, 0.205, 0.146]
[2m[36m(func pid=141107)[0m 
== Status ==
Current time: 2024-01-07 16:49:41 (running for 00:25:39.09)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.468 |  0.178 |                   47 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.411 |  0.172 |                   17 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.355 |  0.157 |                   14 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.284 |  0.169 |                   12 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.1780550181865692
[2m[36m(func pid=132449)[0m mae:  0.1298551857471466
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.268, 0.088, 0.326, 0.092, 0.194, 0.297, 0.147, 0.141, 0.119]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4045 | Steps: 4 | Val loss: 0.3142 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.3502 | Steps: 4 | Val loss: 0.2798 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.3074 | Steps: 4 | Val loss: 0.2675 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=139223)[0m rmse: 0.17158252000808716
[2m[36m(func pid=139223)[0m mae:  0.12420519441366196
[2m[36m(func pid=139223)[0m rmse_per_class: [0.108, 0.266, 0.078, 0.328, 0.07, 0.193, 0.276, 0.136, 0.147, 0.115]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4586 | Steps: 4 | Val loss: 0.3580 | Batch size: 32 | lr: 0.0001 | Duration: 2.75s
[2m[36m(func pid=140307)[0m rmse: 0.1521482765674591
[2m[36m(func pid=140307)[0m mae:  0.10605393350124359
[2m[36m(func pid=140307)[0m rmse_per_class: [0.078, 0.243, 0.054, 0.302, 0.085, 0.177, 0.233, 0.119, 0.135, 0.096]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m rmse: 0.13960027694702148
[2m[36m(func pid=141107)[0m mae:  0.0852748304605484
[2m[36m(func pid=141107)[0m rmse_per_class: [0.071, 0.213, 0.049, 0.26, 0.051, 0.16, 0.227, 0.105, 0.139, 0.12]
[2m[36m(func pid=141107)[0m 
== Status ==
Current time: 2024-01-07 16:49:47 (running for 00:25:44.16)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.459 |  0.178 |                   48 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.405 |  0.172 |                   18 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.35  |  0.152 |                   15 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.307 |  0.14  |                   13 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.17803305387496948
[2m[36m(func pid=132449)[0m mae:  0.12973235547542572
[2m[36m(func pid=132449)[0m rmse_per_class: [0.111, 0.268, 0.089, 0.326, 0.092, 0.194, 0.294, 0.147, 0.14, 0.12]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.4054 | Steps: 4 | Val loss: 0.3129 | Batch size: 32 | lr: 0.001 | Duration: 2.75s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3346 | Steps: 4 | Val loss: 0.2755 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.3138 | Steps: 4 | Val loss: 0.2691 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=139223)[0m rmse: 0.17108683288097382
[2m[36m(func pid=139223)[0m mae:  0.12389390170574188
[2m[36m(func pid=139223)[0m rmse_per_class: [0.108, 0.265, 0.079, 0.326, 0.069, 0.192, 0.276, 0.135, 0.146, 0.114]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.15020358562469482
[2m[36m(func pid=140307)[0m mae:  0.10491582006216049
[2m[36m(func pid=140307)[0m rmse_per_class: [0.076, 0.24, 0.053, 0.282, 0.078, 0.175, 0.242, 0.118, 0.132, 0.107]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4587 | Steps: 4 | Val loss: 0.3568 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=141107)[0m rmse: 0.13692596554756165
[2m[36m(func pid=141107)[0m mae:  0.08419094979763031
[2m[36m(func pid=141107)[0m rmse_per_class: [0.059, 0.202, 0.024, 0.252, 0.072, 0.162, 0.25, 0.112, 0.138, 0.099]
[2m[36m(func pid=141107)[0m 
== Status ==
Current time: 2024-01-07 16:49:52 (running for 00:25:49.53)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.459 |  0.178 |                   49 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.405 |  0.171 |                   19 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.335 |  0.15  |                   16 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.314 |  0.137 |                   14 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.17820513248443604
[2m[36m(func pid=132449)[0m mae:  0.12987801432609558
[2m[36m(func pid=132449)[0m rmse_per_class: [0.111, 0.268, 0.091, 0.327, 0.092, 0.194, 0.295, 0.146, 0.14, 0.119]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4123 | Steps: 4 | Val loss: 0.3127 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3354 | Steps: 4 | Val loss: 0.2754 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.2888 | Steps: 4 | Val loss: 0.3037 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=139223)[0m rmse: 0.17116335034370422
[2m[36m(func pid=139223)[0m mae:  0.12403760105371475
[2m[36m(func pid=139223)[0m rmse_per_class: [0.109, 0.265, 0.079, 0.325, 0.069, 0.192, 0.276, 0.135, 0.147, 0.115]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.1502709686756134
[2m[36m(func pid=140307)[0m mae:  0.10520132631063461
[2m[36m(func pid=140307)[0m rmse_per_class: [0.075, 0.238, 0.053, 0.273, 0.068, 0.174, 0.252, 0.118, 0.133, 0.119]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4614 | Steps: 4 | Val loss: 0.3547 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=141107)[0m rmse: 0.1609225571155548
[2m[36m(func pid=141107)[0m mae:  0.10074824094772339
[2m[36m(func pid=141107)[0m rmse_per_class: [0.073, 0.241, 0.025, 0.308, 0.066, 0.191, 0.224, 0.131, 0.143, 0.206]
[2m[36m(func pid=141107)[0m 
== Status ==
Current time: 2024-01-07 16:49:57 (running for 00:25:54.88)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.461 |  0.179 |                   50 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.412 |  0.171 |                   20 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.335 |  0.15  |                   17 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.289 |  0.161 |                   15 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.17868195474147797
[2m[36m(func pid=132449)[0m mae:  0.13019461929798126
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.269, 0.095, 0.328, 0.092, 0.194, 0.294, 0.145, 0.141, 0.12]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4059 | Steps: 4 | Val loss: 0.3129 | Batch size: 32 | lr: 0.001 | Duration: 2.79s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3447 | Steps: 4 | Val loss: 0.2728 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=139223)[0m rmse: 0.1712104082107544
[2m[36m(func pid=139223)[0m mae:  0.12406414747238159
[2m[36m(func pid=139223)[0m rmse_per_class: [0.11, 0.265, 0.079, 0.325, 0.068, 0.192, 0.275, 0.134, 0.147, 0.116]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.2844 | Steps: 4 | Val loss: 0.2700 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=140307)[0m rmse: 0.14835792779922485
[2m[36m(func pid=140307)[0m mae:  0.10347447544336319
[2m[36m(func pid=140307)[0m rmse_per_class: [0.075, 0.239, 0.057, 0.264, 0.062, 0.174, 0.247, 0.118, 0.135, 0.114]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4589 | Steps: 4 | Val loss: 0.3554 | Batch size: 32 | lr: 0.0001 | Duration: 3.17s
[2m[36m(func pid=141107)[0m rmse: 0.14161095023155212
[2m[36m(func pid=141107)[0m mae:  0.08542294800281525
[2m[36m(func pid=141107)[0m rmse_per_class: [0.063, 0.212, 0.077, 0.265, 0.06, 0.159, 0.207, 0.115, 0.141, 0.117]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4058 | Steps: 4 | Val loss: 0.3120 | Batch size: 32 | lr: 0.001 | Duration: 2.73s
== Status ==
Current time: 2024-01-07 16:50:03 (running for 00:26:00.32)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.459 |  0.178 |                   51 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.406 |  0.171 |                   21 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.345 |  0.148 |                   18 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.284 |  0.142 |                   16 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.1784783899784088
[2m[36m(func pid=132449)[0m mae:  0.13001221418380737
[2m[36m(func pid=132449)[0m rmse_per_class: [0.109, 0.269, 0.095, 0.328, 0.092, 0.194, 0.292, 0.144, 0.141, 0.121]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3360 | Steps: 4 | Val loss: 0.2716 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=139223)[0m rmse: 0.17088329792022705
[2m[36m(func pid=139223)[0m mae:  0.12382874637842178
[2m[36m(func pid=139223)[0m rmse_per_class: [0.111, 0.265, 0.077, 0.323, 0.068, 0.192, 0.276, 0.134, 0.146, 0.117]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.14755085110664368
[2m[36m(func pid=140307)[0m mae:  0.1027711033821106
[2m[36m(func pid=140307)[0m rmse_per_class: [0.076, 0.236, 0.057, 0.267, 0.06, 0.174, 0.244, 0.117, 0.137, 0.109]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.2750 | Steps: 4 | Val loss: 0.2645 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4568 | Steps: 4 | Val loss: 0.3521 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=141107)[0m rmse: 0.13222035765647888
[2m[36m(func pid=141107)[0m mae:  0.08229755610227585
[2m[36m(func pid=141107)[0m rmse_per_class: [0.091, 0.197, 0.027, 0.239, 0.054, 0.158, 0.233, 0.109, 0.136, 0.078]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4034 | Steps: 4 | Val loss: 0.3103 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=132449)[0m rmse: 0.17842024564743042
[2m[36m(func pid=132449)[0m mae:  0.1300516128540039
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.269, 0.092, 0.327, 0.092, 0.194, 0.294, 0.144, 0.141, 0.12]
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3320 | Steps: 4 | Val loss: 0.2688 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 16:50:08 (running for 00:26:05.74)
Memory usage on this node: 24.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.457 |  0.178 |                   52 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.406 |  0.171 |                   22 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.336 |  0.148 |                   19 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.275 |  0.132 |                   17 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.17007747292518616
[2m[36m(func pid=139223)[0m mae:  0.12309744209051132
[2m[36m(func pid=139223)[0m rmse_per_class: [0.112, 0.265, 0.074, 0.32, 0.068, 0.192, 0.275, 0.134, 0.145, 0.116]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.14535465836524963
[2m[36m(func pid=140307)[0m mae:  0.10054290294647217
[2m[36m(func pid=140307)[0m rmse_per_class: [0.074, 0.236, 0.055, 0.267, 0.058, 0.172, 0.235, 0.121, 0.137, 0.099]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.2761 | Steps: 4 | Val loss: 0.2701 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4562 | Steps: 4 | Val loss: 0.3507 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=141107)[0m rmse: 0.1404857337474823
[2m[36m(func pid=141107)[0m mae:  0.08753179013729095
[2m[36m(func pid=141107)[0m rmse_per_class: [0.064, 0.209, 0.025, 0.275, 0.073, 0.183, 0.22, 0.118, 0.149, 0.088]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4023 | Steps: 4 | Val loss: 0.3095 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3324 | Steps: 4 | Val loss: 0.2674 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 16:50:14 (running for 00:26:11.11)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.456 |  0.178 |                   53 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.403 |  0.17  |                   23 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.332 |  0.145 |                   20 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.276 |  0.14  |                   18 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=132449)[0m rmse: 0.17836979031562805
[2m[36m(func pid=132449)[0m mae:  0.13003391027450562
[2m[36m(func pid=132449)[0m rmse_per_class: [0.111, 0.269, 0.092, 0.326, 0.091, 0.194, 0.295, 0.144, 0.141, 0.12]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16971474885940552
[2m[36m(func pid=139223)[0m mae:  0.12279389053583145
[2m[36m(func pid=139223)[0m rmse_per_class: [0.113, 0.265, 0.074, 0.318, 0.067, 0.191, 0.275, 0.134, 0.146, 0.115]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.14389123022556305
[2m[36m(func pid=140307)[0m mae:  0.09880104660987854
[2m[36m(func pid=140307)[0m rmse_per_class: [0.071, 0.232, 0.047, 0.275, 0.056, 0.172, 0.228, 0.13, 0.136, 0.092]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.2700 | Steps: 4 | Val loss: 0.2788 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4540 | Steps: 4 | Val loss: 0.3514 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=141107)[0m rmse: 0.1482563465833664
[2m[36m(func pid=141107)[0m mae:  0.09052630513906479
[2m[36m(func pid=141107)[0m rmse_per_class: [0.06, 0.214, 0.025, 0.258, 0.083, 0.164, 0.224, 0.117, 0.142, 0.196]
[2m[36m(func pid=141107)[0m 
== Status ==
Current time: 2024-01-07 16:50:19 (running for 00:26:16.13)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.456 |  0.178 |                   53 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.402 |  0.17  |                   24 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.332 |  0.144 |                   21 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.27  |  0.148 |                   19 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3233 | Steps: 4 | Val loss: 0.2647 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4006 | Steps: 4 | Val loss: 0.3072 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=132449)[0m rmse: 0.17846396565437317
[2m[36m(func pid=132449)[0m mae:  0.1301320195198059
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.268, 0.092, 0.328, 0.093, 0.193, 0.296, 0.144, 0.141, 0.12]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16849838197231293
[2m[36m(func pid=139223)[0m mae:  0.12170915305614471
[2m[36m(func pid=139223)[0m rmse_per_class: [0.109, 0.265, 0.072, 0.316, 0.067, 0.191, 0.274, 0.134, 0.145, 0.113]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.14204315841197968
[2m[36m(func pid=140307)[0m mae:  0.09760752320289612
[2m[36m(func pid=140307)[0m rmse_per_class: [0.07, 0.226, 0.046, 0.27, 0.056, 0.171, 0.229, 0.126, 0.136, 0.09]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.2671 | Steps: 4 | Val loss: 0.2735 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4471 | Steps: 4 | Val loss: 0.3476 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3284 | Steps: 4 | Val loss: 0.2674 | Batch size: 32 | lr: 0.01 | Duration: 2.80s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4085 | Steps: 4 | Val loss: 0.3073 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 16:50:24 (running for 00:26:21.69)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.454 |  0.178 |                   54 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.401 |  0.168 |                   25 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.323 |  0.142 |                   22 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.267 |  0.143 |                   20 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.14286787807941437
[2m[36m(func pid=141107)[0m mae:  0.087458036839962
[2m[36m(func pid=141107)[0m rmse_per_class: [0.078, 0.251, 0.027, 0.241, 0.052, 0.167, 0.206, 0.105, 0.156, 0.146]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.1776568591594696
[2m[36m(func pid=132449)[0m mae:  0.12956896424293518
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.268, 0.09, 0.327, 0.091, 0.193, 0.295, 0.144, 0.142, 0.116]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.1439744383096695
[2m[36m(func pid=140307)[0m mae:  0.09920769184827805
[2m[36m(func pid=140307)[0m rmse_per_class: [0.07, 0.226, 0.051, 0.269, 0.059, 0.17, 0.239, 0.128, 0.135, 0.093]
[2m[36m(func pid=139223)[0m rmse: 0.1684686243534088
[2m[36m(func pid=139223)[0m mae:  0.12169913947582245
[2m[36m(func pid=139223)[0m rmse_per_class: [0.11, 0.264, 0.073, 0.314, 0.067, 0.191, 0.275, 0.135, 0.145, 0.112]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.2784 | Steps: 4 | Val loss: 0.2714 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4538 | Steps: 4 | Val loss: 0.3473 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 16:50:29 (running for 00:26:26.95)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.447 |  0.178 |                   55 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.408 |  0.168 |                   26 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.328 |  0.144 |                   23 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.278 |  0.143 |                   21 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3100 | Steps: 4 | Val loss: 0.2681 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=141107)[0m rmse: 0.14280804991722107
[2m[36m(func pid=141107)[0m mae:  0.08904053270816803
[2m[36m(func pid=141107)[0m rmse_per_class: [0.058, 0.207, 0.042, 0.268, 0.051, 0.169, 0.236, 0.157, 0.157, 0.084]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3970 | Steps: 4 | Val loss: 0.3069 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=132449)[0m rmse: 0.17732378840446472
[2m[36m(func pid=132449)[0m mae:  0.12929941713809967
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.268, 0.089, 0.327, 0.091, 0.193, 0.294, 0.143, 0.142, 0.115]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16818007826805115
[2m[36m(func pid=139223)[0m mae:  0.12141340970993042
[2m[36m(func pid=139223)[0m rmse_per_class: [0.109, 0.265, 0.073, 0.313, 0.066, 0.192, 0.274, 0.134, 0.145, 0.111]
[2m[36m(func pid=140307)[0m rmse: 0.14438168704509735
[2m[36m(func pid=140307)[0m mae:  0.09975762665271759
[2m[36m(func pid=140307)[0m rmse_per_class: [0.069, 0.227, 0.057, 0.255, 0.061, 0.17, 0.252, 0.119, 0.141, 0.092]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.2914 | Steps: 4 | Val loss: 0.2773 | Batch size: 32 | lr: 0.1 | Duration: 2.97s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4435 | Steps: 4 | Val loss: 0.3471 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 16:50:35 (running for 00:26:32.33)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.454 |  0.177 |                   56 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.397 |  0.168 |                   27 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.31  |  0.144 |                   24 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.291 |  0.144 |                   22 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3195 | Steps: 4 | Val loss: 0.2710 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=141107)[0m rmse: 0.14359235763549805
[2m[36m(func pid=141107)[0m mae:  0.08795791864395142
[2m[36m(func pid=141107)[0m rmse_per_class: [0.059, 0.219, 0.044, 0.278, 0.062, 0.189, 0.228, 0.148, 0.123, 0.086]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4006 | Steps: 4 | Val loss: 0.3064 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=132449)[0m rmse: 0.17734713852405548
[2m[36m(func pid=132449)[0m mae:  0.1293487846851349
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.268, 0.088, 0.326, 0.091, 0.193, 0.294, 0.144, 0.142, 0.117]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16815271973609924
[2m[36m(func pid=139223)[0m mae:  0.12133727222681046
[2m[36m(func pid=139223)[0m rmse_per_class: [0.109, 0.265, 0.075, 0.313, 0.065, 0.191, 0.273, 0.133, 0.145, 0.113]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.1463615596294403
[2m[36m(func pid=140307)[0m mae:  0.1012914776802063
[2m[36m(func pid=140307)[0m rmse_per_class: [0.069, 0.233, 0.053, 0.253, 0.061, 0.17, 0.257, 0.118, 0.15, 0.1]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.2743 | Steps: 4 | Val loss: 0.2757 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4470 | Steps: 4 | Val loss: 0.3452 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 16:50:40 (running for 00:26:37.66)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.443 |  0.177 |                   57 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.401 |  0.168 |                   28 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.319 |  0.146 |                   25 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.274 |  0.147 |                   23 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3962 | Steps: 4 | Val loss: 0.3064 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3272 | Steps: 4 | Val loss: 0.2739 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=141107)[0m rmse: 0.14726468920707703
[2m[36m(func pid=141107)[0m mae:  0.08928079903125763
[2m[36m(func pid=141107)[0m rmse_per_class: [0.075, 0.248, 0.042, 0.238, 0.069, 0.164, 0.206, 0.109, 0.138, 0.183]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.17734557390213013
[2m[36m(func pid=132449)[0m mae:  0.1292610466480255
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.268, 0.089, 0.327, 0.091, 0.193, 0.293, 0.143, 0.142, 0.118]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.1490546613931656
[2m[36m(func pid=140307)[0m mae:  0.10303904116153717
[2m[36m(func pid=140307)[0m rmse_per_class: [0.08, 0.24, 0.056, 0.258, 0.061, 0.17, 0.254, 0.114, 0.146, 0.113]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.1681603193283081
[2m[36m(func pid=139223)[0m mae:  0.12131738662719727
[2m[36m(func pid=139223)[0m rmse_per_class: [0.109, 0.265, 0.076, 0.313, 0.065, 0.191, 0.272, 0.133, 0.144, 0.114]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.2838 | Steps: 4 | Val loss: 0.2681 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4426 | Steps: 4 | Val loss: 0.3464 | Batch size: 32 | lr: 0.0001 | Duration: 2.80s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3176 | Steps: 4 | Val loss: 0.2713 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 16:50:45 (running for 00:26:42.87)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.447 |  0.177 |                   58 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.396 |  0.168 |                   29 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.327 |  0.149 |                   26 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.284 |  0.143 |                   24 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3991 | Steps: 4 | Val loss: 0.3057 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=141107)[0m rmse: 0.14341036975383759
[2m[36m(func pid=141107)[0m mae:  0.0886765867471695
[2m[36m(func pid=141107)[0m rmse_per_class: [0.067, 0.211, 0.027, 0.254, 0.061, 0.161, 0.237, 0.131, 0.167, 0.118]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.1775696873664856
[2m[36m(func pid=132449)[0m mae:  0.1293528527021408
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.269, 0.091, 0.326, 0.093, 0.193, 0.293, 0.143, 0.142, 0.117]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16765426099300385
[2m[36m(func pid=139223)[0m mae:  0.12094371020793915
[2m[36m(func pid=139223)[0m rmse_per_class: [0.109, 0.264, 0.075, 0.31, 0.065, 0.19, 0.274, 0.133, 0.142, 0.115]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.14703916013240814
[2m[36m(func pid=140307)[0m mae:  0.10100559145212173
[2m[36m(func pid=140307)[0m rmse_per_class: [0.076, 0.242, 0.053, 0.269, 0.06, 0.173, 0.238, 0.113, 0.137, 0.11]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.2699 | Steps: 4 | Val loss: 0.2766 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4414 | Steps: 4 | Val loss: 0.3438 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3978 | Steps: 4 | Val loss: 0.3045 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 16:50:51 (running for 00:26:48.23)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.443 |  0.178 |                   59 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.399 |  0.168 |                   30 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.318 |  0.147 |                   27 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.27  |  0.143 |                   25 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3162 | Steps: 4 | Val loss: 0.2675 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=141107)[0m rmse: 0.14251448214054108
[2m[36m(func pid=141107)[0m mae:  0.08756886422634125
[2m[36m(func pid=141107)[0m rmse_per_class: [0.059, 0.217, 0.041, 0.275, 0.06, 0.185, 0.221, 0.139, 0.144, 0.084]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.17771859467029572
[2m[36m(func pid=132449)[0m mae:  0.12930931150913239
[2m[36m(func pid=132449)[0m rmse_per_class: [0.109, 0.269, 0.092, 0.327, 0.094, 0.193, 0.292, 0.144, 0.141, 0.116]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.167013019323349
[2m[36m(func pid=139223)[0m mae:  0.12040267139673233
[2m[36m(func pid=139223)[0m rmse_per_class: [0.108, 0.263, 0.072, 0.308, 0.064, 0.19, 0.274, 0.133, 0.142, 0.116]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.14438089728355408
[2m[36m(func pid=140307)[0m mae:  0.09875034540891647
[2m[36m(func pid=140307)[0m rmse_per_class: [0.07, 0.237, 0.047, 0.27, 0.061, 0.174, 0.228, 0.111, 0.131, 0.114]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.2725 | Steps: 4 | Val loss: 0.2702 | Batch size: 32 | lr: 0.1 | Duration: 2.82s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4488 | Steps: 4 | Val loss: 0.3410 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3990 | Steps: 4 | Val loss: 0.3037 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3093 | Steps: 4 | Val loss: 0.2659 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 16:50:56 (running for 00:26:53.54)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.441 |  0.178 |                   60 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.398 |  0.167 |                   31 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.316 |  0.144 |                   28 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.273 |  0.142 |                   26 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.14151692390441895
[2m[36m(func pid=141107)[0m mae:  0.08560136705636978
[2m[36m(func pid=141107)[0m rmse_per_class: [0.071, 0.23, 0.035, 0.247, 0.075, 0.162, 0.219, 0.113, 0.18, 0.084]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.17739583551883698
[2m[36m(func pid=132449)[0m mae:  0.12891440093517303
[2m[36m(func pid=132449)[0m rmse_per_class: [0.108, 0.269, 0.094, 0.327, 0.093, 0.193, 0.291, 0.143, 0.141, 0.115]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16658857464790344
[2m[36m(func pid=139223)[0m mae:  0.11997906118631363
[2m[36m(func pid=139223)[0m rmse_per_class: [0.105, 0.263, 0.072, 0.306, 0.065, 0.189, 0.274, 0.133, 0.142, 0.115]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.14326860010623932
[2m[36m(func pid=140307)[0m mae:  0.0979631170630455
[2m[36m(func pid=140307)[0m rmse_per_class: [0.066, 0.232, 0.046, 0.269, 0.06, 0.172, 0.227, 0.113, 0.135, 0.113]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.2865 | Steps: 4 | Val loss: 0.2663 | Batch size: 32 | lr: 0.1 | Duration: 2.78s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4434 | Steps: 4 | Val loss: 0.3395 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3942 | Steps: 4 | Val loss: 0.3026 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 16:51:01 (running for 00:26:58.79)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.449 |  0.177 |                   61 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.399 |  0.167 |                   32 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.309 |  0.143 |                   29 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.286 |  0.141 |                   27 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3089 | Steps: 4 | Val loss: 0.2644 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=141107)[0m rmse: 0.14138077199459076
[2m[36m(func pid=141107)[0m mae:  0.08682065457105637
[2m[36m(func pid=141107)[0m rmse_per_class: [0.064, 0.214, 0.027, 0.248, 0.061, 0.162, 0.21, 0.108, 0.161, 0.159]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.17669178545475006
[2m[36m(func pid=132449)[0m mae:  0.12839069962501526
[2m[36m(func pid=132449)[0m rmse_per_class: [0.109, 0.268, 0.091, 0.326, 0.092, 0.193, 0.291, 0.142, 0.141, 0.114]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16594669222831726
[2m[36m(func pid=139223)[0m mae:  0.11939208209514618
[2m[36m(func pid=139223)[0m rmse_per_class: [0.105, 0.262, 0.071, 0.307, 0.065, 0.19, 0.272, 0.133, 0.141, 0.115]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.1418342888355255
[2m[36m(func pid=140307)[0m mae:  0.0965777337551117
[2m[36m(func pid=140307)[0m rmse_per_class: [0.064, 0.228, 0.047, 0.27, 0.059, 0.175, 0.225, 0.113, 0.137, 0.101]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.2562 | Steps: 4 | Val loss: 0.2909 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4403 | Steps: 4 | Val loss: 0.3404 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3971 | Steps: 4 | Val loss: 0.3024 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=141107)[0m rmse: 0.15313179790973663
[2m[36m(func pid=141107)[0m mae:  0.09361855685710907
[2m[36m(func pid=141107)[0m rmse_per_class: [0.058, 0.228, 0.034, 0.307, 0.073, 0.186, 0.224, 0.131, 0.148, 0.143]
== Status ==
Current time: 2024-01-07 16:51:06 (running for 00:27:04.02)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.443 |  0.177 |                   62 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.394 |  0.166 |                   33 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.309 |  0.142 |                   30 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.256 |  0.153 |                   28 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3174 | Steps: 4 | Val loss: 0.2608 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.17687572538852692
[2m[36m(func pid=132449)[0m mae:  0.12866294384002686
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.268, 0.092, 0.326, 0.092, 0.193, 0.291, 0.141, 0.142, 0.114]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16563910245895386
[2m[36m(func pid=139223)[0m mae:  0.11920931190252304
[2m[36m(func pid=139223)[0m rmse_per_class: [0.103, 0.262, 0.071, 0.307, 0.065, 0.19, 0.271, 0.132, 0.14, 0.115]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.13878679275512695
[2m[36m(func pid=140307)[0m mae:  0.09447691589593887
[2m[36m(func pid=140307)[0m rmse_per_class: [0.064, 0.218, 0.046, 0.264, 0.059, 0.17, 0.229, 0.113, 0.133, 0.091]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.2741 | Steps: 4 | Val loss: 0.2713 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4395 | Steps: 4 | Val loss: 0.3383 | Batch size: 32 | lr: 0.0001 | Duration: 3.08s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3930 | Steps: 4 | Val loss: 0.3018 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=141107)[0m rmse: 0.14363951981067657
[2m[36m(func pid=141107)[0m mae:  0.08700276911258698
[2m[36m(func pid=141107)[0m rmse_per_class: [0.063, 0.213, 0.032, 0.249, 0.061, 0.194, 0.238, 0.126, 0.151, 0.111]
[2m[36m(func pid=141107)[0m 
== Status ==
Current time: 2024-01-07 16:51:12 (running for 00:27:09.37)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.44  |  0.177 |                   63 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.397 |  0.166 |                   34 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.317 |  0.139 |                   31 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.274 |  0.144 |                   29 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3055 | Steps: 4 | Val loss: 0.2614 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=132449)[0m rmse: 0.17657320201396942
[2m[36m(func pid=132449)[0m mae:  0.12847232818603516
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.269, 0.089, 0.325, 0.09, 0.193, 0.292, 0.142, 0.141, 0.114]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.1653864085674286
[2m[36m(func pid=139223)[0m mae:  0.11900684982538223
[2m[36m(func pid=139223)[0m rmse_per_class: [0.104, 0.262, 0.068, 0.307, 0.065, 0.19, 0.27, 0.133, 0.14, 0.116]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.1395549178123474
[2m[36m(func pid=140307)[0m mae:  0.09519369155168533
[2m[36m(func pid=140307)[0m rmse_per_class: [0.064, 0.218, 0.043, 0.256, 0.061, 0.167, 0.238, 0.112, 0.132, 0.104]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.2511 | Steps: 4 | Val loss: 0.2595 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4359 | Steps: 4 | Val loss: 0.3367 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 16:51:17 (running for 00:27:14.65)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.44  |  0.177 |                   64 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.393 |  0.165 |                   35 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.306 |  0.14  |                   32 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.251 |  0.132 |                   30 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4012 | Steps: 4 | Val loss: 0.3018 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=141107)[0m rmse: 0.13195782899856567
[2m[36m(func pid=141107)[0m mae:  0.0796286091208458
[2m[36m(func pid=141107)[0m rmse_per_class: [0.077, 0.205, 0.026, 0.236, 0.072, 0.167, 0.201, 0.107, 0.141, 0.088]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3180 | Steps: 4 | Val loss: 0.2606 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=132449)[0m rmse: 0.17644360661506653
[2m[36m(func pid=132449)[0m mae:  0.12832584977149963
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.269, 0.089, 0.325, 0.089, 0.193, 0.291, 0.142, 0.141, 0.114]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16554972529411316
[2m[36m(func pid=139223)[0m mae:  0.11912409961223602
[2m[36m(func pid=139223)[0m rmse_per_class: [0.105, 0.262, 0.069, 0.306, 0.064, 0.19, 0.27, 0.132, 0.141, 0.115]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.13972607254981995
[2m[36m(func pid=140307)[0m mae:  0.0948239341378212
[2m[36m(func pid=140307)[0m rmse_per_class: [0.063, 0.225, 0.038, 0.249, 0.06, 0.167, 0.233, 0.113, 0.131, 0.117]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.2592 | Steps: 4 | Val loss: 0.2759 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4444 | Steps: 4 | Val loss: 0.3367 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3919 | Steps: 4 | Val loss: 0.3018 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
== Status ==
Current time: 2024-01-07 16:51:22 (running for 00:27:20.01)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.436 |  0.176 |                   65 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.401 |  0.166 |                   36 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.318 |  0.14  |                   33 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.259 |  0.148 |                   31 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.14771613478660583
[2m[36m(func pid=141107)[0m mae:  0.08919300884008408
[2m[36m(func pid=141107)[0m rmse_per_class: [0.06, 0.22, 0.027, 0.247, 0.084, 0.172, 0.225, 0.129, 0.195, 0.117]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3063 | Steps: 4 | Val loss: 0.2649 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=132449)[0m rmse: 0.1769174337387085
[2m[36m(func pid=132449)[0m mae:  0.12868593633174896
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.269, 0.091, 0.327, 0.089, 0.193, 0.291, 0.143, 0.142, 0.113]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16563177108764648
[2m[36m(func pid=139223)[0m mae:  0.11923571676015854
[2m[36m(func pid=139223)[0m rmse_per_class: [0.107, 0.263, 0.068, 0.306, 0.065, 0.19, 0.27, 0.133, 0.143, 0.113]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.14330628514289856
[2m[36m(func pid=140307)[0m mae:  0.09721572697162628
[2m[36m(func pid=140307)[0m rmse_per_class: [0.065, 0.233, 0.039, 0.256, 0.058, 0.167, 0.23, 0.114, 0.139, 0.134]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.2577 | Steps: 4 | Val loss: 0.2684 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4347 | Steps: 4 | Val loss: 0.3359 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3916 | Steps: 4 | Val loss: 0.3013 | Batch size: 32 | lr: 0.001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 16:51:28 (running for 00:27:25.26)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.444 |  0.177 |                   66 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.392 |  0.166 |                   37 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.306 |  0.143 |                   34 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.258 |  0.142 |                   32 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.14239825308322906
[2m[36m(func pid=141107)[0m mae:  0.08665885776281357
[2m[36m(func pid=141107)[0m rmse_per_class: [0.059, 0.226, 0.029, 0.249, 0.056, 0.188, 0.211, 0.112, 0.129, 0.166]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3015 | Steps: 4 | Val loss: 0.2690 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=132449)[0m rmse: 0.17656473815441132
[2m[36m(func pid=132449)[0m mae:  0.128384068608284
[2m[36m(func pid=132449)[0m rmse_per_class: [0.111, 0.268, 0.091, 0.326, 0.087, 0.193, 0.291, 0.143, 0.141, 0.114]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.1654043197631836
[2m[36m(func pid=139223)[0m mae:  0.11900701373815536
[2m[36m(func pid=139223)[0m rmse_per_class: [0.107, 0.263, 0.068, 0.306, 0.064, 0.19, 0.269, 0.132, 0.143, 0.112]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.14593806862831116
[2m[36m(func pid=140307)[0m mae:  0.09961584955453873
[2m[36m(func pid=140307)[0m rmse_per_class: [0.066, 0.234, 0.037, 0.264, 0.06, 0.167, 0.233, 0.113, 0.16, 0.125]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.2498 | Steps: 4 | Val loss: 0.2687 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4368 | Steps: 4 | Val loss: 0.3340 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 16:51:33 (running for 00:27:30.38)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.435 |  0.177 |                   67 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.392 |  0.165 |                   38 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.301 |  0.146 |                   35 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.25  |  0.141 |                   33 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.14126840233802795
[2m[36m(func pid=141107)[0m mae:  0.08435722440481186
[2m[36m(func pid=141107)[0m rmse_per_class: [0.067, 0.21, 0.03, 0.249, 0.062, 0.171, 0.226, 0.128, 0.123, 0.146]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3871 | Steps: 4 | Val loss: 0.3017 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3085 | Steps: 4 | Val loss: 0.2666 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=132449)[0m rmse: 0.1768096536397934
[2m[36m(func pid=132449)[0m mae:  0.1285058557987213
[2m[36m(func pid=132449)[0m rmse_per_class: [0.111, 0.269, 0.092, 0.326, 0.088, 0.194, 0.29, 0.141, 0.142, 0.115]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16562680900096893
[2m[36m(func pid=139223)[0m mae:  0.11933392286300659
[2m[36m(func pid=139223)[0m rmse_per_class: [0.108, 0.262, 0.068, 0.307, 0.064, 0.189, 0.271, 0.132, 0.145, 0.111]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.1436745673418045
[2m[36m(func pid=140307)[0m mae:  0.09780509024858475
[2m[36m(func pid=140307)[0m rmse_per_class: [0.067, 0.23, 0.039, 0.263, 0.061, 0.167, 0.23, 0.114, 0.157, 0.109]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2528 | Steps: 4 | Val loss: 0.2654 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4313 | Steps: 4 | Val loss: 0.3337 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 16:51:38 (running for 00:27:35.65)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.437 |  0.177 |                   68 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.387 |  0.166 |                   39 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.309 |  0.144 |                   36 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.253 |  0.139 |                   34 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.1390838474035263
[2m[36m(func pid=141107)[0m mae:  0.08355379849672318
[2m[36m(func pid=141107)[0m rmse_per_class: [0.064, 0.214, 0.033, 0.253, 0.067, 0.168, 0.205, 0.112, 0.151, 0.124]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3891 | Steps: 4 | Val loss: 0.3021 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3105 | Steps: 4 | Val loss: 0.2616 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=132449)[0m rmse: 0.17661046981811523
[2m[36m(func pid=132449)[0m mae:  0.12828440964221954
[2m[36m(func pid=132449)[0m rmse_per_class: [0.11, 0.27, 0.093, 0.327, 0.086, 0.194, 0.288, 0.143, 0.141, 0.115]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16603830456733704
[2m[36m(func pid=139223)[0m mae:  0.11962606757879257
[2m[36m(func pid=139223)[0m rmse_per_class: [0.11, 0.262, 0.07, 0.308, 0.064, 0.19, 0.27, 0.132, 0.146, 0.11]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.13975879549980164
[2m[36m(func pid=140307)[0m mae:  0.0948244035243988
[2m[36m(func pid=140307)[0m rmse_per_class: [0.072, 0.219, 0.044, 0.262, 0.059, 0.165, 0.227, 0.112, 0.143, 0.093]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2573 | Steps: 4 | Val loss: 0.2669 | Batch size: 32 | lr: 0.1 | Duration: 2.77s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4398 | Steps: 4 | Val loss: 0.3331 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 16:51:43 (running for 00:27:40.99)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.431 |  0.177 |                   69 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.389 |  0.166 |                   40 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.311 |  0.14  |                   37 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.257 |  0.141 |                   35 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.14073164761066437
[2m[36m(func pid=141107)[0m mae:  0.08685845881700516
[2m[36m(func pid=141107)[0m rmse_per_class: [0.066, 0.209, 0.027, 0.247, 0.058, 0.177, 0.229, 0.112, 0.189, 0.093]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3903 | Steps: 4 | Val loss: 0.3015 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3027 | Steps: 4 | Val loss: 0.2598 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=132449)[0m rmse: 0.17669083178043365
[2m[36m(func pid=132449)[0m mae:  0.12834730744361877
[2m[36m(func pid=132449)[0m rmse_per_class: [0.112, 0.27, 0.09, 0.327, 0.088, 0.194, 0.288, 0.143, 0.142, 0.113]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.13860748708248138
[2m[36m(func pid=140307)[0m mae:  0.09343387931585312
[2m[36m(func pid=140307)[0m rmse_per_class: [0.069, 0.219, 0.051, 0.265, 0.058, 0.166, 0.221, 0.114, 0.132, 0.092]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16549338400363922
[2m[36m(func pid=139223)[0m mae:  0.11931226402521133
[2m[36m(func pid=139223)[0m rmse_per_class: [0.109, 0.26, 0.068, 0.308, 0.064, 0.189, 0.271, 0.132, 0.145, 0.109]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2635 | Steps: 4 | Val loss: 0.2611 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4318 | Steps: 4 | Val loss: 0.3336 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 16:51:49 (running for 00:27:46.48)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.44  |  0.177 |                   70 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.39  |  0.165 |                   41 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.303 |  0.139 |                   38 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.264 |  0.137 |                   36 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.13724574446678162
[2m[36m(func pid=141107)[0m mae:  0.08282236754894257
[2m[36m(func pid=141107)[0m rmse_per_class: [0.064, 0.213, 0.028, 0.245, 0.067, 0.165, 0.205, 0.119, 0.151, 0.114]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3884 | Steps: 4 | Val loss: 0.3015 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3023 | Steps: 4 | Val loss: 0.2565 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=132449)[0m rmse: 0.17644308507442474
[2m[36m(func pid=132449)[0m mae:  0.1282515525817871
[2m[36m(func pid=132449)[0m rmse_per_class: [0.112, 0.27, 0.087, 0.327, 0.089, 0.193, 0.289, 0.143, 0.142, 0.112]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.165306955575943
[2m[36m(func pid=139223)[0m mae:  0.11917769908905029
[2m[36m(func pid=139223)[0m rmse_per_class: [0.108, 0.259, 0.068, 0.308, 0.064, 0.188, 0.272, 0.131, 0.146, 0.109]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.13610513508319855
[2m[36m(func pid=140307)[0m mae:  0.09123162925243378
[2m[36m(func pid=140307)[0m rmse_per_class: [0.063, 0.218, 0.05, 0.257, 0.058, 0.165, 0.217, 0.116, 0.128, 0.089]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2651 | Steps: 4 | Val loss: 0.2754 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4304 | Steps: 4 | Val loss: 0.3333 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 16:51:54 (running for 00:27:51.81)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.432 |  0.176 |                   71 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.388 |  0.165 |                   42 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.302 |  0.136 |                   39 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.265 |  0.145 |                   37 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3917 | Steps: 4 | Val loss: 0.3002 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=141107)[0m rmse: 0.1447874754667282
[2m[36m(func pid=141107)[0m mae:  0.08622491359710693
[2m[36m(func pid=141107)[0m rmse_per_class: [0.06, 0.224, 0.027, 0.245, 0.088, 0.17, 0.213, 0.151, 0.125, 0.145]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3142 | Steps: 4 | Val loss: 0.2554 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=132449)[0m rmse: 0.17683163285255432
[2m[36m(func pid=132449)[0m mae:  0.12853041291236877
[2m[36m(func pid=132449)[0m rmse_per_class: [0.112, 0.27, 0.088, 0.329, 0.089, 0.193, 0.289, 0.143, 0.142, 0.114]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.1647380292415619
[2m[36m(func pid=139223)[0m mae:  0.11868958175182343
[2m[36m(func pid=139223)[0m rmse_per_class: [0.108, 0.259, 0.067, 0.306, 0.064, 0.188, 0.271, 0.131, 0.146, 0.107]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.13532404601573944
[2m[36m(func pid=140307)[0m mae:  0.09075339138507843
[2m[36m(func pid=140307)[0m rmse_per_class: [0.062, 0.215, 0.041, 0.254, 0.057, 0.165, 0.22, 0.118, 0.126, 0.095]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2723 | Steps: 4 | Val loss: 0.2671 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4369 | Steps: 4 | Val loss: 0.3331 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2972 | Steps: 4 | Val loss: 0.2582 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
== Status ==
Current time: 2024-01-07 16:52:00 (running for 00:27:57.14)
Memory usage on this node: 24.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.43  |  0.177 |                   72 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.392 |  0.165 |                   43 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.314 |  0.135 |                   40 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.272 |  0.142 |                   38 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3915 | Steps: 4 | Val loss: 0.3002 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=141107)[0m rmse: 0.14160655438899994
[2m[36m(func pid=141107)[0m mae:  0.08639649301767349
[2m[36m(func pid=141107)[0m rmse_per_class: [0.086, 0.213, 0.028, 0.247, 0.076, 0.18, 0.22, 0.11, 0.149, 0.108]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.1773536652326584
[2m[36m(func pid=132449)[0m mae:  0.1288791000843048
[2m[36m(func pid=132449)[0m rmse_per_class: [0.113, 0.27, 0.09, 0.329, 0.089, 0.193, 0.288, 0.142, 0.142, 0.117]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16479530930519104
[2m[36m(func pid=139223)[0m mae:  0.11874480545520782
[2m[36m(func pid=139223)[0m rmse_per_class: [0.107, 0.259, 0.066, 0.306, 0.064, 0.188, 0.271, 0.131, 0.147, 0.108]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.1377023160457611
[2m[36m(func pid=140307)[0m mae:  0.09291081130504608
[2m[36m(func pid=140307)[0m rmse_per_class: [0.062, 0.219, 0.042, 0.254, 0.059, 0.165, 0.226, 0.114, 0.134, 0.103]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2490 | Steps: 4 | Val loss: 0.2706 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4304 | Steps: 4 | Val loss: 0.3325 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 16:52:05 (running for 00:28:02.34)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.437 |  0.177 |                   73 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.391 |  0.165 |                   44 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.297 |  0.138 |                   41 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.249 |  0.143 |                   39 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3901 | Steps: 4 | Val loss: 0.2988 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=141107)[0m rmse: 0.14293192327022552
[2m[36m(func pid=141107)[0m mae:  0.08723047375679016
[2m[36m(func pid=141107)[0m rmse_per_class: [0.062, 0.221, 0.027, 0.265, 0.062, 0.163, 0.203, 0.111, 0.195, 0.121]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3035 | Steps: 4 | Val loss: 0.2605 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=132449)[0m rmse: 0.1770133078098297
[2m[36m(func pid=132449)[0m mae:  0.12867984175682068
[2m[36m(func pid=132449)[0m rmse_per_class: [0.113, 0.27, 0.089, 0.328, 0.088, 0.193, 0.288, 0.141, 0.142, 0.118]
[2m[36m(func pid=132449)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16372399032115936
[2m[36m(func pid=139223)[0m mae:  0.11787465959787369
[2m[36m(func pid=139223)[0m rmse_per_class: [0.104, 0.258, 0.065, 0.306, 0.063, 0.188, 0.27, 0.131, 0.144, 0.108]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.13931480050086975
[2m[36m(func pid=140307)[0m mae:  0.09390891343355179
[2m[36m(func pid=140307)[0m rmse_per_class: [0.064, 0.224, 0.037, 0.253, 0.064, 0.166, 0.229, 0.115, 0.141, 0.101]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2894 | Steps: 4 | Val loss: 0.2859 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=132449)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4272 | Steps: 4 | Val loss: 0.3325 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 16:52:10 (running for 00:28:07.61)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=12
Bracket: Iter 75.000: -0.15024999901652336
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (8 PENDING, 4 RUNNING, 12 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00012 | RUNNING    | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.43  |  0.177 |                   74 |
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.39  |  0.164 |                   45 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.304 |  0.139 |                   42 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.289 |  0.155 |                   40 |
| train_c9cb4_00016 | PENDING    |                     | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3849 | Steps: 4 | Val loss: 0.2984 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3026 | Steps: 4 | Val loss: 0.2610 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=141107)[0m rmse: 0.1545671671628952
[2m[36m(func pid=141107)[0m mae:  0.09244029223918915
[2m[36m(func pid=141107)[0m rmse_per_class: [0.08, 0.224, 0.036, 0.261, 0.066, 0.167, 0.231, 0.168, 0.158, 0.156]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=132449)[0m rmse: 0.17650309205055237
[2m[36m(func pid=132449)[0m mae:  0.12837648391723633
[2m[36m(func pid=132449)[0m rmse_per_class: [0.113, 0.269, 0.086, 0.327, 0.089, 0.193, 0.289, 0.14, 0.142, 0.116]
[2m[36m(func pid=139223)[0m rmse: 0.16355085372924805
[2m[36m(func pid=139223)[0m mae:  0.11772630363702774
[2m[36m(func pid=139223)[0m rmse_per_class: [0.103, 0.257, 0.065, 0.307, 0.063, 0.188, 0.269, 0.131, 0.144, 0.108]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.13970589637756348
[2m[36m(func pid=140307)[0m mae:  0.09455397725105286
[2m[36m(func pid=140307)[0m rmse_per_class: [0.063, 0.222, 0.04, 0.252, 0.064, 0.166, 0.234, 0.113, 0.149, 0.095]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2596 | Steps: 4 | Val loss: 0.2613 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3001 | Steps: 4 | Val loss: 0.2601 | Batch size: 32 | lr: 0.01 | Duration: 2.71s
[2m[36m(func pid=141107)[0m rmse: 0.13496072590351105
[2m[36m(func pid=141107)[0m mae:  0.08172202855348587
[2m[36m(func pid=141107)[0m rmse_per_class: [0.065, 0.204, 0.053, 0.24, 0.051, 0.181, 0.216, 0.106, 0.122, 0.112]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3880 | Steps: 4 | Val loss: 0.2973 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=139223)[0m rmse: 0.16290637850761414
[2m[36m(func pid=139223)[0m mae:  0.11717194318771362
[2m[36m(func pid=139223)[0m rmse_per_class: [0.101, 0.256, 0.065, 0.305, 0.064, 0.187, 0.27, 0.131, 0.145, 0.106]
[2m[36m(func pid=140307)[0m rmse: 0.1387023627758026
[2m[36m(func pid=140307)[0m mae:  0.09370487928390503
[2m[36m(func pid=140307)[0m rmse_per_class: [0.066, 0.217, 0.039, 0.255, 0.063, 0.164, 0.231, 0.11, 0.143, 0.098]
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2739 | Steps: 4 | Val loss: 0.2688 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 16:52:15 (running for 00:28:12.84)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.385 |  0.164 |                   46 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.303 |  0.14  |                   43 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.26  |  0.135 |                   41 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=150896)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=150896)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=150896)[0m Configuration completed!
[2m[36m(func pid=150896)[0m New optimizer parameters:
[2m[36m(func pid=150896)[0m SGD (
[2m[36m(func pid=150896)[0m Parameter Group 0
[2m[36m(func pid=150896)[0m     dampening: 0
[2m[36m(func pid=150896)[0m     differentiable: False
[2m[36m(func pid=150896)[0m     foreach: None
[2m[36m(func pid=150896)[0m     lr: 0.0001
[2m[36m(func pid=150896)[0m     maximize: False
[2m[36m(func pid=150896)[0m     momentum: 0.99
[2m[36m(func pid=150896)[0m     nesterov: False
[2m[36m(func pid=150896)[0m     weight_decay: 1e-05
[2m[36m(func pid=150896)[0m )
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m rmse: 0.14190572500228882
[2m[36m(func pid=141107)[0m mae:  0.08460094779729843
[2m[36m(func pid=141107)[0m rmse_per_class: [0.059, 0.225, 0.027, 0.241, 0.064, 0.165, 0.211, 0.127, 0.159, 0.141]
== Status ==
Current time: 2024-01-07 16:52:21 (running for 00:28:18.13)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.388 |  0.163 |                   47 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.3   |  0.139 |                   44 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.274 |  0.142 |                   42 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3828 | Steps: 4 | Val loss: 0.2974 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2917 | Steps: 4 | Val loss: 0.2598 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2494 | Steps: 4 | Val loss: 0.3061 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0798 | Steps: 4 | Val loss: 0.8077 | Batch size: 32 | lr: 0.0001 | Duration: 4.57s
[2m[36m(func pid=139223)[0m rmse: 0.16307637095451355
[2m[36m(func pid=139223)[0m mae:  0.11728520691394806
[2m[36m(func pid=139223)[0m rmse_per_class: [0.101, 0.256, 0.065, 0.307, 0.065, 0.187, 0.268, 0.13, 0.144, 0.109]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.13851937651634216
[2m[36m(func pid=140307)[0m mae:  0.0934077799320221
[2m[36m(func pid=140307)[0m rmse_per_class: [0.065, 0.217, 0.04, 0.259, 0.067, 0.164, 0.228, 0.111, 0.139, 0.096]
[2m[36m(func pid=140307)[0m 
== Status ==
Current time: 2024-01-07 16:52:26 (running for 00:28:23.22)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.383 |  0.163 |                   48 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.292 |  0.139 |                   45 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.249 |  0.166 |                   43 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.16557681560516357
[2m[36m(func pid=141107)[0m mae:  0.10048685222864151
[2m[36m(func pid=141107)[0m rmse_per_class: [0.072, 0.24, 0.034, 0.289, 0.081, 0.169, 0.227, 0.138, 0.242, 0.162]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.1787407398223877
[2m[36m(func pid=150896)[0m mae:  0.13120503723621368
[2m[36m(func pid=150896)[0m rmse_per_class: [0.105, 0.265, 0.087, 0.325, 0.101, 0.192, 0.305, 0.154, 0.139, 0.115]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3888 | Steps: 4 | Val loss: 0.2968 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3021 | Steps: 4 | Val loss: 0.2614 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2730 | Steps: 4 | Val loss: 0.2602 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0644 | Steps: 4 | Val loss: 0.7981 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=139223)[0m rmse: 0.16257186233997345
[2m[36m(func pid=139223)[0m mae:  0.11683902889490128
[2m[36m(func pid=139223)[0m rmse_per_class: [0.1, 0.256, 0.064, 0.305, 0.064, 0.187, 0.267, 0.131, 0.143, 0.108]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.140108123421669
[2m[36m(func pid=140307)[0m mae:  0.09384457767009735
[2m[36m(func pid=140307)[0m rmse_per_class: [0.062, 0.221, 0.041, 0.26, 0.064, 0.164, 0.227, 0.114, 0.133, 0.115]
[2m[36m(func pid=140307)[0m 
== Status ==
Current time: 2024-01-07 16:52:31 (running for 00:28:28.52)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.389 |  0.163 |                   49 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.302 |  0.14  |                   46 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.273 |  0.135 |                   44 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  1.08  |  0.179 |                    1 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.13458152115345
[2m[36m(func pid=141107)[0m mae:  0.08106139302253723
[2m[36m(func pid=141107)[0m rmse_per_class: [0.065, 0.208, 0.027, 0.246, 0.083, 0.173, 0.208, 0.116, 0.129, 0.091]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17930737137794495
[2m[36m(func pid=150896)[0m mae:  0.13162051141262054
[2m[36m(func pid=150896)[0m rmse_per_class: [0.105, 0.265, 0.088, 0.324, 0.104, 0.193, 0.306, 0.154, 0.138, 0.116]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3842 | Steps: 4 | Val loss: 0.2966 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2960 | Steps: 4 | Val loss: 0.2576 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2692 | Steps: 4 | Val loss: 0.2683 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 1.0379 | Steps: 4 | Val loss: 0.7726 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=139223)[0m rmse: 0.16265198588371277
[2m[36m(func pid=139223)[0m mae:  0.11682319641113281
[2m[36m(func pid=139223)[0m rmse_per_class: [0.099, 0.256, 0.064, 0.305, 0.064, 0.187, 0.266, 0.131, 0.143, 0.112]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.13795879483222961
[2m[36m(func pid=140307)[0m mae:  0.09205285459756851
[2m[36m(func pid=140307)[0m rmse_per_class: [0.06, 0.223, 0.039, 0.243, 0.068, 0.163, 0.227, 0.109, 0.129, 0.12]
[2m[36m(func pid=140307)[0m 
== Status ==
Current time: 2024-01-07 16:52:36 (running for 00:28:33.85)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.384 |  0.163 |                   50 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.296 |  0.138 |                   47 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.269 |  0.141 |                   45 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  1.064 |  0.179 |                    2 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.14066745340824127
[2m[36m(func pid=141107)[0m mae:  0.08387920260429382
[2m[36m(func pid=141107)[0m rmse_per_class: [0.06, 0.213, 0.033, 0.238, 0.072, 0.178, 0.226, 0.148, 0.124, 0.116]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17979058623313904
[2m[36m(func pid=150896)[0m mae:  0.13206002116203308
[2m[36m(func pid=150896)[0m rmse_per_class: [0.107, 0.266, 0.088, 0.324, 0.103, 0.194, 0.308, 0.154, 0.137, 0.118]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2876 | Steps: 4 | Val loss: 0.2547 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3855 | Steps: 4 | Val loss: 0.2963 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2678 | Steps: 4 | Val loss: 0.2955 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.9840 | Steps: 4 | Val loss: 0.7417 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=140307)[0m rmse: 0.13541047275066376
[2m[36m(func pid=140307)[0m mae:  0.08950002491474152
[2m[36m(func pid=140307)[0m rmse_per_class: [0.059, 0.226, 0.036, 0.237, 0.068, 0.162, 0.215, 0.113, 0.127, 0.111]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16251280903816223
[2m[36m(func pid=139223)[0m mae:  0.11661113798618317
[2m[36m(func pid=139223)[0m rmse_per_class: [0.099, 0.257, 0.063, 0.304, 0.064, 0.187, 0.266, 0.13, 0.141, 0.114]
[2m[36m(func pid=139223)[0m 
== Status ==
Current time: 2024-01-07 16:52:42 (running for 00:28:39.18)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.385 |  0.163 |                   51 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.288 |  0.135 |                   48 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.268 |  0.156 |                   46 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  1.038 |  0.18  |                    3 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.15598663687705994
[2m[36m(func pid=141107)[0m mae:  0.09490788727998734
[2m[36m(func pid=141107)[0m rmse_per_class: [0.077, 0.232, 0.033, 0.294, 0.054, 0.203, 0.224, 0.115, 0.158, 0.169]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.18017086386680603
[2m[36m(func pid=150896)[0m mae:  0.13224075734615326
[2m[36m(func pid=150896)[0m rmse_per_class: [0.107, 0.266, 0.088, 0.324, 0.104, 0.194, 0.308, 0.154, 0.137, 0.119]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3020 | Steps: 4 | Val loss: 0.2534 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3874 | Steps: 4 | Val loss: 0.2963 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2944 | Steps: 4 | Val loss: 0.2697 | Batch size: 32 | lr: 0.1 | Duration: 2.76s
[2m[36m(func pid=140307)[0m rmse: 0.1338861733675003
[2m[36m(func pid=140307)[0m mae:  0.08848170191049576
[2m[36m(func pid=140307)[0m rmse_per_class: [0.059, 0.222, 0.032, 0.24, 0.062, 0.164, 0.212, 0.119, 0.128, 0.101]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.9237 | Steps: 4 | Val loss: 0.6939 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=139223)[0m rmse: 0.16281595826148987
[2m[36m(func pid=139223)[0m mae:  0.11670317500829697
[2m[36m(func pid=139223)[0m rmse_per_class: [0.099, 0.258, 0.063, 0.306, 0.063, 0.187, 0.263, 0.129, 0.141, 0.118]
[2m[36m(func pid=139223)[0m 
== Status ==
Current time: 2024-01-07 16:52:47 (running for 00:28:44.31)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.387 |  0.163 |                   52 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.302 |  0.134 |                   49 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.294 |  0.143 |                   47 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.984 |  0.18  |                    4 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.14305804669857025
[2m[36m(func pid=141107)[0m mae:  0.08744838088750839
[2m[36m(func pid=141107)[0m rmse_per_class: [0.059, 0.215, 0.025, 0.253, 0.058, 0.169, 0.218, 0.124, 0.202, 0.108]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.18056637048721313
[2m[36m(func pid=150896)[0m mae:  0.13247515261173248
[2m[36m(func pid=150896)[0m rmse_per_class: [0.108, 0.267, 0.089, 0.324, 0.105, 0.194, 0.308, 0.154, 0.137, 0.119]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2857 | Steps: 4 | Val loss: 0.2518 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3892 | Steps: 4 | Val loss: 0.2972 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2716 | Steps: 4 | Val loss: 0.2690 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=140307)[0m rmse: 0.13224577903747559
[2m[36m(func pid=140307)[0m mae:  0.08774431049823761
[2m[36m(func pid=140307)[0m rmse_per_class: [0.059, 0.217, 0.032, 0.234, 0.059, 0.162, 0.22, 0.115, 0.133, 0.091]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.8523 | Steps: 4 | Val loss: 0.6422 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=139223)[0m rmse: 0.1633777916431427
[2m[36m(func pid=139223)[0m mae:  0.11714587360620499
[2m[36m(func pid=139223)[0m rmse_per_class: [0.1, 0.259, 0.065, 0.307, 0.064, 0.187, 0.263, 0.13, 0.143, 0.118]
[2m[36m(func pid=139223)[0m 
== Status ==
Current time: 2024-01-07 16:52:52 (running for 00:28:49.36)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.389 |  0.163 |                   53 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.286 |  0.132 |                   50 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.272 |  0.141 |                   48 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.924 |  0.181 |                    5 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.14055511355400085
[2m[36m(func pid=141107)[0m mae:  0.0857449620962143
[2m[36m(func pid=141107)[0m rmse_per_class: [0.085, 0.207, 0.025, 0.251, 0.062, 0.177, 0.249, 0.113, 0.13, 0.107]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2940 | Steps: 4 | Val loss: 0.2554 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=150896)[0m rmse: 0.18068625032901764
[2m[36m(func pid=150896)[0m mae:  0.13255462050437927
[2m[36m(func pid=150896)[0m rmse_per_class: [0.108, 0.267, 0.089, 0.324, 0.103, 0.194, 0.308, 0.154, 0.138, 0.121]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3829 | Steps: 4 | Val loss: 0.2969 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2548 | Steps: 4 | Val loss: 0.3125 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=140307)[0m rmse: 0.13491861522197723
[2m[36m(func pid=140307)[0m mae:  0.09014854580163956
[2m[36m(func pid=140307)[0m rmse_per_class: [0.06, 0.213, 0.033, 0.243, 0.058, 0.161, 0.228, 0.116, 0.148, 0.089]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16316011548042297
[2m[36m(func pid=139223)[0m mae:  0.11700083315372467
[2m[36m(func pid=139223)[0m rmse_per_class: [0.099, 0.258, 0.064, 0.307, 0.064, 0.187, 0.262, 0.13, 0.144, 0.116]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.7909 | Steps: 4 | Val loss: 0.5896 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 16:52:57 (running for 00:28:54.61)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.383 |  0.163 |                   54 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.294 |  0.135 |                   51 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.255 |  0.16  |                   49 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.852 |  0.181 |                    6 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.1601422131061554
[2m[36m(func pid=141107)[0m mae:  0.09729604423046112
[2m[36m(func pid=141107)[0m rmse_per_class: [0.097, 0.232, 0.026, 0.326, 0.074, 0.183, 0.228, 0.132, 0.145, 0.16]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2785 | Steps: 4 | Val loss: 0.2638 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=150896)[0m rmse: 0.1806568205356598
[2m[36m(func pid=150896)[0m mae:  0.13241451978683472
[2m[36m(func pid=150896)[0m rmse_per_class: [0.108, 0.268, 0.09, 0.324, 0.104, 0.194, 0.307, 0.154, 0.138, 0.119]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3733 | Steps: 4 | Val loss: 0.2964 | Batch size: 32 | lr: 0.001 | Duration: 2.86s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2574 | Steps: 4 | Val loss: 0.2903 | Batch size: 32 | lr: 0.1 | Duration: 2.85s
[2m[36m(func pid=140307)[0m rmse: 0.14133520424365997
[2m[36m(func pid=140307)[0m mae:  0.09499005973339081
[2m[36m(func pid=140307)[0m rmse_per_class: [0.06, 0.219, 0.032, 0.257, 0.055, 0.161, 0.238, 0.116, 0.181, 0.095]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16272279620170593
[2m[36m(func pid=139223)[0m mae:  0.11658024787902832
[2m[36m(func pid=139223)[0m rmse_per_class: [0.098, 0.258, 0.066, 0.307, 0.064, 0.187, 0.26, 0.13, 0.143, 0.114]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.7200 | Steps: 4 | Val loss: 0.5355 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 16:53:02 (running for 00:28:59.73)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.373 |  0.163 |                   55 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.279 |  0.141 |                   52 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.257 |  0.156 |                   50 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.791 |  0.181 |                    7 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.15602204203605652
[2m[36m(func pid=141107)[0m mae:  0.09488128125667572
[2m[36m(func pid=141107)[0m rmse_per_class: [0.067, 0.221, 0.027, 0.268, 0.076, 0.179, 0.222, 0.144, 0.245, 0.112]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3005 | Steps: 4 | Val loss: 0.2620 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=150896)[0m rmse: 0.18050873279571533
[2m[36m(func pid=150896)[0m mae:  0.13219629228115082
[2m[36m(func pid=150896)[0m rmse_per_class: [0.108, 0.268, 0.089, 0.325, 0.104, 0.194, 0.306, 0.153, 0.138, 0.12]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3807 | Steps: 4 | Val loss: 0.2966 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2808 | Steps: 4 | Val loss: 0.2684 | Batch size: 32 | lr: 0.1 | Duration: 2.75s
[2m[36m(func pid=140307)[0m rmse: 0.14000245928764343
[2m[36m(func pid=140307)[0m mae:  0.0939527228474617
[2m[36m(func pid=140307)[0m rmse_per_class: [0.06, 0.222, 0.031, 0.253, 0.054, 0.162, 0.229, 0.113, 0.169, 0.106]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.162676602602005
[2m[36m(func pid=139223)[0m mae:  0.11653182655572891
[2m[36m(func pid=139223)[0m rmse_per_class: [0.099, 0.258, 0.064, 0.309, 0.064, 0.187, 0.26, 0.129, 0.144, 0.113]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.6493 | Steps: 4 | Val loss: 0.4864 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 16:53:07 (running for 00:29:04.74)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.381 |  0.163 |                   56 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.3   |  0.14  |                   53 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.281 |  0.141 |                   51 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.72  |  0.181 |                    8 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.14085307717323303
[2m[36m(func pid=141107)[0m mae:  0.08660888671875
[2m[36m(func pid=141107)[0m rmse_per_class: [0.082, 0.209, 0.024, 0.248, 0.053, 0.175, 0.243, 0.118, 0.148, 0.108]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3021 | Steps: 4 | Val loss: 0.2615 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=150896)[0m rmse: 0.18048252165317535
[2m[36m(func pid=150896)[0m mae:  0.1320919394493103
[2m[36m(func pid=150896)[0m rmse_per_class: [0.108, 0.268, 0.091, 0.325, 0.103, 0.194, 0.305, 0.152, 0.139, 0.119]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3781 | Steps: 4 | Val loss: 0.2967 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2945 | Steps: 4 | Val loss: 0.2865 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=140307)[0m rmse: 0.13963577151298523
[2m[36m(func pid=140307)[0m mae:  0.0931195542216301
[2m[36m(func pid=140307)[0m rmse_per_class: [0.062, 0.224, 0.041, 0.256, 0.054, 0.163, 0.219, 0.111, 0.156, 0.109]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.1627238690853119
[2m[36m(func pid=139223)[0m mae:  0.11667897552251816
[2m[36m(func pid=139223)[0m rmse_per_class: [0.098, 0.257, 0.064, 0.31, 0.065, 0.186, 0.262, 0.129, 0.143, 0.111]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.5994 | Steps: 4 | Val loss: 0.4436 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
== Status ==
Current time: 2024-01-07 16:53:13 (running for 00:29:10.16)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.378 |  0.163 |                   57 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.302 |  0.14  |                   54 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.294 |  0.152 |                   52 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.649 |  0.18  |                    9 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.15212783217430115
[2m[36m(func pid=141107)[0m mae:  0.0903327688574791
[2m[36m(func pid=141107)[0m rmse_per_class: [0.063, 0.221, 0.043, 0.26, 0.082, 0.175, 0.22, 0.124, 0.123, 0.21]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2871 | Steps: 4 | Val loss: 0.2593 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=150896)[0m rmse: 0.1801438182592392
[2m[36m(func pid=150896)[0m mae:  0.13172748684883118
[2m[36m(func pid=150896)[0m rmse_per_class: [0.109, 0.269, 0.091, 0.325, 0.102, 0.194, 0.304, 0.151, 0.14, 0.118]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3782 | Steps: 4 | Val loss: 0.2959 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3005 | Steps: 4 | Val loss: 0.3018 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=140307)[0m rmse: 0.13808663189411163
[2m[36m(func pid=140307)[0m mae:  0.09156092256307602
[2m[36m(func pid=140307)[0m rmse_per_class: [0.065, 0.218, 0.047, 0.263, 0.053, 0.163, 0.213, 0.11, 0.136, 0.112]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16239222884178162
[2m[36m(func pid=139223)[0m mae:  0.11633910238742828
[2m[36m(func pid=139223)[0m rmse_per_class: [0.098, 0.257, 0.065, 0.308, 0.065, 0.186, 0.262, 0.129, 0.143, 0.111]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.5502 | Steps: 4 | Val loss: 0.4074 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 16:53:18 (running for 00:29:15.44)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.378 |  0.162 |                   58 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.287 |  0.138 |                   55 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.3   |  0.161 |                   53 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.599 |  0.18  |                   10 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.16056938469409943
[2m[36m(func pid=141107)[0m mae:  0.0957297831773758
[2m[36m(func pid=141107)[0m rmse_per_class: [0.094, 0.224, 0.129, 0.284, 0.087, 0.169, 0.232, 0.156, 0.143, 0.087]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2847 | Steps: 4 | Val loss: 0.2573 | Batch size: 32 | lr: 0.01 | Duration: 2.74s
[2m[36m(func pid=150896)[0m rmse: 0.17999832332134247
[2m[36m(func pid=150896)[0m mae:  0.13143345713615417
[2m[36m(func pid=150896)[0m rmse_per_class: [0.109, 0.269, 0.097, 0.326, 0.099, 0.194, 0.301, 0.147, 0.141, 0.117]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3762 | Steps: 4 | Val loss: 0.2955 | Batch size: 32 | lr: 0.001 | Duration: 3.14s
[2m[36m(func pid=140307)[0m rmse: 0.13696683943271637
[2m[36m(func pid=140307)[0m mae:  0.09063385426998138
[2m[36m(func pid=140307)[0m rmse_per_class: [0.065, 0.213, 0.05, 0.257, 0.055, 0.162, 0.216, 0.108, 0.127, 0.115]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2828 | Steps: 4 | Val loss: 0.2814 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=139223)[0m rmse: 0.16214558482170105
[2m[36m(func pid=139223)[0m mae:  0.1160813719034195
[2m[36m(func pid=139223)[0m rmse_per_class: [0.098, 0.257, 0.064, 0.307, 0.064, 0.187, 0.261, 0.13, 0.142, 0.111]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.5082 | Steps: 4 | Val loss: 0.3782 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 16:53:23 (running for 00:29:20.84)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.376 |  0.162 |                   59 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.285 |  0.137 |                   56 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.283 |  0.147 |                   54 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.55  |  0.18  |                   11 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.14652469754219055
[2m[36m(func pid=141107)[0m mae:  0.0913381353020668
[2m[36m(func pid=141107)[0m rmse_per_class: [0.06, 0.212, 0.025, 0.251, 0.07, 0.179, 0.255, 0.112, 0.22, 0.082]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3145 | Steps: 4 | Val loss: 0.2558 | Batch size: 32 | lr: 0.01 | Duration: 2.77s
[2m[36m(func pid=150896)[0m rmse: 0.17999377846717834
[2m[36m(func pid=150896)[0m mae:  0.1312907487154007
[2m[36m(func pid=150896)[0m rmse_per_class: [0.109, 0.27, 0.099, 0.329, 0.098, 0.194, 0.298, 0.146, 0.142, 0.116]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3860 | Steps: 4 | Val loss: 0.2943 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=140307)[0m rmse: 0.13621798157691956
[2m[36m(func pid=140307)[0m mae:  0.08987349271774292
[2m[36m(func pid=140307)[0m rmse_per_class: [0.066, 0.213, 0.048, 0.247, 0.056, 0.162, 0.22, 0.108, 0.125, 0.117]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2457 | Steps: 4 | Val loss: 0.2784 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=139223)[0m rmse: 0.1615898162126541
[2m[36m(func pid=139223)[0m mae:  0.11550135910511017
[2m[36m(func pid=139223)[0m rmse_per_class: [0.097, 0.257, 0.065, 0.305, 0.065, 0.186, 0.26, 0.13, 0.141, 0.109]
[2m[36m(func pid=139223)[0m 
== Status ==
Current time: 2024-01-07 16:53:28 (running for 00:29:25.91)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.386 |  0.162 |                   60 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.314 |  0.136 |                   57 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.246 |  0.151 |                   55 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.508 |  0.18  |                   12 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.1508103609085083
[2m[36m(func pid=141107)[0m mae:  0.08882887661457062
[2m[36m(func pid=141107)[0m rmse_per_class: [0.115, 0.226, 0.037, 0.249, 0.069, 0.174, 0.21, 0.109, 0.148, 0.17]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4803 | Steps: 4 | Val loss: 0.3557 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2855 | Steps: 4 | Val loss: 0.2523 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=150896)[0m rmse: 0.17958734929561615
[2m[36m(func pid=150896)[0m mae:  0.1307934671640396
[2m[36m(func pid=150896)[0m rmse_per_class: [0.111, 0.27, 0.1, 0.33, 0.096, 0.194, 0.294, 0.144, 0.142, 0.114]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3895 | Steps: 4 | Val loss: 0.2942 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=140307)[0m rmse: 0.13342684507369995
[2m[36m(func pid=140307)[0m mae:  0.0876336619257927
[2m[36m(func pid=140307)[0m rmse_per_class: [0.061, 0.215, 0.036, 0.239, 0.055, 0.163, 0.213, 0.118, 0.127, 0.108]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2637 | Steps: 4 | Val loss: 0.2890 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=139223)[0m rmse: 0.16144278645515442
[2m[36m(func pid=139223)[0m mae:  0.11540685594081879
[2m[36m(func pid=139223)[0m rmse_per_class: [0.097, 0.256, 0.065, 0.307, 0.065, 0.186, 0.26, 0.13, 0.14, 0.109]
[2m[36m(func pid=139223)[0m 
== Status ==
Current time: 2024-01-07 16:53:34 (running for 00:29:31.34)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.389 |  0.161 |                   61 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.285 |  0.133 |                   58 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.264 |  0.15  |                   56 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.48  |  0.18  |                   13 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.15004314482212067
[2m[36m(func pid=141107)[0m mae:  0.08972477912902832
[2m[36m(func pid=141107)[0m rmse_per_class: [0.061, 0.224, 0.03, 0.272, 0.058, 0.186, 0.222, 0.138, 0.152, 0.156]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4528 | Steps: 4 | Val loss: 0.3419 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2762 | Steps: 4 | Val loss: 0.2519 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3758 | Steps: 4 | Val loss: 0.2941 | Batch size: 32 | lr: 0.001 | Duration: 2.76s
[2m[36m(func pid=140307)[0m rmse: 0.13264790177345276
[2m[36m(func pid=140307)[0m mae:  0.08722583204507828
[2m[36m(func pid=140307)[0m rmse_per_class: [0.06, 0.217, 0.036, 0.237, 0.056, 0.161, 0.214, 0.12, 0.133, 0.093]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17909768223762512
[2m[36m(func pid=150896)[0m mae:  0.1303204596042633
[2m[36m(func pid=150896)[0m rmse_per_class: [0.112, 0.27, 0.101, 0.331, 0.094, 0.194, 0.291, 0.143, 0.143, 0.113]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2710 | Steps: 4 | Val loss: 0.2845 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=139223)[0m rmse: 0.16152048110961914
[2m[36m(func pid=139223)[0m mae:  0.11538778245449066
[2m[36m(func pid=139223)[0m rmse_per_class: [0.098, 0.256, 0.067, 0.304, 0.067, 0.186, 0.26, 0.129, 0.14, 0.108]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2809 | Steps: 4 | Val loss: 0.2542 | Batch size: 32 | lr: 0.01 | Duration: 2.69s
== Status ==
Current time: 2024-01-07 16:53:39 (running for 00:29:36.73)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.376 |  0.162 |                   62 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.276 |  0.133 |                   59 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.271 |  0.15  |                   57 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.453 |  0.179 |                   14 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.15042461454868317
[2m[36m(func pid=141107)[0m mae:  0.09078477323055267
[2m[36m(func pid=141107)[0m rmse_per_class: [0.07, 0.231, 0.046, 0.278, 0.061, 0.18, 0.244, 0.149, 0.162, 0.083]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4407 | Steps: 4 | Val loss: 0.3313 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3766 | Steps: 4 | Val loss: 0.2946 | Batch size: 32 | lr: 0.001 | Duration: 3.14s
[2m[36m(func pid=140307)[0m rmse: 0.1341477334499359
[2m[36m(func pid=140307)[0m mae:  0.0887194275856018
[2m[36m(func pid=140307)[0m rmse_per_class: [0.059, 0.216, 0.032, 0.241, 0.055, 0.161, 0.221, 0.117, 0.148, 0.09]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17857132852077484
[2m[36m(func pid=150896)[0m mae:  0.12971007823944092
[2m[36m(func pid=150896)[0m rmse_per_class: [0.113, 0.27, 0.102, 0.333, 0.092, 0.194, 0.287, 0.139, 0.145, 0.111]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2705 | Steps: 4 | Val loss: 0.2785 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=139223)[0m rmse: 0.1616860330104828
[2m[36m(func pid=139223)[0m mae:  0.1155334934592247
[2m[36m(func pid=139223)[0m rmse_per_class: [0.097, 0.256, 0.068, 0.304, 0.069, 0.186, 0.262, 0.129, 0.14, 0.107]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2981 | Steps: 4 | Val loss: 0.2592 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 16:53:45 (running for 00:29:42.33)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.377 |  0.162 |                   63 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.281 |  0.134 |                   60 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.271 |  0.15  |                   58 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.441 |  0.179 |                   15 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.15021434426307678
[2m[36m(func pid=141107)[0m mae:  0.08828308433294296
[2m[36m(func pid=141107)[0m rmse_per_class: [0.065, 0.22, 0.127, 0.253, 0.096, 0.178, 0.204, 0.109, 0.144, 0.107]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.4311 | Steps: 4 | Val loss: 0.3255 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3723 | Steps: 4 | Val loss: 0.2941 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=140307)[0m rmse: 0.13793444633483887
[2m[36m(func pid=140307)[0m mae:  0.0914791077375412
[2m[36m(func pid=140307)[0m rmse_per_class: [0.059, 0.218, 0.031, 0.251, 0.054, 0.164, 0.226, 0.119, 0.168, 0.088]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2464 | Steps: 4 | Val loss: 0.2854 | Batch size: 32 | lr: 0.1 | Duration: 2.79s
[2m[36m(func pid=150896)[0m rmse: 0.17789609730243683
[2m[36m(func pid=150896)[0m mae:  0.12902608513832092
[2m[36m(func pid=150896)[0m rmse_per_class: [0.115, 0.271, 0.101, 0.332, 0.088, 0.194, 0.284, 0.138, 0.146, 0.11]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16137537360191345
[2m[36m(func pid=139223)[0m mae:  0.11523731052875519
[2m[36m(func pid=139223)[0m rmse_per_class: [0.096, 0.257, 0.066, 0.304, 0.069, 0.186, 0.261, 0.129, 0.139, 0.107]
[2m[36m(func pid=139223)[0m 
== Status ==
Current time: 2024-01-07 16:53:50 (running for 00:29:47.55)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.372 |  0.161 |                   64 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.298 |  0.138 |                   61 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.246 |  0.154 |                   59 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.431 |  0.178 |                   16 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.15429739654064178
[2m[36m(func pid=141107)[0m mae:  0.09281180799007416
[2m[36m(func pid=141107)[0m rmse_per_class: [0.061, 0.23, 0.027, 0.261, 0.084, 0.2, 0.233, 0.128, 0.163, 0.156]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2801 | Steps: 4 | Val loss: 0.2602 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4199 | Steps: 4 | Val loss: 0.3241 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3761 | Steps: 4 | Val loss: 0.2928 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=140307)[0m rmse: 0.13885498046875
[2m[36m(func pid=140307)[0m mae:  0.09214310348033905
[2m[36m(func pid=140307)[0m rmse_per_class: [0.059, 0.22, 0.031, 0.25, 0.054, 0.163, 0.228, 0.113, 0.164, 0.106]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2745 | Steps: 4 | Val loss: 0.2676 | Batch size: 32 | lr: 0.1 | Duration: 2.86s
[2m[36m(func pid=150896)[0m rmse: 0.17754456400871277
[2m[36m(func pid=150896)[0m mae:  0.12859824299812317
[2m[36m(func pid=150896)[0m rmse_per_class: [0.114, 0.271, 0.103, 0.333, 0.086, 0.194, 0.281, 0.137, 0.148, 0.108]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.1605195254087448
[2m[36m(func pid=139223)[0m mae:  0.11450741440057755
[2m[36m(func pid=139223)[0m rmse_per_class: [0.093, 0.256, 0.062, 0.303, 0.068, 0.187, 0.261, 0.129, 0.138, 0.108]
[2m[36m(func pid=139223)[0m 
== Status ==
Current time: 2024-01-07 16:53:55 (running for 00:29:52.87)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.376 |  0.161 |                   65 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.28  |  0.139 |                   62 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.274 |  0.14  |                   60 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.42  |  0.178 |                   17 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2824 | Steps: 4 | Val loss: 0.2567 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=141107)[0m rmse: 0.13950413465499878
[2m[36m(func pid=141107)[0m mae:  0.0833396464586258
[2m[36m(func pid=141107)[0m rmse_per_class: [0.066, 0.218, 0.037, 0.247, 0.055, 0.164, 0.213, 0.11, 0.181, 0.103]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4116 | Steps: 4 | Val loss: 0.3255 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=140307)[0m rmse: 0.1361045390367508
[2m[36m(func pid=140307)[0m mae:  0.08969953656196594
[2m[36m(func pid=140307)[0m rmse_per_class: [0.06, 0.215, 0.031, 0.247, 0.06, 0.165, 0.223, 0.109, 0.142, 0.109]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3713 | Steps: 4 | Val loss: 0.2926 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3117 | Steps: 4 | Val loss: 0.2651 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=150896)[0m rmse: 0.17752952873706818
[2m[36m(func pid=150896)[0m mae:  0.12840205430984497
[2m[36m(func pid=150896)[0m rmse_per_class: [0.115, 0.271, 0.105, 0.336, 0.084, 0.194, 0.278, 0.136, 0.149, 0.107]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16041100025177002
[2m[36m(func pid=139223)[0m mae:  0.11444618552923203
[2m[36m(func pid=139223)[0m rmse_per_class: [0.093, 0.256, 0.062, 0.302, 0.069, 0.186, 0.261, 0.129, 0.138, 0.108]
[2m[36m(func pid=139223)[0m 
== Status ==
Current time: 2024-01-07 16:54:00 (running for 00:29:58.06)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.371 |  0.16  |                   66 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.282 |  0.136 |                   63 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.312 |  0.135 |                   61 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.412 |  0.178 |                   18 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2833 | Steps: 4 | Val loss: 0.2577 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=141107)[0m rmse: 0.13507191836833954
[2m[36m(func pid=141107)[0m mae:  0.08147425204515457
[2m[36m(func pid=141107)[0m rmse_per_class: [0.065, 0.216, 0.024, 0.253, 0.065, 0.184, 0.209, 0.114, 0.131, 0.09]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.4183 | Steps: 4 | Val loss: 0.3299 | Batch size: 32 | lr: 0.0001 | Duration: 3.05s
[2m[36m(func pid=140307)[0m rmse: 0.1373656839132309
[2m[36m(func pid=140307)[0m mae:  0.09024181216955185
[2m[36m(func pid=140307)[0m rmse_per_class: [0.06, 0.216, 0.035, 0.246, 0.062, 0.163, 0.221, 0.108, 0.13, 0.132]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3786 | Steps: 4 | Val loss: 0.2916 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2912 | Steps: 4 | Val loss: 0.3086 | Batch size: 32 | lr: 0.1 | Duration: 2.81s
[2m[36m(func pid=150896)[0m rmse: 0.17777028679847717
[2m[36m(func pid=150896)[0m mae:  0.12832286953926086
[2m[36m(func pid=150896)[0m rmse_per_class: [0.115, 0.272, 0.106, 0.338, 0.083, 0.195, 0.276, 0.136, 0.152, 0.106]
[2m[36m(func pid=150896)[0m 
== Status ==
Current time: 2024-01-07 16:54:06 (running for 00:30:03.18)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.379 |  0.16  |                   67 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.283 |  0.137 |                   64 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.312 |  0.135 |                   61 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.418 |  0.178 |                   19 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=139223)[0m rmse: 0.1598285585641861
[2m[36m(func pid=139223)[0m mae:  0.11392605304718018
[2m[36m(func pid=139223)[0m rmse_per_class: [0.092, 0.255, 0.061, 0.303, 0.069, 0.185, 0.259, 0.129, 0.138, 0.107]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=141107)[0m rmse: 0.1691010445356369
[2m[36m(func pid=141107)[0m mae:  0.10163357108831406
[2m[36m(func pid=141107)[0m rmse_per_class: [0.068, 0.233, 0.043, 0.299, 0.168, 0.185, 0.254, 0.149, 0.13, 0.161]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2639 | Steps: 4 | Val loss: 0.2580 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4349 | Steps: 4 | Val loss: 0.3319 | Batch size: 32 | lr: 0.0001 | Duration: 2.87s
[2m[36m(func pid=140307)[0m rmse: 0.13790661096572876
[2m[36m(func pid=140307)[0m mae:  0.09032939374446869
[2m[36m(func pid=140307)[0m rmse_per_class: [0.06, 0.218, 0.037, 0.245, 0.062, 0.162, 0.219, 0.109, 0.129, 0.139]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3689 | Steps: 4 | Val loss: 0.2923 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2997 | Steps: 4 | Val loss: 0.2659 | Batch size: 32 | lr: 0.1 | Duration: 2.74s
[2m[36m(func pid=150896)[0m rmse: 0.17670832574367523
[2m[36m(func pid=150896)[0m mae:  0.12738558650016785
[2m[36m(func pid=150896)[0m rmse_per_class: [0.116, 0.272, 0.102, 0.339, 0.081, 0.194, 0.274, 0.135, 0.151, 0.103]
[2m[36m(func pid=150896)[0m 
== Status ==
Current time: 2024-01-07 16:54:11 (running for 00:30:08.44)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.379 |  0.16  |                   67 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.264 |  0.138 |                   65 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.3   |  0.138 |                   63 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.435 |  0.177 |                   20 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=139223)[0m rmse: 0.16034331917762756
[2m[36m(func pid=139223)[0m mae:  0.11446960270404816
[2m[36m(func pid=139223)[0m rmse_per_class: [0.092, 0.256, 0.061, 0.303, 0.069, 0.185, 0.26, 0.129, 0.14, 0.108]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=141107)[0m rmse: 0.1384795904159546
[2m[36m(func pid=141107)[0m mae:  0.08378515392541885
[2m[36m(func pid=141107)[0m rmse_per_class: [0.068, 0.222, 0.025, 0.245, 0.05, 0.162, 0.205, 0.109, 0.165, 0.135]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2825 | Steps: 4 | Val loss: 0.2584 | Batch size: 32 | lr: 0.01 | Duration: 3.13s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4235 | Steps: 4 | Val loss: 0.3365 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3044 | Steps: 4 | Val loss: 0.2757 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3747 | Steps: 4 | Val loss: 0.2918 | Batch size: 32 | lr: 0.001 | Duration: 2.88s
[2m[36m(func pid=140307)[0m rmse: 0.13730701804161072
[2m[36m(func pid=140307)[0m mae:  0.09012994170188904
[2m[36m(func pid=140307)[0m rmse_per_class: [0.065, 0.215, 0.038, 0.25, 0.058, 0.161, 0.22, 0.111, 0.137, 0.118]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17633403837680817
[2m[36m(func pid=150896)[0m mae:  0.12683072686195374
[2m[36m(func pid=150896)[0m rmse_per_class: [0.117, 0.272, 0.101, 0.34, 0.079, 0.194, 0.272, 0.134, 0.152, 0.102]
[2m[36m(func pid=150896)[0m 
== Status ==
Current time: 2024-01-07 16:54:16 (running for 00:30:13.75)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.369 |  0.16  |                   68 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.282 |  0.137 |                   66 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.304 |  0.142 |                   64 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.423 |  0.176 |                   21 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.14223602414131165
[2m[36m(func pid=141107)[0m mae:  0.08581029623746872
[2m[36m(func pid=141107)[0m rmse_per_class: [0.06, 0.212, 0.025, 0.256, 0.049, 0.181, 0.241, 0.135, 0.181, 0.084]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.16014249622821808
[2m[36m(func pid=139223)[0m mae:  0.1142471432685852
[2m[36m(func pid=139223)[0m rmse_per_class: [0.093, 0.256, 0.063, 0.3, 0.068, 0.184, 0.26, 0.128, 0.14, 0.109]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2740 | Steps: 4 | Val loss: 0.2550 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4329 | Steps: 4 | Val loss: 0.3417 | Batch size: 32 | lr: 0.0001 | Duration: 2.71s
[2m[36m(func pid=140307)[0m rmse: 0.1339840292930603
[2m[36m(func pid=140307)[0m mae:  0.08843155950307846
[2m[36m(func pid=140307)[0m rmse_per_class: [0.062, 0.207, 0.037, 0.252, 0.056, 0.16, 0.219, 0.109, 0.147, 0.09]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3167 | Steps: 4 | Val loss: 0.2878 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3744 | Steps: 4 | Val loss: 0.2914 | Batch size: 32 | lr: 0.001 | Duration: 2.81s
[2m[36m(func pid=150896)[0m rmse: 0.1762244999408722
[2m[36m(func pid=150896)[0m mae:  0.12674440443515778
[2m[36m(func pid=150896)[0m rmse_per_class: [0.115, 0.271, 0.099, 0.343, 0.077, 0.194, 0.272, 0.134, 0.154, 0.102]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.15980394184589386
[2m[36m(func pid=139223)[0m mae:  0.11396746337413788
[2m[36m(func pid=139223)[0m rmse_per_class: [0.093, 0.255, 0.061, 0.3, 0.069, 0.184, 0.259, 0.128, 0.141, 0.108]
[2m[36m(func pid=139223)[0m 
== Status ==
Current time: 2024-01-07 16:54:21 (running for 00:30:19.09)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.374 |  0.16  |                   70 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.274 |  0.134 |                   67 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.304 |  0.142 |                   64 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.433 |  0.176 |                   22 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.1518959105014801
[2m[36m(func pid=141107)[0m mae:  0.09035003185272217
[2m[36m(func pid=141107)[0m rmse_per_class: [0.084, 0.235, 0.023, 0.269, 0.056, 0.18, 0.222, 0.176, 0.157, 0.117]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2818 | Steps: 4 | Val loss: 0.2555 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4486 | Steps: 4 | Val loss: 0.3461 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=140307)[0m rmse: 0.134703129529953
[2m[36m(func pid=140307)[0m mae:  0.08892954885959625
[2m[36m(func pid=140307)[0m rmse_per_class: [0.059, 0.21, 0.034, 0.254, 0.054, 0.161, 0.219, 0.109, 0.156, 0.091]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3687 | Steps: 4 | Val loss: 0.2910 | Batch size: 32 | lr: 0.001 | Duration: 2.91s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2597 | Steps: 4 | Val loss: 0.3095 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=150896)[0m rmse: 0.17563733458518982
[2m[36m(func pid=150896)[0m mae:  0.12606175243854523
[2m[36m(func pid=150896)[0m rmse_per_class: [0.114, 0.271, 0.095, 0.345, 0.076, 0.194, 0.272, 0.134, 0.154, 0.101]
[2m[36m(func pid=150896)[0m 
== Status ==
Current time: 2024-01-07 16:54:27 (running for 00:30:24.42)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.369 |  0.16  |                   71 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.282 |  0.135 |                   68 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.317 |  0.152 |                   65 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.449 |  0.176 |                   23 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=139223)[0m rmse: 0.15955139696598053
[2m[36m(func pid=139223)[0m mae:  0.11381039768457413
[2m[36m(func pid=139223)[0m rmse_per_class: [0.092, 0.255, 0.062, 0.299, 0.069, 0.184, 0.26, 0.128, 0.141, 0.106]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=141107)[0m rmse: 0.16220416128635406
[2m[36m(func pid=141107)[0m mae:  0.100002720952034
[2m[36m(func pid=141107)[0m rmse_per_class: [0.083, 0.235, 0.042, 0.331, 0.087, 0.187, 0.217, 0.11, 0.166, 0.164]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2838 | Steps: 4 | Val loss: 0.2519 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4515 | Steps: 4 | Val loss: 0.3517 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=140307)[0m rmse: 0.13240651786327362
[2m[36m(func pid=140307)[0m mae:  0.08692147582769394
[2m[36m(func pid=140307)[0m rmse_per_class: [0.059, 0.214, 0.032, 0.242, 0.052, 0.16, 0.213, 0.108, 0.15, 0.094]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3748 | Steps: 4 | Val loss: 0.2904 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2729 | Steps: 4 | Val loss: 0.2711 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=150896)[0m rmse: 0.17580945789813995
[2m[36m(func pid=150896)[0m mae:  0.12598730623722076
[2m[36m(func pid=150896)[0m rmse_per_class: [0.117, 0.271, 0.097, 0.345, 0.073, 0.194, 0.271, 0.135, 0.155, 0.101]
[2m[36m(func pid=150896)[0m 
== Status ==
Current time: 2024-01-07 16:54:32 (running for 00:30:29.61)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.375 |  0.159 |                   72 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.284 |  0.132 |                   69 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.26  |  0.162 |                   66 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.451 |  0.176 |                   24 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=139223)[0m rmse: 0.1593707650899887
[2m[36m(func pid=139223)[0m mae:  0.11358779668807983
[2m[36m(func pid=139223)[0m rmse_per_class: [0.092, 0.254, 0.063, 0.298, 0.07, 0.183, 0.259, 0.128, 0.14, 0.106]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=141107)[0m rmse: 0.1447765827178955
[2m[36m(func pid=141107)[0m mae:  0.08682184666395187
[2m[36m(func pid=141107)[0m rmse_per_class: [0.071, 0.219, 0.037, 0.252, 0.074, 0.178, 0.234, 0.115, 0.15, 0.118]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2773 | Steps: 4 | Val loss: 0.2529 | Batch size: 32 | lr: 0.01 | Duration: 2.81s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4586 | Steps: 4 | Val loss: 0.3580 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=140307)[0m rmse: 0.13344018161296844
[2m[36m(func pid=140307)[0m mae:  0.087640680372715
[2m[36m(func pid=140307)[0m rmse_per_class: [0.059, 0.221, 0.031, 0.237, 0.055, 0.162, 0.216, 0.107, 0.144, 0.103]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3800 | Steps: 4 | Val loss: 0.2899 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2893 | Steps: 4 | Val loss: 0.2699 | Batch size: 32 | lr: 0.1 | Duration: 2.80s
[2m[36m(func pid=150896)[0m rmse: 0.17573924362659454
[2m[36m(func pid=150896)[0m mae:  0.1255544126033783
[2m[36m(func pid=150896)[0m rmse_per_class: [0.115, 0.271, 0.098, 0.346, 0.07, 0.194, 0.271, 0.135, 0.156, 0.1]
[2m[36m(func pid=150896)[0m 
== Status ==
Current time: 2024-01-07 16:54:37 (running for 00:30:34.81)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.38  |  0.159 |                   73 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.277 |  0.133 |                   70 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.273 |  0.145 |                   67 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.459 |  0.176 |                   25 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=139223)[0m rmse: 0.1588701605796814
[2m[36m(func pid=139223)[0m mae:  0.11297913640737534
[2m[36m(func pid=139223)[0m rmse_per_class: [0.091, 0.253, 0.064, 0.299, 0.07, 0.183, 0.258, 0.128, 0.139, 0.103]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=141107)[0m rmse: 0.1386631429195404
[2m[36m(func pid=141107)[0m mae:  0.08367714285850525
[2m[36m(func pid=141107)[0m rmse_per_class: [0.06, 0.225, 0.027, 0.241, 0.051, 0.175, 0.218, 0.138, 0.16, 0.091]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2674 | Steps: 4 | Val loss: 0.2544 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.4630 | Steps: 4 | Val loss: 0.3663 | Batch size: 32 | lr: 0.0001 | Duration: 3.03s
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3735 | Steps: 4 | Val loss: 0.2906 | Batch size: 32 | lr: 0.001 | Duration: 2.90s
[2m[36m(func pid=140307)[0m rmse: 0.13490614295005798
[2m[36m(func pid=140307)[0m mae:  0.08813886344432831
[2m[36m(func pid=140307)[0m rmse_per_class: [0.063, 0.221, 0.029, 0.24, 0.055, 0.161, 0.218, 0.112, 0.135, 0.114]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2555 | Steps: 4 | Val loss: 0.3107 | Batch size: 32 | lr: 0.1 | Duration: 2.83s
[2m[36m(func pid=150896)[0m rmse: 0.17580975592136383
[2m[36m(func pid=150896)[0m mae:  0.12512502074241638
[2m[36m(func pid=150896)[0m rmse_per_class: [0.114, 0.273, 0.096, 0.347, 0.068, 0.194, 0.273, 0.136, 0.157, 0.099]
[2m[36m(func pid=150896)[0m 
== Status ==
Current time: 2024-01-07 16:54:43 (running for 00:30:40.23)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.373 |  0.159 |                   74 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.267 |  0.135 |                   71 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.289 |  0.139 |                   68 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.463 |  0.176 |                   26 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=139223)[0m rmse: 0.15928468108177185
[2m[36m(func pid=139223)[0m mae:  0.11333142220973969
[2m[36m(func pid=139223)[0m rmse_per_class: [0.09, 0.254, 0.065, 0.301, 0.07, 0.183, 0.257, 0.128, 0.139, 0.106]
[2m[36m(func pid=139223)[0m 
[2m[36m(func pid=141107)[0m rmse: 0.1652446985244751
[2m[36m(func pid=141107)[0m mae:  0.10124026238918304
[2m[36m(func pid=141107)[0m rmse_per_class: [0.092, 0.24, 0.034, 0.322, 0.064, 0.183, 0.237, 0.135, 0.217, 0.127]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2625 | Steps: 4 | Val loss: 0.2565 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4745 | Steps: 4 | Val loss: 0.3733 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=140307)[0m rmse: 0.13615259528160095
[2m[36m(func pid=140307)[0m mae:  0.08902929723262787
[2m[36m(func pid=140307)[0m rmse_per_class: [0.065, 0.216, 0.03, 0.249, 0.055, 0.161, 0.219, 0.115, 0.139, 0.112]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=139223)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3684 | Steps: 4 | Val loss: 0.2920 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2682 | Steps: 4 | Val loss: 0.2886 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
[2m[36m(func pid=150896)[0m rmse: 0.17566105723381042
[2m[36m(func pid=150896)[0m mae:  0.12470753490924835
[2m[36m(func pid=150896)[0m rmse_per_class: [0.112, 0.272, 0.094, 0.349, 0.067, 0.194, 0.275, 0.137, 0.159, 0.097]
[2m[36m(func pid=150896)[0m 
== Status ==
Current time: 2024-01-07 16:54:48 (running for 00:30:45.50)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=13
Bracket: Iter 75.000: -0.15399999916553497
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (7 PENDING, 4 RUNNING, 13 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00013 | RUNNING    | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.373 |  0.159 |                   74 |
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.262 |  0.136 |                   72 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.268 |  0.154 |                   70 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.475 |  0.176 |                   27 |
| train_c9cb4_00017 | PENDING    |                     | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.15382930636405945
[2m[36m(func pid=141107)[0m mae:  0.09215067327022552
[2m[36m(func pid=141107)[0m rmse_per_class: [0.073, 0.234, 0.027, 0.289, 0.092, 0.177, 0.212, 0.126, 0.135, 0.173]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=139223)[0m rmse: 0.1602669656276703
[2m[36m(func pid=139223)[0m mae:  0.11421243101358414
[2m[36m(func pid=139223)[0m rmse_per_class: [0.09, 0.253, 0.067, 0.303, 0.07, 0.183, 0.259, 0.128, 0.139, 0.11]
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2718 | Steps: 4 | Val loss: 0.2551 | Batch size: 32 | lr: 0.01 | Duration: 2.75s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4818 | Steps: 4 | Val loss: 0.3783 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=140307)[0m rmse: 0.13467809557914734
[2m[36m(func pid=140307)[0m mae:  0.08822028338909149
[2m[36m(func pid=140307)[0m rmse_per_class: [0.061, 0.211, 0.033, 0.251, 0.055, 0.161, 0.218, 0.116, 0.138, 0.103]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2379 | Steps: 4 | Val loss: 0.2786 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=150896)[0m rmse: 0.17539545893669128
[2m[36m(func pid=150896)[0m mae:  0.12448583543300629
[2m[36m(func pid=150896)[0m rmse_per_class: [0.113, 0.271, 0.089, 0.35, 0.067, 0.194, 0.275, 0.137, 0.161, 0.096]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2694 | Steps: 4 | Val loss: 0.2571 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=141107)[0m rmse: 0.14710329473018646
[2m[36m(func pid=141107)[0m mae:  0.0894647017121315
[2m[36m(func pid=141107)[0m rmse_per_class: [0.063, 0.218, 0.037, 0.252, 0.066, 0.177, 0.258, 0.134, 0.181, 0.087]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4807 | Steps: 4 | Val loss: 0.3867 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=140307)[0m rmse: 0.13624799251556396
[2m[36m(func pid=140307)[0m mae:  0.08942826092243195
[2m[36m(func pid=140307)[0m rmse_per_class: [0.059, 0.209, 0.034, 0.257, 0.057, 0.162, 0.219, 0.116, 0.14, 0.109]
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2846 | Steps: 4 | Val loss: 0.2769 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 16:54:53 (running for 00:30:51.04)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15549999848008156
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.272 |  0.135 |                   73 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.238 |  0.147 |                   71 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.482 |  0.175 |                   28 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=157909)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=157909)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=157909)[0m Configuration completed!
[2m[36m(func pid=157909)[0m New optimizer parameters:
[2m[36m(func pid=157909)[0m SGD (
[2m[36m(func pid=157909)[0m Parameter Group 0
[2m[36m(func pid=157909)[0m     dampening: 0
[2m[36m(func pid=157909)[0m     differentiable: False
[2m[36m(func pid=157909)[0m     foreach: None
[2m[36m(func pid=157909)[0m     lr: 0.001
[2m[36m(func pid=157909)[0m     maximize: False
[2m[36m(func pid=157909)[0m     momentum: 0.99
[2m[36m(func pid=157909)[0m     nesterov: False
[2m[36m(func pid=157909)[0m     weight_decay: 1e-05
[2m[36m(func pid=157909)[0m )
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17563045024871826
[2m[36m(func pid=150896)[0m mae:  0.12421057373285294
[2m[36m(func pid=150896)[0m rmse_per_class: [0.114, 0.272, 0.087, 0.352, 0.065, 0.194, 0.276, 0.138, 0.163, 0.096]
[2m[36m(func pid=150896)[0m 
== Status ==
Current time: 2024-01-07 16:54:59 (running for 00:30:56.43)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.15549999848008156
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.269 |  0.136 |                   74 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.285 |  0.145 |                   72 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.481 |  0.176 |                   29 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.14531543850898743
[2m[36m(func pid=141107)[0m mae:  0.0885474905371666
[2m[36m(func pid=141107)[0m rmse_per_class: [0.084, 0.24, 0.03, 0.263, 0.055, 0.171, 0.221, 0.113, 0.178, 0.097]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2710 | Steps: 4 | Val loss: 0.2572 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4877 | Steps: 4 | Val loss: 0.3902 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2706 | Steps: 4 | Val loss: 0.2797 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0599 | Steps: 4 | Val loss: 0.7499 | Batch size: 32 | lr: 0.001 | Duration: 4.65s
[2m[36m(func pid=140307)[0m rmse: 0.13633477687835693
[2m[36m(func pid=140307)[0m mae:  0.08960144221782684
[2m[36m(func pid=140307)[0m rmse_per_class: [0.059, 0.208, 0.035, 0.258, 0.057, 0.162, 0.218, 0.112, 0.145, 0.11]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17536437511444092
[2m[36m(func pid=150896)[0m mae:  0.12392586469650269
[2m[36m(func pid=150896)[0m rmse_per_class: [0.114, 0.271, 0.085, 0.352, 0.064, 0.194, 0.276, 0.137, 0.164, 0.096]
[2m[36m(func pid=150896)[0m 
== Status ==
Current time: 2024-01-07 16:55:04 (running for 00:31:01.70)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.271 |  0.136 |                   75 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.271 |  0.148 |                   73 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.488 |  0.175 |                   30 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.14754775166511536
[2m[36m(func pid=141107)[0m mae:  0.08888350427150726
[2m[36m(func pid=141107)[0m rmse_per_class: [0.061, 0.231, 0.031, 0.283, 0.065, 0.185, 0.214, 0.128, 0.126, 0.151]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.17893162369728088
[2m[36m(func pid=157909)[0m mae:  0.13132262229919434
[2m[36m(func pid=157909)[0m rmse_per_class: [0.105, 0.266, 0.088, 0.325, 0.101, 0.192, 0.304, 0.153, 0.139, 0.115]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2654 | Steps: 4 | Val loss: 0.2568 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4965 | Steps: 4 | Val loss: 0.3981 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2918 | Steps: 4 | Val loss: 0.2839 | Batch size: 32 | lr: 0.1 | Duration: 2.91s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.8997 | Steps: 4 | Val loss: 0.6096 | Batch size: 32 | lr: 0.001 | Duration: 3.20s
[2m[36m(func pid=140307)[0m rmse: 0.1362784206867218
[2m[36m(func pid=140307)[0m mae:  0.08928292989730835
[2m[36m(func pid=140307)[0m rmse_per_class: [0.064, 0.213, 0.032, 0.25, 0.056, 0.162, 0.217, 0.11, 0.145, 0.113]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.1756090372800827
[2m[36m(func pid=150896)[0m mae:  0.12362396717071533
[2m[36m(func pid=150896)[0m rmse_per_class: [0.114, 0.272, 0.086, 0.354, 0.062, 0.194, 0.277, 0.138, 0.164, 0.095]
[2m[36m(func pid=150896)[0m 
== Status ==
Current time: 2024-01-07 16:55:09 (running for 00:31:07.00)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=14
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 4 RUNNING, 14 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.265 |  0.136 |                   76 |
| train_c9cb4_00015 | RUNNING    | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.292 |  0.154 |                   74 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.496 |  0.176 |                   31 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  1.06  |  0.179 |                    1 |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.1536799669265747
[2m[36m(func pid=141107)[0m mae:  0.09102882444858551
[2m[36m(func pid=141107)[0m rmse_per_class: [0.11, 0.235, 0.044, 0.267, 0.078, 0.173, 0.218, 0.125, 0.142, 0.143]
[2m[36m(func pid=141107)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.1790538728237152
[2m[36m(func pid=157909)[0m mae:  0.13112089037895203
[2m[36m(func pid=157909)[0m rmse_per_class: [0.104, 0.267, 0.089, 0.325, 0.1, 0.193, 0.303, 0.156, 0.138, 0.115]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2847 | Steps: 4 | Val loss: 0.2537 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.5094 | Steps: 4 | Val loss: 0.3950 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=141107)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2539 | Steps: 4 | Val loss: 0.2815 | Batch size: 32 | lr: 0.1 | Duration: 2.90s
[2m[36m(func pid=140307)[0m rmse: 0.13418492674827576
[2m[36m(func pid=140307)[0m mae:  0.08739117532968521
[2m[36m(func pid=140307)[0m rmse_per_class: [0.065, 0.215, 0.032, 0.24, 0.056, 0.161, 0.216, 0.109, 0.138, 0.11]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.6738 | Steps: 4 | Val loss: 0.4467 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=150896)[0m rmse: 0.17553794384002686
[2m[36m(func pid=150896)[0m mae:  0.12347950786352158
[2m[36m(func pid=150896)[0m rmse_per_class: [0.114, 0.271, 0.083, 0.354, 0.061, 0.193, 0.28, 0.138, 0.164, 0.095]
[2m[36m(func pid=150896)[0m 
== Status ==
Current time: 2024-01-07 16:55:15 (running for 00:31:12.27)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (6 PENDING, 3 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.285 |  0.134 |                   77 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.509 |  0.176 |                   32 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.9   |  0.179 |                    2 |
| train_c9cb4_00018 | PENDING    |                     | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=141107)[0m rmse: 0.14737598598003387
[2m[36m(func pid=141107)[0m mae:  0.08918124437332153
[2m[36m(func pid=141107)[0m rmse_per_class: [0.074, 0.242, 0.029, 0.264, 0.06, 0.167, 0.219, 0.116, 0.202, 0.1]
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2758 | Steps: 4 | Val loss: 0.2508 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=157909)[0m rmse: 0.17885755002498627
[2m[36m(func pid=157909)[0m mae:  0.13073647022247314
[2m[36m(func pid=157909)[0m rmse_per_class: [0.105, 0.268, 0.093, 0.327, 0.097, 0.193, 0.3, 0.153, 0.139, 0.114]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.5124 | Steps: 4 | Val loss: 0.3949 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=140307)[0m rmse: 0.13157309591770172
[2m[36m(func pid=140307)[0m mae:  0.08541179448366165
[2m[36m(func pid=140307)[0m rmse_per_class: [0.063, 0.213, 0.032, 0.231, 0.056, 0.161, 0.219, 0.107, 0.136, 0.098]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.5016 | Steps: 4 | Val loss: 0.3481 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=150896)[0m rmse: 0.1751887947320938
[2m[36m(func pid=150896)[0m mae:  0.12287597358226776
[2m[36m(func pid=150896)[0m rmse_per_class: [0.113, 0.271, 0.081, 0.354, 0.061, 0.193, 0.282, 0.139, 0.164, 0.094]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2860 | Steps: 4 | Val loss: 0.2499 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=157909)[0m rmse: 0.17801430821418762
[2m[36m(func pid=157909)[0m mae:  0.12959466874599457
[2m[36m(func pid=157909)[0m rmse_per_class: [0.108, 0.269, 0.1, 0.332, 0.092, 0.193, 0.291, 0.142, 0.142, 0.111]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.5172 | Steps: 4 | Val loss: 0.4006 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 16:55:21 (running for 00:31:19.02)
Memory usage on this node: 23.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.276 |  0.132 |                   78 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.512 |  0.175 |                   33 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.502 |  0.178 |                    4 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=159237)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=159237)[0m Configuration completed!
[2m[36m(func pid=159237)[0m New optimizer parameters:
[2m[36m(func pid=159237)[0m SGD (
[2m[36m(func pid=159237)[0m Parameter Group 0
[2m[36m(func pid=159237)[0m     dampening: 0
[2m[36m(func pid=159237)[0m     differentiable: False
[2m[36m(func pid=159237)[0m     foreach: None
[2m[36m(func pid=159237)[0m     lr: 0.01
[2m[36m(func pid=159237)[0m     maximize: False
[2m[36m(func pid=159237)[0m     momentum: 0.99
[2m[36m(func pid=159237)[0m     nesterov: False
[2m[36m(func pid=159237)[0m     weight_decay: 1e-05
[2m[36m(func pid=159237)[0m )
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.13077740371227264
[2m[36m(func pid=140307)[0m mae:  0.08511306345462799
[2m[36m(func pid=140307)[0m rmse_per_class: [0.062, 0.209, 0.031, 0.235, 0.055, 0.161, 0.215, 0.107, 0.136, 0.098]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.1756356656551361
[2m[36m(func pid=150896)[0m mae:  0.12289746850728989
[2m[36m(func pid=150896)[0m rmse_per_class: [0.113, 0.271, 0.08, 0.355, 0.059, 0.193, 0.286, 0.139, 0.166, 0.094]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.4329 | Steps: 4 | Val loss: 0.3245 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2720 | Steps: 4 | Val loss: 0.2502 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=157909)[0m rmse: 0.17671898007392883
[2m[36m(func pid=157909)[0m mae:  0.12795716524124146
[2m[36m(func pid=157909)[0m rmse_per_class: [0.111, 0.27, 0.103, 0.341, 0.083, 0.194, 0.28, 0.136, 0.144, 0.106]
[2m[36m(func pid=157909)[0m 
== Status ==
Current time: 2024-01-07 16:55:27 (running for 00:31:24.62)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.286 |  0.131 |                   79 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.517 |  0.176 |                   34 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.433 |  0.177 |                    5 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.5206 | Steps: 4 | Val loss: 0.4066 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8645 | Steps: 4 | Val loss: 0.4166 | Batch size: 32 | lr: 0.01 | Duration: 4.48s
[2m[36m(func pid=140307)[0m rmse: 0.1306684911251068
[2m[36m(func pid=140307)[0m mae:  0.08486343920230865
[2m[36m(func pid=140307)[0m rmse_per_class: [0.057, 0.207, 0.031, 0.24, 0.056, 0.163, 0.212, 0.107, 0.132, 0.102]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17603492736816406
[2m[36m(func pid=150896)[0m mae:  0.12294773757457733
[2m[36m(func pid=150896)[0m rmse_per_class: [0.116, 0.271, 0.08, 0.356, 0.059, 0.194, 0.286, 0.14, 0.165, 0.093]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4210 | Steps: 4 | Val loss: 0.3448 | Batch size: 32 | lr: 0.001 | Duration: 2.85s
[2m[36m(func pid=159237)[0m rmse: 0.17656467854976654
[2m[36m(func pid=159237)[0m mae:  0.12898392975330353
[2m[36m(func pid=159237)[0m rmse_per_class: [0.106, 0.269, 0.088, 0.329, 0.09, 0.192, 0.291, 0.151, 0.14, 0.11]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2797 | Steps: 4 | Val loss: 0.2566 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.5211 | Steps: 4 | Val loss: 0.4065 | Batch size: 32 | lr: 0.0001 | Duration: 2.77s
== Status ==
Current time: 2024-01-07 16:55:32 (running for 00:31:30.00)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.272 |  0.131 |                   80 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.521 |  0.176 |                   35 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.421 |  0.176 |                    6 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.864 |  0.177 |                    1 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=157909)[0m rmse: 0.17565317451953888
[2m[36m(func pid=157909)[0m mae:  0.1258166879415512
[2m[36m(func pid=157909)[0m rmse_per_class: [0.112, 0.271, 0.102, 0.348, 0.074, 0.195, 0.272, 0.135, 0.148, 0.099]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.4565 | Steps: 4 | Val loss: 0.3530 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=140307)[0m rmse: 0.13514693081378937
[2m[36m(func pid=140307)[0m mae:  0.08852341026067734
[2m[36m(func pid=140307)[0m rmse_per_class: [0.057, 0.206, 0.03, 0.26, 0.062, 0.174, 0.217, 0.108, 0.14, 0.098]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17577001452445984
[2m[36m(func pid=150896)[0m mae:  0.12219101190567017
[2m[36m(func pid=150896)[0m rmse_per_class: [0.114, 0.271, 0.078, 0.356, 0.058, 0.193, 0.29, 0.141, 0.164, 0.093]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.1759769767522812
[2m[36m(func pid=159237)[0m mae:  0.12548242509365082
[2m[36m(func pid=159237)[0m rmse_per_class: [0.116, 0.277, 0.098, 0.354, 0.069, 0.192, 0.277, 0.133, 0.147, 0.096]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4569 | Steps: 4 | Val loss: 0.3805 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2735 | Steps: 4 | Val loss: 0.2563 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.5273 | Steps: 4 | Val loss: 0.4049 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 16:55:38 (running for 00:31:35.59)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.28  |  0.135 |                   81 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.521 |  0.176 |                   36 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.457 |  0.176 |                    7 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.457 |  0.176 |                    2 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=157909)[0m rmse: 0.17602857947349548
[2m[36m(func pid=157909)[0m mae:  0.12436207383871078
[2m[36m(func pid=157909)[0m rmse_per_class: [0.112, 0.273, 0.097, 0.356, 0.067, 0.195, 0.277, 0.138, 0.15, 0.095]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.5697 | Steps: 4 | Val loss: 0.4903 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=140307)[0m rmse: 0.1346532553434372
[2m[36m(func pid=140307)[0m mae:  0.08799770474433899
[2m[36m(func pid=140307)[0m rmse_per_class: [0.058, 0.207, 0.03, 0.263, 0.064, 0.17, 0.213, 0.11, 0.141, 0.093]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17561589181423187
[2m[36m(func pid=150896)[0m mae:  0.12194126844406128
[2m[36m(func pid=150896)[0m rmse_per_class: [0.116, 0.271, 0.076, 0.355, 0.058, 0.193, 0.289, 0.141, 0.165, 0.093]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.1843687891960144
[2m[36m(func pid=159237)[0m mae:  0.12343361228704453
[2m[36m(func pid=159237)[0m rmse_per_class: [0.108, 0.286, 0.071, 0.375, 0.057, 0.19, 0.379, 0.145, 0.141, 0.092]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.5162 | Steps: 4 | Val loss: 0.4202 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2704 | Steps: 4 | Val loss: 0.2581 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.5212 | Steps: 4 | Val loss: 0.4061 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.7502 | Steps: 4 | Val loss: 0.5948 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=157909)[0m rmse: 0.17740830779075623
[2m[36m(func pid=157909)[0m mae:  0.12307530641555786
== Status ==
Current time: 2024-01-07 16:55:44 (running for 00:31:41.27)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.273 |  0.135 |                   82 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.527 |  0.176 |                   37 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.516 |  0.177 |                    8 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.57  |  0.184 |                    3 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)

[2m[36m(func pid=157909)[0m rmse_per_class: [0.111, 0.274, 0.086, 0.363, 0.061, 0.195, 0.3, 0.141, 0.15, 0.093]

[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.1364535540342331
[2m[36m(func pid=140307)[0m mae:  0.08916158974170685
[2m[36m(func pid=140307)[0m rmse_per_class: [0.059, 0.213, 0.029, 0.261, 0.066, 0.164, 0.211, 0.112, 0.159, 0.092]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17532429099082947
[2m[36m(func pid=150896)[0m mae:  0.12137557566165924
[2m[36m(func pid=150896)[0m rmse_per_class: [0.113, 0.27, 0.074, 0.355, 0.057, 0.193, 0.293, 0.142, 0.163, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.19952693581581116
[2m[36m(func pid=159237)[0m mae:  0.12782502174377441
[2m[36m(func pid=159237)[0m rmse_per_class: [0.099, 0.293, 0.05, 0.384, 0.056, 0.189, 0.544, 0.153, 0.133, 0.094]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.5617 | Steps: 4 | Val loss: 0.4652 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2749 | Steps: 4 | Val loss: 0.2604 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.5322 | Steps: 4 | Val loss: 0.4057 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.8638 | Steps: 4 | Val loss: 0.6334 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=157909)[0m rmse: 0.18010789155960083
[2m[36m(func pid=157909)[0m mae:  0.12280480563640594
[2m[36m(func pid=157909)[0m rmse_per_class: [0.111, 0.275, 0.074, 0.369, 0.058, 0.194, 0.33, 0.145, 0.152, 0.092]
[2m[36m(func pid=157909)[0m 
== Status ==
Current time: 2024-01-07 16:55:49 (running for 00:31:46.89)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.27  |  0.136 |                   83 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.521 |  0.175 |                   38 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.562 |  0.18  |                    9 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.75  |  0.2   |                    4 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m rmse: 0.13875220715999603
[2m[36m(func pid=140307)[0m mae:  0.09083174169063568
[2m[36m(func pid=140307)[0m rmse_per_class: [0.063, 0.214, 0.031, 0.257, 0.067, 0.162, 0.216, 0.11, 0.179, 0.089]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.175482839345932
[2m[36m(func pid=150896)[0m mae:  0.1216437965631485
[2m[36m(func pid=150896)[0m rmse_per_class: [0.114, 0.27, 0.072, 0.355, 0.057, 0.193, 0.292, 0.142, 0.168, 0.093]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.2096070945262909
[2m[36m(func pid=159237)[0m mae:  0.1329963505268097
[2m[36m(func pid=159237)[0m rmse_per_class: [0.094, 0.296, 0.048, 0.387, 0.056, 0.191, 0.638, 0.155, 0.134, 0.096]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.6132 | Steps: 4 | Val loss: 0.4931 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2768 | Steps: 4 | Val loss: 0.2572 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.5216 | Steps: 4 | Val loss: 0.4070 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.8642 | Steps: 4 | Val loss: 0.6095 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 16:55:55 (running for 00:31:52.53)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.275 |  0.139 |                   84 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.532 |  0.175 |                   39 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.613 |  0.183 |                   10 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.864 |  0.21  |                    5 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=157909)[0m rmse: 0.18276014924049377
[2m[36m(func pid=157909)[0m mae:  0.12260057777166367
[2m[36m(func pid=157909)[0m rmse_per_class: [0.107, 0.276, 0.066, 0.372, 0.056, 0.193, 0.365, 0.148, 0.152, 0.092]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.13710464537143707
[2m[36m(func pid=140307)[0m mae:  0.08915060758590698
[2m[36m(func pid=140307)[0m rmse_per_class: [0.064, 0.213, 0.035, 0.245, 0.062, 0.162, 0.221, 0.115, 0.157, 0.098]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17522193491458893
[2m[36m(func pid=150896)[0m mae:  0.12127912044525146
[2m[36m(func pid=150896)[0m rmse_per_class: [0.114, 0.269, 0.07, 0.355, 0.056, 0.193, 0.292, 0.142, 0.168, 0.093]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.21421794593334198
[2m[36m(func pid=159237)[0m mae:  0.13618537783622742
[2m[36m(func pid=159237)[0m rmse_per_class: [0.09, 0.297, 0.048, 0.388, 0.056, 0.195, 0.678, 0.156, 0.137, 0.097]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.6590 | Steps: 4 | Val loss: 0.5207 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2712 | Steps: 4 | Val loss: 0.2550 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.5257 | Steps: 4 | Val loss: 0.3999 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.8315 | Steps: 4 | Val loss: 0.5445 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=157909)[0m rmse: 0.18544620275497437
[2m[36m(func pid=157909)[0m mae:  0.1232360228896141
[2m[36m(func pid=157909)[0m rmse_per_class: [0.105, 0.277, 0.06, 0.376, 0.056, 0.192, 0.391, 0.15, 0.156, 0.093]
[2m[36m(func pid=157909)[0m 
== Status ==
Current time: 2024-01-07 16:56:01 (running for 00:31:58.22)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.277 |  0.137 |                   85 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.522 |  0.175 |                   40 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.659 |  0.185 |                   11 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.864 |  0.214 |                    6 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m rmse: 0.13585838675498962
[2m[36m(func pid=140307)[0m mae:  0.08788566291332245
[2m[36m(func pid=140307)[0m rmse_per_class: [0.061, 0.214, 0.032, 0.238, 0.059, 0.161, 0.223, 0.121, 0.14, 0.109]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17470605671405792
[2m[36m(func pid=150896)[0m mae:  0.12083722651004791
[2m[36m(func pid=150896)[0m rmse_per_class: [0.111, 0.27, 0.068, 0.355, 0.056, 0.193, 0.293, 0.141, 0.167, 0.093]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.20881769061088562
[2m[36m(func pid=159237)[0m mae:  0.13241715729236603
[2m[36m(func pid=159237)[0m rmse_per_class: [0.083, 0.295, 0.049, 0.388, 0.056, 0.182, 0.644, 0.156, 0.137, 0.097]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2593 | Steps: 4 | Val loss: 0.2526 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.7013 | Steps: 4 | Val loss: 0.5419 | Batch size: 32 | lr: 0.001 | Duration: 3.20s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.5211 | Steps: 4 | Val loss: 0.3987 | Batch size: 32 | lr: 0.0001 | Duration: 3.08s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.7465 | Steps: 4 | Val loss: 0.4494 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
== Status ==
Current time: 2024-01-07 16:56:06 (running for 00:32:03.87)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.259 |  0.134 |                   87 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.526 |  0.175 |                   41 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.659 |  0.185 |                   11 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.831 |  0.209 |                    7 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m rmse: 0.13350605964660645
[2m[36m(func pid=140307)[0m mae:  0.0864461287856102
[2m[36m(func pid=140307)[0m rmse_per_class: [0.058, 0.209, 0.033, 0.238, 0.057, 0.161, 0.219, 0.117, 0.135, 0.107]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.1881389319896698
[2m[36m(func pid=157909)[0m mae:  0.12404961884021759
[2m[36m(func pid=157909)[0m rmse_per_class: [0.103, 0.278, 0.055, 0.378, 0.056, 0.191, 0.417, 0.152, 0.158, 0.094]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17437274754047394
[2m[36m(func pid=150896)[0m mae:  0.12047499418258667
[2m[36m(func pid=150896)[0m rmse_per_class: [0.112, 0.269, 0.066, 0.354, 0.056, 0.193, 0.295, 0.141, 0.165, 0.093]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.18840235471725464
[2m[36m(func pid=159237)[0m mae:  0.11803305149078369
[2m[36m(func pid=159237)[0m rmse_per_class: [0.138, 0.272, 0.049, 0.383, 0.056, 0.222, 0.375, 0.156, 0.135, 0.096]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2927 | Steps: 4 | Val loss: 0.2513 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.6981 | Steps: 4 | Val loss: 0.5557 | Batch size: 32 | lr: 0.001 | Duration: 3.19s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.5363 | Steps: 4 | Val loss: 0.3973 | Batch size: 32 | lr: 0.0001 | Duration: 3.10s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.6015 | Steps: 4 | Val loss: 0.3778 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 16:56:12 (running for 00:32:09.39)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.293 |  0.132 |                   88 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.521 |  0.174 |                   42 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.701 |  0.188 |                   12 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.747 |  0.188 |                    8 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m rmse: 0.13212931156158447
[2m[36m(func pid=140307)[0m mae:  0.08533300459384918
[2m[36m(func pid=140307)[0m rmse_per_class: [0.057, 0.208, 0.031, 0.242, 0.054, 0.16, 0.215, 0.118, 0.13, 0.108]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17446006834506989
[2m[36m(func pid=150896)[0m mae:  0.1205621138215065
[2m[36m(func pid=150896)[0m rmse_per_class: [0.111, 0.268, 0.067, 0.354, 0.056, 0.193, 0.294, 0.141, 0.167, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.19134560227394104
[2m[36m(func pid=157909)[0m mae:  0.12511421740055084
[2m[36m(func pid=157909)[0m rmse_per_class: [0.101, 0.279, 0.051, 0.38, 0.056, 0.191, 0.45, 0.153, 0.159, 0.094]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.17984458804130554
[2m[36m(func pid=159237)[0m mae:  0.11735286563634872
[2m[36m(func pid=159237)[0m rmse_per_class: [0.165, 0.226, 0.048, 0.352, 0.056, 0.342, 0.226, 0.156, 0.131, 0.095]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2706 | Steps: 4 | Val loss: 0.2512 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.5235 | Steps: 4 | Val loss: 0.3937 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7352 | Steps: 4 | Val loss: 0.5516 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.5813 | Steps: 4 | Val loss: 0.3816 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 16:56:17 (running for 00:32:14.73)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.271 |  0.132 |                   89 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.536 |  0.174 |                   43 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.698 |  0.191 |                   13 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.602 |  0.18  |                    9 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m rmse: 0.13183411955833435
[2m[36m(func pid=140307)[0m mae:  0.08523602038621902
[2m[36m(func pid=140307)[0m rmse_per_class: [0.057, 0.209, 0.031, 0.245, 0.053, 0.16, 0.21, 0.113, 0.136, 0.104]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17400318384170532
[2m[36m(func pid=150896)[0m mae:  0.12021557241678238
[2m[36m(func pid=150896)[0m rmse_per_class: [0.111, 0.268, 0.064, 0.354, 0.056, 0.193, 0.292, 0.141, 0.168, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.19469180703163147
[2m[36m(func pid=157909)[0m mae:  0.1262771636247635
[2m[36m(func pid=157909)[0m rmse_per_class: [0.098, 0.281, 0.049, 0.381, 0.056, 0.192, 0.488, 0.153, 0.154, 0.095]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.16097970306873322
[2m[36m(func pid=159237)[0m mae:  0.1096787229180336
[2m[36m(func pid=159237)[0m rmse_per_class: [0.107, 0.253, 0.048, 0.265, 0.056, 0.204, 0.303, 0.155, 0.131, 0.088]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2634 | Steps: 4 | Val loss: 0.2516 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.5142 | Steps: 4 | Val loss: 0.3909 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.7169 | Steps: 4 | Val loss: 0.5498 | Batch size: 32 | lr: 0.001 | Duration: 3.28s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.6003 | Steps: 4 | Val loss: 0.4016 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 16:56:23 (running for 00:32:20.23)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.263 |  0.132 |                   90 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.524 |  0.174 |                   44 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.735 |  0.195 |                   14 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.581 |  0.161 |                   10 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m rmse: 0.13168582320213318
[2m[36m(func pid=140307)[0m mae:  0.08527763932943344
[2m[36m(func pid=140307)[0m rmse_per_class: [0.06, 0.206, 0.032, 0.246, 0.056, 0.16, 0.211, 0.108, 0.14, 0.098]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17375321686267853
[2m[36m(func pid=150896)[0m mae:  0.12026441097259521
[2m[36m(func pid=150896)[0m rmse_per_class: [0.111, 0.267, 0.064, 0.354, 0.056, 0.193, 0.286, 0.142, 0.172, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.197636216878891
[2m[36m(func pid=157909)[0m mae:  0.12749233841896057
[2m[36m(func pid=157909)[0m rmse_per_class: [0.097, 0.282, 0.048, 0.382, 0.056, 0.193, 0.519, 0.154, 0.15, 0.095]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.1661192625761032
[2m[36m(func pid=159237)[0m mae:  0.11546490341424942
[2m[36m(func pid=159237)[0m rmse_per_class: [0.072, 0.231, 0.044, 0.291, 0.056, 0.178, 0.319, 0.149, 0.19, 0.131]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2640 | Steps: 4 | Val loss: 0.2521 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.5279 | Steps: 4 | Val loss: 0.3905 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.7206 | Steps: 4 | Val loss: 0.5498 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.5948 | Steps: 4 | Val loss: 0.3832 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 16:56:28 (running for 00:32:25.47)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.264 |  0.132 |                   91 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.514 |  0.174 |                   45 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.717 |  0.198 |                   15 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.6   |  0.166 |                   11 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m rmse: 0.1319364756345749
[2m[36m(func pid=140307)[0m mae:  0.08559286594390869
[2m[36m(func pid=140307)[0m rmse_per_class: [0.062, 0.205, 0.032, 0.236, 0.06, 0.161, 0.219, 0.107, 0.145, 0.092]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17368364334106445
[2m[36m(func pid=150896)[0m mae:  0.12009761482477188
[2m[36m(func pid=150896)[0m rmse_per_class: [0.112, 0.267, 0.063, 0.353, 0.056, 0.193, 0.286, 0.142, 0.172, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.18765828013420105
[2m[36m(func pid=159237)[0m mae:  0.13008125126361847
[2m[36m(func pid=159237)[0m rmse_per_class: [0.077, 0.263, 0.031, 0.256, 0.056, 0.208, 0.307, 0.123, 0.233, 0.322]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.20051810145378113
[2m[36m(func pid=157909)[0m mae:  0.12886208295822144
[2m[36m(func pid=157909)[0m rmse_per_class: [0.097, 0.283, 0.048, 0.383, 0.056, 0.194, 0.544, 0.155, 0.15, 0.096]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.5096 | Steps: 4 | Val loss: 0.3868 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2680 | Steps: 4 | Val loss: 0.2543 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4281 | Steps: 4 | Val loss: 0.3791 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.7393 | Steps: 4 | Val loss: 0.5340 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 16:56:33 (running for 00:32:30.71)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.264 |  0.132 |                   91 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.51  |  0.174 |                   47 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.721 |  0.201 |                   16 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.595 |  0.188 |                   12 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=150896)[0m rmse: 0.17368997633457184
[2m[36m(func pid=150896)[0m mae:  0.11983853578567505
[2m[36m(func pid=150896)[0m rmse_per_class: [0.11, 0.267, 0.06, 0.354, 0.056, 0.192, 0.289, 0.143, 0.174, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.133843332529068
[2m[36m(func pid=140307)[0m mae:  0.08675838261842728
[2m[36m(func pid=140307)[0m rmse_per_class: [0.06, 0.208, 0.029, 0.238, 0.057, 0.161, 0.223, 0.111, 0.149, 0.101]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.20200586318969727
[2m[36m(func pid=159237)[0m mae:  0.13035571575164795
[2m[36m(func pid=159237)[0m rmse_per_class: [0.083, 0.286, 0.146, 0.293, 0.056, 0.212, 0.249, 0.207, 0.166, 0.322]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.2016218602657318
[2m[36m(func pid=157909)[0m mae:  0.12939438223838806
[2m[36m(func pid=157909)[0m rmse_per_class: [0.097, 0.283, 0.048, 0.384, 0.056, 0.194, 0.553, 0.155, 0.152, 0.096]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.5138 | Steps: 4 | Val loss: 0.3855 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2667 | Steps: 4 | Val loss: 0.2544 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4961 | Steps: 4 | Val loss: 0.4926 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=150896)[0m rmse: 0.17353838682174683
[2m[36m(func pid=150896)[0m mae:  0.11931709945201874
[2m[36m(func pid=150896)[0m rmse_per_class: [0.111, 0.267, 0.059, 0.353, 0.056, 0.192, 0.29, 0.143, 0.172, 0.092]
[2m[36m(func pid=150896)[0m 
== Status ==
Current time: 2024-01-07 16:56:38 (running for 00:32:35.92)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.268 |  0.134 |                   92 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.514 |  0.174 |                   48 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.739 |  0.202 |                   17 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.428 |  0.202 |                   13 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.7085 | Steps: 4 | Val loss: 0.5204 | Batch size: 32 | lr: 0.001 | Duration: 3.22s
[2m[36m(func pid=140307)[0m rmse: 0.13413313031196594
[2m[36m(func pid=140307)[0m mae:  0.0863998606801033
[2m[36m(func pid=140307)[0m rmse_per_class: [0.062, 0.21, 0.029, 0.241, 0.056, 0.162, 0.22, 0.114, 0.142, 0.106]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.22357754409313202
[2m[36m(func pid=159237)[0m mae:  0.14449399709701538
[2m[36m(func pid=159237)[0m rmse_per_class: [0.093, 0.296, 0.294, 0.368, 0.056, 0.219, 0.221, 0.463, 0.129, 0.097]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.20384597778320312
[2m[36m(func pid=157909)[0m mae:  0.13055559992790222
[2m[36m(func pid=157909)[0m rmse_per_class: [0.098, 0.285, 0.048, 0.384, 0.056, 0.194, 0.571, 0.155, 0.151, 0.096]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2860 | Steps: 4 | Val loss: 0.2534 | Batch size: 32 | lr: 0.01 | Duration: 2.72s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.5052 | Steps: 4 | Val loss: 0.3823 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.6211 | Steps: 4 | Val loss: 0.5533 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=140307)[0m rmse: 0.13379205763339996
[2m[36m(func pid=140307)[0m mae:  0.0863925963640213
[2m[36m(func pid=140307)[0m rmse_per_class: [0.069, 0.21, 0.03, 0.243, 0.054, 0.161, 0.22, 0.111, 0.135, 0.105]
[2m[36m(func pid=140307)[0m 
== Status ==
Current time: 2024-01-07 16:56:44 (running for 00:32:41.54)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.286 |  0.134 |                   94 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.514 |  0.174 |                   48 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.708 |  0.204 |                   18 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.496 |  0.224 |                   14 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=150896)[0m rmse: 0.17291653156280518
[2m[36m(func pid=150896)[0m mae:  0.11923046410083771
[2m[36m(func pid=150896)[0m rmse_per_class: [0.112, 0.265, 0.058, 0.352, 0.056, 0.192, 0.288, 0.143, 0.172, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.7032 | Steps: 4 | Val loss: 0.4986 | Batch size: 32 | lr: 0.001 | Duration: 3.14s
[2m[36m(func pid=159237)[0m rmse: 0.22237515449523926
[2m[36m(func pid=159237)[0m mae:  0.14319756627082825
[2m[36m(func pid=159237)[0m rmse_per_class: [0.092, 0.297, 0.251, 0.382, 0.056, 0.218, 0.228, 0.475, 0.134, 0.091]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.20290115475654602
[2m[36m(func pid=157909)[0m mae:  0.12986378371715546
[2m[36m(func pid=157909)[0m rmse_per_class: [0.097, 0.284, 0.048, 0.384, 0.056, 0.191, 0.563, 0.155, 0.154, 0.096]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2714 | Steps: 4 | Val loss: 0.2531 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4982 | Steps: 4 | Val loss: 0.3817 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.5902 | Steps: 4 | Val loss: 0.4861 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 16:56:49 (running for 00:32:46.94)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.286 |  0.134 |                   94 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.498 |  0.173 |                   50 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.703 |  0.203 |                   19 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.621 |  0.222 |                   15 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=150896)[0m rmse: 0.17271573841571808
[2m[36m(func pid=150896)[0m mae:  0.11919447034597397
[2m[36m(func pid=150896)[0m rmse_per_class: [0.113, 0.265, 0.058, 0.351, 0.055, 0.191, 0.284, 0.143, 0.174, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.1333279311656952
[2m[36m(func pid=140307)[0m mae:  0.08598948270082474
[2m[36m(func pid=140307)[0m rmse_per_class: [0.066, 0.21, 0.034, 0.249, 0.053, 0.161, 0.212, 0.117, 0.134, 0.098]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.6505 | Steps: 4 | Val loss: 0.4784 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=159237)[0m rmse: 0.20864491164684296
[2m[36m(func pid=159237)[0m mae:  0.1303550899028778
[2m[36m(func pid=159237)[0m rmse_per_class: [0.075, 0.284, 0.222, 0.379, 0.05, 0.197, 0.351, 0.303, 0.133, 0.093]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.2008119821548462
[2m[36m(func pid=157909)[0m mae:  0.1285596638917923
[2m[36m(func pid=157909)[0m rmse_per_class: [0.096, 0.282, 0.048, 0.384, 0.056, 0.188, 0.544, 0.155, 0.158, 0.096]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.5067 | Steps: 4 | Val loss: 0.3770 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2695 | Steps: 4 | Val loss: 0.2522 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.5145 | Steps: 4 | Val loss: 0.4102 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 16:56:55 (running for 00:32:52.22)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.271 |  0.133 |                   95 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.507 |  0.172 |                   51 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.651 |  0.201 |                   20 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.59  |  0.209 |                   16 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=150896)[0m rmse: 0.1722785383462906
[2m[36m(func pid=150896)[0m mae:  0.11862681806087494
[2m[36m(func pid=150896)[0m rmse_per_class: [0.113, 0.265, 0.057, 0.349, 0.055, 0.192, 0.286, 0.144, 0.171, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.13205209374427795
[2m[36m(func pid=140307)[0m mae:  0.08505172282457352
[2m[36m(func pid=140307)[0m rmse_per_class: [0.062, 0.206, 0.033, 0.251, 0.054, 0.16, 0.211, 0.119, 0.129, 0.094]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.6464 | Steps: 4 | Val loss: 0.4529 | Batch size: 32 | lr: 0.001 | Duration: 3.16s
[2m[36m(func pid=159237)[0m rmse: 0.17715439200401306
[2m[36m(func pid=159237)[0m mae:  0.10746648162603378
[2m[36m(func pid=159237)[0m rmse_per_class: [0.108, 0.244, 0.089, 0.37, 0.085, 0.168, 0.343, 0.14, 0.132, 0.093]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4948 | Steps: 4 | Val loss: 0.3741 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2649 | Steps: 4 | Val loss: 0.2530 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=157909)[0m rmse: 0.19774693250656128
[2m[36m(func pid=157909)[0m mae:  0.12683650851249695
[2m[36m(func pid=157909)[0m rmse_per_class: [0.094, 0.28, 0.048, 0.382, 0.056, 0.186, 0.515, 0.155, 0.165, 0.096]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4007 | Steps: 4 | Val loss: 0.3757 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 16:57:00 (running for 00:32:57.82)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.269 |  0.132 |                   96 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.495 |  0.172 |                   52 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.646 |  0.198 |                   21 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.515 |  0.177 |                   17 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=150896)[0m rmse: 0.1719149798154831
[2m[36m(func pid=150896)[0m mae:  0.11855258792638779
[2m[36m(func pid=150896)[0m rmse_per_class: [0.118, 0.264, 0.057, 0.349, 0.055, 0.191, 0.279, 0.144, 0.171, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.13216045498847961
[2m[36m(func pid=140307)[0m mae:  0.08537473529577255
[2m[36m(func pid=140307)[0m rmse_per_class: [0.059, 0.206, 0.034, 0.254, 0.058, 0.163, 0.212, 0.116, 0.13, 0.09]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.6305 | Steps: 4 | Val loss: 0.4255 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=159237)[0m rmse: 0.17890624701976776
[2m[36m(func pid=159237)[0m mae:  0.11214618384838104
[2m[36m(func pid=159237)[0m rmse_per_class: [0.125, 0.216, 0.024, 0.358, 0.223, 0.285, 0.217, 0.12, 0.128, 0.094]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2697 | Steps: 4 | Val loss: 0.2542 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4842 | Steps: 4 | Val loss: 0.3675 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=157909)[0m rmse: 0.19296373426914215
[2m[36m(func pid=157909)[0m mae:  0.12419787794351578
[2m[36m(func pid=157909)[0m rmse_per_class: [0.091, 0.275, 0.048, 0.381, 0.056, 0.183, 0.467, 0.155, 0.178, 0.096]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.4078 | Steps: 4 | Val loss: 0.4011 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 16:57:06 (running for 00:33:03.24)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.265 |  0.132 |                   97 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.484 |  0.171 |                   53 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.631 |  0.193 |                   22 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.401 |  0.179 |                   18 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m rmse: 0.13307319581508636
[2m[36m(func pid=140307)[0m mae:  0.08610706031322479
[2m[36m(func pid=140307)[0m rmse_per_class: [0.058, 0.206, 0.031, 0.257, 0.059, 0.164, 0.213, 0.114, 0.132, 0.096]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17111799120903015
[2m[36m(func pid=150896)[0m mae:  0.11810503154993057
[2m[36m(func pid=150896)[0m rmse_per_class: [0.118, 0.263, 0.055, 0.347, 0.055, 0.191, 0.276, 0.143, 0.17, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.5819 | Steps: 4 | Val loss: 0.4042 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=159237)[0m rmse: 0.186738520860672
[2m[36m(func pid=159237)[0m mae:  0.12156210094690323
[2m[36m(func pid=159237)[0m rmse_per_class: [0.091, 0.203, 0.032, 0.34, 0.263, 0.303, 0.27, 0.142, 0.128, 0.095]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4800 | Steps: 4 | Val loss: 0.3616 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2665 | Steps: 4 | Val loss: 0.2542 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=157909)[0m rmse: 0.18638376891613007
[2m[36m(func pid=157909)[0m mae:  0.12086015939712524
[2m[36m(func pid=157909)[0m rmse_per_class: [0.087, 0.267, 0.048, 0.378, 0.056, 0.182, 0.398, 0.155, 0.197, 0.096]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4670 | Steps: 4 | Val loss: 0.3952 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 16:57:11 (running for 00:33:08.44)
Memory usage on this node: 25.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=15
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 4 RUNNING, 15 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00014 | RUNNING    | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.267 |  0.133 |                   99 |
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.484 |  0.171 |                   53 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.582 |  0.186 |                   23 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.408 |  0.187 |                   19 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=140307)[0m rmse: 0.1332472860813141
[2m[36m(func pid=140307)[0m mae:  0.08597146719694138
[2m[36m(func pid=140307)[0m rmse_per_class: [0.058, 0.207, 0.033, 0.252, 0.063, 0.162, 0.211, 0.11, 0.137, 0.1]
[2m[36m(func pid=140307)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.17089544236660004
[2m[36m(func pid=150896)[0m mae:  0.11798789352178574
[2m[36m(func pid=150896)[0m rmse_per_class: [0.116, 0.263, 0.056, 0.348, 0.055, 0.191, 0.275, 0.143, 0.169, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.17475873231887817
[2m[36m(func pid=159237)[0m mae:  0.11368000507354736
[2m[36m(func pid=159237)[0m rmse_per_class: [0.082, 0.21, 0.042, 0.291, 0.177, 0.242, 0.285, 0.147, 0.179, 0.093]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.5582 | Steps: 4 | Val loss: 0.3778 | Batch size: 32 | lr: 0.001 | Duration: 3.21s
[2m[36m(func pid=140307)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2657 | Steps: 4 | Val loss: 0.2511 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4759 | Steps: 4 | Val loss: 0.3542 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4779 | Steps: 4 | Val loss: 0.3660 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=157909)[0m rmse: 0.17907258868217468
[2m[36m(func pid=157909)[0m mae:  0.11760380119085312
[2m[36m(func pid=157909)[0m rmse_per_class: [0.085, 0.258, 0.048, 0.373, 0.056, 0.19, 0.323, 0.155, 0.207, 0.096]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=140307)[0m rmse: 0.13138684630393982
[2m[36m(func pid=140307)[0m mae:  0.08477582037448883
[2m[36m(func pid=140307)[0m rmse_per_class: [0.057, 0.208, 0.032, 0.241, 0.061, 0.162, 0.211, 0.108, 0.136, 0.099]
== Status ==
Current time: 2024-01-07 16:57:16 (running for 00:33:13.67)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (5 PENDING, 3 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.48  |  0.171 |                   54 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.558 |  0.179 |                   24 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.467 |  0.175 |                   20 |
| train_c9cb4_00019 | PENDING    |                     | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=150896)[0m rmse: 0.17005674540996552
[2m[36m(func pid=150896)[0m mae:  0.1173945888876915
[2m[36m(func pid=150896)[0m rmse_per_class: [0.119, 0.262, 0.055, 0.347, 0.055, 0.191, 0.271, 0.143, 0.166, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.1582041084766388
[2m[36m(func pid=159237)[0m mae:  0.10141347348690033
[2m[36m(func pid=159237)[0m rmse_per_class: [0.069, 0.202, 0.044, 0.25, 0.091, 0.178, 0.261, 0.149, 0.252, 0.085]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.5132 | Steps: 4 | Val loss: 0.3560 | Batch size: 32 | lr: 0.001 | Duration: 3.25s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4801 | Steps: 4 | Val loss: 0.3533 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4805 | Steps: 4 | Val loss: 0.3486 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=157909)[0m rmse: 0.17315088212490082
[2m[36m(func pid=157909)[0m mae:  0.11559073626995087
[2m[36m(func pid=157909)[0m rmse_per_class: [0.087, 0.249, 0.048, 0.366, 0.056, 0.204, 0.258, 0.154, 0.214, 0.095]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.16989798843860626
[2m[36m(func pid=150896)[0m mae:  0.1174405962228775
[2m[36m(func pid=150896)[0m rmse_per_class: [0.12, 0.261, 0.054, 0.346, 0.055, 0.191, 0.268, 0.143, 0.169, 0.092]
[2m[36m(func pid=159237)[0m rmse: 0.15229855477809906
[2m[36m(func pid=159237)[0m mae:  0.09324488043785095
[2m[36m(func pid=159237)[0m rmse_per_class: [0.066, 0.203, 0.042, 0.305, 0.054, 0.18, 0.222, 0.151, 0.211, 0.09]
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.5216 | Steps: 4 | Val loss: 0.3376 | Batch size: 32 | lr: 0.001 | Duration: 2.87s
== Status ==
Current time: 2024-01-07 16:57:21 (running for 00:33:18.79)
Memory usage on this node: 22.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.476 |  0.17  |                   55 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.513 |  0.173 |                   25 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.478 |  0.158 |                   21 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=164825)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=164825)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=164825)[0m Configuration completed!
[2m[36m(func pid=164825)[0m New optimizer parameters:
[2m[36m(func pid=164825)[0m SGD (
[2m[36m(func pid=164825)[0m Parameter Group 0
[2m[36m(func pid=164825)[0m     dampening: 0
[2m[36m(func pid=164825)[0m     differentiable: False
[2m[36m(func pid=164825)[0m     foreach: None
[2m[36m(func pid=164825)[0m     lr: 0.1
[2m[36m(func pid=164825)[0m     maximize: False
[2m[36m(func pid=164825)[0m     momentum: 0.99
[2m[36m(func pid=164825)[0m     nesterov: False
[2m[36m(func pid=164825)[0m     weight_decay: 1e-05
[2m[36m(func pid=164825)[0m )
[2m[36m(func pid=164825)[0m 
== Status ==
Current time: 2024-01-07 16:57:27 (running for 00:33:24.32)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.48  |  0.17  |                   56 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.522 |  0.17  |                   26 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.48  |  0.152 |                   22 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |        |        |                      |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=157909)[0m rmse: 0.16950634121894836
[2m[36m(func pid=157909)[0m mae:  0.114767886698246
[2m[36m(func pid=157909)[0m rmse_per_class: [0.096, 0.242, 0.048, 0.353, 0.056, 0.213, 0.226, 0.154, 0.212, 0.094]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3863 | Steps: 4 | Val loss: 0.3641 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4710 | Steps: 4 | Val loss: 0.3465 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.6837 | Steps: 4 | Val loss: 0.4985 | Batch size: 32 | lr: 0.1 | Duration: 4.70s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4873 | Steps: 4 | Val loss: 0.3250 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=159237)[0m rmse: 0.16269561648368835
[2m[36m(func pid=159237)[0m mae:  0.09472444653511047
[2m[36m(func pid=159237)[0m rmse_per_class: [0.066, 0.249, 0.04, 0.32, 0.05, 0.202, 0.219, 0.147, 0.136, 0.198]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.16910819709300995
[2m[36m(func pid=150896)[0m mae:  0.11700315773487091
[2m[36m(func pid=150896)[0m rmse_per_class: [0.119, 0.261, 0.054, 0.344, 0.055, 0.191, 0.265, 0.142, 0.168, 0.092]
[2m[36m(func pid=150896)[0m 
== Status ==
Current time: 2024-01-07 16:57:32 (running for 00:33:29.45)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.471 |  0.169 |                   57 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.522 |  0.17  |                   26 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.386 |  0.163 |                   23 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.684 |  0.185 |                    1 |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=164825)[0m rmse: 0.18473735451698303
[2m[36m(func pid=164825)[0m mae:  0.12350635230541229
[2m[36m(func pid=164825)[0m rmse_per_class: [0.107, 0.28, 0.06, 0.375, 0.055, 0.188, 0.396, 0.147, 0.146, 0.093]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.16790345311164856
[2m[36m(func pid=157909)[0m mae:  0.11452029645442963
[2m[36m(func pid=157909)[0m rmse_per_class: [0.106, 0.239, 0.048, 0.336, 0.056, 0.221, 0.23, 0.153, 0.198, 0.092]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4294 | Steps: 4 | Val loss: 0.3819 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4544 | Steps: 4 | Val loss: 0.3421 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0046 | Steps: 4 | Val loss: 0.6098 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=159237)[0m rmse: 0.17472943663597107
[2m[36m(func pid=159237)[0m mae:  0.10119946300983429
[2m[36m(func pid=159237)[0m rmse_per_class: [0.067, 0.275, 0.039, 0.263, 0.053, 0.213, 0.267, 0.138, 0.121, 0.313]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.4516 | Steps: 4 | Val loss: 0.3221 | Batch size: 32 | lr: 0.001 | Duration: 3.14s
[2m[36m(func pid=150896)[0m rmse: 0.16829165816307068
[2m[36m(func pid=150896)[0m mae:  0.11654078960418701
[2m[36m(func pid=150896)[0m rmse_per_class: [0.117, 0.259, 0.053, 0.343, 0.055, 0.192, 0.261, 0.142, 0.167, 0.092]
[2m[36m(func pid=150896)[0m 
== Status ==
Current time: 2024-01-07 16:57:37 (running for 00:33:35.06)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.454 |  0.168 |                   58 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.487 |  0.168 |                   27 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.429 |  0.175 |                   24 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  1.005 |  0.209 |                    2 |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=164825)[0m rmse: 0.20944471657276154
[2m[36m(func pid=164825)[0m mae:  0.13311251997947693
[2m[36m(func pid=164825)[0m rmse_per_class: [0.127, 0.292, 0.049, 0.389, 0.056, 0.205, 0.591, 0.156, 0.133, 0.096]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4919 | Steps: 4 | Val loss: 0.3955 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=157909)[0m rmse: 0.16729377210140228
[2m[36m(func pid=157909)[0m mae:  0.1146216168999672
[2m[36m(func pid=157909)[0m rmse_per_class: [0.114, 0.239, 0.048, 0.316, 0.056, 0.218, 0.251, 0.152, 0.189, 0.091]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4456 | Steps: 4 | Val loss: 0.3397 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.9273 | Steps: 4 | Val loss: 0.5049 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=159237)[0m rmse: 0.1825207769870758
[2m[36m(func pid=159237)[0m mae:  0.10605525970458984
[2m[36m(func pid=159237)[0m rmse_per_class: [0.07, 0.282, 0.034, 0.257, 0.054, 0.209, 0.308, 0.127, 0.12, 0.365]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.1681082546710968
[2m[36m(func pid=150896)[0m mae:  0.11621738970279694
[2m[36m(func pid=150896)[0m rmse_per_class: [0.116, 0.259, 0.052, 0.341, 0.055, 0.192, 0.261, 0.143, 0.169, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.4584 | Steps: 4 | Val loss: 0.3245 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
== Status ==
Current time: 2024-01-07 16:57:43 (running for 00:33:40.66)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.446 |  0.168 |                   59 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.452 |  0.167 |                   28 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.492 |  0.183 |                   25 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.927 |  0.182 |                    3 |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=164825)[0m rmse: 0.1818104088306427
[2m[36m(func pid=164825)[0m mae:  0.1239362582564354
[2m[36m(func pid=164825)[0m rmse_per_class: [0.082, 0.231, 0.049, 0.385, 0.056, 0.336, 0.258, 0.156, 0.173, 0.091]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.5135 | Steps: 4 | Val loss: 0.4014 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4494 | Steps: 4 | Val loss: 0.3350 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=157909)[0m rmse: 0.1648457944393158
[2m[36m(func pid=157909)[0m mae:  0.11372190713882446
[2m[36m(func pid=157909)[0m rmse_per_class: [0.122, 0.24, 0.048, 0.292, 0.056, 0.204, 0.275, 0.15, 0.174, 0.089]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.1806468516588211
[2m[36m(func pid=159237)[0m mae:  0.10467906296253204
[2m[36m(func pid=159237)[0m rmse_per_class: [0.074, 0.272, 0.026, 0.275, 0.055, 0.186, 0.301, 0.131, 0.132, 0.355]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.16760052740573883
[2m[36m(func pid=150896)[0m mae:  0.11611555516719818
[2m[36m(func pid=150896)[0m rmse_per_class: [0.118, 0.258, 0.052, 0.34, 0.055, 0.192, 0.258, 0.143, 0.169, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.7438 | Steps: 4 | Val loss: 0.3880 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.4415 | Steps: 4 | Val loss: 0.3271 | Batch size: 32 | lr: 0.001 | Duration: 3.13s
== Status ==
Current time: 2024-01-07 16:57:49 (running for 00:33:46.29)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.449 |  0.168 |                   60 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.458 |  0.165 |                   29 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.514 |  0.181 |                   26 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.744 |  0.186 |                    4 |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4284 | Steps: 4 | Val loss: 0.4068 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=164825)[0m rmse: 0.1857176125049591
[2m[36m(func pid=164825)[0m mae:  0.11872303485870361
[2m[36m(func pid=164825)[0m rmse_per_class: [0.094, 0.273, 0.033, 0.541, 0.056, 0.205, 0.293, 0.115, 0.128, 0.119]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4565 | Steps: 4 | Val loss: 0.3294 | Batch size: 32 | lr: 0.0001 | Duration: 2.81s
[2m[36m(func pid=157909)[0m rmse: 0.16129988431930542
[2m[36m(func pid=157909)[0m mae:  0.11200027167797089
[2m[36m(func pid=157909)[0m rmse_per_class: [0.118, 0.241, 0.047, 0.277, 0.056, 0.191, 0.289, 0.147, 0.159, 0.089]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.17938357591629028
[2m[36m(func pid=159237)[0m mae:  0.101274274289608
[2m[36m(func pid=159237)[0m rmse_per_class: [0.077, 0.256, 0.028, 0.288, 0.055, 0.165, 0.265, 0.19, 0.226, 0.242]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.1668706089258194
[2m[36m(func pid=150896)[0m mae:  0.11574163287878036
[2m[36m(func pid=150896)[0m rmse_per_class: [0.118, 0.257, 0.052, 0.338, 0.055, 0.192, 0.257, 0.141, 0.166, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.7200 | Steps: 4 | Val loss: 0.5237 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4498 | Steps: 4 | Val loss: 0.3276 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3968 | Steps: 4 | Val loss: 0.4105 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 16:57:54 (running for 00:33:51.93)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.456 |  0.167 |                   61 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.441 |  0.161 |                   30 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.428 |  0.179 |                   27 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.72  |  0.215 |                    5 |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=164825)[0m rmse: 0.21536695957183838
[2m[36m(func pid=164825)[0m mae:  0.13370409607887268
[2m[36m(func pid=164825)[0m rmse_per_class: [0.086, 0.296, 0.319, 0.345, 0.056, 0.199, 0.233, 0.386, 0.135, 0.097]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4392 | Steps: 4 | Val loss: 0.3261 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=157909)[0m rmse: 0.15837350487709045
[2m[36m(func pid=157909)[0m mae:  0.11062421649694443
[2m[36m(func pid=157909)[0m rmse_per_class: [0.108, 0.239, 0.046, 0.268, 0.056, 0.181, 0.298, 0.14, 0.147, 0.1]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.18651381134986877
[2m[36m(func pid=159237)[0m mae:  0.10743969678878784
[2m[36m(func pid=159237)[0m rmse_per_class: [0.084, 0.244, 0.035, 0.315, 0.056, 0.203, 0.264, 0.224, 0.316, 0.125]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.16643904149532318
[2m[36m(func pid=150896)[0m mae:  0.11556416749954224
[2m[36m(func pid=150896)[0m rmse_per_class: [0.118, 0.257, 0.052, 0.336, 0.055, 0.192, 0.256, 0.142, 0.165, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.5801 | Steps: 4 | Val loss: 0.4328 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4488 | Steps: 4 | Val loss: 0.3280 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3907 | Steps: 4 | Val loss: 0.4098 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4303 | Steps: 4 | Val loss: 0.3239 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 16:58:00 (running for 00:33:57.60)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.439 |  0.166 |                   62 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.45  |  0.158 |                   31 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.397 |  0.187 |                   28 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.58  |  0.175 |                    6 |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=164825)[0m rmse: 0.17490339279174805
[2m[36m(func pid=164825)[0m mae:  0.10882363468408585
[2m[36m(func pid=164825)[0m rmse_per_class: [0.091, 0.21, 0.039, 0.257, 0.053, 0.336, 0.29, 0.155, 0.22, 0.097]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.15799938142299652
[2m[36m(func pid=157909)[0m mae:  0.11050330102443695
[2m[36m(func pid=157909)[0m rmse_per_class: [0.098, 0.238, 0.045, 0.266, 0.056, 0.174, 0.304, 0.131, 0.138, 0.129]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.18675020337104797
[2m[36m(func pid=159237)[0m mae:  0.11112178862094879
[2m[36m(func pid=159237)[0m rmse_per_class: [0.078, 0.232, 0.04, 0.332, 0.056, 0.257, 0.281, 0.224, 0.286, 0.082]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.16651318967342377
[2m[36m(func pid=150896)[0m mae:  0.11585254967212677
[2m[36m(func pid=150896)[0m rmse_per_class: [0.12, 0.257, 0.052, 0.337, 0.055, 0.192, 0.254, 0.142, 0.164, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.6348 | Steps: 4 | Val loss: 0.5037 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4345 | Steps: 4 | Val loss: 0.3284 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3897 | Steps: 4 | Val loss: 0.4058 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4436 | Steps: 4 | Val loss: 0.3179 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
== Status ==
Current time: 2024-01-07 16:58:06 (running for 00:34:03.28)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.43  |  0.167 |                   63 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.449 |  0.158 |                   32 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.391 |  0.187 |                   29 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.635 |  0.172 |                    7 |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=164825)[0m rmse: 0.1716158241033554
[2m[36m(func pid=164825)[0m mae:  0.10348892211914062
[2m[36m(func pid=164825)[0m rmse_per_class: [0.085, 0.213, 0.03, 0.268, 0.281, 0.192, 0.254, 0.156, 0.143, 0.095]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.15936115384101868
[2m[36m(func pid=157909)[0m mae:  0.11091357469558716
[2m[36m(func pid=157909)[0m rmse_per_class: [0.089, 0.237, 0.044, 0.265, 0.056, 0.173, 0.306, 0.124, 0.132, 0.168]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.17765994369983673
[2m[36m(func pid=159237)[0m mae:  0.10623615980148315
[2m[36m(func pid=159237)[0m rmse_per_class: [0.076, 0.225, 0.052, 0.333, 0.056, 0.266, 0.273, 0.195, 0.219, 0.081]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.16580253839492798
[2m[36m(func pid=150896)[0m mae:  0.11552083492279053
[2m[36m(func pid=150896)[0m rmse_per_class: [0.12, 0.256, 0.052, 0.333, 0.055, 0.192, 0.253, 0.141, 0.165, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.7239 | Steps: 4 | Val loss: 0.6605 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4294 | Steps: 4 | Val loss: 0.3243 | Batch size: 32 | lr: 0.001 | Duration: 3.15s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.4312 | Steps: 4 | Val loss: 0.3976 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4331 | Steps: 4 | Val loss: 0.3143 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 16:58:11 (running for 00:34:08.86)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.444 |  0.166 |                   64 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.435 |  0.159 |                   33 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.39  |  0.178 |                   30 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.724 |  0.213 |                    8 |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=164825)[0m rmse: 0.21291565895080566
[2m[36m(func pid=164825)[0m mae:  0.12262453883886337
[2m[36m(func pid=164825)[0m rmse_per_class: [0.08, 0.299, 0.037, 0.303, 0.242, 0.216, 0.434, 0.156, 0.139, 0.225]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.16127851605415344
[2m[36m(func pid=157909)[0m mae:  0.1115906685590744
[2m[36m(func pid=157909)[0m rmse_per_class: [0.08, 0.239, 0.041, 0.261, 0.056, 0.176, 0.303, 0.112, 0.129, 0.214]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.16831958293914795
[2m[36m(func pid=159237)[0m mae:  0.0995042696595192
[2m[36m(func pid=159237)[0m rmse_per_class: [0.073, 0.233, 0.074, 0.327, 0.056, 0.237, 0.256, 0.175, 0.166, 0.085]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.16503235697746277
[2m[36m(func pid=150896)[0m mae:  0.1149660125374794
[2m[36m(func pid=150896)[0m rmse_per_class: [0.12, 0.256, 0.052, 0.33, 0.055, 0.192, 0.251, 0.141, 0.162, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.9988 | Steps: 4 | Val loss: 0.6779 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.4337 | Steps: 4 | Val loss: 0.3193 | Batch size: 32 | lr: 0.001 | Duration: 2.92s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.4685 | Steps: 4 | Val loss: 0.3614 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4266 | Steps: 4 | Val loss: 0.3093 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 16:58:17 (running for 00:34:14.44)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.433 |  0.165 |                   65 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.429 |  0.161 |                   34 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.431 |  0.168 |                   31 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.999 |  0.208 |                    9 |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=164825)[0m rmse: 0.2079949826002121
[2m[36m(func pid=164825)[0m mae:  0.12115927785634995
[2m[36m(func pid=164825)[0m rmse_per_class: [0.08, 0.295, 0.033, 0.299, 0.051, 0.225, 0.272, 0.156, 0.238, 0.432]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.1631309986114502
[2m[36m(func pid=157909)[0m mae:  0.11222720146179199
[2m[36m(func pid=157909)[0m rmse_per_class: [0.074, 0.242, 0.039, 0.259, 0.056, 0.183, 0.302, 0.113, 0.128, 0.235]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.15488848090171814
[2m[36m(func pid=159237)[0m mae:  0.0888860747218132
[2m[36m(func pid=159237)[0m rmse_per_class: [0.078, 0.248, 0.093, 0.296, 0.055, 0.173, 0.228, 0.162, 0.134, 0.083]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.16407963633537292
[2m[36m(func pid=150896)[0m mae:  0.1142863780260086
[2m[36m(func pid=150896)[0m rmse_per_class: [0.118, 0.254, 0.051, 0.329, 0.055, 0.192, 0.25, 0.14, 0.159, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.9451 | Steps: 4 | Val loss: 0.5522 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4432 | Steps: 4 | Val loss: 0.3262 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4146 | Steps: 4 | Val loss: 0.3161 | Batch size: 32 | lr: 0.001 | Duration: 3.19s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4157 | Steps: 4 | Val loss: 0.3073 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 16:58:23 (running for 00:34:20.20)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.427 |  0.164 |                   66 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.434 |  0.163 |                   35 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.469 |  0.155 |                   32 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.945 |  0.187 |                   10 |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=164825)[0m rmse: 0.18743543326854706
[2m[36m(func pid=164825)[0m mae:  0.11136350780725479
[2m[36m(func pid=164825)[0m rmse_per_class: [0.077, 0.233, 0.038, 0.281, 0.056, 0.36, 0.285, 0.153, 0.301, 0.088]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.16713254153728485
[2m[36m(func pid=157909)[0m mae:  0.11362405121326447
[2m[36m(func pid=157909)[0m rmse_per_class: [0.071, 0.249, 0.041, 0.252, 0.056, 0.188, 0.293, 0.144, 0.127, 0.25]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.14379683136940002
[2m[36m(func pid=159237)[0m mae:  0.08142190426588058
[2m[36m(func pid=159237)[0m rmse_per_class: [0.069, 0.216, 0.089, 0.254, 0.053, 0.161, 0.237, 0.153, 0.125, 0.08]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.16366522014141083
[2m[36m(func pid=150896)[0m mae:  0.11404027044773102
[2m[36m(func pid=150896)[0m rmse_per_class: [0.117, 0.254, 0.05, 0.327, 0.055, 0.192, 0.249, 0.14, 0.159, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.6170 | Steps: 4 | Val loss: 0.5818 | Batch size: 32 | lr: 0.1 | Duration: 3.18s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.4034 | Steps: 4 | Val loss: 0.3191 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4274 | Steps: 4 | Val loss: 0.3046 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3848 | Steps: 4 | Val loss: 0.3145 | Batch size: 32 | lr: 0.001 | Duration: 3.18s
== Status ==
Current time: 2024-01-07 16:58:28 (running for 00:34:26.02)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.416 |  0.164 |                   67 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.415 |  0.167 |                   36 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.443 |  0.144 |                   33 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.617 |  0.149 |                   11 |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=164825)[0m rmse: 0.14898768067359924
[2m[36m(func pid=164825)[0m mae:  0.08707259595394135
[2m[36m(func pid=164825)[0m rmse_per_class: [0.066, 0.238, 0.101, 0.262, 0.056, 0.169, 0.242, 0.127, 0.132, 0.097]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.1632179617881775
[2m[36m(func pid=150896)[0m mae:  0.11379341036081314
[2m[36m(func pid=150896)[0m rmse_per_class: [0.117, 0.255, 0.05, 0.325, 0.055, 0.192, 0.247, 0.14, 0.158, 0.092]
[2m[36m(func pid=159237)[0m rmse: 0.14504067599773407
[2m[36m(func pid=159237)[0m mae:  0.08055990189313889
[2m[36m(func pid=159237)[0m rmse_per_class: [0.074, 0.198, 0.105, 0.255, 0.051, 0.168, 0.241, 0.152, 0.125, 0.082]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.17229127883911133
[2m[36m(func pid=157909)[0m mae:  0.11567239463329315
[2m[36m(func pid=157909)[0m rmse_per_class: [0.07, 0.253, 0.051, 0.253, 0.056, 0.192, 0.285, 0.196, 0.127, 0.24]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.8103 | Steps: 4 | Val loss: 0.6623 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3809 | Steps: 4 | Val loss: 0.3428 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4026 | Steps: 4 | Val loss: 0.3018 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4139 | Steps: 4 | Val loss: 0.3182 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 16:58:34 (running for 00:34:31.77)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.427 |  0.163 |                   68 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.385 |  0.172 |                   37 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.381 |  0.159 |                   35 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.617 |  0.149 |                   11 |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.1588505208492279
[2m[36m(func pid=159237)[0m mae:  0.08588467538356781
[2m[36m(func pid=159237)[0m rmse_per_class: [0.077, 0.211, 0.089, 0.314, 0.075, 0.18, 0.236, 0.147, 0.125, 0.135]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.21526697278022766
[2m[36m(func pid=164825)[0m mae:  0.11840011924505234
[2m[36m(func pid=164825)[0m rmse_per_class: [0.115, 0.281, 0.209, 0.299, 0.056, 0.184, 0.325, 0.43, 0.155, 0.097]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.16259324550628662
[2m[36m(func pid=150896)[0m mae:  0.11325772851705551
[2m[36m(func pid=150896)[0m rmse_per_class: [0.117, 0.254, 0.05, 0.323, 0.055, 0.193, 0.247, 0.14, 0.155, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.17795875668525696
[2m[36m(func pid=157909)[0m mae:  0.11812643706798553
[2m[36m(func pid=157909)[0m rmse_per_class: [0.07, 0.258, 0.073, 0.262, 0.056, 0.196, 0.274, 0.252, 0.127, 0.212]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4015 | Steps: 4 | Val loss: 0.3742 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.9131 | Steps: 4 | Val loss: 0.7332 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4066 | Steps: 4 | Val loss: 0.2995 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4061 | Steps: 4 | Val loss: 0.3264 | Batch size: 32 | lr: 0.001 | Duration: 3.17s
== Status ==
Current time: 2024-01-07 16:58:40 (running for 00:34:37.28)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.163 |                   69 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.414 |  0.178 |                   38 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.401 |  0.177 |                   36 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.81  |  0.215 |                   12 |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.17658762633800507
[2m[36m(func pid=159237)[0m mae:  0.0947975218296051
[2m[36m(func pid=159237)[0m rmse_per_class: [0.071, 0.243, 0.072, 0.341, 0.111, 0.189, 0.238, 0.144, 0.127, 0.23]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.21726647019386292
[2m[36m(func pid=164825)[0m mae:  0.12016025930643082
[2m[36m(func pid=164825)[0m rmse_per_class: [0.155, 0.268, 0.038, 0.305, 0.054, 0.245, 0.331, 0.42, 0.268, 0.089]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.162105530500412
[2m[36m(func pid=150896)[0m mae:  0.11305613815784454
[2m[36m(func pid=150896)[0m rmse_per_class: [0.119, 0.253, 0.049, 0.319, 0.055, 0.192, 0.246, 0.139, 0.155, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.1830807626247406
[2m[36m(func pid=157909)[0m mae:  0.12047644704580307
[2m[36m(func pid=157909)[0m rmse_per_class: [0.072, 0.262, 0.093, 0.279, 0.056, 0.197, 0.257, 0.312, 0.127, 0.175]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3991 | Steps: 4 | Val loss: 0.3924 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7711 | Steps: 4 | Val loss: 0.5933 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3999 | Steps: 4 | Val loss: 0.2971 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4083 | Steps: 4 | Val loss: 0.3316 | Batch size: 32 | lr: 0.001 | Duration: 3.18s
== Status ==
Current time: 2024-01-07 16:58:45 (running for 00:34:42.62)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.407 |  0.162 |                   70 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.406 |  0.183 |                   39 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.399 |  0.186 |                   37 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.913 |  0.217 |                   13 |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.18647263944149017
[2m[36m(func pid=159237)[0m mae:  0.10190562158823013
[2m[36m(func pid=159237)[0m rmse_per_class: [0.069, 0.265, 0.055, 0.303, 0.134, 0.192, 0.243, 0.147, 0.144, 0.314]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.1615971028804779
[2m[36m(func pid=150896)[0m mae:  0.11289010941982269
[2m[36m(func pid=150896)[0m rmse_per_class: [0.118, 0.253, 0.049, 0.316, 0.055, 0.192, 0.247, 0.138, 0.155, 0.092]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.18922638893127441
[2m[36m(func pid=164825)[0m mae:  0.10812511295080185
[2m[36m(func pid=164825)[0m rmse_per_class: [0.074, 0.287, 0.049, 0.307, 0.05, 0.23, 0.351, 0.148, 0.229, 0.168]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.18574407696723938
[2m[36m(func pid=157909)[0m mae:  0.12149256467819214
[2m[36m(func pid=157909)[0m rmse_per_class: [0.074, 0.266, 0.127, 0.294, 0.056, 0.198, 0.243, 0.335, 0.128, 0.136]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4404 | Steps: 4 | Val loss: 0.4030 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4181 | Steps: 4 | Val loss: 0.2937 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.6628 | Steps: 4 | Val loss: 0.6390 | Batch size: 32 | lr: 0.1 | Duration: 3.19s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4318 | Steps: 4 | Val loss: 0.3386 | Batch size: 32 | lr: 0.001 | Duration: 3.17s
== Status ==
Current time: 2024-01-07 16:58:50 (running for 00:34:48.08)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.4   |  0.162 |                   71 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.408 |  0.186 |                   40 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.44  |  0.189 |                   38 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.771 |  0.189 |                   14 |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.18881896138191223
[2m[36m(func pid=159237)[0m mae:  0.10650279372930527
[2m[36m(func pid=159237)[0m rmse_per_class: [0.072, 0.27, 0.038, 0.279, 0.141, 0.189, 0.239, 0.138, 0.179, 0.343]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.16069264709949493
[2m[36m(func pid=150896)[0m mae:  0.1124730259180069
[2m[36m(func pid=150896)[0m rmse_per_class: [0.118, 0.252, 0.05, 0.311, 0.055, 0.19, 0.247, 0.137, 0.153, 0.093]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.201491117477417
[2m[36m(func pid=164825)[0m mae:  0.11575640738010406
[2m[36m(func pid=164825)[0m rmse_per_class: [0.086, 0.252, 0.049, 0.293, 0.084, 0.256, 0.294, 0.149, 0.253, 0.298]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.18750163912773132
[2m[36m(func pid=157909)[0m mae:  0.12240400165319443
[2m[36m(func pid=157909)[0m rmse_per_class: [0.078, 0.266, 0.158, 0.309, 0.056, 0.199, 0.232, 0.343, 0.129, 0.104]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4000 | Steps: 4 | Val loss: 0.3832 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4011 | Steps: 4 | Val loss: 0.2935 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.7400 | Steps: 4 | Val loss: 0.6341 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3964 | Steps: 4 | Val loss: 0.3383 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 16:58:56 (running for 00:34:53.57)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.418 |  0.161 |                   72 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.432 |  0.188 |                   41 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.4   |  0.181 |                   39 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.663 |  0.201 |                   15 |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)

[2m[36m(func pid=159237)[0m rmse: 0.18118825554847717

[2m[36m(func pid=159237)[0m mae:  0.10347143560647964
[2m[36m(func pid=159237)[0m rmse_per_class: [0.072, 0.268, 0.027, 0.266, 0.118, 0.182, 0.237, 0.133, 0.232, 0.277]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.16080239415168762
[2m[36m(func pid=150896)[0m mae:  0.11263300478458405
[2m[36m(func pid=150896)[0m rmse_per_class: [0.118, 0.253, 0.05, 0.309, 0.055, 0.19, 0.249, 0.138, 0.153, 0.093]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.18604445457458496
[2m[36m(func pid=164825)[0m mae:  0.10108904540538788
[2m[36m(func pid=164825)[0m rmse_per_class: [0.094, 0.256, 0.047, 0.325, 0.188, 0.225, 0.276, 0.144, 0.214, 0.093]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.1858348548412323
[2m[36m(func pid=157909)[0m mae:  0.12055826187133789
[2m[36m(func pid=157909)[0m rmse_per_class: [0.077, 0.262, 0.183, 0.321, 0.056, 0.198, 0.226, 0.314, 0.129, 0.092]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3596 | Steps: 4 | Val loss: 0.3783 | Batch size: 32 | lr: 0.01 | Duration: 3.15s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4000 | Steps: 4 | Val loss: 0.2920 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.7987 | Steps: 4 | Val loss: 0.7159 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3739 | Steps: 4 | Val loss: 0.3312 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 16:59:02 (running for 00:34:59.13)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.401 |  0.161 |                   73 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.396 |  0.186 |                   42 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.36  |  0.176 |                   40 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.74  |  0.186 |                   16 |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.17596587538719177
[2m[36m(func pid=159237)[0m mae:  0.10297874361276627
[2m[36m(func pid=159237)[0m rmse_per_class: [0.07, 0.259, 0.028, 0.277, 0.104, 0.212, 0.247, 0.13, 0.238, 0.193]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.1602902114391327
[2m[36m(func pid=150896)[0m mae:  0.11225809901952744
[2m[36m(func pid=150896)[0m rmse_per_class: [0.118, 0.252, 0.049, 0.307, 0.055, 0.19, 0.25, 0.137, 0.152, 0.093]
[2m[36m(func pid=150896)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.1822916567325592
[2m[36m(func pid=164825)[0m mae:  0.09981942921876907
[2m[36m(func pid=164825)[0m rmse_per_class: [0.098, 0.3, 0.039, 0.292, 0.165, 0.209, 0.342, 0.147, 0.145, 0.087]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.1811361014842987
[2m[36m(func pid=157909)[0m mae:  0.1168203130364418
[2m[36m(func pid=157909)[0m rmse_per_class: [0.076, 0.256, 0.208, 0.326, 0.055, 0.194, 0.225, 0.253, 0.132, 0.087]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3326 | Steps: 4 | Val loss: 0.3713 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=150896)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4031 | Steps: 4 | Val loss: 0.2911 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.8562 | Steps: 4 | Val loss: 0.7615 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3830 | Steps: 4 | Val loss: 0.3258 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
== Status ==
Current time: 2024-01-07 16:59:07 (running for 00:35:04.46)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=16
Bracket: Iter 75.000: -0.14499999955296516
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 PENDING, 4 RUNNING, 16 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00016 | RUNNING    | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.4   |  0.16  |                   74 |
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.374 |  0.181 |                   43 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.333 |  0.169 |                   41 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.799 |  0.182 |                   17 |
| train_c9cb4_00020 | PENDING    |                     | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.1691364198923111
[2m[36m(func pid=159237)[0m mae:  0.10064429044723511
[2m[36m(func pid=159237)[0m rmse_per_class: [0.067, 0.242, 0.032, 0.283, 0.093, 0.25, 0.242, 0.126, 0.227, 0.128]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=150896)[0m rmse: 0.15988750755786896
[2m[36m(func pid=150896)[0m mae:  0.11207561194896698
[2m[36m(func pid=150896)[0m rmse_per_class: [0.118, 0.251, 0.049, 0.306, 0.055, 0.189, 0.251, 0.136, 0.15, 0.093]
[2m[36m(func pid=164825)[0m rmse: 0.2054029405117035
[2m[36m(func pid=164825)[0m mae:  0.11735238879919052
[2m[36m(func pid=164825)[0m rmse_per_class: [0.158, 0.283, 0.035, 0.357, 0.104, 0.43, 0.271, 0.147, 0.17, 0.098]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.17536449432373047
[2m[36m(func pid=157909)[0m mae:  0.11268536746501923
[2m[36m(func pid=157909)[0m rmse_per_class: [0.073, 0.245, 0.205, 0.33, 0.055, 0.191, 0.23, 0.203, 0.134, 0.086]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3766 | Steps: 4 | Val loss: 0.3595 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.7774 | Steps: 4 | Val loss: 0.8013 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=159237)[0m rmse: 0.16955935955047607
[2m[36m(func pid=159237)[0m mae:  0.0995582565665245
[2m[36m(func pid=159237)[0m rmse_per_class: [0.079, 0.229, 0.033, 0.296, 0.09, 0.268, 0.248, 0.14, 0.214, 0.098]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4033 | Steps: 4 | Val loss: 0.3242 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=164825)[0m rmse: 0.23751215636730194
[2m[36m(func pid=164825)[0m mae:  0.12966307997703552
[2m[36m(func pid=164825)[0m rmse_per_class: [0.303, 0.28, 0.12, 0.355, 0.156, 0.3, 0.282, 0.144, 0.34, 0.094]
[2m[36m(func pid=157909)[0m rmse: 0.17101635038852692
[2m[36m(func pid=157909)[0m mae:  0.10953347384929657
[2m[36m(func pid=157909)[0m rmse_per_class: [0.072, 0.237, 0.2, 0.336, 0.054, 0.187, 0.24, 0.157, 0.14, 0.087]
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3518 | Steps: 4 | Val loss: 0.3503 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 16:59:12 (running for 00:35:09.73)
Memory usage on this node: 22.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.383 |  0.175 |                   44 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.377 |  0.17  |                   42 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.856 |  0.205 |                   18 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=169620)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=169620)[0m Configuration completed!
[2m[36m(func pid=169620)[0m New optimizer parameters:
[2m[36m(func pid=169620)[0m SGD (
[2m[36m(func pid=169620)[0m Parameter Group 0
[2m[36m(func pid=169620)[0m     dampening: 0
[2m[36m(func pid=169620)[0m     differentiable: False
[2m[36m(func pid=169620)[0m     foreach: None
[2m[36m(func pid=169620)[0m     lr: 0.0001
[2m[36m(func pid=169620)[0m     maximize: False
[2m[36m(func pid=169620)[0m     momentum: 0.9
[2m[36m(func pid=169620)[0m     nesterov: False
[2m[36m(func pid=169620)[0m     weight_decay: 1e-05
[2m[36m(func pid=169620)[0m )
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.17161668837070465
[2m[36m(func pid=159237)[0m mae:  0.09631197899580002
[2m[36m(func pid=159237)[0m rmse_per_class: [0.113, 0.23, 0.035, 0.285, 0.09, 0.211, 0.266, 0.215, 0.188, 0.083]
[2m[36m(func pid=159237)[0m 
== Status ==
Current time: 2024-01-07 16:59:18 (running for 00:35:15.31)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.403 |  0.171 |                   45 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.352 |  0.172 |                   43 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.777 |  0.238 |                   19 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3906 | Steps: 4 | Val loss: 0.3182 | Batch size: 32 | lr: 0.001 | Duration: 3.13s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.8341 | Steps: 4 | Val loss: 0.7400 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3686 | Steps: 4 | Val loss: 0.3781 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0866 | Steps: 4 | Val loss: 0.8119 | Batch size: 32 | lr: 0.0001 | Duration: 4.62s
[2m[36m(func pid=157909)[0m rmse: 0.165852352976799
[2m[36m(func pid=157909)[0m mae:  0.10603494942188263
[2m[36m(func pid=157909)[0m rmse_per_class: [0.071, 0.229, 0.173, 0.339, 0.053, 0.178, 0.255, 0.13, 0.143, 0.088]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.21731288731098175
[2m[36m(func pid=164825)[0m mae:  0.11985635757446289
[2m[36m(func pid=164825)[0m rmse_per_class: [0.204, 0.283, 0.096, 0.31, 0.098, 0.229, 0.377, 0.136, 0.347, 0.093]
[2m[36m(func pid=164825)[0m 
== Status ==
Current time: 2024-01-07 16:59:23 (running for 00:35:20.37)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.391 |  0.166 |                   46 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.369 |  0.181 |                   44 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.834 |  0.217 |                   20 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.18060915172100067
[2m[36m(func pid=159237)[0m mae:  0.10168822854757309
[2m[36m(func pid=159237)[0m rmse_per_class: [0.163, 0.265, 0.035, 0.285, 0.083, 0.176, 0.282, 0.274, 0.164, 0.079]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.1789705604314804
[2m[36m(func pid=169620)[0m mae:  0.13141942024230957
[2m[36m(func pid=169620)[0m rmse_per_class: [0.105, 0.266, 0.088, 0.324, 0.101, 0.193, 0.305, 0.153, 0.139, 0.117]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3788 | Steps: 4 | Val loss: 0.3093 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.7710 | Steps: 4 | Val loss: 0.6188 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3754 | Steps: 4 | Val loss: 0.3816 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 1.0655 | Steps: 4 | Val loss: 0.8118 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=157909)[0m rmse: 0.1592056304216385
[2m[36m(func pid=157909)[0m mae:  0.1018909439444542
[2m[36m(func pid=157909)[0m rmse_per_class: [0.07, 0.223, 0.128, 0.336, 0.052, 0.17, 0.263, 0.114, 0.147, 0.088]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.19500291347503662
[2m[36m(func pid=164825)[0m mae:  0.10586301982402802
[2m[36m(func pid=164825)[0m rmse_per_class: [0.21, 0.254, 0.053, 0.319, 0.069, 0.223, 0.274, 0.143, 0.233, 0.171]
[2m[36m(func pid=164825)[0m 
== Status ==
Current time: 2024-01-07 16:59:28 (running for 00:35:25.94)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.379 |  0.159 |                   47 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.375 |  0.177 |                   45 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.771 |  0.195 |                   21 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  1.087 |  0.179 |                    1 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.17660591006278992
[2m[36m(func pid=159237)[0m mae:  0.10013893991708755
[2m[36m(func pid=159237)[0m rmse_per_class: [0.157, 0.282, 0.033, 0.274, 0.08, 0.185, 0.27, 0.253, 0.153, 0.08]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.17977580428123474
[2m[36m(func pid=169620)[0m mae:  0.13205328583717346
[2m[36m(func pid=169620)[0m rmse_per_class: [0.106, 0.266, 0.09, 0.324, 0.102, 0.193, 0.307, 0.154, 0.138, 0.118]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.6538 | Steps: 4 | Val loss: 0.7196 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3654 | Steps: 4 | Val loss: 0.3005 | Batch size: 32 | lr: 0.001 | Duration: 3.21s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3820 | Steps: 4 | Val loss: 0.3566 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 1.0463 | Steps: 4 | Val loss: 0.7981 | Batch size: 32 | lr: 0.0001 | Duration: 2.79s
[2m[36m(func pid=164825)[0m rmse: 0.192368745803833
[2m[36m(func pid=164825)[0m mae:  0.11300183832645416
[2m[36m(func pid=164825)[0m rmse_per_class: [0.094, 0.231, 0.035, 0.291, 0.055, 0.368, 0.317, 0.146, 0.151, 0.235]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.153219535946846
[2m[36m(func pid=157909)[0m mae:  0.09867136925458908
[2m[36m(func pid=157909)[0m rmse_per_class: [0.067, 0.218, 0.1, 0.33, 0.052, 0.166, 0.251, 0.107, 0.153, 0.089]
[2m[36m(func pid=157909)[0m 
== Status ==
Current time: 2024-01-07 16:59:34 (running for 00:35:31.30)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.365 |  0.153 |                   48 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.382 |  0.164 |                   46 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.654 |  0.192 |                   22 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  1.065 |  0.18  |                    2 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.16362230479717255
[2m[36m(func pid=159237)[0m mae:  0.09174200892448425
[2m[36m(func pid=159237)[0m rmse_per_class: [0.127, 0.251, 0.03, 0.265, 0.071, 0.193, 0.24, 0.221, 0.158, 0.08]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.18009726703166962
[2m[36m(func pid=169620)[0m mae:  0.13231444358825684
[2m[36m(func pid=169620)[0m rmse_per_class: [0.106, 0.266, 0.089, 0.324, 0.104, 0.194, 0.309, 0.154, 0.138, 0.119]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.7626 | Steps: 4 | Val loss: 0.7150 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3440 | Steps: 4 | Val loss: 0.2917 | Batch size: 32 | lr: 0.001 | Duration: 3.19s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3795 | Steps: 4 | Val loss: 0.3360 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 1.0075 | Steps: 4 | Val loss: 0.7797 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 16:59:39 (running for 00:35:36.42)
Memory usage on this node: 25.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.365 |  0.153 |                   48 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.382 |  0.164 |                   46 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.654 |  0.192 |                   22 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  1.046 |  0.18  |                    3 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=164825)[0m rmse: 0.19412387907505035
[2m[36m(func pid=164825)[0m mae:  0.10776768624782562
[2m[36m(func pid=164825)[0m rmse_per_class: [0.117, 0.309, 0.039, 0.323, 0.057, 0.249, 0.29, 0.182, 0.147, 0.228]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.15033307671546936
[2m[36m(func pid=159237)[0m mae:  0.08472628891468048
[2m[36m(func pid=159237)[0m rmse_per_class: [0.087, 0.224, 0.028, 0.257, 0.06, 0.192, 0.253, 0.165, 0.157, 0.081]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.14761263132095337
[2m[36m(func pid=157909)[0m mae:  0.09544700384140015
[2m[36m(func pid=157909)[0m rmse_per_class: [0.064, 0.215, 0.075, 0.322, 0.052, 0.163, 0.233, 0.108, 0.154, 0.09]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.1806265115737915
[2m[36m(func pid=169620)[0m mae:  0.1327759474515915
[2m[36m(func pid=169620)[0m rmse_per_class: [0.107, 0.266, 0.089, 0.324, 0.104, 0.194, 0.31, 0.154, 0.138, 0.121]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3749 | Steps: 4 | Val loss: 0.3302 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.7204 | Steps: 4 | Val loss: 0.7679 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.9817 | Steps: 4 | Val loss: 0.7480 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3538 | Steps: 4 | Val loss: 0.2857 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 16:59:44 (running for 00:35:41.77)
Memory usage on this node: 25.8/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.344 |  0.148 |                   49 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.379 |  0.15  |                   47 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.763 |  0.194 |                   23 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  1.008 |  0.181 |                    4 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.14709706604480743
[2m[36m(func pid=159237)[0m mae:  0.08405476063489914
[2m[36m(func pid=159237)[0m rmse_per_class: [0.071, 0.212, 0.028, 0.255, 0.054, 0.181, 0.29, 0.135, 0.163, 0.083]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.2213466912508011
[2m[36m(func pid=164825)[0m mae:  0.1209200844168663
[2m[36m(func pid=164825)[0m rmse_per_class: [0.284, 0.31, 0.045, 0.361, 0.061, 0.228, 0.339, 0.261, 0.189, 0.135]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.18057507276535034
[2m[36m(func pid=169620)[0m mae:  0.1327231079339981
[2m[36m(func pid=169620)[0m rmse_per_class: [0.107, 0.266, 0.088, 0.324, 0.104, 0.194, 0.31, 0.154, 0.138, 0.121]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.14512516558170319
[2m[36m(func pid=157909)[0m mae:  0.09495316445827484
[2m[36m(func pid=157909)[0m rmse_per_class: [0.063, 0.217, 0.058, 0.32, 0.055, 0.168, 0.209, 0.113, 0.158, 0.091]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3437 | Steps: 4 | Val loss: 0.3277 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.9468 | Steps: 4 | Val loss: 0.7242 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.7019 | Steps: 4 | Val loss: 0.8065 | Batch size: 32 | lr: 0.1 | Duration: 3.23s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3458 | Steps: 4 | Val loss: 0.2829 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=159237)[0m rmse: 0.14827947318553925
[2m[36m(func pid=159237)[0m mae:  0.08410900086164474
[2m[36m(func pid=159237)[0m rmse_per_class: [0.071, 0.226, 0.032, 0.26, 0.052, 0.165, 0.265, 0.124, 0.198, 0.091]
== Status ==
Current time: 2024-01-07 16:59:50 (running for 00:35:47.30)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.354 |  0.145 |                   50 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.344 |  0.148 |                   49 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.72  |  0.221 |                   24 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.982 |  0.181 |                    5 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.18095144629478455
[2m[36m(func pid=169620)[0m mae:  0.13292042911052704
[2m[36m(func pid=169620)[0m rmse_per_class: [0.107, 0.266, 0.089, 0.324, 0.104, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.2343476116657257
[2m[36m(func pid=164825)[0m mae:  0.12632502615451813
[2m[36m(func pid=164825)[0m rmse_per_class: [0.234, 0.273, 0.042, 0.333, 0.119, 0.227, 0.341, 0.298, 0.382, 0.095]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.1450985223054886
[2m[36m(func pid=157909)[0m mae:  0.09575940668582916
[2m[36m(func pid=157909)[0m rmse_per_class: [0.063, 0.217, 0.043, 0.317, 0.062, 0.182, 0.198, 0.118, 0.16, 0.091]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3120 | Steps: 4 | Val loss: 0.3419 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.9058 | Steps: 4 | Val loss: 0.7010 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.7198 | Steps: 4 | Val loss: 0.7397 | Batch size: 32 | lr: 0.1 | Duration: 3.19s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3549 | Steps: 4 | Val loss: 0.2802 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 16:59:55 (running for 00:35:52.41)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.346 |  0.145 |                   51 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.312 |  0.158 |                   50 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.702 |  0.234 |                   25 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.947 |  0.181 |                    6 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.15775354206562042
[2m[36m(func pid=159237)[0m mae:  0.09060437977313995
[2m[36m(func pid=159237)[0m rmse_per_class: [0.068, 0.244, 0.035, 0.266, 0.052, 0.223, 0.232, 0.125, 0.236, 0.098]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.181327685713768
[2m[36m(func pid=169620)[0m mae:  0.1331874430179596
[2m[36m(func pid=169620)[0m rmse_per_class: [0.107, 0.266, 0.091, 0.324, 0.105, 0.194, 0.311, 0.154, 0.138, 0.123]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.2081991732120514
[2m[36m(func pid=164825)[0m mae:  0.11228877305984497
[2m[36m(func pid=164825)[0m rmse_per_class: [0.131, 0.294, 0.04, 0.346, 0.119, 0.277, 0.322, 0.156, 0.308, 0.09]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.14625409245491028
[2m[36m(func pid=157909)[0m mae:  0.09716641157865524
[2m[36m(func pid=157909)[0m rmse_per_class: [0.065, 0.218, 0.034, 0.306, 0.074, 0.19, 0.201, 0.124, 0.159, 0.091]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3516 | Steps: 4 | Val loss: 0.3714 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.8785 | Steps: 4 | Val loss: 0.6750 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.8656 | Steps: 4 | Val loss: 0.8112 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3601 | Steps: 4 | Val loss: 0.2795 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 17:00:00 (running for 00:35:57.73)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.355 |  0.146 |                   52 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.352 |  0.175 |                   51 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.72  |  0.208 |                   26 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.906 |  0.181 |                    7 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.17475652694702148
[2m[36m(func pid=159237)[0m mae:  0.10378358513116837
[2m[36m(func pid=159237)[0m rmse_per_class: [0.069, 0.26, 0.036, 0.266, 0.053, 0.334, 0.253, 0.127, 0.228, 0.122]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.18108759820461273
[2m[36m(func pid=169620)[0m mae:  0.13294807076454163
[2m[36m(func pid=169620)[0m rmse_per_class: [0.107, 0.266, 0.092, 0.324, 0.103, 0.194, 0.31, 0.154, 0.138, 0.123]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.19902528822422028
[2m[36m(func pid=164825)[0m mae:  0.11368199437856674
[2m[36m(func pid=164825)[0m rmse_per_class: [0.168, 0.294, 0.04, 0.311, 0.082, 0.416, 0.269, 0.129, 0.186, 0.096]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.1482100784778595
[2m[36m(func pid=157909)[0m mae:  0.09849173575639725
[2m[36m(func pid=157909)[0m rmse_per_class: [0.068, 0.213, 0.031, 0.293, 0.09, 0.202, 0.212, 0.128, 0.154, 0.091]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3459 | Steps: 4 | Val loss: 0.3784 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.8461 | Steps: 4 | Val loss: 0.6476 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.7882 | Steps: 4 | Val loss: 0.8306 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3621 | Steps: 4 | Val loss: 0.2838 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 17:00:05 (running for 00:36:02.85)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.36  |  0.148 |                   53 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.346 |  0.183 |                   52 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.866 |  0.199 |                   27 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.879 |  0.181 |                    8 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.1826097071170807
[2m[36m(func pid=159237)[0m mae:  0.10862939059734344
[2m[36m(func pid=159237)[0m rmse_per_class: [0.076, 0.247, 0.035, 0.274, 0.053, 0.349, 0.275, 0.128, 0.225, 0.165]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.1810179054737091
[2m[36m(func pid=169620)[0m mae:  0.1327711045742035
[2m[36m(func pid=169620)[0m rmse_per_class: [0.107, 0.267, 0.092, 0.324, 0.106, 0.193, 0.309, 0.151, 0.138, 0.122]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.23802399635314941
[2m[36m(func pid=164825)[0m mae:  0.12866318225860596
[2m[36m(func pid=164825)[0m rmse_per_class: [0.318, 0.283, 0.046, 0.339, 0.172, 0.351, 0.32, 0.158, 0.303, 0.091]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.15182876586914062
[2m[36m(func pid=157909)[0m mae:  0.10113625228404999
[2m[36m(func pid=157909)[0m rmse_per_class: [0.074, 0.215, 0.031, 0.283, 0.108, 0.197, 0.229, 0.134, 0.156, 0.091]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3472 | Steps: 4 | Val loss: 0.3635 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.8154 | Steps: 4 | Val loss: 0.6258 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.8143 | Steps: 4 | Val loss: 0.8847 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3365 | Steps: 4 | Val loss: 0.2823 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=159237)[0m rmse: 0.17958495020866394
[2m[36m(func pid=159237)[0m mae:  0.10313323885202408
[2m[36m(func pid=159237)[0m rmse_per_class: [0.131, 0.237, 0.034, 0.286, 0.053, 0.257, 0.252, 0.125, 0.195, 0.227]
[2m[36m(func pid=159237)[0m 
== Status ==
Current time: 2024-01-07 17:00:11 (running for 00:36:08.24)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.362 |  0.152 |                   54 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.347 |  0.18  |                   53 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.788 |  0.238 |                   28 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.846 |  0.181 |                    9 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.18069949746131897
[2m[36m(func pid=169620)[0m mae:  0.1325618177652359
[2m[36m(func pid=169620)[0m rmse_per_class: [0.107, 0.267, 0.091, 0.324, 0.104, 0.194, 0.309, 0.152, 0.138, 0.123]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.15142211318016052
[2m[36m(func pid=157909)[0m mae:  0.10081644356250763
[2m[36m(func pid=157909)[0m rmse_per_class: [0.07, 0.212, 0.033, 0.268, 0.124, 0.199, 0.236, 0.131, 0.152, 0.09]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.23234733939170837
[2m[36m(func pid=164825)[0m mae:  0.12626567482948303
[2m[36m(func pid=164825)[0m rmse_per_class: [0.148, 0.386, 0.055, 0.372, 0.131, 0.228, 0.328, 0.161, 0.388, 0.128]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3622 | Steps: 4 | Val loss: 0.3684 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.7842 | Steps: 4 | Val loss: 0.6059 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3351 | Steps: 4 | Val loss: 0.2854 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
== Status ==
Current time: 2024-01-07 17:00:16 (running for 00:36:13.75)
Memory usage on this node: 24.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.336 |  0.151 |                   55 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.362 |  0.177 |                   54 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.814 |  0.232 |                   29 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.815 |  0.181 |                   10 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.17660555243492126
[2m[36m(func pid=159237)[0m mae:  0.10226720571517944
[2m[36m(func pid=159237)[0m rmse_per_class: [0.182, 0.235, 0.03, 0.299, 0.053, 0.173, 0.228, 0.123, 0.17, 0.273]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.7587 | Steps: 4 | Val loss: 0.8551 | Batch size: 32 | lr: 0.1 | Duration: 3.23s
[2m[36m(func pid=169620)[0m rmse: 0.18075647950172424
[2m[36m(func pid=169620)[0m mae:  0.1326102316379547
[2m[36m(func pid=169620)[0m rmse_per_class: [0.108, 0.267, 0.09, 0.324, 0.103, 0.194, 0.308, 0.152, 0.139, 0.123]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.1524067223072052
[2m[36m(func pid=157909)[0m mae:  0.1015186458826065
[2m[36m(func pid=157909)[0m rmse_per_class: [0.071, 0.211, 0.035, 0.258, 0.138, 0.196, 0.247, 0.134, 0.147, 0.088]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.20366156101226807
[2m[36m(func pid=164825)[0m mae:  0.11661083996295929
[2m[36m(func pid=164825)[0m rmse_per_class: [0.084, 0.355, 0.033, 0.372, 0.07, 0.231, 0.389, 0.137, 0.215, 0.151]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.7579 | Steps: 4 | Val loss: 0.5840 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3689 | Steps: 4 | Val loss: 0.3713 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 17:00:22 (running for 00:36:19.15)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.335 |  0.152 |                   56 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.362 |  0.177 |                   54 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.759 |  0.204 |                   30 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.758 |  0.181 |                   12 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.18098406493663788
[2m[36m(func pid=169620)[0m mae:  0.13275626301765442
[2m[36m(func pid=169620)[0m rmse_per_class: [0.108, 0.267, 0.09, 0.324, 0.103, 0.194, 0.309, 0.154, 0.139, 0.122]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.17488418519496918
[2m[36m(func pid=159237)[0m mae:  0.10104087740182877
[2m[36m(func pid=159237)[0m rmse_per_class: [0.165, 0.234, 0.03, 0.305, 0.056, 0.185, 0.23, 0.12, 0.153, 0.271]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3471 | Steps: 4 | Val loss: 0.2864 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.6272 | Steps: 4 | Val loss: 0.6425 | Batch size: 32 | lr: 0.1 | Duration: 3.17s
[2m[36m(func pid=157909)[0m rmse: 0.15280543267726898
[2m[36m(func pid=157909)[0m mae:  0.10146798938512802
[2m[36m(func pid=157909)[0m rmse_per_class: [0.076, 0.213, 0.036, 0.249, 0.141, 0.193, 0.252, 0.136, 0.146, 0.086]
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.7400 | Steps: 4 | Val loss: 0.5670 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.2060675323009491
[2m[36m(func pid=164825)[0m mae:  0.1117900162935257
[2m[36m(func pid=164825)[0m rmse_per_class: [0.122, 0.288, 0.038, 0.343, 0.067, 0.261, 0.29, 0.15, 0.226, 0.275]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3208 | Steps: 4 | Val loss: 0.3552 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
== Status ==
Current time: 2024-01-07 17:00:27 (running for 00:36:24.57)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.347 |  0.153 |                   57 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.369 |  0.175 |                   55 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.627 |  0.206 |                   31 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.74  |  0.181 |                   13 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.18118564784526825
[2m[36m(func pid=169620)[0m mae:  0.13283520936965942
[2m[36m(func pid=169620)[0m rmse_per_class: [0.107, 0.268, 0.091, 0.325, 0.103, 0.194, 0.308, 0.153, 0.139, 0.123]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.1685832291841507
[2m[36m(func pid=159237)[0m mae:  0.09538206458091736
[2m[36m(func pid=159237)[0m rmse_per_class: [0.116, 0.238, 0.035, 0.296, 0.059, 0.198, 0.258, 0.121, 0.14, 0.225]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3408 | Steps: 4 | Val loss: 0.2865 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.6682 | Steps: 4 | Val loss: 0.7051 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.7210 | Steps: 4 | Val loss: 0.5527 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=157909)[0m rmse: 0.1527368575334549
[2m[36m(func pid=157909)[0m mae:  0.10111800581216812
[2m[36m(func pid=157909)[0m rmse_per_class: [0.077, 0.215, 0.038, 0.243, 0.151, 0.187, 0.256, 0.135, 0.142, 0.083]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3286 | Steps: 4 | Val loss: 0.3357 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=164825)[0m rmse: 0.21110177040100098
[2m[36m(func pid=164825)[0m mae:  0.1206192821264267
[2m[36m(func pid=164825)[0m rmse_per_class: [0.107, 0.263, 0.041, 0.336, 0.056, 0.44, 0.317, 0.145, 0.173, 0.232]
[2m[36m(func pid=164825)[0m 
== Status ==
Current time: 2024-01-07 17:00:32 (running for 00:36:30.06)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.341 |  0.153 |                   58 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.321 |  0.169 |                   56 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.668 |  0.211 |                   32 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.721 |  0.181 |                   14 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.1809665709733963
[2m[36m(func pid=169620)[0m mae:  0.13268789649009705
[2m[36m(func pid=169620)[0m rmse_per_class: [0.107, 0.268, 0.091, 0.325, 0.101, 0.194, 0.307, 0.153, 0.139, 0.124]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.16196589171886444
[2m[36m(func pid=159237)[0m mae:  0.09045994281768799
[2m[36m(func pid=159237)[0m rmse_per_class: [0.076, 0.236, 0.036, 0.279, 0.061, 0.195, 0.271, 0.144, 0.133, 0.188]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3452 | Steps: 4 | Val loss: 0.2841 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.6290 | Steps: 4 | Val loss: 0.7909 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.6948 | Steps: 4 | Val loss: 0.5397 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3178 | Steps: 4 | Val loss: 0.3200 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
[2m[36m(func pid=157909)[0m rmse: 0.15250201523303986
[2m[36m(func pid=157909)[0m mae:  0.10071273148059845
[2m[36m(func pid=157909)[0m rmse_per_class: [0.079, 0.221, 0.037, 0.24, 0.156, 0.181, 0.254, 0.133, 0.142, 0.082]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.22355978190898895
[2m[36m(func pid=164825)[0m mae:  0.12258587777614594
[2m[36m(func pid=164825)[0m rmse_per_class: [0.146, 0.284, 0.045, 0.362, 0.075, 0.209, 0.492, 0.179, 0.232, 0.212]
[2m[36m(func pid=164825)[0m 
== Status ==
Current time: 2024-01-07 17:00:38 (running for 00:36:35.33)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.345 |  0.153 |                   59 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.329 |  0.162 |                   57 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.629 |  0.224 |                   33 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.695 |  0.181 |                   15 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.18068817257881165
[2m[36m(func pid=169620)[0m mae:  0.13246449828147888
[2m[36m(func pid=169620)[0m rmse_per_class: [0.107, 0.268, 0.091, 0.324, 0.1, 0.194, 0.307, 0.153, 0.139, 0.124]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.15545162558555603
[2m[36m(func pid=159237)[0m mae:  0.08705169707536697
[2m[36m(func pid=159237)[0m rmse_per_class: [0.067, 0.23, 0.031, 0.266, 0.065, 0.18, 0.234, 0.198, 0.138, 0.144]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3317 | Steps: 4 | Val loss: 0.2794 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.7630 | Steps: 4 | Val loss: 0.9299 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.6785 | Steps: 4 | Val loss: 0.5258 | Batch size: 32 | lr: 0.0001 | Duration: 2.97s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3200 | Steps: 4 | Val loss: 0.3223 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=157909)[0m rmse: 0.15046390891075134
[2m[36m(func pid=157909)[0m mae:  0.09902540594339371
[2m[36m(func pid=157909)[0m rmse_per_class: [0.081, 0.225, 0.037, 0.238, 0.143, 0.173, 0.25, 0.13, 0.142, 0.084]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.2438095360994339
[2m[36m(func pid=164825)[0m mae:  0.13267561793327332
[2m[36m(func pid=164825)[0m rmse_per_class: [0.205, 0.286, 0.046, 0.373, 0.123, 0.23, 0.427, 0.198, 0.363, 0.186]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.15799085795879364
[2m[36m(func pid=159237)[0m mae:  0.09053356945514679
[2m[36m(func pid=159237)[0m rmse_per_class: [0.068, 0.219, 0.029, 0.267, 0.065, 0.199, 0.246, 0.233, 0.143, 0.11]
[2m[36m(func pid=159237)[0m 
== Status ==
Current time: 2024-01-07 17:00:43 (running for 00:36:40.73)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.332 |  0.15  |                   60 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.32  |  0.158 |                   59 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.763 |  0.244 |                   34 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.695 |  0.181 |                   15 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.18067635595798492
[2m[36m(func pid=169620)[0m mae:  0.13244417309761047
[2m[36m(func pid=169620)[0m rmse_per_class: [0.108, 0.268, 0.09, 0.324, 0.102, 0.194, 0.307, 0.152, 0.139, 0.122]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3217 | Steps: 4 | Val loss: 0.2727 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.7333 | Steps: 4 | Val loss: 0.7964 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3032 | Steps: 4 | Val loss: 0.3358 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.6669 | Steps: 4 | Val loss: 0.5073 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=157909)[0m rmse: 0.1475009322166443
[2m[36m(func pid=157909)[0m mae:  0.09655268490314484
[2m[36m(func pid=157909)[0m rmse_per_class: [0.075, 0.229, 0.036, 0.236, 0.128, 0.17, 0.24, 0.124, 0.141, 0.095]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.24418798089027405
[2m[36m(func pid=164825)[0m mae:  0.1350802630186081
[2m[36m(func pid=164825)[0m rmse_per_class: [0.292, 0.272, 0.046, 0.344, 0.194, 0.229, 0.303, 0.178, 0.45, 0.134]
[2m[36m(func pid=164825)[0m 
== Status ==
Current time: 2024-01-07 17:00:48 (running for 00:36:46.07)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.322 |  0.148 |                   61 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.303 |  0.166 |                   60 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.733 |  0.244 |                   35 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.678 |  0.181 |                   16 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.16564534604549408
[2m[36m(func pid=159237)[0m mae:  0.09743186831474304
[2m[36m(func pid=159237)[0m rmse_per_class: [0.072, 0.216, 0.03, 0.268, 0.066, 0.292, 0.272, 0.205, 0.145, 0.09]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.18034306168556213
[2m[36m(func pid=169620)[0m mae:  0.13223955035209656
[2m[36m(func pid=169620)[0m rmse_per_class: [0.108, 0.267, 0.089, 0.325, 0.097, 0.194, 0.307, 0.153, 0.139, 0.123]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3302 | Steps: 4 | Val loss: 0.2722 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.6694 | Steps: 4 | Val loss: 0.6140 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3128 | Steps: 4 | Val loss: 0.3385 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.6478 | Steps: 4 | Val loss: 0.4960 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=157909)[0m rmse: 0.14826072752475739
[2m[36m(func pid=157909)[0m mae:  0.09640263766050339
[2m[36m(func pid=157909)[0m rmse_per_class: [0.073, 0.23, 0.036, 0.239, 0.116, 0.168, 0.24, 0.122, 0.137, 0.122]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.19231002032756805
[2m[36m(func pid=164825)[0m mae:  0.10492245852947235
[2m[36m(func pid=164825)[0m rmse_per_class: [0.101, 0.268, 0.044, 0.365, 0.09, 0.264, 0.289, 0.153, 0.241, 0.108]
[2m[36m(func pid=164825)[0m 
== Status ==
Current time: 2024-01-07 17:00:54 (running for 00:36:51.45)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.33  |  0.148 |                   62 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.303 |  0.166 |                   60 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.669 |  0.192 |                   36 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.648 |  0.18  |                   18 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.18046221137046814
[2m[36m(func pid=169620)[0m mae:  0.1322477161884308
[2m[36m(func pid=169620)[0m rmse_per_class: [0.109, 0.268, 0.091, 0.326, 0.099, 0.194, 0.305, 0.151, 0.14, 0.121]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.1677824854850769
[2m[36m(func pid=159237)[0m mae:  0.09887436032295227
[2m[36m(func pid=159237)[0m rmse_per_class: [0.081, 0.22, 0.036, 0.268, 0.073, 0.319, 0.278, 0.161, 0.155, 0.087]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3196 | Steps: 4 | Val loss: 0.2683 | Batch size: 32 | lr: 0.001 | Duration: 3.29s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.6247 | Steps: 4 | Val loss: 0.6927 | Batch size: 32 | lr: 0.1 | Duration: 3.27s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.6332 | Steps: 4 | Val loss: 0.4882 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3436 | Steps: 4 | Val loss: 0.3348 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=157909)[0m rmse: 0.1463957130908966
[2m[36m(func pid=157909)[0m mae:  0.09452329576015472
[2m[36m(func pid=157909)[0m rmse_per_class: [0.066, 0.232, 0.034, 0.236, 0.096, 0.166, 0.228, 0.117, 0.134, 0.154]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.1804182231426239
[2m[36m(func pid=169620)[0m mae:  0.1321834921836853
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.268, 0.092, 0.326, 0.099, 0.194, 0.305, 0.15, 0.14, 0.121]
== Status ==
Current time: 2024-01-07 17:00:59 (running for 00:36:56.78)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.32  |  0.146 |                   63 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.313 |  0.168 |                   61 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.669 |  0.192 |                   36 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.633 |  0.18  |                   19 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.1693335324525833
[2m[36m(func pid=164825)[0m mae:  0.09559965133666992
[2m[36m(func pid=164825)[0m rmse_per_class: [0.095, 0.265, 0.041, 0.303, 0.055, 0.265, 0.29, 0.148, 0.132, 0.099]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.16854305565357208
[2m[36m(func pid=159237)[0m mae:  0.09780614078044891
[2m[36m(func pid=159237)[0m rmse_per_class: [0.125, 0.221, 0.038, 0.268, 0.086, 0.293, 0.262, 0.135, 0.172, 0.086]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3039 | Steps: 4 | Val loss: 0.2652 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.6209 | Steps: 4 | Val loss: 0.4750 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.6492 | Steps: 4 | Val loss: 0.7590 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3233 | Steps: 4 | Val loss: 0.3313 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=157909)[0m rmse: 0.14422108232975006
[2m[36m(func pid=157909)[0m mae:  0.09264995157718658
[2m[36m(func pid=157909)[0m rmse_per_class: [0.061, 0.235, 0.033, 0.234, 0.08, 0.165, 0.215, 0.111, 0.131, 0.178]
[2m[36m(func pid=157909)[0m 
== Status ==
Current time: 2024-01-07 17:01:05 (running for 00:37:02.34)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.304 |  0.144 |                   64 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.323 |  0.168 |                   63 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.625 |  0.169 |                   37 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.633 |  0.18  |                   19 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.16788849234580994
[2m[36m(func pid=159237)[0m mae:  0.09577099233865738
[2m[36m(func pid=159237)[0m rmse_per_class: [0.206, 0.227, 0.038, 0.269, 0.097, 0.204, 0.225, 0.126, 0.198, 0.089]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.18009842932224274
[2m[36m(func pid=169620)[0m mae:  0.13195793330669403
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.268, 0.091, 0.324, 0.097, 0.194, 0.305, 0.149, 0.14, 0.122]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.23657135665416718
[2m[36m(func pid=164825)[0m mae:  0.13047100603580475
[2m[36m(func pid=164825)[0m rmse_per_class: [0.395, 0.345, 0.052, 0.356, 0.062, 0.252, 0.315, 0.271, 0.156, 0.162]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3291 | Steps: 4 | Val loss: 0.2684 | Batch size: 32 | lr: 0.001 | Duration: 3.19s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3301 | Steps: 4 | Val loss: 0.3330 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.6080 | Steps: 4 | Val loss: 0.4668 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.6521 | Steps: 4 | Val loss: 0.9931 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
== Status ==
Current time: 2024-01-07 17:01:10 (running for 00:37:07.37)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.329 |  0.146 |                   65 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.323 |  0.168 |                   63 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.649 |  0.237 |                   38 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.621 |  0.18  |                   20 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=157909)[0m rmse: 0.14608100056648254
[2m[36m(func pid=157909)[0m mae:  0.09347234666347504
[2m[36m(func pid=157909)[0m rmse_per_class: [0.06, 0.232, 0.033, 0.238, 0.065, 0.168, 0.213, 0.113, 0.127, 0.211]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.179878368973732
[2m[36m(func pid=169620)[0m mae:  0.13165059685707092
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.268, 0.093, 0.325, 0.095, 0.193, 0.304, 0.15, 0.139, 0.122]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.16752889752388
[2m[36m(func pid=159237)[0m mae:  0.09537969529628754
[2m[36m(func pid=159237)[0m rmse_per_class: [0.189, 0.226, 0.036, 0.269, 0.1, 0.183, 0.224, 0.123, 0.235, 0.089]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.2761910855770111
[2m[36m(func pid=164825)[0m mae:  0.1526806801557541
[2m[36m(func pid=164825)[0m rmse_per_class: [0.446, 0.291, 0.066, 0.361, 0.099, 0.225, 0.337, 0.374, 0.287, 0.275]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3254 | Steps: 4 | Val loss: 0.2684 | Batch size: 32 | lr: 0.001 | Duration: 3.16s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3257 | Steps: 4 | Val loss: 0.3407 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.5949 | Steps: 4 | Val loss: 0.4579 | Batch size: 32 | lr: 0.0001 | Duration: 3.09s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.7604 | Steps: 4 | Val loss: 0.8889 | Batch size: 32 | lr: 0.1 | Duration: 3.17s
[2m[36m(func pid=157909)[0m rmse: 0.14555589854717255
[2m[36m(func pid=157909)[0m mae:  0.09294082969427109
[2m[36m(func pid=157909)[0m rmse_per_class: [0.06, 0.227, 0.032, 0.239, 0.058, 0.17, 0.207, 0.111, 0.126, 0.225]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.17122569680213928
[2m[36m(func pid=159237)[0m mae:  0.09771128743886948
[2m[36m(func pid=159237)[0m rmse_per_class: [0.165, 0.223, 0.031, 0.281, 0.092, 0.194, 0.249, 0.13, 0.242, 0.104]
== Status ==
Current time: 2024-01-07 17:01:16 (running for 00:37:13.13)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.325 |  0.146 |                   66 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.33  |  0.168 |                   64 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.652 |  0.276 |                   39 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.608 |  0.18  |                   21 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.1801634132862091
[2m[36m(func pid=169620)[0m mae:  0.13183201849460602
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.269, 0.092, 0.325, 0.095, 0.194, 0.304, 0.15, 0.139, 0.124]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.26186031103134155
[2m[36m(func pid=164825)[0m mae:  0.14299926161766052
[2m[36m(func pid=164825)[0m rmse_per_class: [0.172, 0.28, 0.058, 0.352, 0.137, 0.226, 0.333, 0.307, 0.457, 0.297]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3247 | Steps: 4 | Val loss: 0.3372 | Batch size: 32 | lr: 0.01 | Duration: 3.02s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.5835 | Steps: 4 | Val loss: 0.4468 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3161 | Steps: 4 | Val loss: 0.2691 | Batch size: 32 | lr: 0.001 | Duration: 3.23s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.6442 | Steps: 4 | Val loss: 0.6850 | Batch size: 32 | lr: 0.1 | Duration: 3.22s
== Status ==
Current time: 2024-01-07 17:01:21 (running for 00:37:18.59)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.325 |  0.146 |                   66 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.325 |  0.169 |                   66 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.76  |  0.262 |                   40 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.595 |  0.18  |                   22 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.16900654137134552
[2m[36m(func pid=159237)[0m mae:  0.09545876085758209
[2m[36m(func pid=159237)[0m rmse_per_class: [0.112, 0.226, 0.027, 0.29, 0.087, 0.192, 0.267, 0.128, 0.231, 0.131]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.18007051944732666
[2m[36m(func pid=169620)[0m mae:  0.13168582320213318
[2m[36m(func pid=169620)[0m rmse_per_class: [0.109, 0.269, 0.092, 0.325, 0.096, 0.194, 0.304, 0.151, 0.139, 0.123]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.1456497460603714
[2m[36m(func pid=157909)[0m mae:  0.09284700453281403
[2m[36m(func pid=157909)[0m rmse_per_class: [0.059, 0.225, 0.03, 0.243, 0.054, 0.173, 0.202, 0.109, 0.124, 0.238]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.19117394089698792
[2m[36m(func pid=164825)[0m mae:  0.10595341771841049
[2m[36m(func pid=164825)[0m rmse_per_class: [0.14, 0.262, 0.045, 0.29, 0.098, 0.208, 0.332, 0.159, 0.225, 0.154]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2988 | Steps: 4 | Val loss: 0.3300 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.5733 | Steps: 4 | Val loss: 0.4421 | Batch size: 32 | lr: 0.0001 | Duration: 3.02s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3072 | Steps: 4 | Val loss: 0.2682 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.7074 | Steps: 4 | Val loss: 0.7157 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
[2m[36m(func pid=159237)[0m rmse: 0.1650761067867279
[2m[36m(func pid=159237)[0m mae:  0.09245099127292633
[2m[36m(func pid=159237)[0m rmse_per_class: [0.077, 0.235, 0.032, 0.289, 0.077, 0.187, 0.247, 0.131, 0.192, 0.183]
[2m[36m(func pid=159237)[0m 
== Status ==
Current time: 2024-01-07 17:01:26 (running for 00:37:24.08)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.316 |  0.146 |                   67 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.299 |  0.165 |                   67 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.644 |  0.191 |                   41 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.583 |  0.18  |                   23 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.1802660971879959
[2m[36m(func pid=169620)[0m mae:  0.13187828660011292
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.269, 0.093, 0.326, 0.097, 0.194, 0.303, 0.149, 0.14, 0.122]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.14459851384162903
[2m[36m(func pid=157909)[0m mae:  0.09134360402822495
[2m[36m(func pid=157909)[0m rmse_per_class: [0.058, 0.226, 0.028, 0.243, 0.05, 0.171, 0.197, 0.105, 0.123, 0.244]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.20565274357795715
[2m[36m(func pid=164825)[0m mae:  0.11549887806177139
[2m[36m(func pid=164825)[0m rmse_per_class: [0.177, 0.246, 0.053, 0.311, 0.113, 0.397, 0.316, 0.155, 0.168, 0.12]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.5640 | Steps: 4 | Val loss: 0.4359 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2965 | Steps: 4 | Val loss: 0.3283 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3387 | Steps: 4 | Val loss: 0.2689 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.7566 | Steps: 4 | Val loss: 0.8377 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 17:01:32 (running for 00:37:29.44)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.307 |  0.145 |                   68 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.299 |  0.165 |                   67 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.707 |  0.206 |                   42 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.564 |  0.18  |                   25 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.16534700989723206
[2m[36m(func pid=159237)[0m mae:  0.09397734701633453
[2m[36m(func pid=159237)[0m rmse_per_class: [0.067, 0.242, 0.037, 0.291, 0.067, 0.179, 0.226, 0.161, 0.174, 0.207]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.18030469119548798
[2m[36m(func pid=169620)[0m mae:  0.13190941512584686
[2m[36m(func pid=169620)[0m rmse_per_class: [0.109, 0.269, 0.093, 0.326, 0.098, 0.194, 0.303, 0.149, 0.14, 0.122]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.1438954472541809
[2m[36m(func pid=157909)[0m mae:  0.0905454009771347
[2m[36m(func pid=157909)[0m rmse_per_class: [0.058, 0.223, 0.027, 0.245, 0.049, 0.173, 0.195, 0.106, 0.123, 0.24]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.24384495615959167
[2m[36m(func pid=164825)[0m mae:  0.1281122863292694
[2m[36m(func pid=164825)[0m rmse_per_class: [0.216, 0.351, 0.053, 0.345, 0.22, 0.323, 0.342, 0.195, 0.231, 0.162]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.5569 | Steps: 4 | Val loss: 0.4294 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3308 | Steps: 4 | Val loss: 0.3410 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2978 | Steps: 4 | Val loss: 0.2644 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.6624 | Steps: 4 | Val loss: 0.8358 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 17:01:37 (running for 00:37:34.66)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.339 |  0.144 |                   69 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.296 |  0.165 |                   68 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.757 |  0.244 |                   43 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.557 |  0.18  |                   26 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.1802573800086975
[2m[36m(func pid=169620)[0m mae:  0.13188928365707397
[2m[36m(func pid=169620)[0m rmse_per_class: [0.109, 0.269, 0.094, 0.326, 0.097, 0.194, 0.303, 0.148, 0.14, 0.123]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.17235246300697327
[2m[36m(func pid=159237)[0m mae:  0.10008597373962402
[2m[36m(func pid=159237)[0m rmse_per_class: [0.072, 0.237, 0.043, 0.295, 0.055, 0.184, 0.246, 0.224, 0.145, 0.221]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.1401730477809906
[2m[36m(func pid=157909)[0m mae:  0.08777593821287155
[2m[36m(func pid=157909)[0m rmse_per_class: [0.059, 0.22, 0.025, 0.243, 0.049, 0.169, 0.199, 0.112, 0.125, 0.2]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.25304633378982544
[2m[36m(func pid=164825)[0m mae:  0.1329132318496704
[2m[36m(func pid=164825)[0m rmse_per_class: [0.215, 0.328, 0.051, 0.337, 0.205, 0.241, 0.324, 0.298, 0.345, 0.185]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3149 | Steps: 4 | Val loss: 0.3412 | Batch size: 32 | lr: 0.01 | Duration: 2.78s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.5423 | Steps: 4 | Val loss: 0.4234 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2990 | Steps: 4 | Val loss: 0.2645 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.6665 | Steps: 4 | Val loss: 0.7719 | Batch size: 32 | lr: 0.1 | Duration: 3.19s
== Status ==
Current time: 2024-01-07 17:01:42 (running for 00:37:40.07)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.14  |                   70 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.315 |  0.171 |                   70 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.662 |  0.253 |                   44 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.557 |  0.18  |                   26 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.17117014527320862
[2m[36m(func pid=159237)[0m mae:  0.10083838552236557
[2m[36m(func pid=159237)[0m rmse_per_class: [0.072, 0.223, 0.042, 0.283, 0.054, 0.213, 0.264, 0.232, 0.133, 0.196]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.179933562874794
[2m[36m(func pid=169620)[0m mae:  0.13166077435016632
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.268, 0.092, 0.326, 0.098, 0.194, 0.302, 0.148, 0.141, 0.12]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.1392858326435089
[2m[36m(func pid=157909)[0m mae:  0.08716602623462677
[2m[36m(func pid=157909)[0m rmse_per_class: [0.06, 0.216, 0.024, 0.248, 0.049, 0.166, 0.204, 0.126, 0.129, 0.171]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.21731451153755188
[2m[36m(func pid=164825)[0m mae:  0.12077927589416504
[2m[36m(func pid=164825)[0m rmse_per_class: [0.251, 0.27, 0.049, 0.33, 0.091, 0.229, 0.313, 0.21, 0.248, 0.182]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3099 | Steps: 4 | Val loss: 0.3267 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.5399 | Steps: 4 | Val loss: 0.4170 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2992 | Steps: 4 | Val loss: 0.2667 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 17:01:48 (running for 00:37:45.45)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.299 |  0.139 |                   71 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.315 |  0.171 |                   70 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.667 |  0.217 |                   45 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.54  |  0.18  |                   28 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.18000592291355133
[2m[36m(func pid=169620)[0m mae:  0.13174520432949066
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.268, 0.09, 0.326, 0.097, 0.194, 0.303, 0.149, 0.142, 0.121]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.16114334762096405
[2m[36m(func pid=159237)[0m mae:  0.09520437568426132
[2m[36m(func pid=159237)[0m rmse_per_class: [0.068, 0.217, 0.034, 0.271, 0.054, 0.233, 0.262, 0.189, 0.129, 0.156]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.6945 | Steps: 4 | Val loss: 0.7149 | Batch size: 32 | lr: 0.1 | Duration: 3.22s
[2m[36m(func pid=157909)[0m rmse: 0.13990433514118195
[2m[36m(func pid=157909)[0m mae:  0.08776534348726273
[2m[36m(func pid=157909)[0m rmse_per_class: [0.061, 0.214, 0.024, 0.258, 0.049, 0.161, 0.208, 0.14, 0.131, 0.152]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3403 | Steps: 4 | Val loss: 0.3027 | Batch size: 32 | lr: 0.01 | Duration: 2.76s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.5337 | Steps: 4 | Val loss: 0.4134 | Batch size: 32 | lr: 0.0001 | Duration: 2.91s
[2m[36m(func pid=164825)[0m rmse: 0.21892774105072021
[2m[36m(func pid=164825)[0m mae:  0.11741290241479874
[2m[36m(func pid=164825)[0m rmse_per_class: [0.193, 0.274, 0.052, 0.299, 0.074, 0.257, 0.302, 0.282, 0.195, 0.261]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2983 | Steps: 4 | Val loss: 0.2694 | Batch size: 32 | lr: 0.001 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 17:01:53 (running for 00:37:50.67)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.299 |  0.14  |                   72 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.34  |  0.15  |                   72 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.695 |  0.219 |                   46 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.54  |  0.18  |                   28 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.14984004199504852
[2m[36m(func pid=159237)[0m mae:  0.08732137084007263
[2m[36m(func pid=159237)[0m rmse_per_class: [0.067, 0.214, 0.035, 0.266, 0.054, 0.224, 0.237, 0.143, 0.132, 0.127]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.17975962162017822
[2m[36m(func pid=169620)[0m mae:  0.13158604502677917
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.268, 0.089, 0.325, 0.095, 0.194, 0.302, 0.148, 0.141, 0.122]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.7216 | Steps: 4 | Val loss: 0.7307 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=157909)[0m rmse: 0.14113394916057587
[2m[36m(func pid=157909)[0m mae:  0.088555708527565
[2m[36m(func pid=157909)[0m rmse_per_class: [0.062, 0.214, 0.025, 0.263, 0.05, 0.159, 0.21, 0.155, 0.135, 0.138]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2905 | Steps: 4 | Val loss: 0.2966 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.5306 | Steps: 4 | Val loss: 0.4087 | Batch size: 32 | lr: 0.0001 | Duration: 2.90s
[2m[36m(func pid=164825)[0m rmse: 0.2169940173625946
[2m[36m(func pid=164825)[0m mae:  0.11826527118682861
[2m[36m(func pid=164825)[0m rmse_per_class: [0.153, 0.27, 0.051, 0.317, 0.07, 0.401, 0.331, 0.174, 0.205, 0.199]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3132 | Steps: 4 | Val loss: 0.2749 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
== Status ==
Current time: 2024-01-07 17:01:58 (running for 00:37:56.04)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.141 |                   73 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.34  |  0.15  |                   72 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.722 |  0.217 |                   47 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.531 |  0.18  |                   30 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=159237)[0m rmse: 0.14733070135116577
[2m[36m(func pid=159237)[0m mae:  0.08458313345909119
[2m[36m(func pid=159237)[0m rmse_per_class: [0.116, 0.216, 0.033, 0.266, 0.055, 0.188, 0.223, 0.125, 0.141, 0.111]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.1796833723783493
[2m[36m(func pid=169620)[0m mae:  0.13149860501289368
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.268, 0.09, 0.326, 0.094, 0.194, 0.302, 0.15, 0.142, 0.121]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.6117 | Steps: 4 | Val loss: 0.6601 | Batch size: 32 | lr: 0.1 | Duration: 3.20s
[2m[36m(func pid=157909)[0m rmse: 0.14340639114379883
[2m[36m(func pid=157909)[0m mae:  0.09037519991397858
[2m[36m(func pid=157909)[0m rmse_per_class: [0.06, 0.213, 0.026, 0.275, 0.051, 0.158, 0.213, 0.177, 0.14, 0.122]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.5218 | Steps: 4 | Val loss: 0.4034 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2826 | Steps: 4 | Val loss: 0.3100 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
[2m[36m(func pid=164825)[0m rmse: 0.20018479228019714
[2m[36m(func pid=164825)[0m mae:  0.1070920079946518
[2m[36m(func pid=164825)[0m rmse_per_class: [0.126, 0.282, 0.049, 0.312, 0.119, 0.322, 0.301, 0.155, 0.216, 0.121]
[2m[36m(func pid=164825)[0m 
== Status ==
Current time: 2024-01-07 17:02:04 (running for 00:38:01.38)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.313 |  0.143 |                   74 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.291 |  0.147 |                   73 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.612 |  0.2   |                   48 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.522 |  0.18  |                   31 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.1798170655965805
[2m[36m(func pid=169620)[0m mae:  0.13150188326835632
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.269, 0.091, 0.327, 0.094, 0.194, 0.301, 0.15, 0.142, 0.12]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.15469416975975037
[2m[36m(func pid=159237)[0m mae:  0.08897962421178818
[2m[36m(func pid=159237)[0m rmse_per_class: [0.184, 0.22, 0.028, 0.271, 0.056, 0.18, 0.225, 0.126, 0.154, 0.102]
[2m[36m(func pid=159237)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3200 | Steps: 4 | Val loss: 0.2799 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.5658 | Steps: 4 | Val loss: 0.7221 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
[2m[36m(func pid=157909)[0m rmse: 0.14598806202411652
[2m[36m(func pid=157909)[0m mae:  0.09237401187419891
[2m[36m(func pid=157909)[0m rmse_per_class: [0.06, 0.213, 0.028, 0.284, 0.052, 0.158, 0.215, 0.2, 0.14, 0.11]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=159237)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3002 | Steps: 4 | Val loss: 0.3262 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.5182 | Steps: 4 | Val loss: 0.3990 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=164825)[0m rmse: 0.2045256793498993
[2m[36m(func pid=164825)[0m mae:  0.11046785116195679
[2m[36m(func pid=164825)[0m rmse_per_class: [0.15, 0.288, 0.047, 0.303, 0.2, 0.238, 0.344, 0.154, 0.229, 0.091]
[2m[36m(func pid=164825)[0m 
== Status ==
Current time: 2024-01-07 17:02:09 (running for 00:38:06.77)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=17
Bracket: Iter 75.000: -0.14624999836087227
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 PENDING, 4 RUNNING, 17 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.32  |  0.146 |                   75 |
| train_c9cb4_00018 | RUNNING    | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.283 |  0.155 |                   74 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.566 |  0.205 |                   49 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.518 |  0.18  |                   32 |
| train_c9cb4_00021 | PENDING    |                     | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17963750660419464
[2m[36m(func pid=169620)[0m mae:  0.1313186138868332
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.268, 0.088, 0.327, 0.095, 0.194, 0.301, 0.15, 0.141, 0.121]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=159237)[0m rmse: 0.16248786449432373
[2m[36m(func pid=159237)[0m mae:  0.09386482834815979
[2m[36m(func pid=159237)[0m rmse_per_class: [0.215, 0.222, 0.028, 0.282, 0.064, 0.182, 0.233, 0.13, 0.175, 0.093]
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.3282 | Steps: 4 | Val loss: 0.2814 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.7385 | Steps: 4 | Val loss: 0.7994 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.5075 | Steps: 4 | Val loss: 0.3948 | Batch size: 32 | lr: 0.0001 | Duration: 3.06s
[2m[36m(func pid=157909)[0m rmse: 0.14636847376823425
[2m[36m(func pid=157909)[0m mae:  0.09257470816373825
[2m[36m(func pid=157909)[0m rmse_per_class: [0.059, 0.212, 0.03, 0.284, 0.052, 0.157, 0.216, 0.215, 0.139, 0.1]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.24160000681877136
[2m[36m(func pid=164825)[0m mae:  0.12749788165092468
[2m[36m(func pid=164825)[0m rmse_per_class: [0.226, 0.306, 0.055, 0.327, 0.311, 0.269, 0.307, 0.17, 0.337, 0.109]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.17971625924110413
[2m[36m(func pid=169620)[0m mae:  0.1312345564365387
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.269, 0.089, 0.327, 0.096, 0.194, 0.301, 0.15, 0.141, 0.121]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.3104 | Steps: 4 | Val loss: 0.2813 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.6861 | Steps: 4 | Val loss: 0.7133 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.5130 | Steps: 4 | Val loss: 0.3903 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=157909)[0m rmse: 0.14615611732006073
[2m[36m(func pid=157909)[0m mae:  0.09275802224874496
[2m[36m(func pid=157909)[0m rmse_per_class: [0.059, 0.211, 0.03, 0.283, 0.052, 0.159, 0.219, 0.216, 0.141, 0.091]
== Status ==
Current time: 2024-01-07 17:02:15 (running for 00:38:12.33)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.328 |  0.146 |                   76 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.739 |  0.242 |                   50 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.507 |  0.18  |                   33 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=177380)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=177380)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=177380)[0m Configuration completed!
[2m[36m(func pid=177380)[0m New optimizer parameters:
[2m[36m(func pid=177380)[0m SGD (
[2m[36m(func pid=177380)[0m Parameter Group 0
[2m[36m(func pid=177380)[0m     dampening: 0
[2m[36m(func pid=177380)[0m     differentiable: False
[2m[36m(func pid=177380)[0m     foreach: None
[2m[36m(func pid=177380)[0m     lr: 0.001
[2m[36m(func pid=177380)[0m     maximize: False
[2m[36m(func pid=177380)[0m     momentum: 0.9
[2m[36m(func pid=177380)[0m     nesterov: False
[2m[36m(func pid=177380)[0m     weight_decay: 1e-05
[2m[36m(func pid=177380)[0m )
[2m[36m(func pid=177380)[0m 
== Status ==
Current time: 2024-01-07 17:02:20 (running for 00:38:17.42)
Memory usage on this node: 24.9/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.31  |  0.146 |                   77 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.686 |  0.226 |                   51 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.507 |  0.18  |                   33 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=164825)[0m rmse: 0.2264520227909088
[2m[36m(func pid=164825)[0m mae:  0.11800839751958847
[2m[36m(func pid=164825)[0m rmse_per_class: [0.164, 0.292, 0.055, 0.325, 0.164, 0.328, 0.347, 0.24, 0.209, 0.141]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.17940106987953186
[2m[36m(func pid=169620)[0m mae:  0.1310049295425415
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.269, 0.09, 0.326, 0.095, 0.194, 0.299, 0.149, 0.141, 0.12]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2862 | Steps: 4 | Val loss: 0.2749 | Batch size: 32 | lr: 0.001 | Duration: 3.13s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.6003 | Steps: 4 | Val loss: 0.7703 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.5046 | Steps: 4 | Val loss: 0.3873 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 1.0624 | Steps: 4 | Val loss: 0.7576 | Batch size: 32 | lr: 0.001 | Duration: 4.90s
[2m[36m(func pid=157909)[0m rmse: 0.14366061985492706
[2m[36m(func pid=157909)[0m mae:  0.09125610440969467
[2m[36m(func pid=157909)[0m rmse_per_class: [0.058, 0.209, 0.03, 0.271, 0.052, 0.163, 0.223, 0.198, 0.149, 0.083]
[2m[36m(func pid=157909)[0m 
== Status ==
Current time: 2024-01-07 17:02:25 (running for 00:38:23.01)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.286 |  0.144 |                   78 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.6   |  0.202 |                   52 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.513 |  0.179 |                   34 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=164825)[0m rmse: 0.2017885446548462
[2m[36m(func pid=164825)[0m mae:  0.11268110573291779
[2m[36m(func pid=164825)[0m rmse_per_class: [0.113, 0.276, 0.049, 0.325, 0.07, 0.331, 0.302, 0.19, 0.17, 0.192]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.17969092726707458
[2m[36m(func pid=169620)[0m mae:  0.13133592903614044
[2m[36m(func pid=169620)[0m rmse_per_class: [0.112, 0.269, 0.09, 0.327, 0.094, 0.194, 0.3, 0.147, 0.142, 0.121]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.17881447076797485
[2m[36m(func pid=177380)[0m mae:  0.13129179179668427
[2m[36m(func pid=177380)[0m rmse_per_class: [0.105, 0.265, 0.088, 0.325, 0.099, 0.192, 0.305, 0.154, 0.139, 0.116]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.3094 | Steps: 4 | Val loss: 0.2703 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.4974 | Steps: 4 | Val loss: 0.3836 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.6452 | Steps: 4 | Val loss: 0.7362 | Batch size: 32 | lr: 0.1 | Duration: 3.17s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.9145 | Steps: 4 | Val loss: 0.6439 | Batch size: 32 | lr: 0.001 | Duration: 3.22s
[2m[36m(func pid=157909)[0m rmse: 0.14206376671791077
[2m[36m(func pid=157909)[0m mae:  0.0900544598698616
[2m[36m(func pid=157909)[0m rmse_per_class: [0.058, 0.207, 0.033, 0.265, 0.052, 0.165, 0.227, 0.179, 0.153, 0.082]
[2m[36m(func pid=157909)[0m 
== Status ==
Current time: 2024-01-07 17:02:31 (running for 00:38:28.38)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.309 |  0.142 |                   79 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.6   |  0.202 |                   52 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.497 |  0.18  |                   36 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  1.062 |  0.179 |                    1 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17964603006839752
[2m[36m(func pid=169620)[0m mae:  0.13125494122505188
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.269, 0.09, 0.327, 0.094, 0.194, 0.301, 0.149, 0.142, 0.12]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.2135486602783203
[2m[36m(func pid=164825)[0m mae:  0.1189507469534874
[2m[36m(func pid=164825)[0m rmse_per_class: [0.15, 0.289, 0.049, 0.298, 0.063, 0.256, 0.299, 0.21, 0.282, 0.24]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.17913606762886047
[2m[36m(func pid=177380)[0m mae:  0.13131627440452576
[2m[36m(func pid=177380)[0m rmse_per_class: [0.105, 0.266, 0.09, 0.324, 0.1, 0.193, 0.304, 0.155, 0.138, 0.116]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.3065 | Steps: 4 | Val loss: 0.2715 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.4963 | Steps: 4 | Val loss: 0.3813 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.7437 | Steps: 4 | Val loss: 0.5172 | Batch size: 32 | lr: 0.001 | Duration: 2.95s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.6282 | Steps: 4 | Val loss: 0.7433 | Batch size: 32 | lr: 0.1 | Duration: 3.20s
== Status ==
Current time: 2024-01-07 17:02:36 (running for 00:38:33.43)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.307 |  0.143 |                   80 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.645 |  0.214 |                   53 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.497 |  0.18  |                   36 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.914 |  0.179 |                    2 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=157909)[0m rmse: 0.1432669460773468
[2m[36m(func pid=157909)[0m mae:  0.0908123254776001
[2m[36m(func pid=157909)[0m rmse_per_class: [0.058, 0.206, 0.037, 0.265, 0.052, 0.168, 0.231, 0.177, 0.158, 0.081]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.17912337183952332
[2m[36m(func pid=169620)[0m mae:  0.1307806521654129
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.269, 0.089, 0.326, 0.095, 0.194, 0.299, 0.148, 0.141, 0.118]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.21879824995994568
[2m[36m(func pid=164825)[0m mae:  0.12004320323467255
[2m[36m(func pid=164825)[0m rmse_per_class: [0.165, 0.271, 0.049, 0.359, 0.076, 0.246, 0.308, 0.19, 0.329, 0.195]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.1789904087781906
[2m[36m(func pid=177380)[0m mae:  0.13091158866882324
[2m[36m(func pid=177380)[0m rmse_per_class: [0.106, 0.268, 0.091, 0.324, 0.099, 0.193, 0.302, 0.154, 0.138, 0.115]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.3243 | Steps: 4 | Val loss: 0.2715 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.4937 | Steps: 4 | Val loss: 0.3771 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.5972 | Steps: 4 | Val loss: 0.4220 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.6927 | Steps: 4 | Val loss: 0.6794 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
[2m[36m(func pid=169620)[0m rmse: 0.1789870262145996
[2m[36m(func pid=169620)[0m mae:  0.13060902059078217
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.269, 0.092, 0.326, 0.094, 0.194, 0.298, 0.148, 0.142, 0.118]
[2m[36m(func pid=169620)[0m 
== Status ==
Current time: 2024-01-07 17:02:41 (running for 00:38:38.95)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.307 |  0.143 |                   80 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.628 |  0.219 |                   54 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.494 |  0.179 |                   38 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.744 |  0.179 |                    3 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=157909)[0m rmse: 0.1440613716840744
[2m[36m(func pid=157909)[0m mae:  0.09123442322015762
[2m[36m(func pid=157909)[0m rmse_per_class: [0.058, 0.206, 0.041, 0.266, 0.052, 0.172, 0.232, 0.166, 0.166, 0.081]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.17884619534015656
[2m[36m(func pid=177380)[0m mae:  0.13047096133232117
[2m[36m(func pid=177380)[0m rmse_per_class: [0.108, 0.269, 0.093, 0.325, 0.098, 0.193, 0.298, 0.15, 0.139, 0.115]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.20839020609855652
[2m[36m(func pid=164825)[0m mae:  0.11131571233272552
[2m[36m(func pid=164825)[0m rmse_per_class: [0.154, 0.284, 0.049, 0.326, 0.09, 0.274, 0.368, 0.164, 0.202, 0.174]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.4890 | Steps: 4 | Val loss: 0.3771 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.3038 | Steps: 4 | Val loss: 0.2675 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.5041 | Steps: 4 | Val loss: 0.3665 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.5287 | Steps: 4 | Val loss: 0.7670 | Batch size: 32 | lr: 0.1 | Duration: 3.18s
== Status ==
Current time: 2024-01-07 17:02:47 (running for 00:38:44.24)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.324 |  0.144 |                   81 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.693 |  0.208 |                   55 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.489 |  0.179 |                   39 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.597 |  0.179 |                    4 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17929276823997498
[2m[36m(func pid=169620)[0m mae:  0.1308361440896988
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.269, 0.094, 0.327, 0.097, 0.194, 0.298, 0.145, 0.141, 0.117]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.14244484901428223
[2m[36m(func pid=157909)[0m mae:  0.09017404168844223
[2m[36m(func pid=157909)[0m rmse_per_class: [0.058, 0.204, 0.044, 0.257, 0.052, 0.173, 0.234, 0.149, 0.173, 0.08]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.17811113595962524
[2m[36m(func pid=177380)[0m mae:  0.12979987263679504
[2m[36m(func pid=177380)[0m rmse_per_class: [0.11, 0.269, 0.095, 0.327, 0.094, 0.193, 0.295, 0.146, 0.141, 0.112]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.2275005280971527
[2m[36m(func pid=164825)[0m mae:  0.12645046412944794
[2m[36m(func pid=164825)[0m rmse_per_class: [0.237, 0.285, 0.049, 0.347, 0.106, 0.414, 0.338, 0.158, 0.169, 0.173]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.4899 | Steps: 4 | Val loss: 0.3746 | Batch size: 32 | lr: 0.0001 | Duration: 2.98s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.3034 | Steps: 4 | Val loss: 0.2669 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4519 | Steps: 4 | Val loss: 0.3417 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.5886 | Steps: 4 | Val loss: 0.8165 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=169620)[0m rmse: 0.17983345687389374
[2m[36m(func pid=169620)[0m mae:  0.1312721073627472
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.27, 0.094, 0.327, 0.098, 0.194, 0.299, 0.145, 0.142, 0.12]
[2m[36m(func pid=169620)[0m 
== Status ==
Current time: 2024-01-07 17:02:52 (running for 00:38:49.59)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.304 |  0.142 |                   82 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.529 |  0.228 |                   56 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.49  |  0.18  |                   40 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.504 |  0.178 |                    5 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=157909)[0m rmse: 0.14223134517669678
[2m[36m(func pid=157909)[0m mae:  0.09020871669054031
[2m[36m(func pid=157909)[0m rmse_per_class: [0.058, 0.206, 0.041, 0.252, 0.051, 0.178, 0.235, 0.14, 0.181, 0.08]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.17745070159435272
[2m[36m(func pid=177380)[0m mae:  0.12914934754371643
[2m[36m(func pid=177380)[0m rmse_per_class: [0.11, 0.269, 0.097, 0.329, 0.092, 0.193, 0.291, 0.141, 0.142, 0.111]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.23983803391456604
[2m[36m(func pid=164825)[0m mae:  0.12954631447792053
[2m[36m(func pid=164825)[0m rmse_per_class: [0.228, 0.377, 0.049, 0.374, 0.137, 0.291, 0.324, 0.172, 0.206, 0.24]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.4827 | Steps: 4 | Val loss: 0.3729 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2849 | Steps: 4 | Val loss: 0.2631 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4323 | Steps: 4 | Val loss: 0.3292 | Batch size: 32 | lr: 0.001 | Duration: 2.82s
== Status ==
Current time: 2024-01-07 17:02:57 (running for 00:38:54.82)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.303 |  0.142 |                   83 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.589 |  0.24  |                   57 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.483 |  0.179 |                   41 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.452 |  0.177 |                    6 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.6539 | Steps: 4 | Val loss: 0.7739 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=169620)[0m rmse: 0.17913101613521576
[2m[36m(func pid=169620)[0m mae:  0.13070893287658691
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.269, 0.091, 0.326, 0.097, 0.194, 0.298, 0.146, 0.141, 0.118]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.13983294367790222
[2m[36m(func pid=157909)[0m mae:  0.08890362828969955
[2m[36m(func pid=157909)[0m rmse_per_class: [0.06, 0.204, 0.045, 0.245, 0.051, 0.175, 0.236, 0.117, 0.186, 0.08]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.17647913098335266
[2m[36m(func pid=177380)[0m mae:  0.12820608913898468
[2m[36m(func pid=177380)[0m rmse_per_class: [0.109, 0.269, 0.097, 0.331, 0.09, 0.193, 0.286, 0.139, 0.143, 0.109]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.23600955307483673
[2m[36m(func pid=164825)[0m mae:  0.12716206908226013
[2m[36m(func pid=164825)[0m rmse_per_class: [0.196, 0.32, 0.051, 0.349, 0.123, 0.241, 0.332, 0.188, 0.273, 0.286]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.4768 | Steps: 4 | Val loss: 0.3702 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.4242 | Steps: 4 | Val loss: 0.3227 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2845 | Steps: 4 | Val loss: 0.2597 | Batch size: 32 | lr: 0.001 | Duration: 3.24s
== Status ==
Current time: 2024-01-07 17:03:03 (running for 00:39:00.25)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.285 |  0.14  |                   84 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.654 |  0.236 |                   58 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.477 |  0.179 |                   42 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.432 |  0.176 |                    7 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.1790456622838974
[2m[36m(func pid=169620)[0m mae:  0.13066233694553375
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.269, 0.092, 0.326, 0.096, 0.194, 0.297, 0.146, 0.142, 0.117]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.5747 | Steps: 4 | Val loss: 0.7528 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=177380)[0m rmse: 0.17536984384059906
[2m[36m(func pid=177380)[0m mae:  0.12722036242485046
[2m[36m(func pid=177380)[0m rmse_per_class: [0.109, 0.268, 0.095, 0.331, 0.086, 0.193, 0.282, 0.138, 0.144, 0.108]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.13697709143161774
[2m[36m(func pid=157909)[0m mae:  0.08691960573196411
[2m[36m(func pid=157909)[0m rmse_per_class: [0.062, 0.203, 0.041, 0.235, 0.05, 0.174, 0.234, 0.112, 0.179, 0.079]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.20425350964069366
[2m[36m(func pid=164825)[0m mae:  0.11430694162845612
[2m[36m(func pid=164825)[0m rmse_per_class: [0.185, 0.277, 0.049, 0.306, 0.079, 0.231, 0.309, 0.152, 0.218, 0.236]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.4732 | Steps: 4 | Val loss: 0.3671 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.4169 | Steps: 4 | Val loss: 0.3193 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2878 | Steps: 4 | Val loss: 0.2577 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 17:03:08 (running for 00:39:05.65)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.285 |  0.137 |                   85 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.575 |  0.204 |                   59 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.473 |  0.179 |                   43 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.424 |  0.175 |                    8 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17871078848838806
[2m[36m(func pid=169620)[0m mae:  0.13037896156311035
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.269, 0.093, 0.327, 0.093, 0.194, 0.296, 0.145, 0.142, 0.117]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.5429 | Steps: 4 | Val loss: 0.7843 | Batch size: 32 | lr: 0.1 | Duration: 3.20s
[2m[36m(func pid=177380)[0m rmse: 0.1744290441274643
[2m[36m(func pid=177380)[0m mae:  0.1264423280954361
[2m[36m(func pid=177380)[0m rmse_per_class: [0.11, 0.268, 0.091, 0.33, 0.083, 0.193, 0.28, 0.137, 0.145, 0.107]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.13514313101768494
[2m[36m(func pid=157909)[0m mae:  0.08604514598846436
[2m[36m(func pid=157909)[0m rmse_per_class: [0.062, 0.205, 0.035, 0.234, 0.049, 0.171, 0.23, 0.11, 0.177, 0.079]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.4741 | Steps: 4 | Val loss: 0.3674 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=164825)[0m rmse: 0.20475280284881592
[2m[36m(func pid=164825)[0m mae:  0.11329053342342377
[2m[36m(func pid=164825)[0m rmse_per_class: [0.151, 0.289, 0.048, 0.317, 0.072, 0.321, 0.31, 0.178, 0.182, 0.181]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.4161 | Steps: 4 | Val loss: 0.3191 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2663 | Steps: 4 | Val loss: 0.2569 | Batch size: 32 | lr: 0.001 | Duration: 3.19s
== Status ==
Current time: 2024-01-07 17:03:13 (running for 00:39:11.03)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.288 |  0.135 |                   86 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.543 |  0.205 |                   60 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.474 |  0.178 |                   44 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.417 |  0.174 |                    9 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.1783975064754486
[2m[36m(func pid=169620)[0m mae:  0.1301712691783905
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.269, 0.092, 0.326, 0.094, 0.194, 0.296, 0.145, 0.142, 0.116]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.7094 | Steps: 4 | Val loss: 0.7864 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
[2m[36m(func pid=177380)[0m rmse: 0.17435848712921143
[2m[36m(func pid=177380)[0m mae:  0.1263953447341919
[2m[36m(func pid=177380)[0m rmse_per_class: [0.111, 0.267, 0.091, 0.331, 0.083, 0.193, 0.28, 0.136, 0.145, 0.107]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.13404305279254913
[2m[36m(func pid=157909)[0m mae:  0.08525299280881882
[2m[36m(func pid=157909)[0m rmse_per_class: [0.064, 0.204, 0.039, 0.234, 0.049, 0.163, 0.225, 0.108, 0.175, 0.078]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.4701 | Steps: 4 | Val loss: 0.3631 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=164825)[0m rmse: 0.2346901148557663
[2m[36m(func pid=164825)[0m mae:  0.12767702341079712
[2m[36m(func pid=164825)[0m rmse_per_class: [0.253, 0.283, 0.049, 0.334, 0.093, 0.366, 0.361, 0.299, 0.186, 0.124]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.4142 | Steps: 4 | Val loss: 0.3173 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
== Status ==
Current time: 2024-01-07 17:03:19 (running for 00:39:16.13)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.266 |  0.134 |                   87 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.709 |  0.235 |                   61 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.47  |  0.178 |                   45 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.416 |  0.174 |                   10 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17812909185886383
[2m[36m(func pid=169620)[0m mae:  0.12993881106376648
[2m[36m(func pid=169620)[0m rmse_per_class: [0.108, 0.268, 0.093, 0.328, 0.092, 0.194, 0.295, 0.146, 0.142, 0.116]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2763 | Steps: 4 | Val loss: 0.2562 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.7450 | Steps: 4 | Val loss: 0.8209 | Batch size: 32 | lr: 0.1 | Duration: 3.36s
[2m[36m(func pid=177380)[0m rmse: 0.1735265552997589
[2m[36m(func pid=177380)[0m mae:  0.12574313580989838
[2m[36m(func pid=177380)[0m rmse_per_class: [0.111, 0.266, 0.089, 0.329, 0.081, 0.193, 0.28, 0.136, 0.144, 0.106]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.4709 | Steps: 4 | Val loss: 0.3612 | Batch size: 32 | lr: 0.0001 | Duration: 3.10s
[2m[36m(func pid=157909)[0m rmse: 0.13294851779937744
[2m[36m(func pid=157909)[0m mae:  0.08436314761638641
[2m[36m(func pid=157909)[0m rmse_per_class: [0.067, 0.205, 0.04, 0.235, 0.049, 0.161, 0.222, 0.106, 0.166, 0.078]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.21969933807849884
[2m[36m(func pid=164825)[0m mae:  0.12250753492116928
[2m[36m(func pid=164825)[0m rmse_per_class: [0.304, 0.326, 0.048, 0.379, 0.095, 0.235, 0.362, 0.199, 0.154, 0.095]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.4173 | Steps: 4 | Val loss: 0.3155 | Batch size: 32 | lr: 0.001 | Duration: 3.18s
== Status ==
Current time: 2024-01-07 17:03:24 (running for 00:39:21.76)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.276 |  0.133 |                   88 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.745 |  0.22  |                   62 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.471 |  0.178 |                   46 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.414 |  0.174 |                   11 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.1783285290002823
[2m[36m(func pid=169620)[0m mae:  0.13010907173156738
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.269, 0.092, 0.327, 0.093, 0.194, 0.296, 0.145, 0.143, 0.115]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2879 | Steps: 4 | Val loss: 0.2565 | Batch size: 32 | lr: 0.001 | Duration: 3.17s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.7578 | Steps: 4 | Val loss: 0.8135 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=177380)[0m rmse: 0.17256216704845428
[2m[36m(func pid=177380)[0m mae:  0.12475375831127167
[2m[36m(func pid=177380)[0m rmse_per_class: [0.11, 0.267, 0.087, 0.327, 0.08, 0.193, 0.278, 0.135, 0.144, 0.105]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.4680 | Steps: 4 | Val loss: 0.3585 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=157909)[0m rmse: 0.13291573524475098
[2m[36m(func pid=157909)[0m mae:  0.0843341052532196
[2m[36m(func pid=157909)[0m rmse_per_class: [0.07, 0.207, 0.041, 0.237, 0.049, 0.159, 0.217, 0.108, 0.162, 0.08]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.2174389660358429
[2m[36m(func pid=164825)[0m mae:  0.12241759151220322
[2m[36m(func pid=164825)[0m rmse_per_class: [0.182, 0.323, 0.048, 0.365, 0.11, 0.238, 0.325, 0.152, 0.337, 0.094]
[2m[36m(func pid=164825)[0m 
== Status ==
Current time: 2024-01-07 17:03:29 (running for 00:39:27.02)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.288 |  0.133 |                   89 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.758 |  0.217 |                   63 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.468 |  0.179 |                   47 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.417 |  0.173 |                   12 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17850415408611298
[2m[36m(func pid=169620)[0m mae:  0.13019748032093048
[2m[36m(func pid=169620)[0m rmse_per_class: [0.109, 0.268, 0.091, 0.328, 0.095, 0.193, 0.296, 0.145, 0.143, 0.115]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.4115 | Steps: 4 | Val loss: 0.3143 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2896 | Steps: 4 | Val loss: 0.2551 | Batch size: 32 | lr: 0.001 | Duration: 3.13s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.6738 | Steps: 4 | Val loss: 0.7318 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
[2m[36m(func pid=177380)[0m rmse: 0.17163413763046265
[2m[36m(func pid=177380)[0m mae:  0.124028280377388
[2m[36m(func pid=177380)[0m rmse_per_class: [0.111, 0.267, 0.083, 0.327, 0.077, 0.193, 0.276, 0.134, 0.145, 0.105]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.4647 | Steps: 4 | Val loss: 0.3570 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=157909)[0m rmse: 0.1314244568347931
[2m[36m(func pid=157909)[0m mae:  0.08330334722995758
[2m[36m(func pid=157909)[0m rmse_per_class: [0.071, 0.208, 0.035, 0.237, 0.05, 0.158, 0.211, 0.108, 0.151, 0.085]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.20750749111175537
[2m[36m(func pid=164825)[0m mae:  0.11634037643671036
[2m[36m(func pid=164825)[0m rmse_per_class: [0.11, 0.27, 0.043, 0.362, 0.107, 0.311, 0.302, 0.153, 0.322, 0.095]
[2m[36m(func pid=164825)[0m 
== Status ==
Current time: 2024-01-07 17:03:35 (running for 00:39:32.32)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.29  |  0.131 |                   90 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.674 |  0.208 |                   64 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.465 |  0.179 |                   48 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.411 |  0.172 |                   13 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17851516604423523
[2m[36m(func pid=169620)[0m mae:  0.1301865130662918
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.269, 0.09, 0.328, 0.094, 0.194, 0.296, 0.145, 0.143, 0.116]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.4036 | Steps: 4 | Val loss: 0.3131 | Batch size: 32 | lr: 0.001 | Duration: 3.04s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2961 | Steps: 4 | Val loss: 0.2550 | Batch size: 32 | lr: 0.001 | Duration: 3.18s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.8181 | Steps: 4 | Val loss: 0.8566 | Batch size: 32 | lr: 0.1 | Duration: 3.19s
[2m[36m(func pid=177380)[0m rmse: 0.17090511322021484
[2m[36m(func pid=177380)[0m mae:  0.12345889955759048
[2m[36m(func pid=177380)[0m rmse_per_class: [0.11, 0.267, 0.08, 0.325, 0.075, 0.193, 0.274, 0.135, 0.145, 0.106]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.4623 | Steps: 4 | Val loss: 0.3567 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=157909)[0m rmse: 0.13189366459846497
[2m[36m(func pid=157909)[0m mae:  0.08281941711902618
[2m[36m(func pid=157909)[0m rmse_per_class: [0.078, 0.211, 0.038, 0.236, 0.051, 0.159, 0.201, 0.108, 0.147, 0.091]
[2m[36m(func pid=157909)[0m 
== Status ==
Current time: 2024-01-07 17:03:40 (running for 00:39:37.61)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.296 |  0.132 |                   91 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.818 |  0.201 |                   65 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.465 |  0.179 |                   48 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.404 |  0.171 |                   14 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=164825)[0m rmse: 0.20137515664100647
[2m[36m(func pid=164825)[0m mae:  0.11186568439006805
[2m[36m(func pid=164825)[0m rmse_per_class: [0.163, 0.294, 0.053, 0.348, 0.092, 0.31, 0.297, 0.153, 0.15, 0.155]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.17833803594112396
[2m[36m(func pid=169620)[0m mae:  0.12993790209293365
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.269, 0.092, 0.327, 0.095, 0.193, 0.295, 0.144, 0.142, 0.115]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.4085 | Steps: 4 | Val loss: 0.3119 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2698 | Steps: 4 | Val loss: 0.2544 | Batch size: 32 | lr: 0.001 | Duration: 3.14s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.4574 | Steps: 4 | Val loss: 0.3561 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.7756 | Steps: 4 | Val loss: 1.0184 | Batch size: 32 | lr: 0.1 | Duration: 3.24s
[2m[36m(func pid=177380)[0m rmse: 0.1702805757522583
[2m[36m(func pid=177380)[0m mae:  0.1231149435043335
[2m[36m(func pid=177380)[0m rmse_per_class: [0.109, 0.266, 0.077, 0.325, 0.073, 0.192, 0.274, 0.135, 0.145, 0.106]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.13131539523601532
[2m[36m(func pid=157909)[0m mae:  0.08240361511707306
[2m[36m(func pid=157909)[0m rmse_per_class: [0.072, 0.21, 0.037, 0.234, 0.056, 0.16, 0.198, 0.109, 0.144, 0.093]
[2m[36m(func pid=157909)[0m 
== Status ==
Current time: 2024-01-07 17:03:46 (running for 00:39:43.13)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.27  |  0.131 |                   92 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.818 |  0.201 |                   65 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.457 |  0.178 |                   50 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.408 |  0.17  |                   15 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17818418145179749
[2m[36m(func pid=169620)[0m mae:  0.1298965960741043
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.269, 0.091, 0.327, 0.094, 0.193, 0.295, 0.143, 0.142, 0.117]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.2537417411804199
[2m[36m(func pid=164825)[0m mae:  0.14410489797592163
[2m[36m(func pid=164825)[0m rmse_per_class: [0.432, 0.289, 0.066, 0.374, 0.102, 0.239, 0.34, 0.16, 0.137, 0.4]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.4086 | Steps: 4 | Val loss: 0.3109 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2830 | Steps: 4 | Val loss: 0.2561 | Batch size: 32 | lr: 0.001 | Duration: 3.24s
[2m[36m(func pid=177380)[0m rmse: 0.16990479826927185
[2m[36m(func pid=177380)[0m mae:  0.12283442169427872
[2m[36m(func pid=177380)[0m rmse_per_class: [0.109, 0.265, 0.077, 0.325, 0.072, 0.192, 0.273, 0.135, 0.146, 0.106]
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.4572 | Steps: 4 | Val loss: 0.3558 | Batch size: 32 | lr: 0.0001 | Duration: 3.07s
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.7944 | Steps: 4 | Val loss: 1.0744 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
== Status ==
Current time: 2024-01-07 17:03:51 (running for 00:39:48.36)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.283 |  0.133 |                   93 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.776 |  0.254 |                   66 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.457 |  0.178 |                   50 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.409 |  0.17  |                   16 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=157909)[0m rmse: 0.1331036537885666
[2m[36m(func pid=157909)[0m mae:  0.08301472663879395
[2m[36m(func pid=157909)[0m rmse_per_class: [0.077, 0.211, 0.038, 0.235, 0.06, 0.163, 0.194, 0.11, 0.139, 0.105]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.17844118177890778
[2m[36m(func pid=169620)[0m mae:  0.13012711703777313
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.269, 0.092, 0.329, 0.093, 0.193, 0.294, 0.143, 0.143, 0.118]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.24661512672901154
[2m[36m(func pid=164825)[0m mae:  0.1317325085401535
[2m[36m(func pid=164825)[0m rmse_per_class: [0.218, 0.332, 0.066, 0.389, 0.122, 0.234, 0.385, 0.279, 0.136, 0.304]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.4182 | Steps: 4 | Val loss: 0.3110 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2887 | Steps: 4 | Val loss: 0.2543 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.4571 | Steps: 4 | Val loss: 0.3518 | Batch size: 32 | lr: 0.0001 | Duration: 2.78s
[2m[36m(func pid=177380)[0m rmse: 0.16980744898319244
[2m[36m(func pid=177380)[0m mae:  0.12278296053409576
[2m[36m(func pid=177380)[0m rmse_per_class: [0.11, 0.264, 0.075, 0.326, 0.07, 0.192, 0.273, 0.135, 0.146, 0.107]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.8864 | Steps: 4 | Val loss: 1.1614 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 17:03:56 (running for 00:39:53.80)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.283 |  0.133 |                   93 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.794 |  0.247 |                   67 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.457 |  0.178 |                   52 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.418 |  0.17  |                   17 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17810367047786713
[2m[36m(func pid=169620)[0m mae:  0.12983708083629608
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.27, 0.093, 0.328, 0.091, 0.194, 0.293, 0.144, 0.143, 0.116]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.13239440321922302
[2m[36m(func pid=157909)[0m mae:  0.08232806622982025
[2m[36m(func pid=157909)[0m rmse_per_class: [0.068, 0.212, 0.029, 0.232, 0.065, 0.163, 0.193, 0.106, 0.133, 0.123]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.4109 | Steps: 4 | Val loss: 0.3102 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=164825)[0m rmse: 0.22600257396697998
[2m[36m(func pid=164825)[0m mae:  0.12962427735328674
[2m[36m(func pid=164825)[0m rmse_per_class: [0.116, 0.373, 0.048, 0.389, 0.093, 0.245, 0.329, 0.417, 0.138, 0.112]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.4523 | Steps: 4 | Val loss: 0.3517 | Batch size: 32 | lr: 0.0001 | Duration: 2.94s
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.3037 | Steps: 4 | Val loss: 0.2566 | Batch size: 32 | lr: 0.001 | Duration: 3.30s
[2m[36m(func pid=177380)[0m rmse: 0.1694207340478897
[2m[36m(func pid=177380)[0m mae:  0.12233434617519379
[2m[36m(func pid=177380)[0m rmse_per_class: [0.109, 0.265, 0.073, 0.326, 0.069, 0.192, 0.271, 0.136, 0.144, 0.109]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.9033 | Steps: 4 | Val loss: 0.9279 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=169620)[0m rmse: 0.17825858294963837
[2m[36m(func pid=169620)[0m mae:  0.1299745738506317
[2m[36m(func pid=169620)[0m rmse_per_class: [0.109, 0.269, 0.092, 0.328, 0.09, 0.194, 0.293, 0.146, 0.143, 0.118]
== Status ==
Current time: 2024-01-07 17:04:02 (running for 00:39:59.28)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.289 |  0.132 |                   94 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.886 |  0.226 |                   68 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.452 |  0.178 |                   53 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.411 |  0.169 |                   18 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=157909)[0m rmse: 0.13402989506721497
[2m[36m(func pid=157909)[0m mae:  0.08322615921497345
[2m[36m(func pid=157909)[0m rmse_per_class: [0.067, 0.211, 0.029, 0.235, 0.064, 0.164, 0.193, 0.109, 0.131, 0.137]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.4072 | Steps: 4 | Val loss: 0.3100 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=164825)[0m rmse: 0.2237064391374588
[2m[36m(func pid=164825)[0m mae:  0.12640348076820374
[2m[36m(func pid=164825)[0m rmse_per_class: [0.167, 0.269, 0.049, 0.377, 0.09, 0.325, 0.341, 0.245, 0.278, 0.096]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.4505 | Steps: 4 | Val loss: 0.3483 | Batch size: 32 | lr: 0.0001 | Duration: 2.99s
[2m[36m(func pid=177380)[0m rmse: 0.16930429637432098
[2m[36m(func pid=177380)[0m mae:  0.12240002304315567
[2m[36m(func pid=177380)[0m rmse_per_class: [0.107, 0.264, 0.072, 0.326, 0.068, 0.192, 0.272, 0.136, 0.145, 0.111]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2753 | Steps: 4 | Val loss: 0.2593 | Batch size: 32 | lr: 0.001 | Duration: 3.23s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.8480 | Steps: 4 | Val loss: 0.8924 | Batch size: 32 | lr: 0.1 | Duration: 3.18s
== Status ==
Current time: 2024-01-07 17:04:07 (running for 00:40:04.89)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.304 |  0.134 |                   95 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.903 |  0.224 |                   69 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.45  |  0.178 |                   54 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.407 |  0.169 |                   19 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17769813537597656
[2m[36m(func pid=169620)[0m mae:  0.1294741928577423
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.27, 0.091, 0.326, 0.089, 0.194, 0.292, 0.144, 0.143, 0.117]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.4057 | Steps: 4 | Val loss: 0.3098 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=157909)[0m rmse: 0.13666626811027527
[2m[36m(func pid=157909)[0m mae:  0.0845746174454689
[2m[36m(func pid=157909)[0m rmse_per_class: [0.063, 0.214, 0.03, 0.236, 0.074, 0.164, 0.194, 0.112, 0.126, 0.153]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.21304669976234436
[2m[36m(func pid=164825)[0m mae:  0.11910760402679443
[2m[36m(func pid=164825)[0m rmse_per_class: [0.164, 0.301, 0.048, 0.323, 0.123, 0.25, 0.285, 0.164, 0.365, 0.107]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.4479 | Steps: 4 | Val loss: 0.3487 | Batch size: 32 | lr: 0.0001 | Duration: 3.08s
[2m[36m(func pid=177380)[0m rmse: 0.16930650174617767
[2m[36m(func pid=177380)[0m mae:  0.12248148769140244
[2m[36m(func pid=177380)[0m rmse_per_class: [0.107, 0.263, 0.071, 0.326, 0.068, 0.192, 0.273, 0.136, 0.144, 0.113]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2932 | Steps: 4 | Val loss: 0.2582 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.7890 | Steps: 4 | Val loss: 0.9305 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
== Status ==
Current time: 2024-01-07 17:04:13 (running for 00:40:10.35)
Memory usage on this node: 25.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.275 |  0.137 |                   96 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.848 |  0.213 |                   70 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.448 |  0.178 |                   55 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.406 |  0.169 |                   20 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17817401885986328
[2m[36m(func pid=169620)[0m mae:  0.12983331084251404
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.269, 0.093, 0.327, 0.09, 0.194, 0.293, 0.144, 0.143, 0.117]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.4029 | Steps: 4 | Val loss: 0.3084 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=157909)[0m rmse: 0.13599613308906555
[2m[36m(func pid=157909)[0m mae:  0.08400003612041473
[2m[36m(func pid=157909)[0m rmse_per_class: [0.059, 0.213, 0.031, 0.233, 0.085, 0.164, 0.194, 0.112, 0.126, 0.142]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.21809323132038116
[2m[36m(func pid=164825)[0m mae:  0.11620266735553741
[2m[36m(func pid=164825)[0m rmse_per_class: [0.147, 0.301, 0.037, 0.432, 0.172, 0.26, 0.304, 0.16, 0.188, 0.179]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.4524 | Steps: 4 | Val loss: 0.3472 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=177380)[0m rmse: 0.1686980426311493
[2m[36m(func pid=177380)[0m mae:  0.12201184034347534
[2m[36m(func pid=177380)[0m rmse_per_class: [0.108, 0.263, 0.069, 0.323, 0.067, 0.192, 0.273, 0.136, 0.144, 0.112]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2834 | Steps: 4 | Val loss: 0.2632 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.7978 | Steps: 4 | Val loss: 0.8272 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 17:04:18 (running for 00:40:15.61)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.293 |  0.136 |                   97 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.789 |  0.218 |                   71 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.452 |  0.179 |                   56 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.403 |  0.169 |                   21 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17859669029712677
[2m[36m(func pid=169620)[0m mae:  0.1300862580537796
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.27, 0.094, 0.328, 0.091, 0.194, 0.293, 0.144, 0.143, 0.119]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.4047 | Steps: 4 | Val loss: 0.3085 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=157909)[0m rmse: 0.13983266055583954
[2m[36m(func pid=157909)[0m mae:  0.08672326058149338
[2m[36m(func pid=157909)[0m rmse_per_class: [0.059, 0.212, 0.031, 0.241, 0.092, 0.166, 0.195, 0.114, 0.126, 0.163]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.22776922583580017
[2m[36m(func pid=164825)[0m mae:  0.1191120371222496
[2m[36m(func pid=164825)[0m rmse_per_class: [0.162, 0.287, 0.079, 0.315, 0.167, 0.306, 0.367, 0.161, 0.14, 0.294]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.4469 | Steps: 4 | Val loss: 0.3463 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=177380)[0m rmse: 0.16871728003025055
[2m[36m(func pid=177380)[0m mae:  0.12200045585632324
[2m[36m(func pid=177380)[0m rmse_per_class: [0.108, 0.263, 0.068, 0.322, 0.068, 0.192, 0.273, 0.137, 0.144, 0.112]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2921 | Steps: 4 | Val loss: 0.2657 | Batch size: 32 | lr: 0.001 | Duration: 3.18s
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.7529 | Steps: 4 | Val loss: 0.9308 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
== Status ==
Current time: 2024-01-07 17:04:23 (running for 00:40:20.88)
Memory usage on this node: 25.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.283 |  0.14  |                   98 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.798 |  0.228 |                   72 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.447 |  0.178 |                   57 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.405 |  0.169 |                   22 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.178249329328537
[2m[36m(func pid=169620)[0m mae:  0.12982431054115295
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.27, 0.093, 0.327, 0.091, 0.194, 0.292, 0.144, 0.145, 0.117]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.4042 | Steps: 4 | Val loss: 0.3079 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=157909)[0m rmse: 0.1418946236371994
[2m[36m(func pid=157909)[0m mae:  0.08838517963886261
[2m[36m(func pid=157909)[0m rmse_per_class: [0.056, 0.213, 0.03, 0.248, 0.097, 0.166, 0.198, 0.109, 0.125, 0.177]
[2m[36m(func pid=157909)[0m 
[2m[36m(func pid=164825)[0m rmse: 0.21513459086418152
[2m[36m(func pid=164825)[0m mae:  0.1185653805732727
[2m[36m(func pid=164825)[0m rmse_per_class: [0.093, 0.301, 0.079, 0.371, 0.095, 0.35, 0.33, 0.173, 0.135, 0.225]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.4464 | Steps: 4 | Val loss: 0.3447 | Batch size: 32 | lr: 0.0001 | Duration: 2.93s
[2m[36m(func pid=177380)[0m rmse: 0.16843357682228088
[2m[36m(func pid=177380)[0m mae:  0.12177995592355728
[2m[36m(func pid=177380)[0m rmse_per_class: [0.109, 0.263, 0.067, 0.321, 0.067, 0.191, 0.274, 0.136, 0.143, 0.112]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=157909)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2985 | Steps: 4 | Val loss: 0.2686 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
== Status ==
Current time: 2024-01-07 17:04:29 (running for 00:40:26.24)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=18
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 PENDING, 4 RUNNING, 18 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00017 | RUNNING    | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.292 |  0.142 |                   99 |
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.753 |  0.215 |                   73 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.446 |  0.178 |                   58 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.404 |  0.168 |                   23 |
| train_c9cb4_00022 | PENDING    |                     | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.8246 | Steps: 4 | Val loss: 1.1621 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=169620)[0m rmse: 0.17785117030143738
[2m[36m(func pid=169620)[0m mae:  0.12956134974956512
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.27, 0.092, 0.326, 0.088, 0.194, 0.292, 0.145, 0.144, 0.117]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.4084 | Steps: 4 | Val loss: 0.3081 | Batch size: 32 | lr: 0.001 | Duration: 2.94s
[2m[36m(func pid=157909)[0m rmse: 0.1438058763742447
[2m[36m(func pid=157909)[0m mae:  0.09000736474990845
[2m[36m(func pid=157909)[0m rmse_per_class: [0.056, 0.215, 0.029, 0.255, 0.095, 0.165, 0.2, 0.109, 0.127, 0.186]
[2m[36m(func pid=164825)[0m rmse: 0.23148302733898163
[2m[36m(func pid=164825)[0m mae:  0.12913569808006287
[2m[36m(func pid=164825)[0m rmse_per_class: [0.123, 0.39, 0.059, 0.386, 0.124, 0.317, 0.309, 0.283, 0.133, 0.191]
[2m[36m(func pid=164825)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.4419 | Steps: 4 | Val loss: 0.3458 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=177380)[0m rmse: 0.16845189034938812
[2m[36m(func pid=177380)[0m mae:  0.12180075794458389
[2m[36m(func pid=177380)[0m rmse_per_class: [0.11, 0.263, 0.068, 0.321, 0.068, 0.191, 0.273, 0.136, 0.142, 0.112]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.17779015004634857
[2m[36m(func pid=169620)[0m mae:  0.12965184450149536
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.269, 0.089, 0.328, 0.09, 0.193, 0.292, 0.144, 0.145, 0.117]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=164825)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.8437 | Steps: 4 | Val loss: 1.0187 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.4033 | Steps: 4 | Val loss: 0.3083 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
[2m[36m(func pid=164825)[0m rmse: 0.2487352192401886
[2m[36m(func pid=164825)[0m mae:  0.13567665219306946
[2m[36m(func pid=164825)[0m rmse_per_class: [0.325, 0.263, 0.048, 0.376, 0.146, 0.312, 0.308, 0.347, 0.165, 0.197]
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.4439 | Steps: 4 | Val loss: 0.3443 | Batch size: 32 | lr: 0.0001 | Duration: 2.88s
[2m[36m(func pid=177380)[0m rmse: 0.1688014566898346
[2m[36m(func pid=177380)[0m mae:  0.12204760313034058
[2m[36m(func pid=177380)[0m rmse_per_class: [0.112, 0.263, 0.068, 0.322, 0.067, 0.191, 0.273, 0.136, 0.142, 0.115]
== Status ==
Current time: 2024-01-07 17:04:34 (running for 00:40:31.76)
Memory usage on this node: 22.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.825 |  0.231 |                   74 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.442 |  0.178 |                   59 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.408 |  0.168 |                   24 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=183330)[0m Configuration completed!
[2m[36m(func pid=183330)[0m New optimizer parameters:
[2m[36m(func pid=183330)[0m SGD (
[2m[36m(func pid=183330)[0m Parameter Group 0
[2m[36m(func pid=183330)[0m     dampening: 0
== Status ==
Current time: 2024-01-07 17:04:39 (running for 00:40:36.84)
Memory usage on this node: 23.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=19
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 PENDING, 4 RUNNING, 19 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00019 | RUNNING    | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.825 |  0.231 |                   74 |
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.442 |  0.178 |                   59 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.403 |  0.169 |                   25 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | PENDING    |                     | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)

[2m[36m(func pid=183330)[0m     differentiable: False

[2m[36m(func pid=183330)[0m     foreach: None
[2m[36m(func pid=183330)[0m     lr: 0.01
[2m[36m(func pid=183330)[0m     maximize: False
[2m[36m(func pid=183330)[0m     momentum: 0.9
[2m[36m(func pid=183330)[0m     nesterov: False
[2m[36m(func pid=183330)[0m     weight_decay: 1e-05
[2m[36m(func pid=183330)[0m )
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.17763416469097137
[2m[36m(func pid=169620)[0m mae:  0.129545658826828
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.269, 0.09, 0.329, 0.089, 0.194, 0.293, 0.143, 0.145, 0.115]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.4441 | Steps: 4 | Val loss: 0.3433 | Batch size: 32 | lr: 0.0001 | Duration: 2.82s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3988 | Steps: 4 | Val loss: 0.3081 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.8690 | Steps: 4 | Val loss: 0.4371 | Batch size: 32 | lr: 0.01 | Duration: 4.55s
[2m[36m(func pid=169620)[0m rmse: 0.17754149436950684
[2m[36m(func pid=169620)[0m mae:  0.1294698268175125
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.269, 0.089, 0.328, 0.089, 0.194, 0.292, 0.144, 0.144, 0.116]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16888952255249023
[2m[36m(func pid=177380)[0m mae:  0.12208022177219391
[2m[36m(func pid=177380)[0m rmse_per_class: [0.112, 0.263, 0.066, 0.321, 0.067, 0.191, 0.274, 0.136, 0.141, 0.118]
[2m[36m(func pid=183330)[0m rmse: 0.17721393704414368
[2m[36m(func pid=183330)[0m mae:  0.12957358360290527
[2m[36m(func pid=183330)[0m rmse_per_class: [0.104, 0.269, 0.088, 0.327, 0.092, 0.192, 0.294, 0.153, 0.142, 0.111]
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.4407 | Steps: 4 | Val loss: 0.3415 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 17:04:45 (running for 00:40:42.20)
Memory usage on this node: 22.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.444 |  0.178 |                   61 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.403 |  0.169 |                   25 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m Dataloader to compute accuracy: val
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183978)[0m Adjusting optimizer according to the provided configuration...
[2m[36m(func pid=183978)[0m Configuration completed!
[2m[36m(func pid=183978)[0m New optimizer parameters:
[2m[36m(func pid=183978)[0m SGD (
[2m[36m(func pid=183978)[0m Parameter Group 0
[2m[36m(func pid=183978)[0m     dampening: 0
[2m[36m(func pid=183978)[0m     differentiable: False
[2m[36m(func pid=183978)[0m     foreach: None
[2m[36m(func pid=183978)[0m     lr: 0.1
[2m[36m(func pid=183978)[0m     maximize: False
[2m[36m(func pid=183978)[0m     momentum: 0.9
[2m[36m(func pid=183978)[0m     nesterov: False
[2m[36m(func pid=183978)[0m     weight_decay: 1e-05
[2m[36m(func pid=183978)[0m )
[2m[36m(func pid=183978)[0m 
== Status ==
Current time: 2024-01-07 17:04:50 (running for 00:40:47.64)
Memory usage on this node: 25.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.441 |  0.177 |                   62 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.399 |  0.169 |                   26 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.869 |  0.177 |                    1 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17748436331748962
[2m[36m(func pid=169620)[0m mae:  0.1293821632862091
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.269, 0.089, 0.327, 0.088, 0.194, 0.293, 0.144, 0.144, 0.116]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.4610 | Steps: 4 | Val loss: 0.3272 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.4008 | Steps: 4 | Val loss: 0.3080 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.4389 | Steps: 4 | Val loss: 0.3399 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 0] | Train loss: 0.6708 | Steps: 4 | Val loss: 0.4393 | Batch size: 32 | lr: 0.1 | Duration: 4.69s
[2m[36m(func pid=183330)[0m rmse: 0.17537856101989746
[2m[36m(func pid=183330)[0m mae:  0.12689583003520966
[2m[36m(func pid=183330)[0m rmse_per_class: [0.107, 0.273, 0.098, 0.341, 0.075, 0.193, 0.275, 0.133, 0.155, 0.104]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.1688411384820938
[2m[36m(func pid=177380)[0m mae:  0.12201809883117676
[2m[36m(func pid=177380)[0m rmse_per_class: [0.111, 0.263, 0.067, 0.321, 0.067, 0.191, 0.274, 0.136, 0.142, 0.118]
[2m[36m(func pid=177380)[0m 
== Status ==
Current time: 2024-01-07 17:04:55 (running for 00:40:52.82)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.439 |  0.178 |                   63 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.401 |  0.169 |                   27 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.461 |  0.175 |                    2 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |        |        |                      |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17752216756343842
[2m[36m(func pid=169620)[0m mae:  0.1293708235025406
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.269, 0.09, 0.327, 0.089, 0.194, 0.292, 0.143, 0.145, 0.115]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.17894233763217926
[2m[36m(func pid=183978)[0m mae:  0.12292134761810303
[2m[36m(func pid=183978)[0m rmse_per_class: [0.116, 0.271, 0.067, 0.37, 0.056, 0.188, 0.33, 0.144, 0.155, 0.093]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.4591 | Steps: 4 | Val loss: 0.3644 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3933 | Steps: 4 | Val loss: 0.3079 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.4376 | Steps: 4 | Val loss: 0.3402 | Batch size: 32 | lr: 0.0001 | Duration: 2.73s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 1] | Train loss: 0.7147 | Steps: 4 | Val loss: 0.4388 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
[2m[36m(func pid=183330)[0m rmse: 0.17369911074638367
[2m[36m(func pid=183330)[0m mae:  0.12281988561153412
[2m[36m(func pid=183330)[0m rmse_per_class: [0.105, 0.272, 0.083, 0.344, 0.063, 0.193, 0.283, 0.134, 0.164, 0.096]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.1687028855085373
[2m[36m(func pid=177380)[0m mae:  0.12193236500024796
[2m[36m(func pid=177380)[0m rmse_per_class: [0.109, 0.262, 0.066, 0.32, 0.067, 0.191, 0.275, 0.136, 0.143, 0.119]
[2m[36m(func pid=177380)[0m 
== Status ==
Current time: 2024-01-07 17:05:00 (running for 00:40:57.97)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.438 |  0.178 |                   64 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.393 |  0.169 |                   28 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.459 |  0.174 |                    3 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.671 |  0.179 |                    1 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.1777631938457489
[2m[36m(func pid=169620)[0m mae:  0.12948660552501678
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.269, 0.091, 0.328, 0.089, 0.193, 0.291, 0.143, 0.144, 0.117]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.18331193923950195
[2m[36m(func pid=183978)[0m mae:  0.12439252436161041
[2m[36m(func pid=183978)[0m rmse_per_class: [0.248, 0.251, 0.049, 0.387, 0.056, 0.195, 0.251, 0.155, 0.145, 0.096]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.5154 | Steps: 4 | Val loss: 0.3748 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3954 | Steps: 4 | Val loss: 0.3079 | Batch size: 32 | lr: 0.001 | Duration: 2.93s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.4426 | Steps: 4 | Val loss: 0.3391 | Batch size: 32 | lr: 0.0001 | Duration: 2.85s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 2] | Train loss: 0.6774 | Steps: 4 | Val loss: 0.3335 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
[2m[36m(func pid=183330)[0m rmse: 0.1737421154975891
[2m[36m(func pid=183330)[0m mae:  0.11983175575733185
[2m[36m(func pid=183330)[0m rmse_per_class: [0.104, 0.272, 0.062, 0.344, 0.057, 0.192, 0.307, 0.136, 0.171, 0.093]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16858705878257751
[2m[36m(func pid=177380)[0m mae:  0.12186108529567719
[2m[36m(func pid=177380)[0m rmse_per_class: [0.108, 0.262, 0.067, 0.321, 0.067, 0.19, 0.275, 0.136, 0.144, 0.117]
[2m[36m(func pid=177380)[0m 
== Status ==
Current time: 2024-01-07 17:05:06 (running for 00:41:03.27)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.443 |  0.178 |                   65 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.395 |  0.169 |                   29 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.515 |  0.174 |                    4 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.715 |  0.183 |                    2 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17750120162963867
[2m[36m(func pid=169620)[0m mae:  0.12928816676139832
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.269, 0.093, 0.326, 0.088, 0.194, 0.292, 0.143, 0.144, 0.116]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.17716576159000397
[2m[36m(func pid=183978)[0m mae:  0.1185741201043129
[2m[36m(func pid=183978)[0m rmse_per_class: [0.073, 0.242, 0.047, 0.33, 0.056, 0.37, 0.246, 0.152, 0.165, 0.091]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.5096 | Steps: 4 | Val loss: 0.3444 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3964 | Steps: 4 | Val loss: 0.3071 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.4399 | Steps: 4 | Val loss: 0.3389 | Batch size: 32 | lr: 0.0001 | Duration: 3.01s
[2m[36m(func pid=183330)[0m rmse: 0.1697981208562851
[2m[36m(func pid=183330)[0m mae:  0.11560281366109848
[2m[36m(func pid=183330)[0m rmse_per_class: [0.109, 0.266, 0.051, 0.332, 0.055, 0.191, 0.302, 0.138, 0.162, 0.092]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 3] | Train loss: 0.4404 | Steps: 4 | Val loss: 0.3065 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=177380)[0m rmse: 0.16811411082744598
[2m[36m(func pid=177380)[0m mae:  0.12150086462497711
[2m[36m(func pid=177380)[0m rmse_per_class: [0.109, 0.261, 0.066, 0.319, 0.066, 0.19, 0.276, 0.136, 0.143, 0.115]
[2m[36m(func pid=177380)[0m 
== Status ==
Current time: 2024-01-07 17:05:11 (running for 00:41:08.78)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.44  |  0.178 |                   66 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.396 |  0.168 |                   30 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.51  |  0.17  |                    5 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.677 |  0.177 |                    3 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17783237993717194
[2m[36m(func pid=169620)[0m mae:  0.12947218120098114
[2m[36m(func pid=169620)[0m rmse_per_class: [0.112, 0.27, 0.092, 0.326, 0.089, 0.194, 0.292, 0.143, 0.144, 0.117]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.16575577855110168
[2m[36m(func pid=183978)[0m mae:  0.10816262662410736
[2m[36m(func pid=183978)[0m rmse_per_class: [0.07, 0.265, 0.072, 0.272, 0.056, 0.185, 0.29, 0.208, 0.128, 0.113]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4739 | Steps: 4 | Val loss: 0.3054 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3997 | Steps: 4 | Val loss: 0.3069 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.4408 | Steps: 4 | Val loss: 0.3374 | Batch size: 32 | lr: 0.0001 | Duration: 2.83s
[2m[36m(func pid=183330)[0m rmse: 0.16189944744110107
[2m[36m(func pid=183330)[0m mae:  0.11060252040624619
[2m[36m(func pid=183330)[0m rmse_per_class: [0.114, 0.26, 0.049, 0.307, 0.055, 0.187, 0.266, 0.137, 0.152, 0.091]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 4] | Train loss: 0.3798 | Steps: 4 | Val loss: 0.3424 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=177380)[0m rmse: 0.1680023968219757
[2m[36m(func pid=177380)[0m mae:  0.12129680812358856
[2m[36m(func pid=177380)[0m rmse_per_class: [0.108, 0.262, 0.065, 0.32, 0.066, 0.19, 0.275, 0.137, 0.144, 0.113]
[2m[36m(func pid=177380)[0m 
== Status ==
Current time: 2024-01-07 17:05:16 (running for 00:41:13.90)
Memory usage on this node: 25.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.441 |  0.178 |                   67 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.4   |  0.168 |                   31 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.474 |  0.162 |                    6 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.44  |  0.166 |                    4 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.1779220551252365
[2m[36m(func pid=169620)[0m mae:  0.12939253449440002
[2m[36m(func pid=169620)[0m rmse_per_class: [0.112, 0.27, 0.094, 0.327, 0.088, 0.193, 0.292, 0.144, 0.142, 0.117]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.1555931717157364
[2m[36m(func pid=183978)[0m mae:  0.10482463985681534
[2m[36m(func pid=183978)[0m rmse_per_class: [0.064, 0.214, 0.059, 0.373, 0.112, 0.186, 0.21, 0.108, 0.137, 0.093]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.4352 | Steps: 4 | Val loss: 0.2861 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3990 | Steps: 4 | Val loss: 0.3066 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.4327 | Steps: 4 | Val loss: 0.3361 | Batch size: 32 | lr: 0.0001 | Duration: 2.86s
[2m[36m(func pid=183330)[0m rmse: 0.15687698125839233
[2m[36m(func pid=183330)[0m mae:  0.10869280248880386
[2m[36m(func pid=183330)[0m rmse_per_class: [0.112, 0.253, 0.048, 0.294, 0.055, 0.189, 0.248, 0.133, 0.145, 0.091]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 5] | Train loss: 0.4044 | Steps: 4 | Val loss: 0.2897 | Batch size: 32 | lr: 0.1 | Duration: 2.92s
[2m[36m(func pid=177380)[0m rmse: 0.16779479384422302
[2m[36m(func pid=177380)[0m mae:  0.12120477855205536
[2m[36m(func pid=177380)[0m rmse_per_class: [0.107, 0.261, 0.064, 0.32, 0.067, 0.19, 0.275, 0.138, 0.145, 0.111]
[2m[36m(func pid=177380)[0m 
== Status ==
Current time: 2024-01-07 17:05:22 (running for 00:41:19.14)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.433 |  0.177 |                   68 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.399 |  0.168 |                   32 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.435 |  0.157 |                    7 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.38  |  0.156 |                    5 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17702189087867737
[2m[36m(func pid=169620)[0m mae:  0.1287398338317871
[2m[36m(func pid=169620)[0m rmse_per_class: [0.112, 0.269, 0.089, 0.326, 0.089, 0.193, 0.29, 0.144, 0.143, 0.115]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.15097561478614807
[2m[36m(func pid=183978)[0m mae:  0.09416042268276215
[2m[36m(func pid=183978)[0m rmse_per_class: [0.096, 0.236, 0.032, 0.235, 0.093, 0.184, 0.217, 0.137, 0.125, 0.153]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.3968 | Steps: 4 | Val loss: 0.2903 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.4016 | Steps: 4 | Val loss: 0.3065 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.4311 | Steps: 4 | Val loss: 0.3367 | Batch size: 32 | lr: 0.0001 | Duration: 2.95s
[2m[36m(func pid=183330)[0m rmse: 0.15811865031719208
[2m[36m(func pid=183330)[0m mae:  0.11191902309656143
[2m[36m(func pid=183330)[0m rmse_per_class: [0.105, 0.249, 0.049, 0.295, 0.055, 0.188, 0.266, 0.126, 0.145, 0.104]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 6] | Train loss: 0.3900 | Steps: 4 | Val loss: 0.2805 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 17:05:27 (running for 00:41:24.37)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.433 |  0.177 |                   68 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.402 |  0.168 |                   33 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.397 |  0.158 |                    8 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.404 |  0.151 |                    6 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=177380)[0m rmse: 0.16773514449596405
[2m[36m(func pid=177380)[0m mae:  0.12112061679363251
[2m[36m(func pid=177380)[0m rmse_per_class: [0.106, 0.26, 0.064, 0.321, 0.068, 0.19, 0.274, 0.138, 0.144, 0.111]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=169620)[0m rmse: 0.17648610472679138
[2m[36m(func pid=169620)[0m mae:  0.12837804853916168
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.269, 0.087, 0.327, 0.087, 0.193, 0.29, 0.145, 0.142, 0.114]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.14564330875873566
[2m[36m(func pid=183978)[0m mae:  0.08878660947084427
[2m[36m(func pid=183978)[0m rmse_per_class: [0.075, 0.255, 0.034, 0.273, 0.052, 0.16, 0.202, 0.126, 0.161, 0.118]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.3991 | Steps: 4 | Val loss: 0.2998 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.4327 | Steps: 4 | Val loss: 0.3373 | Batch size: 32 | lr: 0.0001 | Duration: 3.04s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.3939 | Steps: 4 | Val loss: 0.3065 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=183330)[0m rmse: 0.16284950077533722
[2m[36m(func pid=183330)[0m mae:  0.1169854998588562
[2m[36m(func pid=183330)[0m rmse_per_class: [0.096, 0.249, 0.054, 0.304, 0.055, 0.183, 0.281, 0.124, 0.152, 0.131]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 7] | Train loss: 0.3402 | Steps: 4 | Val loss: 0.3123 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=169620)[0m rmse: 0.17718133330345154
[2m[36m(func pid=169620)[0m mae:  0.12894895672798157
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.269, 0.09, 0.33, 0.087, 0.193, 0.289, 0.144, 0.143, 0.116]
[2m[36m(func pid=169620)[0m 
== Status ==
Current time: 2024-01-07 17:05:32 (running for 00:41:29.95)
Memory usage on this node: 25.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.433 |  0.177 |                   70 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.402 |  0.168 |                   33 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.399 |  0.163 |                    9 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.39  |  0.146 |                    7 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=177380)[0m rmse: 0.1676940768957138
[2m[36m(func pid=177380)[0m mae:  0.12115738540887833
[2m[36m(func pid=177380)[0m rmse_per_class: [0.106, 0.26, 0.064, 0.323, 0.068, 0.19, 0.273, 0.137, 0.145, 0.112]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3816 | Steps: 4 | Val loss: 0.3076 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=183978)[0m rmse: 0.1522902250289917
[2m[36m(func pid=183978)[0m mae:  0.09685535728931427
[2m[36m(func pid=183978)[0m rmse_per_class: [0.062, 0.22, 0.026, 0.357, 0.051, 0.174, 0.214, 0.11, 0.219, 0.09]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.4370 | Steps: 4 | Val loss: 0.3360 | Batch size: 32 | lr: 0.0001 | Duration: 2.92s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.3957 | Steps: 4 | Val loss: 0.3063 | Batch size: 32 | lr: 0.001 | Duration: 3.06s
[2m[36m(func pid=183330)[0m rmse: 0.16931672394275665
[2m[36m(func pid=183330)[0m mae:  0.12139271199703217
[2m[36m(func pid=183330)[0m rmse_per_class: [0.088, 0.253, 0.07, 0.313, 0.056, 0.185, 0.279, 0.134, 0.179, 0.136]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 8] | Train loss: 0.3399 | Steps: 4 | Val loss: 0.3211 | Batch size: 32 | lr: 0.1 | Duration: 2.89s
== Status ==
Current time: 2024-01-07 17:05:38 (running for 00:41:35.19)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.437 |  0.177 |                   71 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.394 |  0.168 |                   34 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.382 |  0.169 |                   10 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.34  |  0.152 |                    8 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17668452858924866
[2m[36m(func pid=169620)[0m mae:  0.12861058115959167
[2m[36m(func pid=169620)[0m rmse_per_class: [0.109, 0.269, 0.088, 0.328, 0.086, 0.194, 0.289, 0.144, 0.143, 0.117]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.1673387587070465
[2m[36m(func pid=177380)[0m mae:  0.12093706429004669
[2m[36m(func pid=177380)[0m rmse_per_class: [0.103, 0.26, 0.066, 0.322, 0.068, 0.19, 0.273, 0.137, 0.144, 0.111]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3700 | Steps: 4 | Val loss: 0.3077 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=183978)[0m rmse: 0.17300720512866974
[2m[36m(func pid=183978)[0m mae:  0.10624714940786362
[2m[36m(func pid=183978)[0m rmse_per_class: [0.071, 0.262, 0.143, 0.293, 0.088, 0.17, 0.235, 0.202, 0.134, 0.131]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.4355 | Steps: 4 | Val loss: 0.3362 | Batch size: 32 | lr: 0.0001 | Duration: 2.89s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.3957 | Steps: 4 | Val loss: 0.3060 | Batch size: 32 | lr: 0.001 | Duration: 2.96s
[2m[36m(func pid=183330)[0m rmse: 0.1703978329896927
[2m[36m(func pid=183330)[0m mae:  0.12082073837518692
[2m[36m(func pid=183330)[0m rmse_per_class: [0.085, 0.263, 0.093, 0.316, 0.06, 0.183, 0.264, 0.144, 0.172, 0.123]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 9] | Train loss: 0.3259 | Steps: 4 | Val loss: 0.2765 | Batch size: 32 | lr: 0.1 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 17:05:43 (running for 00:41:40.52)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.436 |  0.177 |                   72 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.396 |  0.167 |                   35 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.37  |  0.17  |                   11 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.34  |  0.173 |                    9 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.1765725314617157
[2m[36m(func pid=169620)[0m mae:  0.1285109519958496
[2m[36m(func pid=169620)[0m rmse_per_class: [0.108, 0.27, 0.088, 0.328, 0.088, 0.194, 0.288, 0.142, 0.143, 0.117]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.167216494679451
[2m[36m(func pid=177380)[0m mae:  0.12085060775279999
[2m[36m(func pid=177380)[0m rmse_per_class: [0.103, 0.259, 0.067, 0.322, 0.068, 0.19, 0.273, 0.136, 0.144, 0.111]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.3632 | Steps: 4 | Val loss: 0.2973 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=183978)[0m rmse: 0.1426524817943573
[2m[36m(func pid=183978)[0m mae:  0.08724283427000046
[2m[36m(func pid=183978)[0m rmse_per_class: [0.062, 0.224, 0.034, 0.237, 0.097, 0.166, 0.216, 0.109, 0.13, 0.152]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.4322 | Steps: 4 | Val loss: 0.3347 | Batch size: 32 | lr: 0.0001 | Duration: 2.96s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.3968 | Steps: 4 | Val loss: 0.3049 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=183330)[0m rmse: 0.16324210166931152
[2m[36m(func pid=183330)[0m mae:  0.11484798043966293
[2m[36m(func pid=183330)[0m rmse_per_class: [0.082, 0.26, 0.09, 0.309, 0.069, 0.182, 0.248, 0.135, 0.154, 0.104]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 10] | Train loss: 0.3231 | Steps: 4 | Val loss: 0.2810 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
== Status ==
Current time: 2024-01-07 17:05:48 (running for 00:41:45.94)
Memory usage on this node: 25.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.432 |  0.177 |                   73 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.396 |  0.167 |                   36 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.363 |  0.163 |                   12 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.326 |  0.143 |                   10 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17685876786708832
[2m[36m(func pid=169620)[0m mae:  0.12871922552585602
[2m[36m(func pid=169620)[0m rmse_per_class: [0.11, 0.27, 0.09, 0.328, 0.085, 0.194, 0.288, 0.142, 0.144, 0.118]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16674843430519104
[2m[36m(func pid=177380)[0m mae:  0.12048757076263428
[2m[36m(func pid=177380)[0m rmse_per_class: [0.102, 0.258, 0.067, 0.321, 0.067, 0.189, 0.273, 0.135, 0.144, 0.11]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.3678 | Steps: 4 | Val loss: 0.2884 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=183978)[0m rmse: 0.13995826244354248
[2m[36m(func pid=183978)[0m mae:  0.08667721599340439
[2m[36m(func pid=183978)[0m rmse_per_class: [0.069, 0.261, 0.028, 0.284, 0.054, 0.169, 0.202, 0.119, 0.129, 0.085]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.4286 | Steps: 4 | Val loss: 0.3331 | Batch size: 32 | lr: 0.0001 | Duration: 3.00s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3940 | Steps: 4 | Val loss: 0.3054 | Batch size: 32 | lr: 0.001 | Duration: 2.89s
[2m[36m(func pid=183330)[0m rmse: 0.15741726756095886
[2m[36m(func pid=183330)[0m mae:  0.11025966703891754
[2m[36m(func pid=183330)[0m rmse_per_class: [0.083, 0.252, 0.082, 0.301, 0.078, 0.179, 0.239, 0.12, 0.137, 0.102]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 11] | Train loss: 0.3169 | Steps: 4 | Val loss: 0.2926 | Batch size: 32 | lr: 0.1 | Duration: 2.93s
== Status ==
Current time: 2024-01-07 17:05:54 (running for 00:41:51.18)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=20
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 16.0/72 CPUs, 4.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (4 RUNNING, 20 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00020 | RUNNING    | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.429 |  0.176 |                   74 |
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.397 |  0.167 |                   37 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.368 |  0.157 |                   13 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.323 |  0.14  |                   11 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.1763843297958374
[2m[36m(func pid=169620)[0m mae:  0.1283189356327057
[2m[36m(func pid=169620)[0m rmse_per_class: [0.109, 0.27, 0.091, 0.327, 0.086, 0.193, 0.288, 0.141, 0.144, 0.114]
[2m[36m(func pid=169620)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.1671895980834961
[2m[36m(func pid=177380)[0m mae:  0.12081718444824219
[2m[36m(func pid=177380)[0m rmse_per_class: [0.103, 0.258, 0.07, 0.321, 0.067, 0.189, 0.273, 0.134, 0.144, 0.112]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.3493 | Steps: 4 | Val loss: 0.2831 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=183978)[0m rmse: 0.1550327092409134
[2m[36m(func pid=183978)[0m mae:  0.096763014793396
[2m[36m(func pid=183978)[0m rmse_per_class: [0.099, 0.218, 0.027, 0.299, 0.049, 0.176, 0.214, 0.113, 0.201, 0.156]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=169620)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.4284 | Steps: 4 | Val loss: 0.3317 | Batch size: 32 | lr: 0.0001 | Duration: 2.84s
[2m[36m(func pid=183330)[0m rmse: 0.15480560064315796
[2m[36m(func pid=183330)[0m mae:  0.10849924385547638
[2m[36m(func pid=183330)[0m rmse_per_class: [0.086, 0.246, 0.063, 0.296, 0.083, 0.178, 0.237, 0.118, 0.134, 0.108]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3880 | Steps: 4 | Val loss: 0.3051 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 12] | Train loss: 0.2827 | Steps: 4 | Val loss: 0.2647 | Batch size: 32 | lr: 0.1 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 17:05:59 (running for 00:41:56.53)
Memory usage on this node: 25.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.394 |  0.167 |                   38 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.349 |  0.155 |                   14 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.317 |  0.155 |                   12 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=169620)[0m rmse: 0.17612949013710022
[2m[36m(func pid=169620)[0m mae:  0.12815125286579132
[2m[36m(func pid=169620)[0m rmse_per_class: [0.111, 0.269, 0.088, 0.326, 0.086, 0.193, 0.29, 0.142, 0.143, 0.114]
[2m[36m(func pid=177380)[0m rmse: 0.16710004210472107
[2m[36m(func pid=177380)[0m mae:  0.12069721519947052
[2m[36m(func pid=177380)[0m rmse_per_class: [0.102, 0.259, 0.07, 0.32, 0.067, 0.189, 0.274, 0.133, 0.144, 0.112]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.3564 | Steps: 4 | Val loss: 0.2803 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=183978)[0m rmse: 0.13360321521759033
[2m[36m(func pid=183978)[0m mae:  0.08186451345682144
[2m[36m(func pid=183978)[0m rmse_per_class: [0.062, 0.221, 0.025, 0.234, 0.051, 0.164, 0.22, 0.143, 0.128, 0.089]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.15358704328536987
[2m[36m(func pid=183330)[0m mae:  0.10777817666530609
[2m[36m(func pid=183330)[0m rmse_per_class: [0.083, 0.242, 0.052, 0.293, 0.084, 0.177, 0.24, 0.117, 0.134, 0.113]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.3886 | Steps: 4 | Val loss: 0.3044 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 13] | Train loss: 0.3044 | Steps: 4 | Val loss: 0.2711 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
== Status ==
Current time: 2024-01-07 17:06:06 (running for 00:42:03.25)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.389 |  0.167 |                   40 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.356 |  0.154 |                   15 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.283 |  0.134 |                   13 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=177380)[0m rmse: 0.16683098673820496
[2m[36m(func pid=177380)[0m mae:  0.12042354047298431
[2m[36m(func pid=177380)[0m rmse_per_class: [0.105, 0.259, 0.069, 0.318, 0.066, 0.189, 0.273, 0.133, 0.144, 0.113]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.3494 | Steps: 4 | Val loss: 0.2761 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=183978)[0m rmse: 0.14474275708198547
[2m[36m(func pid=183978)[0m mae:  0.08889515697956085
[2m[36m(func pid=183978)[0m rmse_per_class: [0.067, 0.209, 0.024, 0.265, 0.09, 0.169, 0.225, 0.145, 0.122, 0.13]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.15095387399196625
[2m[36m(func pid=183330)[0m mae:  0.10594823211431503
[2m[36m(func pid=183330)[0m rmse_per_class: [0.079, 0.24, 0.046, 0.278, 0.075, 0.176, 0.246, 0.115, 0.146, 0.109]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.3829 | Steps: 4 | Val loss: 0.3034 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 14] | Train loss: 0.2867 | Steps: 4 | Val loss: 0.2886 | Batch size: 32 | lr: 0.1 | Duration: 3.24s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.3356 | Steps: 4 | Val loss: 0.2751 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 17:06:11 (running for 00:42:08.80)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.383 |  0.166 |                   41 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.349 |  0.151 |                   16 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.304 |  0.145 |                   14 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=177380)[0m rmse: 0.1661752462387085
[2m[36m(func pid=177380)[0m mae:  0.11979101598262787
[2m[36m(func pid=177380)[0m rmse_per_class: [0.102, 0.259, 0.069, 0.317, 0.066, 0.188, 0.272, 0.132, 0.143, 0.113]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.15042556822299957
[2m[36m(func pid=183978)[0m mae:  0.09503337740898132
[2m[36m(func pid=183978)[0m rmse_per_class: [0.101, 0.218, 0.025, 0.308, 0.068, 0.182, 0.207, 0.12, 0.168, 0.107]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.15014955401420593
[2m[36m(func pid=183330)[0m mae:  0.10529311001300812
[2m[36m(func pid=183330)[0m rmse_per_class: [0.079, 0.242, 0.045, 0.263, 0.064, 0.175, 0.252, 0.114, 0.161, 0.105]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.3843 | Steps: 4 | Val loss: 0.3036 | Batch size: 32 | lr: 0.001 | Duration: 3.17s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 15] | Train loss: 0.2819 | Steps: 4 | Val loss: 0.2619 | Batch size: 32 | lr: 0.1 | Duration: 2.96s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3443 | Steps: 4 | Val loss: 0.2747 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
== Status ==
Current time: 2024-01-07 17:06:17 (running for 00:42:14.39)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.384 |  0.167 |                   42 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.336 |  0.15  |                   17 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.287 |  0.15  |                   15 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=177380)[0m rmse: 0.16650265455245972
[2m[36m(func pid=177380)[0m mae:  0.11998176574707031
[2m[36m(func pid=177380)[0m rmse_per_class: [0.104, 0.259, 0.069, 0.316, 0.066, 0.188, 0.272, 0.131, 0.143, 0.117]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.1363646239042282
[2m[36m(func pid=183978)[0m mae:  0.08344628661870956
[2m[36m(func pid=183978)[0m rmse_per_class: [0.061, 0.224, 0.038, 0.237, 0.056, 0.164, 0.206, 0.108, 0.167, 0.102]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.14950010180473328
[2m[36m(func pid=183330)[0m mae:  0.1045914888381958
[2m[36m(func pid=183330)[0m rmse_per_class: [0.077, 0.243, 0.045, 0.258, 0.06, 0.176, 0.252, 0.113, 0.165, 0.106]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.3870 | Steps: 4 | Val loss: 0.3017 | Batch size: 32 | lr: 0.001 | Duration: 3.14s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 16] | Train loss: 0.2846 | Steps: 4 | Val loss: 0.2730 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3436 | Steps: 4 | Val loss: 0.2763 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
== Status ==
Current time: 2024-01-07 17:06:22 (running for 00:42:19.98)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.387 |  0.166 |                   43 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.344 |  0.15  |                   18 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.282 |  0.136 |                   16 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=177380)[0m rmse: 0.16553369164466858
[2m[36m(func pid=177380)[0m mae:  0.11912500858306885
[2m[36m(func pid=177380)[0m rmse_per_class: [0.103, 0.258, 0.068, 0.315, 0.065, 0.188, 0.269, 0.131, 0.142, 0.117]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.14521172642707825
[2m[36m(func pid=183978)[0m mae:  0.09005320072174072
[2m[36m(func pid=183978)[0m rmse_per_class: [0.059, 0.214, 0.026, 0.257, 0.064, 0.165, 0.239, 0.175, 0.171, 0.082]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.15107400715351105
[2m[36m(func pid=183330)[0m mae:  0.10547935962677002
[2m[36m(func pid=183330)[0m rmse_per_class: [0.076, 0.241, 0.048, 0.272, 0.058, 0.175, 0.246, 0.116, 0.151, 0.128]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3914 | Steps: 4 | Val loss: 0.3014 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 17] | Train loss: 0.3026 | Steps: 4 | Val loss: 0.2649 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.3235 | Steps: 4 | Val loss: 0.2769 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
== Status ==
Current time: 2024-01-07 17:06:28 (running for 00:42:25.62)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.391 |  0.165 |                   44 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.344 |  0.151 |                   19 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.285 |  0.145 |                   17 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=177380)[0m rmse: 0.1651972085237503
[2m[36m(func pid=177380)[0m mae:  0.11894264072179794
[2m[36m(func pid=177380)[0m rmse_per_class: [0.102, 0.258, 0.067, 0.315, 0.065, 0.187, 0.268, 0.131, 0.143, 0.115]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.13701343536376953
[2m[36m(func pid=183978)[0m mae:  0.08577791601419449
[2m[36m(func pid=183978)[0m rmse_per_class: [0.073, 0.205, 0.023, 0.245, 0.072, 0.172, 0.223, 0.115, 0.134, 0.108]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.15123140811920166
[2m[36m(func pid=183330)[0m mae:  0.10519397258758545
[2m[36m(func pid=183330)[0m rmse_per_class: [0.087, 0.236, 0.056, 0.289, 0.056, 0.173, 0.237, 0.116, 0.137, 0.124]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.3929 | Steps: 4 | Val loss: 0.3003 | Batch size: 32 | lr: 0.001 | Duration: 2.98s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 18] | Train loss: 0.3126 | Steps: 4 | Val loss: 0.2681 | Batch size: 32 | lr: 0.1 | Duration: 2.87s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3220 | Steps: 4 | Val loss: 0.2730 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 17:06:34 (running for 00:42:31.23)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.391 |  0.165 |                   44 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.324 |  0.151 |                   20 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.313 |  0.139 |                   19 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183978)[0m rmse: 0.13896358013153076
[2m[36m(func pid=183978)[0m mae:  0.08278293907642365
[2m[36m(func pid=183978)[0m rmse_per_class: [0.068, 0.212, 0.031, 0.248, 0.065, 0.168, 0.205, 0.11, 0.12, 0.163]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16461439430713654
[2m[36m(func pid=177380)[0m mae:  0.11845624446868896
[2m[36m(func pid=177380)[0m rmse_per_class: [0.1, 0.258, 0.065, 0.315, 0.064, 0.188, 0.267, 0.132, 0.143, 0.115]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.14828911423683167
[2m[36m(func pid=183330)[0m mae:  0.10217753797769547
[2m[36m(func pid=183330)[0m rmse_per_class: [0.09, 0.235, 0.062, 0.286, 0.056, 0.172, 0.225, 0.114, 0.133, 0.11]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 19] | Train loss: 0.2530 | Steps: 4 | Val loss: 0.3597 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.3883 | Steps: 4 | Val loss: 0.3000 | Batch size: 32 | lr: 0.001 | Duration: 3.05s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3269 | Steps: 4 | Val loss: 0.2708 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
== Status ==
Current time: 2024-01-07 17:06:39 (running for 00:42:36.75)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.388 |  0.165 |                   46 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.322 |  0.148 |                   21 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.313 |  0.139 |                   19 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=177380)[0m rmse: 0.1645403802394867
[2m[36m(func pid=177380)[0m mae:  0.11828313767910004
[2m[36m(func pid=177380)[0m rmse_per_class: [0.099, 0.257, 0.067, 0.315, 0.063, 0.188, 0.265, 0.132, 0.142, 0.116]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.16730758547782898
[2m[36m(func pid=183978)[0m mae:  0.10818697512149811
[2m[36m(func pid=183978)[0m rmse_per_class: [0.06, 0.222, 0.026, 0.375, 0.049, 0.172, 0.235, 0.303, 0.145, 0.087]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.1464281529188156
[2m[36m(func pid=183330)[0m mae:  0.10082228481769562
[2m[36m(func pid=183330)[0m rmse_per_class: [0.085, 0.234, 0.057, 0.282, 0.058, 0.172, 0.223, 0.114, 0.136, 0.103]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.3862 | Steps: 4 | Val loss: 0.2996 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 20] | Train loss: 0.3109 | Steps: 4 | Val loss: 0.2924 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.3229 | Steps: 4 | Val loss: 0.2639 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 17:06:45 (running for 00:42:42.21)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.388 |  0.165 |                   46 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.327 |  0.146 |                   22 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.311 |  0.153 |                   21 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=177380)[0m rmse: 0.16415010392665863
[2m[36m(func pid=177380)[0m mae:  0.11789365112781525
[2m[36m(func pid=177380)[0m rmse_per_class: [0.099, 0.257, 0.067, 0.315, 0.063, 0.187, 0.265, 0.132, 0.144, 0.111]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.15289895236492157
[2m[36m(func pid=183978)[0m mae:  0.0952986478805542
[2m[36m(func pid=183978)[0m rmse_per_class: [0.08, 0.221, 0.025, 0.306, 0.054, 0.185, 0.222, 0.118, 0.208, 0.11]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.14131776988506317
[2m[36m(func pid=183330)[0m mae:  0.09695513546466827
[2m[36m(func pid=183330)[0m rmse_per_class: [0.071, 0.229, 0.046, 0.265, 0.059, 0.171, 0.224, 0.116, 0.136, 0.096]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 21] | Train loss: 0.3008 | Steps: 4 | Val loss: 0.2793 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.3864 | Steps: 4 | Val loss: 0.3004 | Batch size: 32 | lr: 0.001 | Duration: 3.16s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.3199 | Steps: 4 | Val loss: 0.2619 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
== Status ==
Current time: 2024-01-07 17:06:50 (running for 00:42:47.90)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.386 |  0.164 |                   47 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.323 |  0.141 |                   23 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.301 |  0.145 |                   22 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183978)[0m rmse: 0.14497487246990204
[2m[36m(func pid=183978)[0m mae:  0.08944545686244965
[2m[36m(func pid=183978)[0m rmse_per_class: [0.06, 0.218, 0.027, 0.272, 0.07, 0.171, 0.223, 0.125, 0.142, 0.142]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16464634239673615
[2m[36m(func pid=177380)[0m mae:  0.11832402646541595
[2m[36m(func pid=177380)[0m rmse_per_class: [0.098, 0.257, 0.069, 0.314, 0.063, 0.187, 0.267, 0.132, 0.147, 0.112]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.1404532641172409
[2m[36m(func pid=183330)[0m mae:  0.09639544785022736
[2m[36m(func pid=183330)[0m rmse_per_class: [0.068, 0.227, 0.041, 0.252, 0.062, 0.169, 0.234, 0.116, 0.136, 0.098]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 22] | Train loss: 0.2767 | Steps: 4 | Val loss: 0.2903 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.3898 | Steps: 4 | Val loss: 0.3001 | Batch size: 32 | lr: 0.001 | Duration: 3.07s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.3320 | Steps: 4 | Val loss: 0.2623 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 17:06:56 (running for 00:42:53.32)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.386 |  0.165 |                   48 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.32  |  0.14  |                   24 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.277 |  0.151 |                   23 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183978)[0m rmse: 0.15086045861244202
[2m[36m(func pid=183978)[0m mae:  0.09246324002742767
[2m[36m(func pid=183978)[0m rmse_per_class: [0.062, 0.221, 0.069, 0.313, 0.092, 0.2, 0.216, 0.124, 0.133, 0.079]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16464123129844666
[2m[36m(func pid=177380)[0m mae:  0.11833801120519638
[2m[36m(func pid=177380)[0m rmse_per_class: [0.1, 0.257, 0.069, 0.312, 0.063, 0.187, 0.267, 0.131, 0.147, 0.114]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.14118359982967377
[2m[36m(func pid=183330)[0m mae:  0.09666241705417633
[2m[36m(func pid=183330)[0m rmse_per_class: [0.068, 0.229, 0.039, 0.245, 0.064, 0.17, 0.239, 0.116, 0.136, 0.107]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 23] | Train loss: 0.2951 | Steps: 4 | Val loss: 0.2736 | Batch size: 32 | lr: 0.1 | Duration: 2.94s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.3756 | Steps: 4 | Val loss: 0.2995 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.3132 | Steps: 4 | Val loss: 0.2622 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 17:07:01 (running for 00:42:58.62)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.39  |  0.165 |                   49 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.332 |  0.141 |                   25 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.295 |  0.143 |                   24 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183978)[0m rmse: 0.14322681725025177
[2m[36m(func pid=183978)[0m mae:  0.08797462284564972
[2m[36m(func pid=183978)[0m rmse_per_class: [0.061, 0.213, 0.028, 0.269, 0.064, 0.165, 0.227, 0.161, 0.165, 0.08]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16450068354606628
[2m[36m(func pid=177380)[0m mae:  0.11820181459188461
[2m[36m(func pid=177380)[0m rmse_per_class: [0.099, 0.257, 0.068, 0.31, 0.063, 0.187, 0.267, 0.131, 0.147, 0.117]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.14090700447559357
[2m[36m(func pid=183330)[0m mae:  0.09666559845209122
[2m[36m(func pid=183330)[0m rmse_per_class: [0.067, 0.226, 0.039, 0.247, 0.064, 0.168, 0.241, 0.112, 0.137, 0.107]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 24] | Train loss: 0.2735 | Steps: 4 | Val loss: 0.2645 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.3807 | Steps: 4 | Val loss: 0.2989 | Batch size: 32 | lr: 0.001 | Duration: 3.21s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.3190 | Steps: 4 | Val loss: 0.2611 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
== Status ==
Current time: 2024-01-07 17:07:07 (running for 00:43:04.19)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.376 |  0.165 |                   50 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.313 |  0.141 |                   26 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.273 |  0.138 |                   25 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183978)[0m rmse: 0.138249009847641
[2m[36m(func pid=183978)[0m mae:  0.0843132883310318
[2m[36m(func pid=183978)[0m rmse_per_class: [0.074, 0.209, 0.03, 0.248, 0.051, 0.163, 0.217, 0.112, 0.151, 0.129]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.1397523730993271
[2m[36m(func pid=183330)[0m mae:  0.09582717716693878
[2m[36m(func pid=183330)[0m rmse_per_class: [0.067, 0.222, 0.039, 0.259, 0.061, 0.169, 0.233, 0.112, 0.136, 0.099]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.1641583889722824
[2m[36m(func pid=177380)[0m mae:  0.11798256635665894
[2m[36m(func pid=177380)[0m rmse_per_class: [0.1, 0.256, 0.067, 0.308, 0.064, 0.186, 0.268, 0.13, 0.149, 0.114]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 25] | Train loss: 0.2546 | Steps: 4 | Val loss: 0.2922 | Batch size: 32 | lr: 0.1 | Duration: 3.18s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.3135 | Steps: 4 | Val loss: 0.2631 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.3861 | Steps: 4 | Val loss: 0.2985 | Batch size: 32 | lr: 0.001 | Duration: 3.20s
== Status ==
Current time: 2024-01-07 17:07:12 (running for 00:43:09.83)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.381 |  0.164 |                   51 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.319 |  0.14  |                   27 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.255 |  0.151 |                   26 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183978)[0m rmse: 0.15089187026023865
[2m[36m(func pid=183978)[0m mae:  0.09264445304870605
[2m[36m(func pid=183978)[0m rmse_per_class: [0.098, 0.22, 0.031, 0.307, 0.053, 0.188, 0.21, 0.114, 0.152, 0.136]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.1403522789478302
[2m[36m(func pid=183330)[0m mae:  0.09612634032964706
[2m[36m(func pid=183330)[0m rmse_per_class: [0.067, 0.221, 0.039, 0.277, 0.062, 0.17, 0.224, 0.113, 0.137, 0.093]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16386732459068298
[2m[36m(func pid=177380)[0m mae:  0.11776826530694962
[2m[36m(func pid=177380)[0m rmse_per_class: [0.099, 0.256, 0.068, 0.309, 0.064, 0.186, 0.266, 0.129, 0.15, 0.112]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 26] | Train loss: 0.2683 | Steps: 4 | Val loss: 0.2739 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.3148 | Steps: 4 | Val loss: 0.2686 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.3857 | Steps: 4 | Val loss: 0.2976 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=183978)[0m rmse: 0.14188824594020844
[2m[36m(func pid=183978)[0m mae:  0.08614010363817215
[2m[36m(func pid=183978)[0m rmse_per_class: [0.059, 0.21, 0.039, 0.283, 0.063, 0.171, 0.215, 0.135, 0.137, 0.106]
== Status ==
Current time: 2024-01-07 17:07:18 (running for 00:43:15.49)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.386 |  0.164 |                   52 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.314 |  0.14  |                   28 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.268 |  0.142 |                   27 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.14413654804229736
[2m[36m(func pid=183330)[0m mae:  0.09860099852085114
[2m[36m(func pid=183330)[0m rmse_per_class: [0.067, 0.227, 0.04, 0.286, 0.062, 0.169, 0.222, 0.119, 0.159, 0.091]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16344164311885834
[2m[36m(func pid=177380)[0m mae:  0.11744950711727142
[2m[36m(func pid=177380)[0m rmse_per_class: [0.099, 0.256, 0.065, 0.308, 0.063, 0.186, 0.266, 0.129, 0.149, 0.113]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 27] | Train loss: 0.2618 | Steps: 4 | Val loss: 0.2654 | Batch size: 32 | lr: 0.1 | Duration: 3.12s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.3191 | Steps: 4 | Val loss: 0.2672 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.3838 | Steps: 4 | Val loss: 0.2984 | Batch size: 32 | lr: 0.001 | Duration: 3.17s
== Status ==
Current time: 2024-01-07 17:07:23 (running for 00:43:21.10)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.386 |  0.163 |                   53 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.315 |  0.144 |                   29 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.262 |  0.14  |                   28 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183978)[0m rmse: 0.13965557515621185
[2m[36m(func pid=183978)[0m mae:  0.08552016317844391
[2m[36m(func pid=183978)[0m rmse_per_class: [0.059, 0.203, 0.028, 0.244, 0.072, 0.169, 0.232, 0.128, 0.126, 0.135]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.14340034127235413
[2m[36m(func pid=183330)[0m mae:  0.09749704599380493
[2m[36m(func pid=183330)[0m rmse_per_class: [0.066, 0.232, 0.04, 0.276, 0.06, 0.17, 0.22, 0.122, 0.157, 0.091]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16389048099517822
[2m[36m(func pid=177380)[0m mae:  0.11786504089832306
[2m[36m(func pid=177380)[0m rmse_per_class: [0.1, 0.256, 0.065, 0.309, 0.064, 0.186, 0.266, 0.128, 0.149, 0.115]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.3157 | Steps: 4 | Val loss: 0.2636 | Batch size: 32 | lr: 0.01 | Duration: 2.82s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 28] | Train loss: 0.2521 | Steps: 4 | Val loss: 0.2702 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.3785 | Steps: 4 | Val loss: 0.2990 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
== Status ==
Current time: 2024-01-07 17:07:29 (running for 00:43:26.54)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.384 |  0.164 |                   54 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.319 |  0.143 |                   30 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.252 |  0.145 |                   29 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183978)[0m rmse: 0.14535827934741974
[2m[36m(func pid=183978)[0m mae:  0.08771507441997528
[2m[36m(func pid=183978)[0m rmse_per_class: [0.071, 0.222, 0.028, 0.249, 0.073, 0.17, 0.205, 0.109, 0.147, 0.179]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.14095699787139893
[2m[36m(func pid=183330)[0m mae:  0.09550890326499939
[2m[36m(func pid=183330)[0m rmse_per_class: [0.065, 0.23, 0.039, 0.267, 0.057, 0.168, 0.218, 0.12, 0.145, 0.1]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16427408158779144
[2m[36m(func pid=177380)[0m mae:  0.11816557496786118
[2m[36m(func pid=177380)[0m rmse_per_class: [0.098, 0.256, 0.066, 0.311, 0.064, 0.186, 0.265, 0.129, 0.151, 0.117]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.3095 | Steps: 4 | Val loss: 0.2609 | Batch size: 32 | lr: 0.01 | Duration: 3.06s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 29] | Train loss: 0.2566 | Steps: 4 | Val loss: 0.2770 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.3820 | Steps: 4 | Val loss: 0.2975 | Batch size: 32 | lr: 0.001 | Duration: 3.15s
== Status ==
Current time: 2024-01-07 17:07:35 (running for 00:43:32.14)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.379 |  0.164 |                   55 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.31  |  0.139 |                   32 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.252 |  0.145 |                   29 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13912461698055267
[2m[36m(func pid=183330)[0m mae:  0.09405595064163208
[2m[36m(func pid=183330)[0m rmse_per_class: [0.065, 0.228, 0.038, 0.26, 0.058, 0.166, 0.215, 0.114, 0.143, 0.104]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.1411975771188736
[2m[36m(func pid=183978)[0m mae:  0.08570658415555954
[2m[36m(func pid=183978)[0m rmse_per_class: [0.067, 0.218, 0.03, 0.274, 0.06, 0.172, 0.219, 0.125, 0.161, 0.087]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16357210278511047
[2m[36m(func pid=177380)[0m mae:  0.11761150509119034
[2m[36m(func pid=177380)[0m rmse_per_class: [0.101, 0.255, 0.064, 0.308, 0.063, 0.186, 0.264, 0.128, 0.152, 0.116]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.3087 | Steps: 4 | Val loss: 0.2557 | Batch size: 32 | lr: 0.01 | Duration: 3.16s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 30] | Train loss: 0.2552 | Steps: 4 | Val loss: 0.2608 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.3799 | Steps: 4 | Val loss: 0.2956 | Batch size: 32 | lr: 0.001 | Duration: 3.03s
[2m[36m(func pid=183330)[0m rmse: 0.13567274808883667
== Status ==
Current time: 2024-01-07 17:07:40 (running for 00:43:37.65)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.382 |  0.164 |                   56 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.309 |  0.136 |                   33 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.257 |  0.141 |                   30 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)

[2m[36m(func pid=183330)[0m mae:  0.0914292186498642

[2m[36m(func pid=183330)[0m rmse_per_class: [0.064, 0.226, 0.036, 0.244, 0.058, 0.166, 0.215, 0.11, 0.136, 0.1]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.13153138756752014
[2m[36m(func pid=183978)[0m mae:  0.08144810050725937
[2m[36m(func pid=183978)[0m rmse_per_class: [0.059, 0.204, 0.032, 0.243, 0.052, 0.163, 0.222, 0.122, 0.14, 0.078]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16225700080394745
[2m[36m(func pid=177380)[0m mae:  0.11654438823461533
[2m[36m(func pid=177380)[0m rmse_per_class: [0.099, 0.254, 0.062, 0.307, 0.063, 0.185, 0.263, 0.128, 0.15, 0.112]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2989 | Steps: 4 | Val loss: 0.2581 | Batch size: 32 | lr: 0.01 | Duration: 3.08s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 31] | Train loss: 0.2731 | Steps: 4 | Val loss: 0.2621 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.3801 | Steps: 4 | Val loss: 0.2946 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 17:07:46 (running for 00:43:43.28)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.38  |  0.162 |                   57 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.299 |  0.138 |                   34 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.255 |  0.132 |                   31 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13783451914787292
[2m[36m(func pid=183330)[0m mae:  0.09309284389019012
[2m[36m(func pid=183330)[0m rmse_per_class: [0.063, 0.225, 0.04, 0.244, 0.065, 0.166, 0.221, 0.109, 0.132, 0.112]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.1392415463924408
[2m[36m(func pid=183978)[0m mae:  0.08406923711299896
[2m[36m(func pid=183978)[0m rmse_per_class: [0.082, 0.209, 0.028, 0.241, 0.061, 0.167, 0.227, 0.123, 0.13, 0.124]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.1616794914007187
[2m[36m(func pid=177380)[0m mae:  0.1159718781709671
[2m[36m(func pid=177380)[0m rmse_per_class: [0.099, 0.254, 0.064, 0.305, 0.063, 0.185, 0.261, 0.128, 0.148, 0.111]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2990 | Steps: 4 | Val loss: 0.2584 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 32] | Train loss: 0.2554 | Steps: 4 | Val loss: 0.2908 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.3846 | Steps: 4 | Val loss: 0.2936 | Batch size: 32 | lr: 0.001 | Duration: 3.21s
== Status ==
Current time: 2024-01-07 17:07:51 (running for 00:43:48.69)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.38  |  0.162 |                   58 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.299 |  0.138 |                   35 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.273 |  0.139 |                   32 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13803300261497498
[2m[36m(func pid=183330)[0m mae:  0.09333380311727524
[2m[36m(func pid=183330)[0m rmse_per_class: [0.063, 0.22, 0.038, 0.246, 0.067, 0.166, 0.226, 0.11, 0.131, 0.113]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.1552487164735794
[2m[36m(func pid=183978)[0m mae:  0.09368941932916641
[2m[36m(func pid=183978)[0m rmse_per_class: [0.091, 0.222, 0.025, 0.296, 0.099, 0.18, 0.224, 0.117, 0.139, 0.159]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16112565994262695
[2m[36m(func pid=177380)[0m mae:  0.11540757119655609
[2m[36m(func pid=177380)[0m rmse_per_class: [0.097, 0.254, 0.063, 0.304, 0.063, 0.185, 0.261, 0.128, 0.146, 0.111]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2947 | Steps: 4 | Val loss: 0.2606 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 33] | Train loss: 0.2461 | Steps: 4 | Val loss: 0.2747 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.3777 | Steps: 4 | Val loss: 0.2942 | Batch size: 32 | lr: 0.001 | Duration: 3.17s
== Status ==
Current time: 2024-01-07 17:07:56 (running for 00:43:54.01)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.385 |  0.161 |                   59 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.295 |  0.139 |                   36 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.255 |  0.155 |                   33 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13935235142707825
[2m[36m(func pid=183330)[0m mae:  0.09436921030282974
[2m[36m(func pid=183330)[0m rmse_per_class: [0.064, 0.22, 0.042, 0.256, 0.067, 0.165, 0.227, 0.111, 0.133, 0.108]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.1424780786037445
[2m[36m(func pid=183978)[0m mae:  0.08667074888944626
[2m[36m(func pid=183978)[0m rmse_per_class: [0.058, 0.234, 0.026, 0.285, 0.056, 0.171, 0.215, 0.133, 0.14, 0.108]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.1614084541797638
[2m[36m(func pid=177380)[0m mae:  0.11571844667196274
[2m[36m(func pid=177380)[0m rmse_per_class: [0.097, 0.254, 0.065, 0.302, 0.064, 0.185, 0.264, 0.127, 0.147, 0.11]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2919 | Steps: 4 | Val loss: 0.2605 | Batch size: 32 | lr: 0.01 | Duration: 2.87s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 34] | Train loss: 0.2574 | Steps: 4 | Val loss: 0.2680 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.3806 | Steps: 4 | Val loss: 0.2935 | Batch size: 32 | lr: 0.001 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 17:08:02 (running for 00:43:59.20)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.378 |  0.161 |                   60 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.292 |  0.139 |                   37 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.246 |  0.142 |                   34 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13900519907474518
[2m[36m(func pid=183330)[0m mae:  0.09401306509971619
[2m[36m(func pid=183330)[0m rmse_per_class: [0.065, 0.223, 0.041, 0.258, 0.064, 0.165, 0.219, 0.113, 0.142, 0.101]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.14263394474983215
[2m[36m(func pid=183978)[0m mae:  0.08762012422084808
[2m[36m(func pid=183978)[0m rmse_per_class: [0.066, 0.218, 0.027, 0.245, 0.05, 0.192, 0.229, 0.111, 0.18, 0.109]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16081523895263672
[2m[36m(func pid=177380)[0m mae:  0.11521278321743011
[2m[36m(func pid=177380)[0m rmse_per_class: [0.096, 0.253, 0.064, 0.301, 0.064, 0.185, 0.263, 0.127, 0.146, 0.109]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.3004 | Steps: 4 | Val loss: 0.2575 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 35] | Train loss: 0.2535 | Steps: 4 | Val loss: 0.2723 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.3800 | Steps: 4 | Val loss: 0.2939 | Batch size: 32 | lr: 0.001 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 17:08:07 (running for 00:44:04.69)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.381 |  0.161 |                   61 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.3   |  0.137 |                   38 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.257 |  0.143 |                   35 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.1368207037448883
[2m[36m(func pid=183330)[0m mae:  0.09196464717388153
[2m[36m(func pid=183330)[0m rmse_per_class: [0.065, 0.226, 0.037, 0.245, 0.059, 0.165, 0.218, 0.115, 0.145, 0.093]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.1475425809621811
[2m[36m(func pid=183978)[0m mae:  0.08893956989049911
[2m[36m(func pid=183978)[0m rmse_per_class: [0.095, 0.227, 0.026, 0.258, 0.068, 0.169, 0.212, 0.113, 0.15, 0.157]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16123202443122864
[2m[36m(func pid=177380)[0m mae:  0.11556495726108551
[2m[36m(func pid=177380)[0m rmse_per_class: [0.095, 0.253, 0.064, 0.302, 0.064, 0.185, 0.264, 0.128, 0.145, 0.111]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.3007 | Steps: 4 | Val loss: 0.2573 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 36] | Train loss: 0.2611 | Steps: 4 | Val loss: 0.2823 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.3746 | Steps: 4 | Val loss: 0.2941 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
== Status ==
Current time: 2024-01-07 17:08:12 (running for 00:44:10.03)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.38  |  0.161 |                   62 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.301 |  0.137 |                   39 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.254 |  0.148 |                   36 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13687220215797424
[2m[36m(func pid=183330)[0m mae:  0.0920783132314682
[2m[36m(func pid=183330)[0m rmse_per_class: [0.066, 0.224, 0.036, 0.243, 0.057, 0.164, 0.224, 0.114, 0.144, 0.097]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.14519241452217102
[2m[36m(func pid=183978)[0m mae:  0.08871325105428696
[2m[36m(func pid=183978)[0m rmse_per_class: [0.061, 0.269, 0.024, 0.285, 0.074, 0.177, 0.229, 0.122, 0.121, 0.091]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.1612391471862793
[2m[36m(func pid=177380)[0m mae:  0.11561913788318634
[2m[36m(func pid=177380)[0m rmse_per_class: [0.094, 0.251, 0.064, 0.304, 0.064, 0.185, 0.264, 0.128, 0.143, 0.113]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2880 | Steps: 4 | Val loss: 0.2592 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 37] | Train loss: 0.2662 | Steps: 4 | Val loss: 0.2644 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.3736 | Steps: 4 | Val loss: 0.2937 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=183330)[0m rmse: 0.1383158415555954
[2m[36m(func pid=183330)[0m mae:  0.09275517612695694
[2m[36m(func pid=183330)[0m rmse_per_class: [0.063, 0.226, 0.036, 0.253, 0.056, 0.169, 0.225, 0.119, 0.138, 0.099]
[2m[36m(func pid=183330)[0m 
== Status ==
Current time: 2024-01-07 17:08:18 (running for 00:44:15.36)
Memory usage on this node: 22.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.375 |  0.161 |                   63 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.288 |  0.138 |                   40 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.261 |  0.145 |                   37 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183978)[0m rmse: 0.13849091529846191
[2m[36m(func pid=183978)[0m mae:  0.08398958295583725
[2m[36m(func pid=183978)[0m rmse_per_class: [0.062, 0.206, 0.027, 0.244, 0.07, 0.186, 0.226, 0.117, 0.133, 0.116]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.1611359566450119
[2m[36m(func pid=177380)[0m mae:  0.11550772190093994
[2m[36m(func pid=177380)[0m rmse_per_class: [0.094, 0.251, 0.064, 0.304, 0.065, 0.185, 0.265, 0.128, 0.142, 0.115]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2963 | Steps: 4 | Val loss: 0.2617 | Batch size: 32 | lr: 0.01 | Duration: 2.94s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 38] | Train loss: 0.2576 | Steps: 4 | Val loss: 0.2784 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 17:08:23 (running for 00:44:20.65)
Memory usage on this node: 22.1/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.374 |  0.161 |                   64 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.296 |  0.14  |                   41 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.266 |  0.138 |                   38 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.3753 | Steps: 4 | Val loss: 0.2940 | Batch size: 32 | lr: 0.001 | Duration: 3.00s
[2m[36m(func pid=183330)[0m rmse: 0.14032696187496185
[2m[36m(func pid=183330)[0m mae:  0.09442804008722305
[2m[36m(func pid=183330)[0m rmse_per_class: [0.063, 0.226, 0.041, 0.259, 0.057, 0.172, 0.229, 0.113, 0.137, 0.107]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.14975695312023163
[2m[36m(func pid=183978)[0m mae:  0.09101943671703339
[2m[36m(func pid=183978)[0m rmse_per_class: [0.07, 0.231, 0.027, 0.261, 0.057, 0.169, 0.212, 0.115, 0.197, 0.159]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16130873560905457
[2m[36m(func pid=177380)[0m mae:  0.11557022482156754
[2m[36m(func pid=177380)[0m rmse_per_class: [0.094, 0.251, 0.062, 0.305, 0.065, 0.185, 0.265, 0.128, 0.14, 0.118]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2940 | Steps: 4 | Val loss: 0.2592 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 39] | Train loss: 0.2631 | Steps: 4 | Val loss: 0.2851 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=183330)[0m rmse: 0.1383325308561325
[2m[36m(func pid=183330)[0m mae:  0.09281419217586517
[2m[36m(func pid=183330)[0m rmse_per_class: [0.063, 0.221, 0.04, 0.256, 0.059, 0.166, 0.224, 0.109, 0.134, 0.112]
[2m[36m(func pid=183330)[0m 
== Status ==
Current time: 2024-01-07 17:08:28 (running for 00:44:26.04)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.375 |  0.161 |                   65 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.294 |  0.138 |                   42 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.258 |  0.15  |                   39 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.3759 | Steps: 4 | Val loss: 0.2939 | Batch size: 32 | lr: 0.001 | Duration: 3.11s
[2m[36m(func pid=183978)[0m rmse: 0.1483677178621292
[2m[36m(func pid=183978)[0m mae:  0.09074187278747559
[2m[36m(func pid=183978)[0m rmse_per_class: [0.079, 0.247, 0.026, 0.288, 0.056, 0.17, 0.236, 0.13, 0.166, 0.085]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16148629784584045
[2m[36m(func pid=177380)[0m mae:  0.11557899415493011
[2m[36m(func pid=177380)[0m rmse_per_class: [0.093, 0.251, 0.063, 0.305, 0.065, 0.184, 0.264, 0.128, 0.14, 0.122]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2811 | Steps: 4 | Val loss: 0.2556 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 40] | Train loss: 0.2653 | Steps: 4 | Val loss: 0.2618 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 17:08:34 (running for 00:44:31.55)
Memory usage on this node: 22.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.376 |  0.161 |                   66 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.281 |  0.135 |                   43 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.263 |  0.148 |                   40 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13538730144500732
[2m[36m(func pid=183330)[0m mae:  0.09033405035734177
[2m[36m(func pid=183330)[0m rmse_per_class: [0.062, 0.221, 0.038, 0.251, 0.058, 0.165, 0.213, 0.109, 0.134, 0.103]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.3758 | Steps: 4 | Val loss: 0.2945 | Batch size: 32 | lr: 0.001 | Duration: 3.18s
[2m[36m(func pid=183978)[0m rmse: 0.13409867882728577
[2m[36m(func pid=183978)[0m mae:  0.08090656250715256
[2m[36m(func pid=183978)[0m rmse_per_class: [0.061, 0.21, 0.027, 0.242, 0.06, 0.173, 0.22, 0.115, 0.13, 0.104]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.1619647741317749
[2m[36m(func pid=177380)[0m mae:  0.11606837809085846
[2m[36m(func pid=177380)[0m rmse_per_class: [0.094, 0.251, 0.063, 0.306, 0.065, 0.184, 0.264, 0.127, 0.142, 0.123]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.3033 | Steps: 4 | Val loss: 0.2573 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 17:08:39 (running for 00:44:37.03)
Memory usage on this node: 22.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.376 |  0.162 |                   67 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.303 |  0.137 |                   44 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.265 |  0.134 |                   41 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13696357607841492
[2m[36m(func pid=183330)[0m mae:  0.09146410971879959
[2m[36m(func pid=183330)[0m rmse_per_class: [0.061, 0.221, 0.038, 0.257, 0.06, 0.165, 0.213, 0.11, 0.134, 0.11]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 41] | Train loss: 0.2728 | Steps: 4 | Val loss: 0.2919 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.3720 | Steps: 4 | Val loss: 0.2938 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=183978)[0m rmse: 0.15963134169578552
[2m[36m(func pid=183978)[0m mae:  0.0958947166800499
[2m[36m(func pid=183978)[0m rmse_per_class: [0.082, 0.222, 0.025, 0.255, 0.078, 0.178, 0.242, 0.141, 0.184, 0.188]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.16152533888816833
[2m[36m(func pid=177380)[0m mae:  0.11572732776403427
[2m[36m(func pid=177380)[0m rmse_per_class: [0.093, 0.252, 0.063, 0.304, 0.065, 0.184, 0.263, 0.128, 0.143, 0.12]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2928 | Steps: 4 | Val loss: 0.2600 | Batch size: 32 | lr: 0.01 | Duration: 2.85s
== Status ==
Current time: 2024-01-07 17:08:45 (running for 00:44:42.25)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.372 |  0.162 |                   68 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.293 |  0.139 |                   45 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.273 |  0.16  |                   42 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13929452002048492
[2m[36m(func pid=183330)[0m mae:  0.09312295913696289
[2m[36m(func pid=183330)[0m rmse_per_class: [0.061, 0.225, 0.041, 0.256, 0.06, 0.165, 0.216, 0.11, 0.14, 0.12]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 42] | Train loss: 0.2870 | Steps: 4 | Val loss: 0.3005 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.3788 | Steps: 4 | Val loss: 0.2925 | Batch size: 32 | lr: 0.001 | Duration: 2.97s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2782 | Steps: 4 | Val loss: 0.2583 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=177380)[0m rmse: 0.16084596514701843
[2m[36m(func pid=177380)[0m mae:  0.11507318913936615
[2m[36m(func pid=177380)[0m rmse_per_class: [0.093, 0.251, 0.063, 0.303, 0.065, 0.183, 0.262, 0.127, 0.142, 0.119]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.15762220323085785
[2m[36m(func pid=183978)[0m mae:  0.0970856249332428
[2m[36m(func pid=183978)[0m rmse_per_class: [0.069, 0.251, 0.025, 0.309, 0.067, 0.195, 0.249, 0.114, 0.17, 0.127]
[2m[36m(func pid=183978)[0m 
== Status ==
Current time: 2024-01-07 17:08:50 (running for 00:44:47.86)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.379 |  0.161 |                   69 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.278 |  0.138 |                   46 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.287 |  0.158 |                   43 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13787713646888733
[2m[36m(func pid=183330)[0m mae:  0.09216388314962387
[2m[36m(func pid=183330)[0m rmse_per_class: [0.061, 0.223, 0.038, 0.247, 0.059, 0.164, 0.222, 0.109, 0.146, 0.109]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.3694 | Steps: 4 | Val loss: 0.2923 | Batch size: 32 | lr: 0.001 | Duration: 3.10s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 43] | Train loss: 0.2624 | Steps: 4 | Val loss: 0.2724 | Batch size: 32 | lr: 0.1 | Duration: 3.07s
[2m[36m(func pid=183978)[0m rmse: 0.14397428929805756
[2m[36m(func pid=183978)[0m mae:  0.08638779073953629
[2m[36m(func pid=183978)[0m rmse_per_class: [0.065, 0.223, 0.047, 0.255, 0.053, 0.17, 0.223, 0.114, 0.149, 0.142]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.1606244146823883
[2m[36m(func pid=177380)[0m mae:  0.11482761055231094
[2m[36m(func pid=177380)[0m rmse_per_class: [0.092, 0.252, 0.065, 0.303, 0.065, 0.184, 0.259, 0.127, 0.142, 0.117]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2951 | Steps: 4 | Val loss: 0.2567 | Batch size: 32 | lr: 0.01 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 17:08:56 (running for 00:44:53.38)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.369 |  0.161 |                   70 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.295 |  0.136 |                   47 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.262 |  0.144 |                   44 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13630886375904083
[2m[36m(func pid=183330)[0m mae:  0.0914849042892456
[2m[36m(func pid=183330)[0m rmse_per_class: [0.062, 0.216, 0.037, 0.247, 0.058, 0.165, 0.227, 0.108, 0.142, 0.101]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.3712 | Steps: 4 | Val loss: 0.2927 | Batch size: 32 | lr: 0.001 | Duration: 3.09s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 44] | Train loss: 0.2704 | Steps: 4 | Val loss: 0.2770 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
[2m[36m(func pid=177380)[0m rmse: 0.16069374978542328
[2m[36m(func pid=177380)[0m mae:  0.11472345888614655
[2m[36m(func pid=177380)[0m rmse_per_class: [0.092, 0.253, 0.063, 0.304, 0.064, 0.184, 0.258, 0.129, 0.142, 0.117]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2916 | Steps: 4 | Val loss: 0.2551 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=183978)[0m rmse: 0.14530858397483826
[2m[36m(func pid=183978)[0m mae:  0.0883132666349411
[2m[36m(func pid=183978)[0m rmse_per_class: [0.061, 0.203, 0.028, 0.251, 0.067, 0.173, 0.252, 0.141, 0.193, 0.084]
[2m[36m(func pid=183978)[0m 
== Status ==
Current time: 2024-01-07 17:09:01 (running for 00:44:58.86)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.371 |  0.161 |                   71 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.292 |  0.134 |                   48 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.27  |  0.145 |                   45 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13419213891029358
[2m[36m(func pid=183330)[0m mae:  0.08993791043758392
[2m[36m(func pid=183330)[0m rmse_per_class: [0.062, 0.21, 0.034, 0.256, 0.056, 0.164, 0.227, 0.108, 0.133, 0.093]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.3731 | Steps: 4 | Val loss: 0.2926 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 45] | Train loss: 0.2562 | Steps: 4 | Val loss: 0.2767 | Batch size: 32 | lr: 0.1 | Duration: 3.08s
[2m[36m(func pid=177380)[0m rmse: 0.16062608361244202
[2m[36m(func pid=177380)[0m mae:  0.11458422243595123
[2m[36m(func pid=177380)[0m rmse_per_class: [0.092, 0.254, 0.065, 0.305, 0.064, 0.184, 0.258, 0.13, 0.141, 0.114]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2902 | Steps: 4 | Val loss: 0.2559 | Batch size: 32 | lr: 0.01 | Duration: 3.15s
[2m[36m(func pid=183978)[0m rmse: 0.14204087853431702
[2m[36m(func pid=183978)[0m mae:  0.08511558920145035
[2m[36m(func pid=183978)[0m rmse_per_class: [0.083, 0.228, 0.024, 0.298, 0.066, 0.17, 0.218, 0.109, 0.134, 0.09]
[2m[36m(func pid=183978)[0m 
== Status ==
Current time: 2024-01-07 17:09:07 (running for 00:45:04.38)
Memory usage on this node: 22.5/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.373 |  0.161 |                   72 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.29  |  0.135 |                   49 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.256 |  0.142 |                   46 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13462293148040771
[2m[36m(func pid=183330)[0m mae:  0.09037051349878311
[2m[36m(func pid=183330)[0m rmse_per_class: [0.062, 0.211, 0.032, 0.256, 0.055, 0.165, 0.228, 0.108, 0.137, 0.092]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.3739 | Steps: 4 | Val loss: 0.2922 | Batch size: 32 | lr: 0.001 | Duration: 3.18s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 46] | Train loss: 0.2698 | Steps: 4 | Val loss: 0.3046 | Batch size: 32 | lr: 0.1 | Duration: 2.98s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2892 | Steps: 4 | Val loss: 0.2576 | Batch size: 32 | lr: 0.01 | Duration: 2.79s
[2m[36m(func pid=177380)[0m rmse: 0.16029547154903412
[2m[36m(func pid=177380)[0m mae:  0.11438500881195068
[2m[36m(func pid=177380)[0m rmse_per_class: [0.092, 0.253, 0.066, 0.305, 0.065, 0.184, 0.257, 0.128, 0.14, 0.112]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.16117271780967712
[2m[36m(func pid=183978)[0m mae:  0.09721861779689789
[2m[36m(func pid=183978)[0m rmse_per_class: [0.065, 0.247, 0.024, 0.277, 0.071, 0.201, 0.227, 0.144, 0.161, 0.195]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.1366415172815323
[2m[36m(func pid=183330)[0m mae:  0.09123900532722473
[2m[36m(func pid=183330)[0m rmse_per_class: [0.061, 0.215, 0.031, 0.252, 0.055, 0.165, 0.225, 0.112, 0.148, 0.103]
[2m[36m(func pid=183330)[0m 
== Status ==
Current time: 2024-01-07 17:09:12 (running for 00:45:09.59)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.374 |  0.16  |                   73 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.289 |  0.137 |                   50 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.27  |  0.161 |                   47 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.3664 | Steps: 4 | Val loss: 0.2926 | Batch size: 32 | lr: 0.001 | Duration: 3.12s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 47] | Train loss: 0.2665 | Steps: 4 | Val loss: 0.2739 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2866 | Steps: 4 | Val loss: 0.2580 | Batch size: 32 | lr: 0.01 | Duration: 2.84s
[2m[36m(func pid=177380)[0m rmse: 0.1604730635881424
[2m[36m(func pid=177380)[0m mae:  0.11450958251953125
[2m[36m(func pid=177380)[0m rmse_per_class: [0.091, 0.254, 0.067, 0.303, 0.065, 0.184, 0.258, 0.128, 0.142, 0.111]
[2m[36m(func pid=177380)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.14714348316192627
[2m[36m(func pid=183978)[0m mae:  0.08840323239564896
[2m[36m(func pid=183978)[0m rmse_per_class: [0.066, 0.207, 0.025, 0.253, 0.063, 0.179, 0.237, 0.163, 0.151, 0.128]
[2m[36m(func pid=183978)[0m 
== Status ==
Current time: 2024-01-07 17:09:17 (running for 00:45:14.82)
Memory usage on this node: 22.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=21
Bracket: Iter 75.000: -0.1469999998807907
Resources requested: 12.0/72 CPUs, 3.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (3 RUNNING, 21 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00021 | RUNNING    | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.366 |  0.16  |                   74 |
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.287 |  0.137 |                   51 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.267 |  0.147 |                   48 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13696205615997314
[2m[36m(func pid=183330)[0m mae:  0.09082493931055069
[2m[36m(func pid=183330)[0m rmse_per_class: [0.062, 0.224, 0.03, 0.245, 0.054, 0.164, 0.22, 0.117, 0.149, 0.104]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=177380)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.3701 | Steps: 4 | Val loss: 0.2919 | Batch size: 32 | lr: 0.001 | Duration: 3.08s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 48] | Train loss: 0.2559 | Steps: 4 | Val loss: 0.2708 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2800 | Steps: 4 | Val loss: 0.2580 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=183978)[0m rmse: 0.14005810022354126
[2m[36m(func pid=183978)[0m mae:  0.08525992184877396
[2m[36m(func pid=183978)[0m rmse_per_class: [0.079, 0.21, 0.026, 0.265, 0.068, 0.179, 0.211, 0.112, 0.154, 0.097]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=177380)[0m rmse: 0.1601342260837555
[2m[36m(func pid=177380)[0m mae:  0.11424288898706436
[2m[36m(func pid=177380)[0m rmse_per_class: [0.092, 0.252, 0.065, 0.303, 0.066, 0.184, 0.258, 0.128, 0.141, 0.113]
== Status ==
Current time: 2024-01-07 17:09:23 (running for 00:45:20.23)
Memory usage on this node: 19.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.28  |  0.137 |                   52 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.256 |  0.14  |                   49 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13680562376976013
[2m[36m(func pid=183330)[0m mae:  0.09025101363658905
[2m[36m(func pid=183330)[0m rmse_per_class: [0.063, 0.226, 0.032, 0.247, 0.054, 0.163, 0.215, 0.118, 0.142, 0.108]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 49] | Train loss: 0.2840 | Steps: 4 | Val loss: 0.2875 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2894 | Steps: 4 | Val loss: 0.2569 | Batch size: 32 | lr: 0.01 | Duration: 2.83s
[2m[36m(func pid=183978)[0m rmse: 0.1496153324842453
[2m[36m(func pid=183978)[0m mae:  0.08917195349931717
[2m[36m(func pid=183978)[0m rmse_per_class: [0.072, 0.214, 0.042, 0.293, 0.074, 0.185, 0.221, 0.111, 0.16, 0.124]
[2m[36m(func pid=183978)[0m 
== Status ==
Current time: 2024-01-07 17:09:28 (running for 00:45:25.49)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.289 |  0.137 |                   53 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.284 |  0.15  |                   50 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13654257357120514
[2m[36m(func pid=183330)[0m mae:  0.08987079560756683
[2m[36m(func pid=183330)[0m rmse_per_class: [0.067, 0.222, 0.035, 0.244, 0.054, 0.163, 0.22, 0.12, 0.136, 0.105]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 50] | Train loss: 0.2844 | Steps: 4 | Val loss: 0.3042 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2925 | Steps: 4 | Val loss: 0.2548 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=183978)[0m rmse: 0.1623535454273224
[2m[36m(func pid=183978)[0m mae:  0.09857531636953354
[2m[36m(func pid=183978)[0m rmse_per_class: [0.063, 0.227, 0.031, 0.278, 0.066, 0.177, 0.238, 0.247, 0.142, 0.153]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.13554903864860535
[2m[36m(func pid=183330)[0m mae:  0.08959947526454926
[2m[36m(func pid=183330)[0m rmse_per_class: [0.081, 0.217, 0.035, 0.241, 0.054, 0.163, 0.224, 0.111, 0.134, 0.096]
[2m[36m(func pid=183330)[0m 
== Status ==
Current time: 2024-01-07 17:09:33 (running for 00:45:30.81)
Memory usage on this node: 19.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.293 |  0.136 |                   54 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.284 |  0.162 |                   51 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 51] | Train loss: 0.2673 | Steps: 4 | Val loss: 0.2738 | Batch size: 32 | lr: 0.1 | Duration: 3.03s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2763 | Steps: 4 | Val loss: 0.2519 | Batch size: 32 | lr: 0.01 | Duration: 3.01s
[2m[36m(func pid=183978)[0m rmse: 0.14284482598304749
[2m[36m(func pid=183978)[0m mae:  0.08652081340551376
[2m[36m(func pid=183978)[0m rmse_per_class: [0.079, 0.205, 0.028, 0.255, 0.057, 0.179, 0.211, 0.125, 0.169, 0.121]
[2m[36m(func pid=183978)[0m 
== Status ==
Current time: 2024-01-07 17:09:39 (running for 00:45:36.22)
Memory usage on this node: 19.0/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.276 |  0.133 |                   55 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.267 |  0.143 |                   52 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13282518088817596
[2m[36m(func pid=183330)[0m mae:  0.08753382414579391
[2m[36m(func pid=183330)[0m rmse_per_class: [0.073, 0.215, 0.034, 0.241, 0.055, 0.163, 0.212, 0.11, 0.136, 0.09]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 52] | Train loss: 0.2782 | Steps: 4 | Val loss: 0.2844 | Batch size: 32 | lr: 0.1 | Duration: 3.19s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2750 | Steps: 4 | Val loss: 0.2542 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 17:09:44 (running for 00:45:41.24)
Memory usage on this node: 19.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.276 |  0.133 |                   55 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.267 |  0.143 |                   52 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183978)[0m rmse: 0.14891615509986877
[2m[36m(func pid=183978)[0m mae:  0.08975573629140854
[2m[36m(func pid=183978)[0m rmse_per_class: [0.06, 0.209, 0.025, 0.264, 0.078, 0.204, 0.214, 0.128, 0.202, 0.105]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.1339218020439148
[2m[36m(func pid=183330)[0m mae:  0.08866821229457855
[2m[36m(func pid=183330)[0m rmse_per_class: [0.062, 0.214, 0.035, 0.25, 0.06, 0.164, 0.211, 0.108, 0.148, 0.088]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 53] | Train loss: 0.2645 | Steps: 4 | Val loss: 0.2798 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2710 | Steps: 4 | Val loss: 0.2574 | Batch size: 32 | lr: 0.01 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 17:09:49 (running for 00:45:46.73)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.275 |  0.134 |                   56 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.278 |  0.149 |                   53 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183978)[0m rmse: 0.1486368477344513
[2m[36m(func pid=183978)[0m mae:  0.08777560293674469
[2m[36m(func pid=183978)[0m rmse_per_class: [0.069, 0.213, 0.034, 0.249, 0.068, 0.174, 0.246, 0.16, 0.14, 0.134]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m rmse: 0.13592523336410522
[2m[36m(func pid=183330)[0m mae:  0.09017302840948105
[2m[36m(func pid=183330)[0m rmse_per_class: [0.059, 0.212, 0.034, 0.264, 0.064, 0.165, 0.212, 0.108, 0.147, 0.095]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 54] | Train loss: 0.2616 | Steps: 4 | Val loss: 0.2804 | Batch size: 32 | lr: 0.1 | Duration: 3.15s
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2866 | Steps: 4 | Val loss: 0.2621 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
== Status ==
Current time: 2024-01-07 17:09:55 (running for 00:45:52.26)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.271 |  0.136 |                   57 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.264 |  0.149 |                   54 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13916543126106262
[2m[36m(func pid=183330)[0m mae:  0.09256601333618164
[2m[36m(func pid=183330)[0m rmse_per_class: [0.059, 0.213, 0.034, 0.274, 0.068, 0.167, 0.22, 0.11, 0.141, 0.106]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.1443861722946167
[2m[36m(func pid=183978)[0m mae:  0.0869220644235611
[2m[36m(func pid=183978)[0m rmse_per_class: [0.085, 0.216, 0.029, 0.29, 0.053, 0.166, 0.215, 0.156, 0.122, 0.112]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2840 | Steps: 4 | Val loss: 0.2617 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 55] | Train loss: 0.2659 | Steps: 4 | Val loss: 0.2896 | Batch size: 32 | lr: 0.1 | Duration: 3.16s
== Status ==
Current time: 2024-01-07 17:10:00 (running for 00:45:57.74)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.287 |  0.139 |                   58 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.262 |  0.144 |                   55 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13929405808448792
[2m[36m(func pid=183330)[0m mae:  0.09253443032503128
[2m[36m(func pid=183330)[0m rmse_per_class: [0.061, 0.213, 0.032, 0.27, 0.066, 0.167, 0.226, 0.108, 0.135, 0.115]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.1520204246044159
[2m[36m(func pid=183978)[0m mae:  0.09124545007944107
[2m[36m(func pid=183978)[0m rmse_per_class: [0.061, 0.222, 0.035, 0.281, 0.063, 0.2, 0.225, 0.115, 0.178, 0.139]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2906 | Steps: 4 | Val loss: 0.2620 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 56] | Train loss: 0.2659 | Steps: 4 | Val loss: 0.2927 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
== Status ==
Current time: 2024-01-07 17:10:06 (running for 00:46:03.37)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.284 |  0.139 |                   59 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.266 |  0.152 |                   56 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.1403246819972992
[2m[36m(func pid=183330)[0m mae:  0.0930645540356636
[2m[36m(func pid=183330)[0m rmse_per_class: [0.061, 0.216, 0.032, 0.264, 0.064, 0.165, 0.226, 0.109, 0.141, 0.126]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.15179668366909027
[2m[36m(func pid=183978)[0m mae:  0.08977620303630829
[2m[36m(func pid=183978)[0m rmse_per_class: [0.089, 0.259, 0.025, 0.25, 0.075, 0.172, 0.216, 0.112, 0.182, 0.139]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2736 | Steps: 4 | Val loss: 0.2581 | Batch size: 32 | lr: 0.01 | Duration: 2.97s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 57] | Train loss: 0.2655 | Steps: 4 | Val loss: 0.2730 | Batch size: 32 | lr: 0.1 | Duration: 3.00s
== Status ==
Current time: 2024-01-07 17:10:11 (running for 00:46:08.97)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.291 |  0.14  |                   60 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.266 |  0.152 |                   57 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.1374225616455078
[2m[36m(func pid=183330)[0m mae:  0.09059049189090729
[2m[36m(func pid=183330)[0m rmse_per_class: [0.061, 0.218, 0.031, 0.258, 0.064, 0.164, 0.215, 0.111, 0.142, 0.11]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.14483001828193665
[2m[36m(func pid=183978)[0m mae:  0.08709158003330231
[2m[36m(func pid=183978)[0m rmse_per_class: [0.063, 0.21, 0.039, 0.249, 0.059, 0.171, 0.244, 0.156, 0.133, 0.125]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2872 | Steps: 4 | Val loss: 0.2577 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 58] | Train loss: 0.2666 | Steps: 4 | Val loss: 0.2679 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 17:10:17 (running for 00:46:14.45)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.274 |  0.137 |                   61 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.265 |  0.145 |                   58 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13684755563735962
[2m[36m(func pid=183330)[0m mae:  0.0900420993566513
[2m[36m(func pid=183330)[0m rmse_per_class: [0.059, 0.22, 0.029, 0.259, 0.063, 0.167, 0.214, 0.113, 0.139, 0.105]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.1363174021244049
[2m[36m(func pid=183978)[0m mae:  0.08210521936416626
[2m[36m(func pid=183978)[0m rmse_per_class: [0.059, 0.218, 0.026, 0.266, 0.054, 0.173, 0.21, 0.126, 0.125, 0.106]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2838 | Steps: 4 | Val loss: 0.2536 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 59] | Train loss: 0.2921 | Steps: 4 | Val loss: 0.2963 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
== Status ==
Current time: 2024-01-07 17:10:22 (running for 00:46:19.96)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.287 |  0.137 |                   62 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.267 |  0.136 |                   59 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13400930166244507
[2m[36m(func pid=183330)[0m mae:  0.08790944516658783
[2m[36m(func pid=183330)[0m rmse_per_class: [0.061, 0.219, 0.03, 0.243, 0.06, 0.164, 0.215, 0.11, 0.136, 0.102]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.15507593750953674
[2m[36m(func pid=183978)[0m mae:  0.09199477732181549
[2m[36m(func pid=183978)[0m rmse_per_class: [0.1, 0.228, 0.023, 0.292, 0.091, 0.186, 0.213, 0.118, 0.166, 0.134]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2721 | Steps: 4 | Val loss: 0.2525 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 60] | Train loss: 0.2680 | Steps: 4 | Val loss: 0.2671 | Batch size: 32 | lr: 0.1 | Duration: 3.10s
== Status ==
Current time: 2024-01-07 17:10:28 (running for 00:46:25.44)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.284 |  0.134 |                   63 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.292 |  0.155 |                   60 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13300034403800964
[2m[36m(func pid=183330)[0m mae:  0.08736427128314972
[2m[36m(func pid=183330)[0m rmse_per_class: [0.061, 0.217, 0.03, 0.236, 0.058, 0.163, 0.221, 0.108, 0.143, 0.094]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.13919682800769806
[2m[36m(func pid=183978)[0m mae:  0.0838584378361702
[2m[36m(func pid=183978)[0m rmse_per_class: [0.059, 0.217, 0.023, 0.245, 0.062, 0.172, 0.208, 0.114, 0.146, 0.148]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2794 | Steps: 4 | Val loss: 0.2524 | Batch size: 32 | lr: 0.01 | Duration: 3.11s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 61] | Train loss: 0.2720 | Steps: 4 | Val loss: 0.2826 | Batch size: 32 | lr: 0.1 | Duration: 3.01s
== Status ==
Current time: 2024-01-07 17:10:33 (running for 00:46:30.96)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.272 |  0.133 |                   64 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.268 |  0.139 |                   61 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13269701600074768
[2m[36m(func pid=183330)[0m mae:  0.08728183060884476
[2m[36m(func pid=183330)[0m rmse_per_class: [0.062, 0.214, 0.031, 0.235, 0.055, 0.162, 0.226, 0.107, 0.143, 0.093]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.14777404069900513
[2m[36m(func pid=183978)[0m mae:  0.09060917794704437
[2m[36m(func pid=183978)[0m rmse_per_class: [0.069, 0.216, 0.03, 0.296, 0.053, 0.186, 0.223, 0.161, 0.144, 0.099]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2604 | Steps: 4 | Val loss: 0.2525 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 62] | Train loss: 0.2845 | Steps: 4 | Val loss: 0.2988 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 17:10:39 (running for 00:46:36.45)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.279 |  0.133 |                   65 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.272 |  0.148 |                   62 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.1325952708721161
[2m[36m(func pid=183330)[0m mae:  0.0870656669139862
[2m[36m(func pid=183330)[0m rmse_per_class: [0.062, 0.214, 0.031, 0.235, 0.055, 0.162, 0.225, 0.106, 0.138, 0.097]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.16115891933441162
[2m[36m(func pid=183978)[0m mae:  0.09608393162488937
[2m[36m(func pid=183978)[0m rmse_per_class: [0.098, 0.222, 0.054, 0.287, 0.074, 0.174, 0.234, 0.148, 0.191, 0.129]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2703 | Steps: 4 | Val loss: 0.2548 | Batch size: 32 | lr: 0.01 | Duration: 3.19s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 63] | Train loss: 0.2594 | Steps: 4 | Val loss: 0.2744 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
== Status ==
Current time: 2024-01-07 17:10:44 (running for 00:46:42.00)
Memory usage on this node: 19.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.26  |  0.133 |                   66 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.284 |  0.161 |                   63 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13424722850322723
[2m[36m(func pid=183330)[0m mae:  0.08782152831554413
[2m[36m(func pid=183330)[0m rmse_per_class: [0.065, 0.217, 0.031, 0.245, 0.054, 0.161, 0.213, 0.106, 0.141, 0.109]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.14174214005470276
[2m[36m(func pid=183978)[0m mae:  0.08667407929897308
[2m[36m(func pid=183978)[0m rmse_per_class: [0.065, 0.212, 0.024, 0.25, 0.062, 0.18, 0.217, 0.11, 0.16, 0.137]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2717 | Steps: 4 | Val loss: 0.2596 | Batch size: 32 | lr: 0.01 | Duration: 3.03s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 64] | Train loss: 0.2668 | Steps: 4 | Val loss: 0.2865 | Batch size: 32 | lr: 0.1 | Duration: 3.06s
== Status ==
Current time: 2024-01-07 17:10:50 (running for 00:46:47.53)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.272 |  0.137 |                   68 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.259 |  0.142 |                   64 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.1372673213481903
[2m[36m(func pid=183330)[0m mae:  0.08955197036266327
[2m[36m(func pid=183330)[0m rmse_per_class: [0.063, 0.221, 0.034, 0.261, 0.056, 0.162, 0.207, 0.108, 0.141, 0.119]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.14850346744060516
[2m[36m(func pid=183978)[0m mae:  0.0895628035068512
[2m[36m(func pid=183978)[0m rmse_per_class: [0.061, 0.22, 0.03, 0.289, 0.059, 0.177, 0.232, 0.149, 0.128, 0.141]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2903 | Steps: 4 | Val loss: 0.2635 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 65] | Train loss: 0.2758 | Steps: 4 | Val loss: 0.2915 | Batch size: 32 | lr: 0.1 | Duration: 3.11s
== Status ==
Current time: 2024-01-07 17:10:55 (running for 00:46:52.90)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.29  |  0.14  |                   69 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.267 |  0.149 |                   65 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.14022141695022583
[2m[36m(func pid=183330)[0m mae:  0.09131006896495819
[2m[36m(func pid=183330)[0m rmse_per_class: [0.059, 0.225, 0.036, 0.269, 0.055, 0.166, 0.21, 0.111, 0.14, 0.131]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.152884379029274
[2m[36m(func pid=183978)[0m mae:  0.0923987403512001
[2m[36m(func pid=183978)[0m rmse_per_class: [0.092, 0.21, 0.039, 0.289, 0.069, 0.196, 0.234, 0.178, 0.137, 0.083]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2764 | Steps: 4 | Val loss: 0.2583 | Batch size: 32 | lr: 0.01 | Duration: 2.89s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 66] | Train loss: 0.2606 | Steps: 4 | Val loss: 0.2652 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 17:11:01 (running for 00:46:58.31)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.276 |  0.138 |                   70 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.276 |  0.153 |                   66 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.1377241015434265
[2m[36m(func pid=183330)[0m mae:  0.08978940546512604
[2m[36m(func pid=183330)[0m rmse_per_class: [0.06, 0.22, 0.035, 0.256, 0.056, 0.169, 0.219, 0.111, 0.133, 0.119]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.13170728087425232
[2m[36m(func pid=183978)[0m mae:  0.080595962703228
[2m[36m(func pid=183978)[0m rmse_per_class: [0.062, 0.204, 0.029, 0.247, 0.057, 0.167, 0.21, 0.112, 0.15, 0.08]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2781 | Steps: 4 | Val loss: 0.2528 | Batch size: 32 | lr: 0.01 | Duration: 3.14s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 67] | Train loss: 0.2857 | Steps: 4 | Val loss: 0.2710 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 17:11:06 (running for 00:47:03.94)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.278 |  0.134 |                   71 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.261 |  0.132 |                   67 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13369803130626678
[2m[36m(func pid=183330)[0m mae:  0.08743824064731598
[2m[36m(func pid=183330)[0m rmse_per_class: [0.059, 0.217, 0.035, 0.235, 0.056, 0.163, 0.227, 0.112, 0.131, 0.102]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.14265203475952148
[2m[36m(func pid=183978)[0m mae:  0.08457142859697342
[2m[36m(func pid=183978)[0m rmse_per_class: [0.074, 0.221, 0.025, 0.243, 0.064, 0.176, 0.21, 0.112, 0.144, 0.158]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2822 | Steps: 4 | Val loss: 0.2512 | Batch size: 32 | lr: 0.01 | Duration: 2.93s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 68] | Train loss: 0.2805 | Steps: 4 | Val loss: 0.3177 | Batch size: 32 | lr: 0.1 | Duration: 3.19s
== Status ==
Current time: 2024-01-07 17:11:12 (running for 00:47:09.34)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.282 |  0.132 |                   72 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.286 |  0.143 |                   68 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13197572529315948
[2m[36m(func pid=183330)[0m mae:  0.08632051199674606
[2m[36m(func pid=183330)[0m rmse_per_class: [0.059, 0.213, 0.031, 0.231, 0.053, 0.163, 0.23, 0.111, 0.129, 0.1]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.16355520486831665
[2m[36m(func pid=183978)[0m mae:  0.0991307869553566
[2m[36m(func pid=183978)[0m rmse_per_class: [0.082, 0.236, 0.027, 0.335, 0.076, 0.189, 0.236, 0.155, 0.168, 0.131]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2714 | Steps: 4 | Val loss: 0.2512 | Batch size: 32 | lr: 0.01 | Duration: 2.96s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 69] | Train loss: 0.2982 | Steps: 4 | Val loss: 0.2678 | Batch size: 32 | lr: 0.1 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 17:11:17 (running for 00:47:14.77)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.271 |  0.132 |                   73 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.281 |  0.164 |                   69 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13182759284973145
[2m[36m(func pid=183330)[0m mae:  0.085970439016819
[2m[36m(func pid=183330)[0m rmse_per_class: [0.06, 0.21, 0.041, 0.234, 0.054, 0.161, 0.226, 0.107, 0.128, 0.097]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.13496747612953186
[2m[36m(func pid=183978)[0m mae:  0.08084940910339355
[2m[36m(func pid=183978)[0m rmse_per_class: [0.062, 0.224, 0.024, 0.247, 0.061, 0.176, 0.207, 0.119, 0.139, 0.09]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2606 | Steps: 4 | Val loss: 0.2501 | Batch size: 32 | lr: 0.01 | Duration: 2.90s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 70] | Train loss: 0.2807 | Steps: 4 | Val loss: 0.2813 | Batch size: 32 | lr: 0.1 | Duration: 3.09s
== Status ==
Current time: 2024-01-07 17:11:23 (running for 00:47:20.10)
Memory usage on this node: 19.4/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14874999970197678
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.261 |  0.131 |                   74 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.298 |  0.135 |                   70 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13121461868286133
[2m[36m(func pid=183330)[0m mae:  0.08481468260288239
[2m[36m(func pid=183330)[0m rmse_per_class: [0.06, 0.214, 0.047, 0.234, 0.054, 0.161, 0.208, 0.106, 0.131, 0.098]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.14432105422019958
[2m[36m(func pid=183978)[0m mae:  0.0868217945098877
[2m[36m(func pid=183978)[0m rmse_per_class: [0.062, 0.25, 0.034, 0.244, 0.055, 0.222, 0.222, 0.112, 0.13, 0.114]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2781 | Steps: 4 | Val loss: 0.2545 | Batch size: 32 | lr: 0.01 | Duration: 2.88s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 71] | Train loss: 0.2718 | Steps: 4 | Val loss: 0.3115 | Batch size: 32 | lr: 0.1 | Duration: 3.13s
== Status ==
Current time: 2024-01-07 17:11:28 (running for 00:47:25.48)
Memory usage on this node: 19.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.278 |  0.134 |                   75 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.281 |  0.144 |                   71 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.1343430131673813
[2m[36m(func pid=183330)[0m mae:  0.08692970126867294
[2m[36m(func pid=183330)[0m rmse_per_class: [0.058, 0.216, 0.042, 0.251, 0.053, 0.162, 0.206, 0.106, 0.136, 0.113]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.16665752232074738
[2m[36m(func pid=183978)[0m mae:  0.10102783143520355
[2m[36m(func pid=183978)[0m rmse_per_class: [0.069, 0.228, 0.033, 0.313, 0.089, 0.175, 0.223, 0.174, 0.193, 0.17]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 75] | Train loss: 0.2941 | Steps: 4 | Val loss: 0.2569 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 72] | Train loss: 0.2506 | Steps: 4 | Val loss: 0.2929 | Batch size: 32 | lr: 0.1 | Duration: 3.02s
== Status ==
Current time: 2024-01-07 17:11:34 (running for 00:47:31.10)
Memory usage on this node: 19.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.294 |  0.136 |                   76 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.272 |  0.167 |                   72 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13554225862026215
[2m[36m(func pid=183330)[0m mae:  0.08790154755115509
[2m[36m(func pid=183330)[0m rmse_per_class: [0.058, 0.214, 0.036, 0.262, 0.052, 0.163, 0.208, 0.108, 0.137, 0.116]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.15315929055213928
[2m[36m(func pid=183978)[0m mae:  0.09328159689903259
[2m[36m(func pid=183978)[0m rmse_per_class: [0.069, 0.245, 0.025, 0.278, 0.075, 0.174, 0.233, 0.117, 0.206, 0.109]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 76] | Train loss: 0.2727 | Steps: 4 | Val loss: 0.2605 | Batch size: 32 | lr: 0.01 | Duration: 2.92s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 73] | Train loss: 0.2786 | Steps: 4 | Val loss: 0.2681 | Batch size: 32 | lr: 0.1 | Duration: 3.14s
== Status ==
Current time: 2024-01-07 17:11:39 (running for 00:47:36.67)
Memory usage on this node: 19.2/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.273 |  0.138 |                   77 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.251 |  0.153 |                   73 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.1376616656780243
[2m[36m(func pid=183330)[0m mae:  0.0900144875049591
[2m[36m(func pid=183330)[0m rmse_per_class: [0.063, 0.215, 0.031, 0.273, 0.055, 0.165, 0.215, 0.108, 0.141, 0.11]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.13492222130298615
[2m[36m(func pid=183978)[0m mae:  0.08066487312316895
[2m[36m(func pid=183978)[0m rmse_per_class: [0.063, 0.208, 0.024, 0.241, 0.054, 0.213, 0.213, 0.112, 0.122, 0.1]
[2m[36m(func pid=183978)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 77] | Train loss: 0.2839 | Steps: 4 | Val loss: 0.2594 | Batch size: 32 | lr: 0.01 | Duration: 2.99s
[2m[36m(func pid=183978)[0m [N0-GPU0] | [Epoch: 74] | Train loss: 0.2485 | Steps: 4 | Val loss: 0.2928 | Batch size: 32 | lr: 0.1 | Duration: 2.99s
[2m[36m(func pid=183330)[0m rmse: 0.1372895985841751
[2m[36m(func pid=183330)[0m mae:  0.08976984024047852
[2m[36m(func pid=183330)[0m rmse_per_class: [0.064, 0.212, 0.032, 0.268, 0.058, 0.166, 0.22, 0.115, 0.142, 0.098]
== Status ==
Current time: 2024-01-07 17:11:45 (running for 00:47:42.24)
Memory usage on this node: 19.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=22
Bracket: Iter 75.000: -0.14649999886751175
Resources requested: 8.0/72 CPUs, 2.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (2 RUNNING, 22 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.284 |  0.137 |                   78 |
| train_c9cb4_00023 | RUNNING    | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.279 |  0.135 |                   74 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183978)[0m rmse: 0.14928898215293884
[2m[36m(func pid=183978)[0m mae:  0.08928888291120529
[2m[36m(func pid=183978)[0m rmse_per_class: [0.073, 0.243, 0.028, 0.297, 0.061, 0.175, 0.226, 0.167, 0.122, 0.101]
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 78] | Train loss: 0.2747 | Steps: 4 | Val loss: 0.2594 | Batch size: 32 | lr: 0.01 | Duration: 3.14s
== Status ==
Current time: 2024-01-07 17:11:50 (running for 00:47:47.74)
Memory usage on this node: 16.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.275 |  0.138 |                   79 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.1380603015422821
[2m[36m(func pid=183330)[0m mae:  0.08980872482061386
[2m[36m(func pid=183330)[0m rmse_per_class: [0.067, 0.21, 0.031, 0.264, 0.058, 0.164, 0.223, 0.125, 0.138, 0.1]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 79] | Train loss: 0.2835 | Steps: 4 | Val loss: 0.2555 | Batch size: 32 | lr: 0.01 | Duration: 3.26s
== Status ==
Current time: 2024-01-07 17:11:55 (running for 00:47:52.77)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.275 |  0.138 |                   79 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13515838980674744
[2m[36m(func pid=183330)[0m mae:  0.08829957991838455
[2m[36m(func pid=183330)[0m rmse_per_class: [0.061, 0.207, 0.029, 0.251, 0.064, 0.164, 0.227, 0.118, 0.136, 0.094]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 80] | Train loss: 0.2852 | Steps: 4 | Val loss: 0.2537 | Batch size: 32 | lr: 0.01 | Duration: 3.26s
== Status ==
Current time: 2024-01-07 17:12:01 (running for 00:47:58.53)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.284 |  0.135 |                   80 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13371329009532928
[2m[36m(func pid=183330)[0m mae:  0.08765124529600143
[2m[36m(func pid=183330)[0m rmse_per_class: [0.058, 0.207, 0.028, 0.247, 0.062, 0.163, 0.228, 0.112, 0.138, 0.095]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 81] | Train loss: 0.2725 | Steps: 4 | Val loss: 0.2518 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 17:12:07 (running for 00:48:04.38)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.285 |  0.134 |                   81 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13261958956718445
[2m[36m(func pid=183330)[0m mae:  0.08661194145679474
[2m[36m(func pid=183330)[0m rmse_per_class: [0.057, 0.208, 0.027, 0.242, 0.066, 0.164, 0.22, 0.109, 0.136, 0.096]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 82] | Train loss: 0.2720 | Steps: 4 | Val loss: 0.2517 | Batch size: 32 | lr: 0.01 | Duration: 3.09s
== Status ==
Current time: 2024-01-07 17:12:12 (running for 00:48:09.83)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.273 |  0.133 |                   82 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13242708146572113
[2m[36m(func pid=183330)[0m mae:  0.08629491925239563
[2m[36m(func pid=183330)[0m rmse_per_class: [0.058, 0.216, 0.028, 0.235, 0.063, 0.164, 0.214, 0.107, 0.14, 0.098]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 83] | Train loss: 0.2569 | Steps: 4 | Val loss: 0.2528 | Batch size: 32 | lr: 0.01 | Duration: 3.22s
== Status ==
Current time: 2024-01-07 17:12:18 (running for 00:48:15.41)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.272 |  0.132 |                   83 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.1328246146440506
[2m[36m(func pid=183330)[0m mae:  0.08616376668214798
[2m[36m(func pid=183330)[0m rmse_per_class: [0.061, 0.218, 0.028, 0.233, 0.063, 0.164, 0.216, 0.11, 0.142, 0.093]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 84] | Train loss: 0.2835 | Steps: 4 | Val loss: 0.2556 | Batch size: 32 | lr: 0.01 | Duration: 3.04s
== Status ==
Current time: 2024-01-07 17:12:24 (running for 00:48:21.14)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.257 |  0.133 |                   84 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.1345990002155304
[2m[36m(func pid=183330)[0m mae:  0.08706916868686676
[2m[36m(func pid=183330)[0m rmse_per_class: [0.063, 0.218, 0.032, 0.234, 0.063, 0.164, 0.221, 0.109, 0.143, 0.099]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 85] | Train loss: 0.2728 | Steps: 4 | Val loss: 0.2571 | Batch size: 32 | lr: 0.01 | Duration: 3.12s
== Status ==
Current time: 2024-01-07 17:12:29 (running for 00:48:26.68)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.283 |  0.135 |                   85 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13581803441047668
[2m[36m(func pid=183330)[0m mae:  0.08818899095058441
[2m[36m(func pid=183330)[0m rmse_per_class: [0.062, 0.211, 0.033, 0.247, 0.065, 0.165, 0.222, 0.113, 0.138, 0.103]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 86] | Train loss: 0.2734 | Steps: 4 | Val loss: 0.2534 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 17:12:35 (running for 00:48:32.28)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.273 |  0.136 |                   86 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13286468386650085
[2m[36m(func pid=183330)[0m mae:  0.08634322136640549
[2m[36m(func pid=183330)[0m rmse_per_class: [0.058, 0.207, 0.032, 0.247, 0.061, 0.163, 0.216, 0.113, 0.134, 0.097]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 87] | Train loss: 0.2644 | Steps: 4 | Val loss: 0.2515 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 17:12:40 (running for 00:48:37.80)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.273 |  0.133 |                   87 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13163670897483826
[2m[36m(func pid=183330)[0m mae:  0.08548053354024887
[2m[36m(func pid=183330)[0m rmse_per_class: [0.059, 0.207, 0.032, 0.249, 0.057, 0.162, 0.21, 0.111, 0.135, 0.095]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 88] | Train loss: 0.2882 | Steps: 4 | Val loss: 0.2510 | Batch size: 32 | lr: 0.01 | Duration: 3.13s
== Status ==
Current time: 2024-01-07 17:12:46 (running for 00:48:43.22)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.264 |  0.132 |                   88 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13159246742725372
[2m[36m(func pid=183330)[0m mae:  0.08526692539453506
[2m[36m(func pid=183330)[0m rmse_per_class: [0.058, 0.209, 0.029, 0.246, 0.054, 0.161, 0.211, 0.113, 0.132, 0.102]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 89] | Train loss: 0.2709 | Steps: 4 | Val loss: 0.2525 | Batch size: 32 | lr: 0.01 | Duration: 3.17s
== Status ==
Current time: 2024-01-07 17:12:51 (running for 00:48:48.81)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.288 |  0.132 |                   89 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13283702731132507
[2m[36m(func pid=183330)[0m mae:  0.08619887381792068
[2m[36m(func pid=183330)[0m rmse_per_class: [0.062, 0.21, 0.033, 0.246, 0.055, 0.161, 0.215, 0.111, 0.132, 0.103]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 90] | Train loss: 0.2748 | Steps: 4 | Val loss: 0.2555 | Batch size: 32 | lr: 0.01 | Duration: 3.05s
== Status ==
Current time: 2024-01-07 17:12:57 (running for 00:48:54.43)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.271 |  0.133 |                   90 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.135599285364151
[2m[36m(func pid=183330)[0m mae:  0.08831600099802017
[2m[36m(func pid=183330)[0m rmse_per_class: [0.066, 0.211, 0.036, 0.25, 0.058, 0.165, 0.224, 0.108, 0.134, 0.104]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 91] | Train loss: 0.2685 | Steps: 4 | Val loss: 0.2590 | Batch size: 32 | lr: 0.01 | Duration: 3.07s
== Status ==
Current time: 2024-01-07 17:13:02 (running for 00:48:59.73)
Memory usage on this node: 16.6/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.275 |  0.136 |                   91 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13904857635498047
[2m[36m(func pid=183330)[0m mae:  0.09049882739782333
[2m[36m(func pid=183330)[0m rmse_per_class: [0.064, 0.217, 0.032, 0.252, 0.055, 0.168, 0.23, 0.107, 0.134, 0.131]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 92] | Train loss: 0.2678 | Steps: 4 | Val loss: 0.2570 | Batch size: 32 | lr: 0.01 | Duration: 2.86s
== Status ==
Current time: 2024-01-07 17:13:08 (running for 00:49:05.24)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.268 |  0.139 |                   92 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13725893199443817
[2m[36m(func pid=183330)[0m mae:  0.0889255478978157
[2m[36m(func pid=183330)[0m rmse_per_class: [0.061, 0.218, 0.033, 0.251, 0.057, 0.164, 0.215, 0.106, 0.136, 0.132]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 93] | Train loss: 0.2783 | Steps: 4 | Val loss: 0.2551 | Batch size: 32 | lr: 0.01 | Duration: 3.18s
== Status ==
Current time: 2024-01-07 17:13:13 (running for 00:49:10.54)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.268 |  0.137 |                   93 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13491618633270264
[2m[36m(func pid=183330)[0m mae:  0.08696728944778442
[2m[36m(func pid=183330)[0m rmse_per_class: [0.06, 0.214, 0.033, 0.255, 0.057, 0.161, 0.205, 0.106, 0.137, 0.122]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 94] | Train loss: 0.2505 | Steps: 4 | Val loss: 0.2527 | Batch size: 32 | lr: 0.01 | Duration: 2.95s
== Status ==
Current time: 2024-01-07 17:13:19 (running for 00:49:16.14)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.278 |  0.135 |                   94 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13217423856258392
[2m[36m(func pid=183330)[0m mae:  0.08568154275417328
[2m[36m(func pid=183330)[0m rmse_per_class: [0.058, 0.209, 0.033, 0.253, 0.058, 0.162, 0.208, 0.107, 0.136, 0.098]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 95] | Train loss: 0.2750 | Steps: 4 | Val loss: 0.2548 | Batch size: 32 | lr: 0.01 | Duration: 3.27s
== Status ==
Current time: 2024-01-07 17:13:24 (running for 00:49:21.55)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.251 |  0.132 |                   95 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.1339324414730072
[2m[36m(func pid=183330)[0m mae:  0.08676379919052124
[2m[36m(func pid=183330)[0m rmse_per_class: [0.061, 0.21, 0.032, 0.249, 0.059, 0.164, 0.218, 0.113, 0.138, 0.095]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 96] | Train loss: 0.2721 | Steps: 4 | Val loss: 0.2556 | Batch size: 32 | lr: 0.01 | Duration: 3.17s
== Status ==
Current time: 2024-01-07 17:13:30 (running for 00:49:27.17)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.275 |  0.134 |                   96 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13493090867996216
[2m[36m(func pid=183330)[0m mae:  0.0869804173707962
[2m[36m(func pid=183330)[0m rmse_per_class: [0.061, 0.212, 0.03, 0.241, 0.056, 0.163, 0.227, 0.117, 0.142, 0.101]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 97] | Train loss: 0.2617 | Steps: 4 | Val loss: 0.2554 | Batch size: 32 | lr: 0.01 | Duration: 2.98s
== Status ==
Current time: 2024-01-07 17:13:35 (running for 00:49:32.62)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.272 |  0.135 |                   97 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.1353224217891693
[2m[36m(func pid=183330)[0m mae:  0.08728072792291641
[2m[36m(func pid=183330)[0m rmse_per_class: [0.063, 0.216, 0.031, 0.236, 0.059, 0.163, 0.229, 0.113, 0.145, 0.1]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 98] | Train loss: 0.2795 | Steps: 4 | Val loss: 0.2527 | Batch size: 32 | lr: 0.01 | Duration: 2.91s
== Status ==
Current time: 2024-01-07 17:13:40 (running for 00:49:37.89)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.262 |  0.135 |                   98 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13342557847499847
[2m[36m(func pid=183330)[0m mae:  0.08573554456233978
[2m[36m(func pid=183330)[0m rmse_per_class: [0.06, 0.215, 0.03, 0.234, 0.058, 0.162, 0.221, 0.116, 0.138, 0.1]
[2m[36m(func pid=183330)[0m 
[2m[36m(func pid=183330)[0m [N0-GPU0] | [Epoch: 99] | Train loss: 0.2724 | Steps: 4 | Val loss: 0.2529 | Batch size: 32 | lr: 0.01 | Duration: 3.14s
== Status ==
Current time: 2024-01-07 17:13:46 (running for 00:49:43.48)
Memory usage on this node: 16.7/187.4 GiB 
Using AsyncHyperBand: num_stopped=23
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 4.0/72 CPUs, 1.0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (1 RUNNING, 23 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00022 | RUNNING    | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.279 |  0.133 |                   99 |
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
... 4 more trials not shown (4 TERMINATED)


[2m[36m(func pid=183330)[0m rmse: 0.13384591042995453
[2m[36m(func pid=183330)[0m mae:  0.0860791951417923
[2m[36m(func pid=183330)[0m rmse_per_class: [0.059, 0.209, 0.029, 0.239, 0.056, 0.162, 0.22, 0.115, 0.136, 0.113]
== Status ==
Current time: 2024-01-07 17:13:47 (running for 00:49:44.12)
Memory usage on this node: 16.3/187.4 GiB 
Using AsyncHyperBand: num_stopped=24
Bracket: Iter 75.000: -0.14674999937415123
Resources requested: 0/72 CPUs, 0/4 GPUs, 0.0/120.01 GiB heap, 0.0/55.42 GiB objects (0.0/1.0 accelerator_type:V100)
Result logdir: /home/ajsanchez/GitHub/ssl-bsu/output/finetuning/ray_tune/Supervised
Number of trials: 24/24 (24 TERMINATED)
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+
| Trial name        | status     | loc                 |     lr |   momentum |   weight_decay |   loss |   rmse |   training_iteration |
|-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------|
| train_c9cb4_00000 | TERMINATED | 192.168.7.53:77085  | 0.0001 |       0.99 |         0      |  0.395 |  0.162 |                   75 |
| train_c9cb4_00001 | TERMINATED | 192.168.7.53:77465  | 0.001  |       0.99 |         0      |  0.273 |  0.139 |                  100 |
| train_c9cb4_00002 | TERMINATED | 192.168.7.53:77888  | 0.01   |       0.99 |         0      |  0.306 |  0.154 |                   75 |
| train_c9cb4_00003 | TERMINATED | 192.168.7.53:78316  | 0.1    |       0.99 |         0      |  0.77  |  0.219 |                   75 |
| train_c9cb4_00004 | TERMINATED | 192.168.7.53:95877  | 0.0001 |       0.9  |         0      |  0.431 |  0.177 |                   75 |
| train_c9cb4_00005 | TERMINATED | 192.168.7.53:96425  | 0.001  |       0.9  |         0      |  0.37  |  0.16  |                   75 |
| train_c9cb4_00006 | TERMINATED | 192.168.7.53:97213  | 0.01   |       0.9  |         0      |  0.28  |  0.135 |                  100 |
| train_c9cb4_00007 | TERMINATED | 192.168.7.53:101872 | 0.1    |       0.9  |         0      |  0.269 |  0.16  |                   75 |
| train_c9cb4_00008 | TERMINATED | 192.168.7.53:114403 | 0.0001 |       0.99 |         0.0001 |  0.388 |  0.16  |                   75 |
| train_c9cb4_00009 | TERMINATED | 192.168.7.53:114490 | 0.001  |       0.99 |         0.0001 |  0.278 |  0.138 |                  100 |
| train_c9cb4_00010 | TERMINATED | 192.168.7.53:120822 | 0.01   |       0.99 |         0.0001 |  0.344 |  0.161 |                   75 |
| train_c9cb4_00011 | TERMINATED | 192.168.7.53:122557 | 0.1    |       0.99 |         0.0001 |  0.668 |  0.226 |                   75 |
| train_c9cb4_00012 | TERMINATED | 192.168.7.53:132449 | 0.0001 |       0.9  |         0.0001 |  0.427 |  0.177 |                   75 |
| train_c9cb4_00013 | TERMINATED | 192.168.7.53:139223 | 0.001  |       0.9  |         0.0001 |  0.368 |  0.16  |                   75 |
| train_c9cb4_00014 | TERMINATED | 192.168.7.53:140307 | 0.01   |       0.9  |         0.0001 |  0.266 |  0.131 |                  100 |
| train_c9cb4_00015 | TERMINATED | 192.168.7.53:141107 | 0.1    |       0.9  |         0.0001 |  0.254 |  0.147 |                   75 |
| train_c9cb4_00016 | TERMINATED | 192.168.7.53:150896 | 0.0001 |       0.99 |         1e-05  |  0.403 |  0.16  |                   75 |
| train_c9cb4_00017 | TERMINATED | 192.168.7.53:157909 | 0.001  |       0.99 |         1e-05  |  0.298 |  0.144 |                  100 |
| train_c9cb4_00018 | TERMINATED | 192.168.7.53:159237 | 0.01   |       0.99 |         1e-05  |  0.3   |  0.162 |                   75 |
| train_c9cb4_00019 | TERMINATED | 192.168.7.53:164825 | 0.1    |       0.99 |         1e-05  |  0.844 |  0.249 |                   75 |
| train_c9cb4_00020 | TERMINATED | 192.168.7.53:169620 | 0.0001 |       0.9  |         1e-05  |  0.428 |  0.176 |                   75 |
| train_c9cb4_00021 | TERMINATED | 192.168.7.53:177380 | 0.001  |       0.9  |         1e-05  |  0.37  |  0.16  |                   75 |
| train_c9cb4_00022 | TERMINATED | 192.168.7.53:183330 | 0.01   |       0.9  |         1e-05  |  0.272 |  0.134 |                  100 |
| train_c9cb4_00023 | TERMINATED | 192.168.7.53:183978 | 0.1    |       0.9  |         1e-05  |  0.249 |  0.149 |                   75 |
+-------------------+------------+---------------------+--------+------------+----------------+--------+--------+----------------------+


2024-01-07 17:13:47,032	INFO tune.py:798 -- Total run time: 2984.94 seconds (2984.10 seconds for the tuning loop).
srun: Job step aborted: Waiting up to 32 seconds for job step to finish.
slurmstepd: error: *** STEP 1341352.1 ON aap04 CANCELLED AT 2024-01-07T17:13:53 ***
srun: error: aap04: task 0: Exited with exit code 1
